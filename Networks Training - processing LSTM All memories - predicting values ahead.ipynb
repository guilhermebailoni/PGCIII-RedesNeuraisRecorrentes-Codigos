{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0333e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as kr\n",
    "\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "import supportFunctions as sf\n",
    "\n",
    "import inspect\n",
    "lines = inspect.getsource(sf.highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f60e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função utilizada para normalizar os dados de treino e validação\n",
    "def normalize_data(train, test):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    train_scaled = scaler.transform(train)\n",
    "    test_scaled = scaler.transform(test)\n",
    "    \n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "#função utilizada para desnormalizar os dados, no formato de entrada\n",
    "def denormalize_data(scaler,data):\n",
    "    result = scaler.inverse_transform(data)\n",
    "    return result\n",
    "\n",
    "#função utilizada para desnomalizar o valor predito\n",
    "def denormalize_prediction(scaler, dataX, dataY):\n",
    "    formatted_data = np.array(dataX)\n",
    "    formatted_data[:,3] = np.array(dataY)\n",
    "    \n",
    "    return denormalize_data(scaler,formatted_data)[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f62a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.12.0\n",
      "Keras Version: 2.12.0\n",
      "\n",
      "Python 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas 1.5.2\n",
      "Scikit-Learn 1.2.1\n",
      "WARNING:tensorflow:From C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_3700\\3882079960.py:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n",
    "# tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c84100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantos passos para trás os indicadores técnicos vão olhar\n",
    "ti_memory = 10\n",
    "\n",
    "#lendo os dados que serão utilizados para treinamento e validação\n",
    "ge1day = pd.read_csv('Data\\GE.csv')\n",
    "#removendo a coluna que indica a data\n",
    "ge1day = ge1day.drop(['Date'], axis = 1)\n",
    "\n",
    "df = ge1day\n",
    "#reseting the index\n",
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ca2794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\PythonCodes\\supportFunctions.py:263: RuntimeWarning: divide by zero encountered in divide\n",
      "  rs = ag_vector/al_vector #numpy arrays so therefore can use element wise division\n",
      "C:\\Users\\guilh\\PythonCodes\\supportFunctions.py:263: RuntimeWarning: invalid value encountered in divide\n",
      "  rs = ag_vector/al_vector #numpy arrays so therefore can use element wise division\n"
     ]
    }
   ],
   "source": [
    "#adicionando os parametros de indicadores tecnicos ao dataframe\n",
    "df[\"\"\"highest_{}\"\"\".format(ti_memory)] = sf.highest(df.Close,ti_memory)\n",
    "df[\"\"\"lowest_{}\"\"\".format(ti_memory)] = sf.lowest(df.Close,ti_memory)\n",
    "df[\"\"\"wma_{}\"\"\".format(ti_memory)] = sf.wma(df.Close,ti_memory)\n",
    "df[\"\"\"ema_{}\"\"\".format(ti_memory)] = sf.ema(df.Close,ti_memory)\n",
    "df[\"\"\"hma_{}\"\"\".format(ti_memory)] = sf.hma(df.Close,ti_memory)\n",
    "df[\"\"\"macd_12_26\"\"\"] = sf.macd(df.Close,12,26)\n",
    "df[\"\"\"rsi_{}\"\"\".format(ti_memory)] = sf.rsi(df.Close,ti_memory)\n",
    "df[\"\"\"dpo_{}\"\"\".format(ti_memory)] = sf.dpo(df.Close,ti_memory)\n",
    "\n",
    "#parametros nao utilizados:\n",
    "# df[\"\"\"sma_{}\"\"\".format(ti_memory)] = sf.sma(df.Close,ti_memory)\n",
    "# df[\"\"\"so_k_5\"\"\"] = sf.so_k(df.Close)\n",
    "# df[\"\"\"so_d_3\"\"\"] = sf.so_d(df.Close)\n",
    "# df[\"\"\"obv\"\"\".format(ti_memory)] = sf.obv(df.Close,df.Volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c08296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>highest_10</th>\n",
       "      <th>lowest_10</th>\n",
       "      <th>wma_10</th>\n",
       "      <th>ema_10</th>\n",
       "      <th>hma_10</th>\n",
       "      <th>macd_12_26</th>\n",
       "      <th>rsi_10</th>\n",
       "      <th>dpo_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.751202</td>\n",
       "      <td>0.763722</td>\n",
       "      <td>0.743690</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>2156500</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.744942</td>\n",
       "      <td>0.744942</td>\n",
       "      <td>0.738682</td>\n",
       "      <td>0.741186</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>1477600</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.741186</td>\n",
       "      <td>0.743690</td>\n",
       "      <td>0.744942</td>\n",
       "      <td>0.745359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.744942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741186</td>\n",
       "      <td>0.747446</td>\n",
       "      <td>0.726162</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>1837000</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.738056</td>\n",
       "      <td>0.740769</td>\n",
       "      <td>0.741708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.740769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.733674</td>\n",
       "      <td>0.701122</td>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>2725600</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.728290</td>\n",
       "      <td>0.733987</td>\n",
       "      <td>0.734112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.733987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.691106</td>\n",
       "      <td>0.712390</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>3095000</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.712390</td>\n",
       "      <td>0.722990</td>\n",
       "      <td>0.729667</td>\n",
       "      <td>0.727268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.729667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14658</th>\n",
       "      <td>7.630000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>7.510000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>123180900</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.062182</td>\n",
       "      <td>7.424700</td>\n",
       "      <td>7.239323</td>\n",
       "      <td>-1.116727</td>\n",
       "      <td>50.108961</td>\n",
       "      <td>-0.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14659</th>\n",
       "      <td>7.680000</td>\n",
       "      <td>7.870000</td>\n",
       "      <td>7.540000</td>\n",
       "      <td>7.620000</td>\n",
       "      <td>7.620000</td>\n",
       "      <td>93299000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.175091</td>\n",
       "      <td>7.460209</td>\n",
       "      <td>7.697586</td>\n",
       "      <td>-1.029444</td>\n",
       "      <td>40.027642</td>\n",
       "      <td>-0.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14660</th>\n",
       "      <td>7.540000</td>\n",
       "      <td>7.940000</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>7.890000</td>\n",
       "      <td>7.890000</td>\n",
       "      <td>86850200</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.341273</td>\n",
       "      <td>7.538353</td>\n",
       "      <td>8.019525</td>\n",
       "      <td>-0.927790</td>\n",
       "      <td>41.907705</td>\n",
       "      <td>-0.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14661</th>\n",
       "      <td>7.870000</td>\n",
       "      <td>8.180000</td>\n",
       "      <td>7.820000</td>\n",
       "      <td>7.940000</td>\n",
       "      <td>7.940000</td>\n",
       "      <td>121149900</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.494182</td>\n",
       "      <td>7.611380</td>\n",
       "      <td>8.165303</td>\n",
       "      <td>-0.833585</td>\n",
       "      <td>32.316173</td>\n",
       "      <td>-1.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14662</th>\n",
       "      <td>7.520000</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.040000</td>\n",
       "      <td>7.040000</td>\n",
       "      <td>99330200</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.467818</td>\n",
       "      <td>7.507492</td>\n",
       "      <td>7.971818</td>\n",
       "      <td>-0.822072</td>\n",
       "      <td>45.132949</td>\n",
       "      <td>-0.219000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14663 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open      High       Low     Close  Adj Close     Volume  \\\n",
       "0      0.751202  0.763722  0.743690  0.748698   0.001782    2156500   \n",
       "1      0.744942  0.744942  0.738682  0.741186   0.001764    1477600   \n",
       "2      0.741186  0.747446  0.726162  0.732422   0.001743    1837000   \n",
       "3      0.732422  0.733674  0.701122  0.713642   0.001698    2725600   \n",
       "4      0.713642  0.713642  0.691106  0.712390   0.001695    3095000   \n",
       "...         ...       ...       ...       ...        ...        ...   \n",
       "14658  7.630000  8.300000  7.510000  8.120000   8.120000  123180900   \n",
       "14659  7.680000  7.870000  7.540000  7.620000   7.620000   93299000   \n",
       "14660  7.540000  7.940000  7.350000  7.890000   7.890000   86850200   \n",
       "14661  7.870000  8.180000  7.820000  7.940000   7.940000  121149900   \n",
       "14662  7.520000  7.550000  7.000000  7.040000   7.040000   99330200   \n",
       "\n",
       "       highest_10  lowest_10    wma_10    ema_10    hma_10  macd_12_26  \\\n",
       "0        0.748698   0.748698  0.748698  0.748698  0.748698    0.000000   \n",
       "1        0.748698   0.741186  0.743690  0.744942  0.745359    0.000000   \n",
       "2        0.748698   0.732422  0.738056  0.740769  0.741708    0.000000   \n",
       "3        0.748698   0.713642  0.728290  0.733987  0.734112    0.000000   \n",
       "4        0.748698   0.712390  0.722990  0.729667  0.727268    0.000000   \n",
       "...           ...        ...       ...       ...       ...         ...   \n",
       "14658    8.120000   6.110000  7.062182  7.424700  7.239323   -1.116727   \n",
       "14659    8.120000   6.110000  7.175091  7.460209  7.697586   -1.029444   \n",
       "14660    8.120000   6.110000  7.341273  7.538353  8.019525   -0.927790   \n",
       "14661    8.120000   6.110000  7.494182  7.611380  8.165303   -0.833585   \n",
       "14662    8.120000   6.110000  7.467818  7.507492  7.971818   -0.822072   \n",
       "\n",
       "           rsi_10    dpo_10  \n",
       "0             NaN  0.000000  \n",
       "1      100.000000 -0.744942  \n",
       "2      100.000000 -0.740769  \n",
       "3      100.000000 -0.733987  \n",
       "4      100.000000 -0.729667  \n",
       "...           ...       ...  \n",
       "14658   50.108961 -0.399000  \n",
       "14659   40.027642 -0.496000  \n",
       "14660   41.907705 -0.579000  \n",
       "14661   32.316173 -1.075000  \n",
       "14662   45.132949 -0.219000  \n",
       "\n",
       "[14663 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7c3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jogando alguns dados fora para termos todas variaveis incializadas\n",
    "inicialization_steps = 30\n",
    "prediction_ahead = 10\n",
    "\n",
    "dataValues = df.values\n",
    "\n",
    "trainSize = int(len(dataValues)*0.8)\n",
    "testSize = len(dataValues) - trainSize\n",
    "\n",
    "train = df.head(trainSize)\n",
    "# train,minDataTrain,minMaxDataTrain = sf.normalizaTrain(train)\n",
    "test = df.tail(testSize)\n",
    "# test = sf.normalizaTest(test, minDataTrain, minMaxDataTrain)\n",
    "\n",
    "scaler, train_normalized, test_normalized = normalize_data(train, test)\n",
    "\n",
    "#deixando um valor de fora, para podermos prever o próximo valor quando for o último:\n",
    "trainX = train_normalized[inicialization_steps:(len(train)-prediction_ahead)]\n",
    "testX = test_normalized[0:(len(test)-prediction_ahead)]\n",
    "\n",
    "#normalizando as entradas\n",
    "# scalerX, trainX, testX = normalize_data(trainX, testX)\n",
    "\n",
    "#pegando apenas o valor que queremos prever\n",
    "trainY = train_normalized[(inicialization_steps+prediction_ahead):len(train),3]\n",
    "testY = test_normalized[prediction_ahead:len(test),3]\n",
    "\n",
    "#calculando a diferenca percentual do preco de fechamento entre um dia e outro\n",
    "# trainY = (train.values[(inicialization_steps+1):len(train),3]/trainX[:,3])-1\n",
    "# testY = (test.values[1:len(test),3]/testX[:,3])-1\n",
    "\n",
    "\n",
    "# scalerY, trainY, testY = normalize_data(trainY, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd9aebb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 14)\n",
      "(11690,)\n",
      "(2923, 14)\n",
      "(2923,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4aa933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if it makes sense\n",
    "# print(trainInputX[:10,(rnn_memory-1),3])\n",
    "# print(trainInputY[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a092eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11640, 50, 14)\n",
      "(11640,)\n",
      "(2873, 50, 14)\n",
      "(2873,)\n",
      "11690\n",
      "11640\n",
      "11690\n",
      "11640\n",
      "(11640, 50, 14)\n",
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 30ms/step - loss: 0.0444 - val_loss: 0.0032\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 7.1545e-04 - val_loss: 0.0039\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 5.5066e-04 - val_loss: 0.0049\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.8493e-04 - val_loss: 0.0045\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.3998e-04 - val_loss: 0.0044\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.0440e-04 - val_loss: 0.0040\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.8526e-04 - val_loss: 0.0034\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.6110e-04 - val_loss: 0.0031\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.4964e-04 - val_loss: 0.0027\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.3854e-04 - val_loss: 0.0022\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2921e-04 - val_loss: 0.0021\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2281e-04 - val_loss: 0.0022\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2000e-04 - val_loss: 0.0018\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1641e-04 - val_loss: 0.0016\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1520e-04 - val_loss: 0.0016\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1337e-04 - val_loss: 0.0014\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1157e-04 - val_loss: 0.0014\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0974e-04 - val_loss: 0.0010\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0550e-04 - val_loss: 0.0013\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0489e-04 - val_loss: 0.0010\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0257e-04 - val_loss: 0.0011\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0259e-04 - val_loss: 0.0011\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.0732e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1149e-04 - val_loss: 0.0011\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.0072e-04 - val_loss: 0.0015\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.1547e-04 - val_loss: 0.0010\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0727e-04 - val_loss: 7.1651e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9515e-04 - val_loss: 0.0011\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9939e-04 - val_loss: 5.9601e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0703e-04 - val_loss: 6.8769e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0144e-04 - val_loss: 9.2078e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9964e-04 - val_loss: 0.0011\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0787e-04 - val_loss: 8.3472e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9430e-04 - val_loss: 9.5402e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9846e-04 - val_loss: 5.4541e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9430e-04 - val_loss: 8.1794e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9378e-04 - val_loss: 6.3895e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8913e-04 - val_loss: 8.5784e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8928e-04 - val_loss: 7.7362e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.1540e-04 - val_loss: 0.0010\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9934e-04 - val_loss: 7.0556e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8995e-04 - val_loss: 9.8783e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9224e-04 - val_loss: 4.9672e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8867e-04 - val_loss: 7.0198e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8569e-04 - val_loss: 9.5173e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9397e-04 - val_loss: 6.5867e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8310e-04 - val_loss: 6.2292e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.8517e-04 - val_loss: 6.1866e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9063e-04 - val_loss: 5.4256e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8421e-04 - val_loss: 5.5012e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8439e-04 - val_loss: 5.5602e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.8369e-04 - val_loss: 7.1810e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8361e-04 - val_loss: 7.9831e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0525e-04 - val_loss: 4.8432e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1431e-04 - val_loss: 7.6683e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9900e-04 - val_loss: 4.9431e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8202e-04 - val_loss: 4.5836e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9132e-04 - val_loss: 5.1940e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7813e-04 - val_loss: 9.7462e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8540e-04 - val_loss: 6.3397e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8154e-04 - val_loss: 5.0670e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7865e-04 - val_loss: 6.9763e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7933e-04 - val_loss: 6.8313e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8014e-04 - val_loss: 9.3242e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8600e-04 - val_loss: 5.0390e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0105e-04 - val_loss: 4.8038e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8031e-04 - val_loss: 5.3008e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8161e-04 - val_loss: 5.8839e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7675e-04 - val_loss: 6.9767e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7621e-04 - val_loss: 5.8691e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7888e-04 - val_loss: 5.6554e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7662e-04 - val_loss: 4.8549e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7666e-04 - val_loss: 6.1050e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7694e-04 - val_loss: 7.1797e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8390e-04 - val_loss: 5.2678e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7646e-04 - val_loss: 5.5490e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7087e-04 - val_loss: 5.6574e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8591e-04 - val_loss: 4.5970e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8247e-04 - val_loss: 5.6600e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7802e-04 - val_loss: 5.2223e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7154e-04 - val_loss: 7.6403e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8072e-04 - val_loss: 6.2036e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9534e-04 - val_loss: 4.9152e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.7637e-04 - val_loss: 5.2047e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.6917e-04 - val_loss: 5.7749e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.7322e-04 - val_loss: 4.9193e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.8283e-04 - val_loss: 5.1490e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 29ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 7.5138e-04 - val_loss: 0.0020\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 4.4014e-04 - val_loss: 0.0015\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.8125e-04 - val_loss: 0.0013\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.5380e-04 - val_loss: 0.0014\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.4176e-04 - val_loss: 0.0011\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.3707e-04 - val_loss: 0.0018\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2067e-04 - val_loss: 0.0012\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.1594e-04 - val_loss: 0.0016\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2956e-04 - val_loss: 9.7880e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.1597e-04 - val_loss: 0.0012\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0107e-04 - val_loss: 0.0011\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.0009e-04 - val_loss: 0.0013\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.0321e-04 - val_loss: 0.0011\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9157e-04 - val_loss: 9.6815e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9378e-04 - val_loss: 0.0011\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9162e-04 - val_loss: 8.5997e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9592e-04 - val_loss: 8.7466e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9284e-04 - val_loss: 0.0011\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9495e-04 - val_loss: 0.0010\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9808e-04 - val_loss: 9.7892e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8633e-04 - val_loss: 9.7538e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8902e-04 - val_loss: 0.0010\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8367e-04 - val_loss: 0.0011\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7835e-04 - val_loss: 0.0010\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8655e-04 - val_loss: 0.0012\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7847e-04 - val_loss: 8.8456e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8255e-04 - val_loss: 0.0010\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8246e-04 - val_loss: 9.7947e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8228e-04 - val_loss: 0.0012\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7996e-04 - val_loss: 8.9625e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7701e-04 - val_loss: 0.0010\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.7917e-04 - val_loss: 7.1882e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.7780e-04 - val_loss: 7.7457e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.6650e-04 - val_loss: 9.8483e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.6944e-04 - val_loss: 9.3608e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6938e-04 - val_loss: 8.1853e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7488e-04 - val_loss: 0.0011\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7520e-04 - val_loss: 9.4996e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7326e-04 - val_loss: 8.0183e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6911e-04 - val_loss: 6.3902e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6549e-04 - val_loss: 9.5829e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7352e-04 - val_loss: 8.3742e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6452e-04 - val_loss: 7.3358e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6413e-04 - val_loss: 7.9225e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6596e-04 - val_loss: 8.2700e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6317e-04 - val_loss: 7.5409e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5754e-04 - val_loss: 7.6386e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6177e-04 - val_loss: 8.8292e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6474e-04 - val_loss: 8.2113e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6674e-04 - val_loss: 8.6490e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6238e-04 - val_loss: 0.0010\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7795e-04 - val_loss: 9.0320e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6221e-04 - val_loss: 8.2185e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6477e-04 - val_loss: 7.9903e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5435e-04 - val_loss: 8.1224e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5617e-04 - val_loss: 7.1509e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7992e-04 - val_loss: 0.0011\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8325e-04 - val_loss: 7.9816e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5541e-04 - val_loss: 9.4217e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5973e-04 - val_loss: 9.5441e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5732e-04 - val_loss: 8.5820e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8058e-04 - val_loss: 7.6376e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5222e-04 - val_loss: 7.8779e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5860e-04 - val_loss: 8.5839e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6826e-04 - val_loss: 0.0011\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5337e-04 - val_loss: 8.4847e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5953e-04 - val_loss: 7.2842e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6160e-04 - val_loss: 9.8868e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5998e-04 - val_loss: 8.7705e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5107e-04 - val_loss: 9.3875e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 27ms/step - loss: 0.0379 - val_loss: 0.0115\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 7.3375e-04 - val_loss: 0.0025\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 5.6890e-04 - val_loss: 0.0024\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.7878e-04 - val_loss: 0.0020\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.2365e-04 - val_loss: 0.0018\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.9314e-04 - val_loss: 0.0015\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.7250e-04 - val_loss: 0.0014\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.5462e-04 - val_loss: 0.0012\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.4161e-04 - val_loss: 0.0012\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.3142e-04 - val_loss: 0.0011\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.2409e-04 - val_loss: 9.9816e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2006e-04 - val_loss: 9.0742e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.1756e-04 - val_loss: 8.8106e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0821e-04 - val_loss: 8.2262e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0780e-04 - val_loss: 7.9082e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0997e-04 - val_loss: 7.7885e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0115e-04 - val_loss: 8.4804e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0161e-04 - val_loss: 6.7012e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0247e-04 - val_loss: 7.1799e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9968e-04 - val_loss: 7.2724e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9792e-04 - val_loss: 8.4070e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9260e-04 - val_loss: 7.4917e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9354e-04 - val_loss: 9.9955e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9342e-04 - val_loss: 7.0617e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0057e-04 - val_loss: 8.5306e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9029e-04 - val_loss: 8.4792e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8798e-04 - val_loss: 8.2638e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8699e-04 - val_loss: 7.8664e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8993e-04 - val_loss: 6.8227e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9558e-04 - val_loss: 7.5650e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8897e-04 - val_loss: 7.7065e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8506e-04 - val_loss: 8.4515e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9764e-04 - val_loss: 6.9520e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8857e-04 - val_loss: 7.0197e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9152e-04 - val_loss: 5.5911e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8775e-04 - val_loss: 7.0002e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8338e-04 - val_loss: 7.2637e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8444e-04 - val_loss: 6.5507e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8126e-04 - val_loss: 9.2681e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9574e-04 - val_loss: 8.6301e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8149e-04 - val_loss: 6.2846e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7891e-04 - val_loss: 7.9439e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8824e-04 - val_loss: 5.3142e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8174e-04 - val_loss: 4.7119e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8796e-04 - val_loss: 6.8451e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8558e-04 - val_loss: 5.8938e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8301e-04 - val_loss: 7.1055e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9386e-04 - val_loss: 5.5053e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9103e-04 - val_loss: 5.7422e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7833e-04 - val_loss: 5.8433e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7753e-04 - val_loss: 7.8739e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8687e-04 - val_loss: 5.8385e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8425e-04 - val_loss: 6.0759e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9879e-04 - val_loss: 7.4162e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7791e-04 - val_loss: 5.8651e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7328e-04 - val_loss: 5.7273e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7574e-04 - val_loss: 5.6708e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8664e-04 - val_loss: 5.9794e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7450e-04 - val_loss: 4.8306e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8024e-04 - val_loss: 8.0636e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7954e-04 - val_loss: 6.8059e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7775e-04 - val_loss: 5.6567e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7723e-04 - val_loss: 4.8706e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7785e-04 - val_loss: 5.6865e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7587e-04 - val_loss: 4.6054e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7824e-04 - val_loss: 5.1421e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7759e-04 - val_loss: 5.0567e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7414e-04 - val_loss: 5.1272e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7719e-04 - val_loss: 5.4713e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8119e-04 - val_loss: 4.9070e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6756e-04 - val_loss: 5.2633e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7243e-04 - val_loss: 5.0178e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7208e-04 - val_loss: 5.7433e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7744e-04 - val_loss: 5.0087e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7570e-04 - val_loss: 4.5247e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7568e-04 - val_loss: 5.4772e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6633e-04 - val_loss: 4.5836e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7043e-04 - val_loss: 5.3918e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6509e-04 - val_loss: 5.3481e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7932e-04 - val_loss: 4.8753e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8513e-04 - val_loss: 5.9706e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7778e-04 - val_loss: 7.0744e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9480e-04 - val_loss: 4.5474e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7539e-04 - val_loss: 9.3902e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8033e-04 - val_loss: 7.0561e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8485e-04 - val_loss: 4.6919e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7421e-04 - val_loss: 4.6670e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7977e-04 - val_loss: 4.4810e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5942e-04 - val_loss: 4.9539e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6328e-04 - val_loss: 4.7846e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6931e-04 - val_loss: 5.0079e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6867e-04 - val_loss: 5.6985e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6137e-04 - val_loss: 6.3396e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6424e-04 - val_loss: 4.9190e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5652e-04 - val_loss: 5.4532e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6084e-04 - val_loss: 4.6139e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6414e-04 - val_loss: 4.7641e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5981e-04 - val_loss: 5.0064e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6486e-04 - val_loss: 4.7798e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5580e-04 - val_loss: 5.2505e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5654e-04 - val_loss: 4.9999e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5916e-04 - val_loss: 4.9834e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5480e-04 - val_loss: 5.3465e-04\n",
      "Epoch 106/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5899e-04 - val_loss: 4.7276e-04\n",
      "Epoch 107/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5582e-04 - val_loss: 4.9164e-04\n",
      "Epoch 108/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6324e-04 - val_loss: 4.8925e-04\n",
      "Epoch 109/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5208e-04 - val_loss: 5.0558e-04\n",
      "Epoch 110/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5897e-04 - val_loss: 5.0346e-04\n",
      "Epoch 111/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7448e-04 - val_loss: 5.3930e-04\n",
      "Epoch 112/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5407e-04 - val_loss: 4.6345e-04\n",
      "Epoch 113/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5947e-04 - val_loss: 4.6500e-04\n",
      "Epoch 114/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5948e-04 - val_loss: 5.5383e-04\n",
      "Epoch 115/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5724e-04 - val_loss: 4.6274e-04\n",
      "Epoch 116/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5988e-04 - val_loss: 4.5987e-04\n",
      "Epoch 117/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5923e-04 - val_loss: 4.4702e-04\n",
      "Epoch 118/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5470e-04 - val_loss: 4.9645e-04\n",
      "Epoch 119/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5810e-04 - val_loss: 4.7114e-04\n",
      "Epoch 120/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5687e-04 - val_loss: 5.0182e-04\n",
      "Epoch 121/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8215e-04 - val_loss: 5.5433e-04\n",
      "Epoch 122/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6069e-04 - val_loss: 5.1221e-04\n",
      "Epoch 123/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6305e-04 - val_loss: 4.5828e-04\n",
      "Epoch 124/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5171e-04 - val_loss: 5.3079e-04\n",
      "Epoch 125/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.5161e-04 - val_loss: 5.5817e-04\n",
      "Epoch 126/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.5384e-04 - val_loss: 4.6589e-04\n",
      "Epoch 127/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5204e-04 - val_loss: 4.5992e-04\n",
      "Epoch 128/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6173e-04 - val_loss: 4.5333e-04\n",
      "Epoch 129/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5648e-04 - val_loss: 4.7030e-04\n",
      "Epoch 130/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4679e-04 - val_loss: 4.6259e-04\n",
      "Epoch 131/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.5534e-04 - val_loss: 4.4171e-04\n",
      "Epoch 132/2000\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 2.4641e-04 - val_loss: 4.9586e-04\n",
      "Epoch 133/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.5905e-04 - val_loss: 4.5359e-04\n",
      "Epoch 134/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.5441e-04 - val_loss: 4.4872e-04\n",
      "Epoch 135/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5454e-04 - val_loss: 4.8004e-04\n",
      "Epoch 136/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5716e-04 - val_loss: 4.7955e-04\n",
      "Epoch 137/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5217e-04 - val_loss: 4.6441e-04\n",
      "Epoch 138/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4728e-04 - val_loss: 4.6976e-04\n",
      "Epoch 139/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.4945e-04 - val_loss: 4.4827e-04\n",
      "Epoch 140/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4428e-04 - val_loss: 4.4374e-04\n",
      "Epoch 141/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4262e-04 - val_loss: 4.5793e-04\n",
      "Epoch 142/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.6392e-04 - val_loss: 4.8493e-04\n",
      "Epoch 143/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.4715e-04 - val_loss: 4.4653e-04\n",
      "Epoch 144/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.4143e-04 - val_loss: 4.5392e-04\n",
      "Epoch 145/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.5179e-04 - val_loss: 4.4544e-04\n",
      "Epoch 146/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.4537e-04 - val_loss: 4.7639e-04\n",
      "Epoch 147/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.4667e-04 - val_loss: 4.6277e-04\n",
      "Epoch 148/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.5597e-04 - val_loss: 5.2316e-04\n",
      "Epoch 149/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.4786e-04 - val_loss: 4.4090e-04\n",
      "Epoch 150/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6043e-04 - val_loss: 4.8057e-04\n",
      "Epoch 151/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4271e-04 - val_loss: 4.3861e-04\n",
      "Epoch 152/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4620e-04 - val_loss: 5.6396e-04\n",
      "Epoch 153/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.4725e-04 - val_loss: 4.5337e-04\n",
      "Epoch 154/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4691e-04 - val_loss: 4.2460e-04\n",
      "Epoch 155/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.4349e-04 - val_loss: 4.3912e-04\n",
      "Epoch 156/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4587e-04 - val_loss: 4.7761e-04\n",
      "Epoch 157/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.4693e-04 - val_loss: 4.5378e-04\n",
      "Epoch 158/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4874e-04 - val_loss: 4.2722e-04\n",
      "Epoch 159/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.4204e-04 - val_loss: 4.5169e-04\n",
      "Epoch 160/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.4512e-04 - val_loss: 4.6072e-04\n",
      "Epoch 161/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.4426e-04 - val_loss: 4.6947e-04\n",
      "Epoch 162/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.4175e-04 - val_loss: 4.5773e-04\n",
      "Epoch 163/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.3974e-04 - val_loss: 4.5682e-04\n",
      "Epoch 164/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4347e-04 - val_loss: 4.6410e-04\n",
      "Epoch 165/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4971e-04 - val_loss: 4.6622e-04\n",
      "Epoch 166/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4818e-04 - val_loss: 5.0069e-04\n",
      "Epoch 167/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.4225e-04 - val_loss: 4.5127e-04\n",
      "Epoch 168/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5154e-04 - val_loss: 4.8811e-04\n",
      "Epoch 169/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4491e-04 - val_loss: 4.7193e-04\n",
      "Epoch 170/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4136e-04 - val_loss: 4.5758e-04\n",
      "Epoch 171/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.3800e-04 - val_loss: 4.6102e-04\n",
      "Epoch 172/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4083e-04 - val_loss: 4.6024e-04\n",
      "Epoch 173/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.3989e-04 - val_loss: 4.6388e-04\n",
      "Epoch 174/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5332e-04 - val_loss: 4.5662e-04\n",
      "Epoch 175/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4337e-04 - val_loss: 5.6647e-04\n",
      "Epoch 176/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4054e-04 - val_loss: 5.0388e-04\n",
      "Epoch 177/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.3982e-04 - val_loss: 4.6932e-04\n",
      "Epoch 178/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4800e-04 - val_loss: 5.3622e-04\n",
      "Epoch 179/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4554e-04 - val_loss: 4.7912e-04\n",
      "Epoch 180/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.3762e-04 - val_loss: 4.8880e-04\n",
      "Epoch 181/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5239e-04 - val_loss: 6.4696e-04\n",
      "Epoch 182/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.5630e-04 - val_loss: 4.9573e-04\n",
      "Epoch 183/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4529e-04 - val_loss: 4.7359e-04\n",
      "Epoch 184/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.3663e-04 - val_loss: 4.9629e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 29ms/step - loss: 0.0515 - val_loss: 0.0148\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0022 - val_loss: 0.0235\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 0.0013 - val_loss: 0.0189\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 9.7450e-04 - val_loss: 0.0172\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 7.9227e-04 - val_loss: 0.0161\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 6.3731e-04 - val_loss: 0.0139\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 5.3765e-04 - val_loss: 0.0122\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 4.7572e-04 - val_loss: 0.0086\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 4.4253e-04 - val_loss: 0.0087\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 4.1751e-04 - val_loss: 0.0082\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.8616e-04 - val_loss: 0.0048\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.7007e-04 - val_loss: 0.0048\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.5048e-04 - val_loss: 0.0043\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3570e-04 - val_loss: 0.0034\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3487e-04 - val_loss: 0.0030\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1843e-04 - val_loss: 0.0031\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1193e-04 - val_loss: 0.0028\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0711e-04 - val_loss: 0.0027\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0050e-04 - val_loss: 0.0024\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9451e-04 - val_loss: 0.0016\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9846e-04 - val_loss: 0.0022\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9290e-04 - val_loss: 0.0016\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9560e-04 - val_loss: 0.0020\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8882e-04 - val_loss: 0.0019\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8354e-04 - val_loss: 0.0018\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8146e-04 - val_loss: 0.0014\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8121e-04 - val_loss: 0.0013\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8241e-04 - val_loss: 0.0014\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7795e-04 - val_loss: 0.0011\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8816e-04 - val_loss: 0.0012\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9424e-04 - val_loss: 0.0014\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8261e-04 - val_loss: 0.0013\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7489e-04 - val_loss: 0.0014\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7276e-04 - val_loss: 0.0013\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7759e-04 - val_loss: 0.0010\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8617e-04 - val_loss: 0.0013\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7804e-04 - val_loss: 0.0013\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7111e-04 - val_loss: 0.0012\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8004e-04 - val_loss: 0.0012\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8092e-04 - val_loss: 0.0010\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7569e-04 - val_loss: 0.0012\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7168e-04 - val_loss: 0.0015\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7668e-04 - val_loss: 7.7333e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7723e-04 - val_loss: 0.0011\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7592e-04 - val_loss: 0.0013\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7680e-04 - val_loss: 0.0014\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7736e-04 - val_loss: 0.0010\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6820e-04 - val_loss: 0.0012\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7616e-04 - val_loss: 0.0013\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7608e-04 - val_loss: 9.2669e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6708e-04 - val_loss: 0.0011\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7010e-04 - val_loss: 9.9002e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7169e-04 - val_loss: 0.0010\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8011e-04 - val_loss: 0.0016\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8900e-04 - val_loss: 0.0010\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6967e-04 - val_loss: 0.0012\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7433e-04 - val_loss: 9.2307e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6445e-04 - val_loss: 9.1002e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7332e-04 - val_loss: 0.0012\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6979e-04 - val_loss: 8.7620e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6937e-04 - val_loss: 9.6014e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6211e-04 - val_loss: 8.0441e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6513e-04 - val_loss: 9.8407e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6229e-04 - val_loss: 7.6418e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7023e-04 - val_loss: 0.0011\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7029e-04 - val_loss: 6.6355e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7743e-04 - val_loss: 0.0011\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7318e-04 - val_loss: 0.0011\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7222e-04 - val_loss: 0.0012\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7317e-04 - val_loss: 7.7119e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6433e-04 - val_loss: 8.9715e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6607e-04 - val_loss: 6.5223e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7685e-04 - val_loss: 0.0012\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6732e-04 - val_loss: 9.7717e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6639e-04 - val_loss: 0.0010\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6479e-04 - val_loss: 8.6086e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6161e-04 - val_loss: 8.9949e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6359e-04 - val_loss: 6.7088e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6394e-04 - val_loss: 7.6041e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6625e-04 - val_loss: 9.7398e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6335e-04 - val_loss: 8.1616e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6043e-04 - val_loss: 8.9427e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6138e-04 - val_loss: 8.8080e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5743e-04 - val_loss: 5.6928e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6093e-04 - val_loss: 9.2980e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6748e-04 - val_loss: 6.7764e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6364e-04 - val_loss: 6.3814e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6228e-04 - val_loss: 6.9672e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6963e-04 - val_loss: 8.8206e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6367e-04 - val_loss: 0.0012\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7998e-04 - val_loss: 8.6165e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6079e-04 - val_loss: 9.1205e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5651e-04 - val_loss: 0.0012\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6254e-04 - val_loss: 6.7830e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.6110e-04 - val_loss: 8.6980e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.5552e-04 - val_loss: 8.0217e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.5946e-04 - val_loss: 9.5843e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6119e-04 - val_loss: 6.0045e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6289e-04 - val_loss: 7.0710e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5598e-04 - val_loss: 5.2785e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6332e-04 - val_loss: 6.4138e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5455e-04 - val_loss: 9.4720e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5210e-04 - val_loss: 7.7640e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6172e-04 - val_loss: 7.3502e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6918e-04 - val_loss: 6.1824e-04\n",
      "Epoch 106/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5542e-04 - val_loss: 0.0012\n",
      "Epoch 107/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6302e-04 - val_loss: 7.6372e-04\n",
      "Epoch 108/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5002e-04 - val_loss: 9.4133e-04\n",
      "Epoch 109/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5678e-04 - val_loss: 6.7700e-04\n",
      "Epoch 110/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5243e-04 - val_loss: 7.0392e-04\n",
      "Epoch 111/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5930e-04 - val_loss: 6.8258e-04\n",
      "Epoch 112/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5034e-04 - val_loss: 8.4664e-04\n",
      "Epoch 113/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5263e-04 - val_loss: 8.7777e-04\n",
      "Epoch 114/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6012e-04 - val_loss: 5.3232e-04\n",
      "Epoch 115/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5499e-04 - val_loss: 7.1159e-04\n",
      "Epoch 116/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.4865e-04 - val_loss: 9.4439e-04\n",
      "Epoch 117/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6033e-04 - val_loss: 0.0012\n",
      "Epoch 118/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5966e-04 - val_loss: 8.2540e-04\n",
      "Epoch 119/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5491e-04 - val_loss: 8.9575e-04\n",
      "Epoch 120/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.4675e-04 - val_loss: 0.0012\n",
      "Epoch 121/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.4657e-04 - val_loss: 7.9687e-04\n",
      "Epoch 122/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.4493e-04 - val_loss: 6.6017e-04\n",
      "Epoch 123/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5401e-04 - val_loss: 8.2852e-04\n",
      "Epoch 124/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5728e-04 - val_loss: 7.0149e-04\n",
      "Epoch 125/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6281e-04 - val_loss: 9.7039e-04\n",
      "Epoch 126/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.4348e-04 - val_loss: 9.0388e-04\n",
      "Epoch 127/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.4556e-04 - val_loss: 0.0011\n",
      "Epoch 128/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5926e-04 - val_loss: 8.9090e-04\n",
      "Epoch 129/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5260e-04 - val_loss: 7.2765e-04\n",
      "Epoch 130/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.4579e-04 - val_loss: 9.4519e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 29ms/step - loss: 0.0440 - val_loss: 0.0261\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0017 - val_loss: 0.0137\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 9.9740e-04 - val_loss: 0.0084\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 7.3483e-04 - val_loss: 0.0064\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 5.8870e-04 - val_loss: 0.0037\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.9321e-04 - val_loss: 0.0028\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 4.2345e-04 - val_loss: 0.0019\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 3.7056e-04 - val_loss: 0.0020\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 3.4522e-04 - val_loss: 0.0019\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 3.3504e-04 - val_loss: 0.0018\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.2619e-04 - val_loss: 0.0014\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2093e-04 - val_loss: 0.0013\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1360e-04 - val_loss: 0.0012\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1379e-04 - val_loss: 0.0013\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0926e-04 - val_loss: 0.0012\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0957e-04 - val_loss: 0.0012\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0595e-04 - val_loss: 0.0011\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1151e-04 - val_loss: 9.9223e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0125e-04 - val_loss: 9.9746e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0028e-04 - val_loss: 9.9318e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9899e-04 - val_loss: 9.3510e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9800e-04 - val_loss: 9.2468e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9556e-04 - val_loss: 8.6616e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9414e-04 - val_loss: 8.5480e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9303e-04 - val_loss: 8.1999e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9176e-04 - val_loss: 8.2586e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0113e-04 - val_loss: 8.3640e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9208e-04 - val_loss: 8.4963e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9105e-04 - val_loss: 7.7373e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8638e-04 - val_loss: 7.5325e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9509e-04 - val_loss: 8.1502e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8908e-04 - val_loss: 7.7687e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9219e-04 - val_loss: 7.2341e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9458e-04 - val_loss: 7.6431e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8723e-04 - val_loss: 8.1671e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8407e-04 - val_loss: 7.5118e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8452e-04 - val_loss: 7.4700e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8858e-04 - val_loss: 7.2142e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8261e-04 - val_loss: 7.8972e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8308e-04 - val_loss: 8.2757e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7926e-04 - val_loss: 7.1292e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8902e-04 - val_loss: 6.9760e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9353e-04 - val_loss: 7.2766e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8317e-04 - val_loss: 6.9396e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8041e-04 - val_loss: 7.2046e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7660e-04 - val_loss: 7.2396e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8862e-04 - val_loss: 7.2082e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7910e-04 - val_loss: 6.9823e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7856e-04 - val_loss: 6.7037e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8797e-04 - val_loss: 6.7907e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8517e-04 - val_loss: 9.9072e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9588e-04 - val_loss: 6.8733e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8043e-04 - val_loss: 6.8792e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8388e-04 - val_loss: 7.1128e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7611e-04 - val_loss: 6.5327e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8359e-04 - val_loss: 6.4116e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7479e-04 - val_loss: 7.0276e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7816e-04 - val_loss: 6.9284e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7408e-04 - val_loss: 7.0378e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7633e-04 - val_loss: 7.4764e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7920e-04 - val_loss: 6.5759e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8376e-04 - val_loss: 8.1239e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8991e-04 - val_loss: 6.6916e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8177e-04 - val_loss: 7.1850e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7486e-04 - val_loss: 6.4668e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8338e-04 - val_loss: 6.8566e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7384e-04 - val_loss: 7.2214e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9097e-04 - val_loss: 6.8641e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8070e-04 - val_loss: 7.0420e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7948e-04 - val_loss: 6.3114e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7400e-04 - val_loss: 7.7827e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7265e-04 - val_loss: 6.2952e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7710e-04 - val_loss: 8.0167e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8413e-04 - val_loss: 7.1100e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6888e-04 - val_loss: 6.5455e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6618e-04 - val_loss: 6.6940e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6648e-04 - val_loss: 7.0878e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7594e-04 - val_loss: 6.9168e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6759e-04 - val_loss: 6.6652e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6537e-04 - val_loss: 6.3552e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6546e-04 - val_loss: 7.3771e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6534e-04 - val_loss: 6.6499e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6844e-04 - val_loss: 6.5372e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7773e-04 - val_loss: 6.3777e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6801e-04 - val_loss: 6.5675e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6854e-04 - val_loss: 6.6231e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7095e-04 - val_loss: 6.6650e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6358e-04 - val_loss: 6.2949e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6143e-04 - val_loss: 6.2847e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.7522e-04 - val_loss: 6.1040e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.6827e-04 - val_loss: 6.2992e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6806e-04 - val_loss: 7.6198e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8612e-04 - val_loss: 6.6937e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6588e-04 - val_loss: 7.6245e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8046e-04 - val_loss: 6.2901e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7256e-04 - val_loss: 6.6222e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.6782e-04 - val_loss: 5.6638e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6717e-04 - val_loss: 6.4553e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7087e-04 - val_loss: 5.8734e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6528e-04 - val_loss: 6.5470e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7305e-04 - val_loss: 6.1062e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.6223e-04 - val_loss: 5.8470e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6155e-04 - val_loss: 6.2686e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6176e-04 - val_loss: 5.7736e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6029e-04 - val_loss: 6.5008e-04\n",
      "Epoch 106/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6152e-04 - val_loss: 6.6769e-04\n",
      "Epoch 107/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.7352e-04 - val_loss: 6.1092e-04\n",
      "Epoch 108/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.6453e-04 - val_loss: 6.3096e-04\n",
      "Epoch 109/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6113e-04 - val_loss: 6.1196e-04\n",
      "Epoch 110/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6197e-04 - val_loss: 6.0764e-04\n",
      "Epoch 111/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5635e-04 - val_loss: 5.9830e-04\n",
      "Epoch 112/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6216e-04 - val_loss: 5.9356e-04\n",
      "Epoch 113/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6179e-04 - val_loss: 6.0202e-04\n",
      "Epoch 114/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5455e-04 - val_loss: 6.2362e-04\n",
      "Epoch 115/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6508e-04 - val_loss: 7.0978e-04\n",
      "Epoch 116/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7139e-04 - val_loss: 6.0030e-04\n",
      "Epoch 117/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6843e-04 - val_loss: 5.8727e-04\n",
      "Epoch 118/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5881e-04 - val_loss: 6.6289e-04\n",
      "Epoch 119/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5528e-04 - val_loss: 5.8981e-04\n",
      "Epoch 120/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6058e-04 - val_loss: 5.8092e-04\n",
      "Epoch 121/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5844e-04 - val_loss: 6.0264e-04\n",
      "Epoch 122/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5742e-04 - val_loss: 6.4441e-04\n",
      "Epoch 123/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5736e-04 - val_loss: 5.9913e-04\n",
      "Epoch 124/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5973e-04 - val_loss: 6.0986e-04\n",
      "Epoch 125/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5671e-04 - val_loss: 5.8653e-04\n",
      "Epoch 126/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6954e-04 - val_loss: 6.4856e-04\n",
      "Epoch 127/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5480e-04 - val_loss: 5.9161e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 29ms/step - loss: 0.0203 - val_loss: 0.0033\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 6.6967e-04\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.7129e-04 - val_loss: 5.4628e-04\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3566e-04 - val_loss: 5.9355e-04\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2229e-04 - val_loss: 5.5722e-04\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1407e-04 - val_loss: 5.3545e-04\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1031e-04 - val_loss: 5.3589e-04\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0156e-04 - val_loss: 5.9839e-04\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0202e-04 - val_loss: 5.8033e-04\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9608e-04 - val_loss: 5.7969e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9315e-04 - val_loss: 6.3968e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9556e-04 - val_loss: 5.8813e-04\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9586e-04 - val_loss: 5.8239e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8748e-04 - val_loss: 6.1314e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8328e-04 - val_loss: 6.0409e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8793e-04 - val_loss: 6.3491e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9211e-04 - val_loss: 6.4905e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9347e-04 - val_loss: 6.3542e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8004e-04 - val_loss: 6.4578e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8476e-04 - val_loss: 6.5972e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8209e-04 - val_loss: 6.7677e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8132e-04 - val_loss: 6.7650e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8184e-04 - val_loss: 6.8978e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9483e-04 - val_loss: 7.1149e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8697e-04 - val_loss: 6.7580e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8026e-04 - val_loss: 6.9383e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7743e-04 - val_loss: 7.2772e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7664e-04 - val_loss: 7.1282e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8258e-04 - val_loss: 7.2560e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9042e-04 - val_loss: 7.1132e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8570e-04 - val_loss: 6.7691e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7800e-04 - val_loss: 7.1745e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7587e-04 - val_loss: 7.4030e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7562e-04 - val_loss: 7.4490e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8672e-04 - val_loss: 7.1662e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8242e-04 - val_loss: 7.4794e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 30ms/step - loss: 0.0336 - val_loss: 0.0260\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0015 - val_loss: 0.0114\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 9.7118e-04 - val_loss: 0.0104\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 8.0739e-04 - val_loss: 0.0076\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 6.8708e-04 - val_loss: 0.0059\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 5.8803e-04 - val_loss: 0.0056\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 4.9669e-04 - val_loss: 0.0052\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 4.4245e-04 - val_loss: 0.0052\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.2538e-04 - val_loss: 0.0041\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.9708e-04 - val_loss: 0.0034\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.8448e-04 - val_loss: 0.0033\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.7392e-04 - val_loss: 0.0033\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.8710e-04 - val_loss: 0.0031\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.5387e-04 - val_loss: 0.0026\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.4454e-04 - val_loss: 0.0026\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.4013e-04 - val_loss: 0.0023\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3035e-04 - val_loss: 0.0019\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3896e-04 - val_loss: 0.0020\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2010e-04 - val_loss: 0.0013\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2558e-04 - val_loss: 0.0013\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1009e-04 - val_loss: 0.0013\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2505e-04 - val_loss: 0.0014\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1014e-04 - val_loss: 0.0011\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0839e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0412e-04 - val_loss: 0.0012\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0030e-04 - val_loss: 6.8375e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0801e-04 - val_loss: 6.6116e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0834e-04 - val_loss: 6.5681e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9973e-04 - val_loss: 9.0979e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9464e-04 - val_loss: 7.3582e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9187e-04 - val_loss: 6.8517e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9244e-04 - val_loss: 7.2616e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9437e-04 - val_loss: 7.6141e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9118e-04 - val_loss: 8.5893e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0118e-04 - val_loss: 0.0011\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9760e-04 - val_loss: 7.0435e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8682e-04 - val_loss: 7.5014e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8780e-04 - val_loss: 8.3944e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9123e-04 - val_loss: 5.7875e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8906e-04 - val_loss: 6.9919e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8376e-04 - val_loss: 6.3333e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8583e-04 - val_loss: 5.7620e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8941e-04 - val_loss: 5.5449e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8680e-04 - val_loss: 6.6132e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8092e-04 - val_loss: 5.3207e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9491e-04 - val_loss: 5.9597e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9450e-04 - val_loss: 6.5845e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8813e-04 - val_loss: 5.5451e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8820e-04 - val_loss: 7.9898e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7815e-04 - val_loss: 5.9617e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9060e-04 - val_loss: 5.7385e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9550e-04 - val_loss: 6.4731e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.7680e-04 - val_loss: 7.1886e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8838e-04 - val_loss: 6.6657e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.7705e-04 - val_loss: 5.9055e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8399e-04 - val_loss: 7.0888e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8540e-04 - val_loss: 6.9465e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8303e-04 - val_loss: 5.7889e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8797e-04 - val_loss: 8.5606e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8077e-04 - val_loss: 7.0967e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7915e-04 - val_loss: 5.2359e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7660e-04 - val_loss: 5.6245e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9029e-04 - val_loss: 5.7223e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7376e-04 - val_loss: 5.3513e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7202e-04 - val_loss: 6.5533e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7118e-04 - val_loss: 6.0522e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7612e-04 - val_loss: 7.2124e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7457e-04 - val_loss: 5.8856e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7804e-04 - val_loss: 5.6791e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7384e-04 - val_loss: 5.7202e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7613e-04 - val_loss: 5.9368e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7397e-04 - val_loss: 6.0276e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7221e-04 - val_loss: 6.1262e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8512e-04 - val_loss: 6.3165e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7812e-04 - val_loss: 5.1432e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7609e-04 - val_loss: 5.4830e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6760e-04 - val_loss: 5.6822e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8265e-04 - val_loss: 5.4173e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7581e-04 - val_loss: 5.6679e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7120e-04 - val_loss: 6.1610e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6703e-04 - val_loss: 5.8378e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6370e-04 - val_loss: 6.0572e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8469e-04 - val_loss: 5.9770e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6627e-04 - val_loss: 6.9146e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7714e-04 - val_loss: 5.7082e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7413e-04 - val_loss: 6.0648e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7395e-04 - val_loss: 6.1228e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8586e-04 - val_loss: 5.4901e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8252e-04 - val_loss: 5.3384e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6733e-04 - val_loss: 5.2720e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6412e-04 - val_loss: 6.6017e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6433e-04 - val_loss: 5.5550e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7137e-04 - val_loss: 7.6378e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8728e-04 - val_loss: 7.3726e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7777e-04 - val_loss: 5.5098e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6594e-04 - val_loss: 5.6492e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6152e-04 - val_loss: 5.7504e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6336e-04 - val_loss: 5.8724e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7051e-04 - val_loss: 6.4342e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6840e-04 - val_loss: 7.4176e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6935e-04 - val_loss: 7.4467e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6332e-04 - val_loss: 6.4839e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6416e-04 - val_loss: 7.8267e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7463e-04 - val_loss: 6.2439e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7579e-04 - val_loss: 5.5776e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 27ms/step - loss: 0.0061 - val_loss: 0.0017\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 7.3100e-04 - val_loss: 0.0036\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 4.2846e-04 - val_loss: 0.0043\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.7163e-04 - val_loss: 0.0045\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.4652e-04 - val_loss: 0.0041\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3022e-04 - val_loss: 0.0037\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2744e-04 - val_loss: 0.0039\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2416e-04 - val_loss: 0.0032\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1744e-04 - val_loss: 0.0019\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2068e-04 - val_loss: 0.0023\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1043e-04 - val_loss: 0.0024\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1001e-04 - val_loss: 0.0018\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0128e-04 - val_loss: 0.0018\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9677e-04 - val_loss: 0.0018\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9477e-04 - val_loss: 0.0023\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9252e-04 - val_loss: 0.0011\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0452e-04 - val_loss: 0.0013\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9238e-04 - val_loss: 0.0013\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8705e-04 - val_loss: 0.0015\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8381e-04 - val_loss: 0.0012\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8178e-04 - val_loss: 0.0014\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8910e-04 - val_loss: 0.0012\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8753e-04 - val_loss: 0.0011\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7877e-04 - val_loss: 0.0011\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8628e-04 - val_loss: 7.5704e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7507e-04 - val_loss: 8.0864e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7870e-04 - val_loss: 8.5286e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8767e-04 - val_loss: 9.2611e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7941e-04 - val_loss: 8.8980e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7598e-04 - val_loss: 0.0010\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7961e-04 - val_loss: 8.4801e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8420e-04 - val_loss: 0.0010\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8560e-04 - val_loss: 7.5899e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6688e-04 - val_loss: 7.6774e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7387e-04 - val_loss: 7.9198e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7926e-04 - val_loss: 7.3596e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8008e-04 - val_loss: 8.1367e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.8904e-04 - val_loss: 7.2333e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.6696e-04 - val_loss: 7.7640e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.6659e-04 - val_loss: 7.3005e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7117e-04 - val_loss: 7.0618e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7067e-04 - val_loss: 7.7469e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7196e-04 - val_loss: 7.3670e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8108e-04 - val_loss: 8.1675e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6516e-04 - val_loss: 7.8091e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6652e-04 - val_loss: 7.6093e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7319e-04 - val_loss: 7.2555e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6627e-04 - val_loss: 8.0755e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7426e-04 - val_loss: 7.3481e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7340e-04 - val_loss: 7.1625e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5739e-04 - val_loss: 7.9319e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7709e-04 - val_loss: 7.6739e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6777e-04 - val_loss: 7.2011e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5828e-04 - val_loss: 7.7821e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7068e-04 - val_loss: 8.0157e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6268e-04 - val_loss: 7.9695e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5774e-04 - val_loss: 8.4712e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7079e-04 - val_loss: 9.9873e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8872e-04 - val_loss: 8.2311e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7023e-04 - val_loss: 8.1790e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5521e-04 - val_loss: 7.0889e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6549e-04 - val_loss: 8.6657e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6206e-04 - val_loss: 7.7768e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5249e-04 - val_loss: 7.7146e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.6554e-04 - val_loss: 8.2894e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.6187e-04 - val_loss: 7.4104e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.5960e-04 - val_loss: 0.0012\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6804e-04 - val_loss: 7.8563e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5270e-04 - val_loss: 8.7383e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6256e-04 - val_loss: 7.7033e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.5168e-04 - val_loss: 8.0103e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_15_layer_call_fn, lstm_cell_15_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 26ms/step - loss: 0.0130 - val_loss: 0.0022\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 8.5409e-04 - val_loss: 0.0014\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 5.3219e-04 - val_loss: 8.3817e-04\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.1763e-04 - val_loss: 5.0417e-04\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.6049e-04 - val_loss: 7.2112e-04\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.4578e-04 - val_loss: 8.5414e-04\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.4599e-04 - val_loss: 7.9259e-04\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3015e-04 - val_loss: 6.4921e-04\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.4400e-04 - val_loss: 5.7810e-04\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2050e-04 - val_loss: 6.3452e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1823e-04 - val_loss: 6.6947e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.4901e-04 - val_loss: 5.6454e-04\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1032e-04 - val_loss: 6.4346e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0989e-04 - val_loss: 5.3255e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0643e-04 - val_loss: 5.5882e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0641e-04 - val_loss: 7.4326e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0289e-04 - val_loss: 6.4731e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0325e-04 - val_loss: 6.6851e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0360e-04 - val_loss: 6.5113e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0152e-04 - val_loss: 6.0171e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0158e-04 - val_loss: 7.2047e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9690e-04 - val_loss: 4.6919e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9330e-04 - val_loss: 7.5825e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1003e-04 - val_loss: 4.7482e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0144e-04 - val_loss: 4.5381e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0990e-04 - val_loss: 5.5282e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9621e-04 - val_loss: 9.6382e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8960e-04 - val_loss: 6.6636e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9226e-04 - val_loss: 6.0021e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9688e-04 - val_loss: 4.5080e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9725e-04 - val_loss: 5.5769e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8326e-04 - val_loss: 8.0594e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9696e-04 - val_loss: 7.3608e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8613e-04 - val_loss: 5.8821e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8904e-04 - val_loss: 5.9531e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8232e-04 - val_loss: 5.6203e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9322e-04 - val_loss: 4.7191e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8180e-04 - val_loss: 5.6808e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7838e-04 - val_loss: 7.6416e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9551e-04 - val_loss: 6.2262e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8742e-04 - val_loss: 4.8719e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7993e-04 - val_loss: 6.7567e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8797e-04 - val_loss: 5.2782e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8036e-04 - val_loss: 5.7302e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7694e-04 - val_loss: 7.7062e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8857e-04 - val_loss: 6.1684e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8117e-04 - val_loss: 4.9408e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7497e-04 - val_loss: 5.7314e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7509e-04 - val_loss: 4.9925e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1317e-04 - val_loss: 5.2472e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7512e-04 - val_loss: 6.8789e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7244e-04 - val_loss: 5.6422e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7394e-04 - val_loss: 8.0296e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7245e-04 - val_loss: 7.9185e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7689e-04 - val_loss: 5.5047e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7097e-04 - val_loss: 7.9836e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7868e-04 - val_loss: 5.5804e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6553e-04 - val_loss: 5.5775e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6749e-04 - val_loss: 6.0372e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7126e-04 - val_loss: 5.6486e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 30ms/step - loss: 0.0190 - val_loss: 0.0032\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 5.9521e-04 - val_loss: 7.1661e-04\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.7457e-04 - val_loss: 8.0769e-04\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.0662e-04 - val_loss: 0.0013\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.7846e-04 - val_loss: 0.0011\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.3471e-04 - val_loss: 0.0012\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2279e-04 - val_loss: 0.0013\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2217e-04 - val_loss: 0.0015\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1247e-04 - val_loss: 0.0015\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1688e-04 - val_loss: 0.0014\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0585e-04 - val_loss: 0.0016\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0873e-04 - val_loss: 0.0015\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0596e-04 - val_loss: 0.0015\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9842e-04 - val_loss: 0.0016\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0316e-04 - val_loss: 0.0014\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0342e-04 - val_loss: 0.0014\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9606e-04 - val_loss: 0.0014\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9449e-04 - val_loss: 0.0014\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.8852e-04 - val_loss: 0.0014\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.9017e-04 - val_loss: 0.0014\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.9378e-04 - val_loss: 0.0014\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.9185e-04 - val_loss: 0.0013\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.8967e-04 - val_loss: 0.0014\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.9170e-04 - val_loss: 0.0014\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8708e-04 - val_loss: 0.0014\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8669e-04 - val_loss: 0.0014\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8630e-04 - val_loss: 0.0012\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8397e-04 - val_loss: 0.0013\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9476e-04 - val_loss: 0.0014\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8796e-04 - val_loss: 0.0013\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8559e-04 - val_loss: 0.0013\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1442e-04 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 3s 26ms/step - loss: 0.0162 - val_loss: 0.0024\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0012 - val_loss: 7.5063e-04\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 5.4691e-04 - val_loss: 5.6124e-04\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.0442e-04 - val_loss: 6.5970e-04\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.5880e-04 - val_loss: 7.6220e-04\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.4030e-04 - val_loss: 8.0622e-04\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.3079e-04 - val_loss: 7.8417e-04\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2341e-04 - val_loss: 7.4701e-04\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2004e-04 - val_loss: 0.0011\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1432e-04 - val_loss: 9.1662e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0948e-04 - val_loss: 7.7559e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1369e-04 - val_loss: 8.2768e-04\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1467e-04 - val_loss: 7.9917e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0338e-04 - val_loss: 0.0011\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0550e-04 - val_loss: 0.0010\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9887e-04 - val_loss: 9.8272e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9405e-04 - val_loss: 0.0014\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9297e-04 - val_loss: 9.5699e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9125e-04 - val_loss: 0.0012\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9116e-04 - val_loss: 8.5602e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8978e-04 - val_loss: 0.0012\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8940e-04 - val_loss: 9.5451e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9207e-04 - val_loss: 0.0011\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9276e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9047e-04 - val_loss: 7.0462e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0048e-04 - val_loss: 0.0012\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9018e-04 - val_loss: 9.3494e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8391e-04 - val_loss: 9.5907e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8513e-04 - val_loss: 8.7362e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8869e-04 - val_loss: 9.4782e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9117e-04 - val_loss: 0.0010\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 2.8149e-04 - val_loss: 9.6605e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.8394e-04 - val_loss: 8.7124e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses, lstm_cell_21_layer_call_fn, lstm_cell_21_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 32ms/step - loss: 0.0805 - val_loss: 0.0057\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 6.3684e-04 - val_loss: 0.0012\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.0419e-04 - val_loss: 0.0013\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 3.5016e-04 - val_loss: 0.0013\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.3008e-04 - val_loss: 0.0016\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2038e-04 - val_loss: 0.0014\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1289e-04 - val_loss: 0.0015\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1086e-04 - val_loss: 0.0015\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0474e-04 - val_loss: 0.0014\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0223e-04 - val_loss: 0.0013\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0631e-04 - val_loss: 0.0013\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9327e-04 - val_loss: 0.0011\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9674e-04 - val_loss: 0.0011\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9043e-04 - val_loss: 0.0013\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8982e-04 - val_loss: 0.0011\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8790e-04 - val_loss: 9.7015e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8952e-04 - val_loss: 0.0012\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8734e-04 - val_loss: 0.0010\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8631e-04 - val_loss: 0.0013\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8892e-04 - val_loss: 0.0012\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8583e-04 - val_loss: 0.0011\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8599e-04 - val_loss: 9.8444e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.8818e-04 - val_loss: 0.0012\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8631e-04 - val_loss: 9.5000e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8216e-04 - val_loss: 0.0011\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8858e-04 - val_loss: 7.9166e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8139e-04 - val_loss: 0.0011\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9184e-04 - val_loss: 0.0012\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9016e-04 - val_loss: 6.2231e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8192e-04 - val_loss: 6.8919e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8493e-04 - val_loss: 8.8259e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8861e-04 - val_loss: 0.0011\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8394e-04 - val_loss: 6.8327e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7678e-04 - val_loss: 8.5763e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7871e-04 - val_loss: 7.6709e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7626e-04 - val_loss: 9.3976e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7738e-04 - val_loss: 7.6705e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7932e-04 - val_loss: 8.2055e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7593e-04 - val_loss: 6.9342e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7752e-04 - val_loss: 7.8944e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7799e-04 - val_loss: 7.4099e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7292e-04 - val_loss: 7.4228e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8406e-04 - val_loss: 5.9746e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8189e-04 - val_loss: 8.8002e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8584e-04 - val_loss: 8.4774e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7784e-04 - val_loss: 8.6780e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7719e-04 - val_loss: 7.7810e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8135e-04 - val_loss: 6.9389e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7550e-04 - val_loss: 7.8269e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8205e-04 - val_loss: 7.6794e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8420e-04 - val_loss: 7.2867e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8061e-04 - val_loss: 6.5491e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7608e-04 - val_loss: 7.6930e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8130e-04 - val_loss: 8.1037e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8109e-04 - val_loss: 7.0360e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7223e-04 - val_loss: 6.4079e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7515e-04 - val_loss: 6.3838e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6950e-04 - val_loss: 7.3644e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7329e-04 - val_loss: 5.6130e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7538e-04 - val_loss: 6.8403e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7689e-04 - val_loss: 5.6532e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7687e-04 - val_loss: 5.4144e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7434e-04 - val_loss: 6.6661e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7010e-04 - val_loss: 5.5096e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7438e-04 - val_loss: 6.9255e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7471e-04 - val_loss: 7.5399e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8208e-04 - val_loss: 5.9767e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7192e-04 - val_loss: 5.6120e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7188e-04 - val_loss: 7.0031e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7568e-04 - val_loss: 6.6298e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6756e-04 - val_loss: 5.9462e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6948e-04 - val_loss: 5.8650e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7804e-04 - val_loss: 6.7557e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7406e-04 - val_loss: 5.5680e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7364e-04 - val_loss: 5.9891e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7346e-04 - val_loss: 4.7488e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7086e-04 - val_loss: 7.1600e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6867e-04 - val_loss: 7.0336e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7262e-04 - val_loss: 7.8668e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7342e-04 - val_loss: 6.2979e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7707e-04 - val_loss: 6.7001e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7202e-04 - val_loss: 4.8960e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6915e-04 - val_loss: 5.3879e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6685e-04 - val_loss: 6.6185e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6894e-04 - val_loss: 5.5121e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7482e-04 - val_loss: 6.3983e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7617e-04 - val_loss: 6.5646e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6892e-04 - val_loss: 5.2715e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6484e-04 - val_loss: 6.0067e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7054e-04 - val_loss: 5.1689e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7237e-04 - val_loss: 7.1637e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7349e-04 - val_loss: 6.0354e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6890e-04 - val_loss: 5.2456e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6701e-04 - val_loss: 6.6313e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6442e-04 - val_loss: 6.0071e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7487e-04 - val_loss: 5.8648e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6659e-04 - val_loss: 5.3969e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6792e-04 - val_loss: 7.5288e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6372e-04 - val_loss: 5.8230e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6598e-04 - val_loss: 5.3176e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7700e-04 - val_loss: 5.5139e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6814e-04 - val_loss: 6.1758e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6195e-04 - val_loss: 6.0653e-04\n",
      "Epoch 106/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6204e-04 - val_loss: 6.0709e-04\n",
      "Epoch 107/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6351e-04 - val_loss: 6.4905e-04\n",
      "Epoch 108/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6790e-04 - val_loss: 6.8094e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_22_layer_call_fn, lstm_cell_22_layer_call_and_return_conditional_losses, lstm_cell_23_layer_call_fn, lstm_cell_23_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_11\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 31ms/step - loss: 0.0078 - val_loss: 0.0029\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 6.3079e-04 - val_loss: 0.0026\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.8008e-04 - val_loss: 0.0021\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.1457e-04 - val_loss: 0.0023\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.8163e-04 - val_loss: 0.0030\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.6604e-04 - val_loss: 0.0022\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.3501e-04 - val_loss: 0.0024\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.3539e-04 - val_loss: 0.0019\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.2055e-04 - val_loss: 0.0024\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2616e-04 - val_loss: 0.0022\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1831e-04 - val_loss: 0.0017\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.1740e-04 - val_loss: 0.0013\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0486e-04 - val_loss: 0.0017\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0761e-04 - val_loss: 0.0015\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9894e-04 - val_loss: 0.0010\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9515e-04 - val_loss: 0.0011\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0291e-04 - val_loss: 0.0013\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9663e-04 - val_loss: 0.0015\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8922e-04 - val_loss: 0.0011\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9078e-04 - val_loss: 7.5120e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9906e-04 - val_loss: 9.6079e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8361e-04 - val_loss: 0.0011\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9832e-04 - val_loss: 0.0014\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9078e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8160e-04 - val_loss: 0.0014\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7977e-04 - val_loss: 0.0012\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8083e-04 - val_loss: 9.8721e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8172e-04 - val_loss: 0.0020\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9556e-04 - val_loss: 9.8693e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8335e-04 - val_loss: 0.0014\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8320e-04 - val_loss: 0.0012\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8343e-04 - val_loss: 0.0012\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7489e-04 - val_loss: 9.7598e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7580e-04 - val_loss: 0.0010\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8339e-04 - val_loss: 0.0013\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7734e-04 - val_loss: 8.2099e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7899e-04 - val_loss: 0.0012\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7526e-04 - val_loss: 0.0011\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7879e-04 - val_loss: 8.4412e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7135e-04 - val_loss: 0.0012\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7036e-04 - val_loss: 9.0760e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7452e-04 - val_loss: 0.0013\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6933e-04 - val_loss: 9.4448e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7389e-04 - val_loss: 0.0012\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7519e-04 - val_loss: 0.0012\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7631e-04 - val_loss: 9.1842e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7766e-04 - val_loss: 9.4695e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7147e-04 - val_loss: 0.0012\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6967e-04 - val_loss: 0.0013\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7265e-04 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_24_layer_call_fn, lstm_cell_24_layer_call_and_return_conditional_losses, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_12\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 30ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 5.8897e-04 - val_loss: 0.0023\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 4.4968e-04 - val_loss: 0.0023\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.9290e-04 - val_loss: 0.0016\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.5827e-04 - val_loss: 0.0012\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.4135e-04 - val_loss: 0.0012\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2846e-04 - val_loss: 0.0013\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2617e-04 - val_loss: 0.0011\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0984e-04 - val_loss: 8.4118e-04\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0534e-04 - val_loss: 9.3608e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1955e-04 - val_loss: 7.7482e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0475e-04 - val_loss: 7.3237e-04\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9908e-04 - val_loss: 8.1520e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9566e-04 - val_loss: 6.4262e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8978e-04 - val_loss: 6.5180e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9552e-04 - val_loss: 5.7763e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.9217e-04 - val_loss: 7.1472e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.8697e-04 - val_loss: 6.8404e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.0179e-04 - val_loss: 7.4360e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9029e-04 - val_loss: 6.5513e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9069e-04 - val_loss: 6.3102e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8689e-04 - val_loss: 8.5773e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.0097e-04 - val_loss: 6.7675e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9335e-04 - val_loss: 7.4318e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8522e-04 - val_loss: 7.3717e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8354e-04 - val_loss: 5.4031e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8763e-04 - val_loss: 5.8853e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8555e-04 - val_loss: 6.9545e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7600e-04 - val_loss: 6.8266e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7612e-04 - val_loss: 7.5554e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8060e-04 - val_loss: 6.9029e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7763e-04 - val_loss: 5.4486e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7735e-04 - val_loss: 6.6662e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7457e-04 - val_loss: 6.1715e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7405e-04 - val_loss: 6.0087e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.9539e-04 - val_loss: 6.3858e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7167e-04 - val_loss: 7.4846e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6911e-04 - val_loss: 5.9449e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7095e-04 - val_loss: 5.8965e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7644e-04 - val_loss: 6.2915e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7147e-04 - val_loss: 7.5733e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7427e-04 - val_loss: 6.4751e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6801e-04 - val_loss: 8.7115e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7391e-04 - val_loss: 6.2578e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8007e-04 - val_loss: 6.9308e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6508e-04 - val_loss: 6.0020e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7337e-04 - val_loss: 9.1477e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8329e-04 - val_loss: 6.0414e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8535e-04 - val_loss: 9.5222e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7386e-04 - val_loss: 6.3073e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6473e-04 - val_loss: 6.5191e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.8441e-04 - val_loss: 6.2292e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7818e-04 - val_loss: 8.0108e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6557e-04 - val_loss: 8.6613e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6931e-04 - val_loss: 6.7471e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.6766e-04 - val_loss: 7.9272e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses, lstm_cell_27_layer_call_fn, lstm_cell_27_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_13\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_13\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 31ms/step - loss: 0.0141 - val_loss: 0.0072\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 8.0314e-04 - val_loss: 0.0022\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 6.3540e-04 - val_loss: 0.0020\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 5.2613e-04 - val_loss: 0.0018\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.5114e-04 - val_loss: 0.0016\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 4.0588e-04 - val_loss: 0.0015\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.8065e-04 - val_loss: 0.0012\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.6385e-04 - val_loss: 0.0013\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.5636e-04 - val_loss: 0.0011\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.4693e-04 - val_loss: 0.0011\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.4283e-04 - val_loss: 0.0011\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.3768e-04 - val_loss: 0.0012\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.4134e-04 - val_loss: 0.0010\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.2644e-04 - val_loss: 8.8413e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.2392e-04 - val_loss: 0.0010\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.2022e-04 - val_loss: 8.5185e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1728e-04 - val_loss: 7.8767e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.1993e-04 - val_loss: 7.4014e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1668e-04 - val_loss: 9.3453e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.0948e-04 - val_loss: 7.6510e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.1375e-04 - val_loss: 7.8230e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.0981e-04 - val_loss: 8.6611e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.1435e-04 - val_loss: 8.2073e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0463e-04 - val_loss: 7.7187e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0032e-04 - val_loss: 7.5348e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9798e-04 - val_loss: 6.9105e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0209e-04 - val_loss: 8.0004e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9800e-04 - val_loss: 7.5113e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0021e-04 - val_loss: 8.4414e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 3.0521e-04 - val_loss: 7.4091e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9761e-04 - val_loss: 6.3496e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9460e-04 - val_loss: 6.2456e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8881e-04 - val_loss: 7.9357e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9654e-04 - val_loss: 7.0711e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9006e-04 - val_loss: 7.3102e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8938e-04 - val_loss: 6.2397e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9119e-04 - val_loss: 8.0431e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9351e-04 - val_loss: 5.5878e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8488e-04 - val_loss: 7.0957e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8261e-04 - val_loss: 6.4597e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8560e-04 - val_loss: 6.3894e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8540e-04 - val_loss: 7.3637e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8302e-04 - val_loss: 5.9442e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9998e-04 - val_loss: 8.5991e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8581e-04 - val_loss: 6.6050e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8992e-04 - val_loss: 6.1672e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8283e-04 - val_loss: 7.4397e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8187e-04 - val_loss: 7.3094e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7885e-04 - val_loss: 6.8439e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9254e-04 - val_loss: 7.9017e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8496e-04 - val_loss: 5.6882e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7590e-04 - val_loss: 5.6850e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7509e-04 - val_loss: 6.7834e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9232e-04 - val_loss: 6.7140e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8323e-04 - val_loss: 7.0991e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7624e-04 - val_loss: 5.7824e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7447e-04 - val_loss: 7.9474e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7664e-04 - val_loss: 6.9126e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7333e-04 - val_loss: 5.9315e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7762e-04 - val_loss: 6.1508e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7290e-04 - val_loss: 6.0196e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7056e-04 - val_loss: 6.9239e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7191e-04 - val_loss: 7.9986e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.7353e-04 - val_loss: 7.6091e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.9099e-04 - val_loss: 7.7945e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8243e-04 - val_loss: 7.7881e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.8124e-04 - val_loss: 8.1085e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.6949e-04 - val_loss: 6.4197e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_28_layer_call_fn, lstm_cell_28_layer_call_and_return_conditional_losses, lstm_cell_29_layer_call_fn, lstm_cell_29_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_14\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_14\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 41ms/step - loss: 0.0200 - val_loss: 0.0169\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0106\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 6.6051e-04 - val_loss: 0.0093\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 5.2809e-04 - val_loss: 0.0094\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.6091e-04 - val_loss: 0.0081\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.2475e-04 - val_loss: 0.0067\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.0702e-04 - val_loss: 0.0054\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.9156e-04 - val_loss: 0.0046\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.8870e-04 - val_loss: 0.0040\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.5993e-04 - val_loss: 0.0037\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.5204e-04 - val_loss: 0.0032\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.4560e-04 - val_loss: 0.0036\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.3726e-04 - val_loss: 0.0027\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3662e-04 - val_loss: 0.0018\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2430e-04 - val_loss: 0.0018\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2278e-04 - val_loss: 0.0014\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1349e-04 - val_loss: 0.0017\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.1760e-04 - val_loss: 0.0013\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1038e-04 - val_loss: 9.1266e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1488e-04 - val_loss: 0.0011\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0894e-04 - val_loss: 8.9455e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9866e-04 - val_loss: 0.0011\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0297e-04 - val_loss: 6.5907e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9415e-04 - val_loss: 9.4604e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9655e-04 - val_loss: 7.4568e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9331e-04 - val_loss: 7.9359e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9589e-04 - val_loss: 5.0553e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9328e-04 - val_loss: 6.6794e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9469e-04 - val_loss: 7.9892e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9664e-04 - val_loss: 6.7599e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9829e-04 - val_loss: 5.3417e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9506e-04 - val_loss: 8.4405e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8923e-04 - val_loss: 5.1004e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8690e-04 - val_loss: 6.5491e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8943e-04 - val_loss: 5.6492e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8443e-04 - val_loss: 6.0149e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8563e-04 - val_loss: 5.9640e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8546e-04 - val_loss: 4.2312e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8245e-04 - val_loss: 4.7668e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7794e-04 - val_loss: 4.5612e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8578e-04 - val_loss: 6.8033e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8005e-04 - val_loss: 5.0865e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8471e-04 - val_loss: 4.4432e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7574e-04 - val_loss: 4.2596e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8540e-04 - val_loss: 5.2029e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8213e-04 - val_loss: 6.2848e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7652e-04 - val_loss: 7.2662e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8239e-04 - val_loss: 5.0355e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8306e-04 - val_loss: 6.6869e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7688e-04 - val_loss: 7.3303e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 3.0553e-04 - val_loss: 5.1314e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8172e-04 - val_loss: 7.8334e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7667e-04 - val_loss: 4.1257e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8259e-04 - val_loss: 5.7755e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7956e-04 - val_loss: 5.1188e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7164e-04 - val_loss: 4.1111e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8038e-04 - val_loss: 4.0602e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7691e-04 - val_loss: 4.8202e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7020e-04 - val_loss: 4.6486e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6660e-04 - val_loss: 5.3215e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9195e-04 - val_loss: 6.1091e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7421e-04 - val_loss: 4.4427e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7447e-04 - val_loss: 5.2575e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7074e-04 - val_loss: 4.9033e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7650e-04 - val_loss: 4.2956e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6734e-04 - val_loss: 4.5337e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6573e-04 - val_loss: 4.8220e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6540e-04 - val_loss: 4.1375e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.8306e-04 - val_loss: 4.0769e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7232e-04 - val_loss: 4.1465e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6637e-04 - val_loss: 7.7513e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6584e-04 - val_loss: 4.1401e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7620e-04 - val_loss: 4.4701e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6354e-04 - val_loss: 4.9245e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7436e-04 - val_loss: 5.0584e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.6461e-04 - val_loss: 4.4409e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6812e-04 - val_loss: 4.3408e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7311e-04 - val_loss: 4.5434e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6484e-04 - val_loss: 6.0917e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6344e-04 - val_loss: 4.7913e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6196e-04 - val_loss: 4.7030e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.5797e-04 - val_loss: 4.1939e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.6036e-04 - val_loss: 4.4769e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 1s 17ms/step - loss: 2.5789e-04 - val_loss: 5.4775e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.6655e-04 - val_loss: 5.5663e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6397e-04 - val_loss: 5.3517e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6086e-04 - val_loss: 5.3935e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_30_layer_call_fn, lstm_cell_30_layer_call_and_return_conditional_losses, lstm_cell_31_layer_call_fn, lstm_cell_31_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_15\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_15\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 29ms/step - loss: 0.0276 - val_loss: 0.0079\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0014 - val_loss: 0.0061\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 8.4208e-04 - val_loss: 0.0044\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 6.7909e-04 - val_loss: 0.0050\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 5.4584e-04 - val_loss: 0.0049\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.5493e-04 - val_loss: 0.0030\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.1486e-04 - val_loss: 0.0030\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.8635e-04 - val_loss: 0.0033\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.7398e-04 - val_loss: 0.0033\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.5776e-04 - val_loss: 0.0032\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.5370e-04 - val_loss: 0.0027\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.4527e-04 - val_loss: 0.0023\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.4022e-04 - val_loss: 0.0023\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3602e-04 - val_loss: 0.0024\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 3.3083e-04 - val_loss: 0.0019\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2068e-04 - val_loss: 0.0017\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1798e-04 - val_loss: 0.0019\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1568e-04 - val_loss: 0.0017\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1185e-04 - val_loss: 0.0012\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1255e-04 - val_loss: 0.0014\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0952e-04 - val_loss: 0.0016\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0899e-04 - val_loss: 0.0013\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0238e-04 - val_loss: 0.0011\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9690e-04 - val_loss: 0.0011\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0308e-04 - val_loss: 0.0012\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0875e-04 - val_loss: 8.6362e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9885e-04 - val_loss: 6.8327e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9804e-04 - val_loss: 7.7404e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9068e-04 - val_loss: 6.2839e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0667e-04 - val_loss: 0.0014\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9533e-04 - val_loss: 7.4339e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9071e-04 - val_loss: 7.2241e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0013e-04 - val_loss: 8.3206e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9080e-04 - val_loss: 5.9960e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8978e-04 - val_loss: 6.9882e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8864e-04 - val_loss: 6.2640e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8733e-04 - val_loss: 5.4221e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9539e-04 - val_loss: 7.1547e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8973e-04 - val_loss: 7.1850e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8916e-04 - val_loss: 5.2310e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8325e-04 - val_loss: 5.0536e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7919e-04 - val_loss: 6.1604e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8304e-04 - val_loss: 4.6434e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0046e-04 - val_loss: 5.4365e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8798e-04 - val_loss: 5.2928e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8047e-04 - val_loss: 7.5376e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9618e-04 - val_loss: 6.4193e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8035e-04 - val_loss: 4.5334e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7781e-04 - val_loss: 4.8215e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8101e-04 - val_loss: 6.6199e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7727e-04 - val_loss: 5.0903e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9075e-04 - val_loss: 5.2235e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8095e-04 - val_loss: 5.2466e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7385e-04 - val_loss: 4.9104e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7699e-04 - val_loss: 5.0478e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8478e-04 - val_loss: 4.8733e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7606e-04 - val_loss: 5.3969e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8604e-04 - val_loss: 4.4798e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7692e-04 - val_loss: 5.5859e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8643e-04 - val_loss: 4.6259e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7463e-04 - val_loss: 5.7859e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7701e-04 - val_loss: 4.9395e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7990e-04 - val_loss: 5.1316e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6925e-04 - val_loss: 4.8454e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7613e-04 - val_loss: 5.1722e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8447e-04 - val_loss: 5.2755e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7541e-04 - val_loss: 5.2269e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7187e-04 - val_loss: 6.1408e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7742e-04 - val_loss: 4.8496e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8192e-04 - val_loss: 5.2388e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7931e-04 - val_loss: 4.9240e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8711e-04 - val_loss: 6.5658e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7023e-04 - val_loss: 5.3985e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7133e-04 - val_loss: 4.8579e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8462e-04 - val_loss: 5.9063e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7718e-04 - val_loss: 5.1983e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8220e-04 - val_loss: 4.9574e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8542e-04 - val_loss: 5.0887e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7632e-04 - val_loss: 4.7332e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7474e-04 - val_loss: 5.9723e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8137e-04 - val_loss: 6.6100e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8740e-04 - val_loss: 7.4045e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7365e-04 - val_loss: 5.7142e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6820e-04 - val_loss: 6.6861e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8759e-04 - val_loss: 5.1109e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7339e-04 - val_loss: 6.2322e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7788e-04 - val_loss: 5.2014e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6456e-04 - val_loss: 5.7780e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_32_layer_call_fn, lstm_cell_32_layer_call_and_return_conditional_losses, lstm_cell_33_layer_call_fn, lstm_cell_33_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 29ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 5.6003e-04 - val_loss: 0.0019\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.7364e-04 - val_loss: 0.0015\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.3053e-04 - val_loss: 0.0013\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.0212e-04 - val_loss: 8.3214e-04\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.8479e-04 - val_loss: 7.9319e-04\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.6480e-04 - val_loss: 8.3328e-04\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.7525e-04 - val_loss: 6.5814e-04\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.4495e-04 - val_loss: 5.6685e-04\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3057e-04 - val_loss: 5.2967e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2100e-04 - val_loss: 5.3724e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3247e-04 - val_loss: 5.4558e-04\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1832e-04 - val_loss: 5.6574e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1305e-04 - val_loss: 5.3222e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1634e-04 - val_loss: 5.2271e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0777e-04 - val_loss: 5.7601e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9858e-04 - val_loss: 5.3590e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0548e-04 - val_loss: 7.1540e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9997e-04 - val_loss: 5.1189e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0712e-04 - val_loss: 5.1436e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0123e-04 - val_loss: 5.4706e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0048e-04 - val_loss: 5.7971e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9272e-04 - val_loss: 5.3938e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8962e-04 - val_loss: 5.1335e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0480e-04 - val_loss: 5.4251e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0997e-04 - val_loss: 5.1379e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9640e-04 - val_loss: 5.1980e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9561e-04 - val_loss: 6.2137e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9750e-04 - val_loss: 5.1741e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8753e-04 - val_loss: 5.3823e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8781e-04 - val_loss: 5.7146e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9826e-04 - val_loss: 5.0818e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8714e-04 - val_loss: 5.6490e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.4241e-04 - val_loss: 4.9786e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9292e-04 - val_loss: 5.1702e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9277e-04 - val_loss: 6.4073e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8817e-04 - val_loss: 5.0026e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8347e-04 - val_loss: 5.4030e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8102e-04 - val_loss: 5.3134e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8214e-04 - val_loss: 5.0193e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8614e-04 - val_loss: 5.1853e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9086e-04 - val_loss: 5.2194e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8550e-04 - val_loss: 5.2728e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8649e-04 - val_loss: 5.1866e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8803e-04 - val_loss: 6.2920e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9234e-04 - val_loss: 5.3517e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9012e-04 - val_loss: 5.1160e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7956e-04 - val_loss: 5.6338e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7898e-04 - val_loss: 5.1122e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7252e-04 - val_loss: 5.1405e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7923e-04 - val_loss: 4.9834e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7647e-04 - val_loss: 5.8148e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7818e-04 - val_loss: 5.4222e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7920e-04 - val_loss: 5.2639e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8325e-04 - val_loss: 5.1210e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9077e-04 - val_loss: 5.2361e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7143e-04 - val_loss: 5.1975e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8725e-04 - val_loss: 5.0505e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9023e-04 - val_loss: 5.9862e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7020e-04 - val_loss: 5.0550e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7125e-04 - val_loss: 5.1729e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8632e-04 - val_loss: 5.6357e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6936e-04 - val_loss: 5.0418e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7047e-04 - val_loss: 5.0167e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_34_layer_call_fn, lstm_cell_34_layer_call_and_return_conditional_losses, lstm_cell_35_layer_call_fn, lstm_cell_35_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_17\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_17\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 30ms/step - loss: 0.0081 - val_loss: 0.0042\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 9.2665e-04 - val_loss: 0.0023\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 6.4010e-04 - val_loss: 0.0017\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 5.2516e-04 - val_loss: 0.0012\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.4503e-04 - val_loss: 0.0012\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.0244e-04 - val_loss: 9.2497e-04\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.7902e-04 - val_loss: 7.2522e-04\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.7007e-04 - val_loss: 7.6786e-04\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.5301e-04 - val_loss: 7.2246e-04\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3573e-04 - val_loss: 7.1602e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3006e-04 - val_loss: 5.7287e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.4689e-04 - val_loss: 6.6291e-04\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1796e-04 - val_loss: 6.3305e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1533e-04 - val_loss: 5.5732e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0391e-04 - val_loss: 5.0522e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2157e-04 - val_loss: 6.3666e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0261e-04 - val_loss: 6.8089e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9548e-04 - val_loss: 5.3080e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9279e-04 - val_loss: 5.7749e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8889e-04 - val_loss: 5.0345e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8610e-04 - val_loss: 6.3946e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0117e-04 - val_loss: 7.6683e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9520e-04 - val_loss: 4.7823e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 3.0909e-04 - val_loss: 5.0107e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 2.8671e-04 - val_loss: 6.3865e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 16ms/step - loss: 3.0403e-04 - val_loss: 4.9855e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.9847e-04 - val_loss: 4.9694e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 2.7715e-04 - val_loss: 4.9972e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7675e-04 - val_loss: 4.7525e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7989e-04 - val_loss: 5.2808e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7882e-04 - val_loss: 5.5411e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7382e-04 - val_loss: 5.2870e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7210e-04 - val_loss: 6.0309e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7062e-04 - val_loss: 6.5318e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7496e-04 - val_loss: 5.5070e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6644e-04 - val_loss: 4.9720e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6852e-04 - val_loss: 5.0914e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6790e-04 - val_loss: 4.9219e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7153e-04 - val_loss: 6.0635e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6610e-04 - val_loss: 5.3958e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6905e-04 - val_loss: 4.8587e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7099e-04 - val_loss: 5.0856e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7214e-04 - val_loss: 5.6619e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6238e-04 - val_loss: 5.7472e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6496e-04 - val_loss: 6.3720e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5993e-04 - val_loss: 6.0566e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6493e-04 - val_loss: 5.8315e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8679e-04 - val_loss: 5.7966e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6019e-04 - val_loss: 6.0485e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5930e-04 - val_loss: 6.3810e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5445e-04 - val_loss: 6.6779e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5631e-04 - val_loss: 7.6456e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5274e-04 - val_loss: 7.2990e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5098e-04 - val_loss: 6.9753e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5537e-04 - val_loss: 6.6413e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5213e-04 - val_loss: 5.9557e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.4481e-04 - val_loss: 6.0083e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.5240e-04 - val_loss: 7.8371e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.4853e-04 - val_loss: 7.5370e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_36_layer_call_fn, lstm_cell_36_layer_call_and_return_conditional_losses, lstm_cell_37_layer_call_fn, lstm_cell_37_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_18\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_18\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 30ms/step - loss: 0.0331 - val_loss: 0.0139\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 9.8652e-04 - val_loss: 0.0017\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 6.4471e-04 - val_loss: 0.0017\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.9876e-04 - val_loss: 0.0015\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 4.3010e-04 - val_loss: 0.0013\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.9346e-04 - val_loss: 0.0013\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.6859e-04 - val_loss: 0.0012\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.5205e-04 - val_loss: 0.0011\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.4118e-04 - val_loss: 0.0011\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.3863e-04 - val_loss: 0.0010\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2374e-04 - val_loss: 0.0011\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2378e-04 - val_loss: 8.5862e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2509e-04 - val_loss: 0.0011\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.2718e-04 - val_loss: 9.2161e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1891e-04 - val_loss: 7.5600e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1309e-04 - val_loss: 7.5262e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1876e-04 - val_loss: 7.4598e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0441e-04 - val_loss: 9.6220e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0631e-04 - val_loss: 7.9558e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0906e-04 - val_loss: 9.4285e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0846e-04 - val_loss: 8.4461e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0950e-04 - val_loss: 9.0005e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1184e-04 - val_loss: 6.4753e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0087e-04 - val_loss: 7.2896e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0190e-04 - val_loss: 6.3264e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0086e-04 - val_loss: 5.8439e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9955e-04 - val_loss: 8.4488e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0704e-04 - val_loss: 7.3865e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9682e-04 - val_loss: 6.5917e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9615e-04 - val_loss: 6.4658e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9279e-04 - val_loss: 6.4392e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9341e-04 - val_loss: 5.4793e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.0024e-04 - val_loss: 6.5035e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9861e-04 - val_loss: 7.9596e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8587e-04 - val_loss: 8.4343e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9522e-04 - val_loss: 6.8013e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9217e-04 - val_loss: 7.9687e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9112e-04 - val_loss: 0.0012\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9915e-04 - val_loss: 5.5063e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.1015e-04 - val_loss: 5.8954e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8791e-04 - val_loss: 7.6458e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8708e-04 - val_loss: 7.5511e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8819e-04 - val_loss: 7.4035e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8145e-04 - val_loss: 6.4455e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9286e-04 - val_loss: 5.2996e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7940e-04 - val_loss: 6.6118e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8326e-04 - val_loss: 8.2100e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9114e-04 - val_loss: 6.1400e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8399e-04 - val_loss: 6.1505e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7520e-04 - val_loss: 6.0654e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8659e-04 - val_loss: 7.9934e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8975e-04 - val_loss: 5.2607e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9390e-04 - val_loss: 9.0082e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8470e-04 - val_loss: 5.2754e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7857e-04 - val_loss: 6.9359e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7855e-04 - val_loss: 5.5891e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8086e-04 - val_loss: 4.9037e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.9485e-04 - val_loss: 5.4207e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7697e-04 - val_loss: 8.1379e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7394e-04 - val_loss: 6.7111e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7606e-04 - val_loss: 5.0216e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8203e-04 - val_loss: 7.2469e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7828e-04 - val_loss: 6.0143e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7852e-04 - val_loss: 6.5344e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8200e-04 - val_loss: 6.0378e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7452e-04 - val_loss: 7.4893e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7575e-04 - val_loss: 7.9804e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7812e-04 - val_loss: 6.4079e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7469e-04 - val_loss: 6.8717e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7710e-04 - val_loss: 5.2312e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 2.7213e-04 - val_loss: 4.8711e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8015e-04 - val_loss: 8.0800e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7768e-04 - val_loss: 7.8316e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7365e-04 - val_loss: 5.6508e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7050e-04 - val_loss: 6.2562e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6827e-04 - val_loss: 5.5787e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7454e-04 - val_loss: 5.2706e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6877e-04 - val_loss: 4.9093e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7452e-04 - val_loss: 8.2403e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6864e-04 - val_loss: 5.8187e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6925e-04 - val_loss: 6.3009e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6884e-04 - val_loss: 5.5133e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7371e-04 - val_loss: 6.4369e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7134e-04 - val_loss: 6.7244e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6940e-04 - val_loss: 6.6087e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6285e-04 - val_loss: 6.7917e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6184e-04 - val_loss: 5.6796e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7152e-04 - val_loss: 8.0626e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7987e-04 - val_loss: 8.4536e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7092e-04 - val_loss: 6.7459e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7709e-04 - val_loss: 7.2653e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7454e-04 - val_loss: 6.1306e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7559e-04 - val_loss: 6.6023e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7002e-04 - val_loss: 5.3338e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7756e-04 - val_loss: 5.6667e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6328e-04 - val_loss: 7.4148e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6582e-04 - val_loss: 8.2357e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7277e-04 - val_loss: 6.4818e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.7322e-04 - val_loss: 6.0639e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.6973e-04 - val_loss: 9.3422e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.8098e-04 - val_loss: 6.5151e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_38_layer_call_fn, lstm_cell_38_layer_call_and_return_conditional_losses, lstm_cell_39_layer_call_fn, lstm_cell_39_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_19\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_memory = 50\n",
    "\n",
    "trainInputX, trainInputY = sf.prepareData(trainX, trainY, lstm_memory)\n",
    "testInputX, testInputY = sf.prepareData(testX, testY, lstm_memory)\n",
    "print(trainInputX.shape)\n",
    "print(trainInputY.shape)\n",
    "print(testInputX.shape)\n",
    "print(testInputY.shape)\n",
    "\n",
    "#validacao tamanho apos tratamentos\n",
    "print(len(trainX))\n",
    "print(len(trainInputX))\n",
    "\n",
    "print(len(trainY))\n",
    "print(len(trainInputY))\n",
    "\n",
    "trainInputX = trainInputX [:,:,0:14]\n",
    "testInputX = testInputX [:,:,0:14]\n",
    "print(trainInputX.shape)\n",
    "\n",
    "trained_models_lstm_50 = []\n",
    "trained_models_lstm_50_history = []\n",
    "\n",
    "for i in range(0,20):\n",
    "\n",
    "    #giving it reproducibility\n",
    "    seed = (i+1000)\n",
    "\n",
    "    os.environ['PYTHONHASHseed']=str(seed)\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    batch_size = 256\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "    \n",
    "    trained_models_lstm_50.append(kr.Sequential())\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_50[i].add(kr.layers.LSTM(14,return_sequences = True))\n",
    "    trained_models_lstm_50[i].add(kr.layers.LSTM(8))\n",
    "    # lstm_model.add(kr.layers.Simplelstm(5,input_shape=(trainInputX.shape[1],trainInputX.shape[2])))\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_50[i].add(kr.layers.Dense(1))\n",
    "    trained_models_lstm_50[i].compile(loss='mean_squared_error',optimizer='adam')\n",
    "    \n",
    "    trained_models_lstm_50_history.append(trained_models_lstm_50[i].fit(trainInputX, trainInputY, epochs=2000, batch_size=batch_size, verbose = 1, validation_data=(testInputX,testInputY),  callbacks=[callback]))\n",
    "    \n",
    "    trained_models_lstm_50[i].save('C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_50_batch_256_earlystop_valloss_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a4fed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11590, 100, 14)\n",
      "(11590,)\n",
      "(2823, 100, 14)\n",
      "(2823,)\n",
      "11690\n",
      "11590\n",
      "11690\n",
      "11590\n",
      "(11590, 100, 14)\n",
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 48ms/step - loss: 0.0458 - val_loss: 0.0030\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 7.2536e-04 - val_loss: 0.0037\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5.5586e-04 - val_loss: 0.0047\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.8949e-04 - val_loss: 0.0041\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.4252e-04 - val_loss: 0.0038\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.0888e-04 - val_loss: 0.0040\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.8215e-04 - val_loss: 0.0032\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.6462e-04 - val_loss: 0.0029\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.5049e-04 - val_loss: 0.0025\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4980e-04 - val_loss: 0.0024\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.3641e-04 - val_loss: 0.0020\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.3267e-04 - val_loss: 0.0028\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3036e-04 - val_loss: 0.0018\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1537e-04 - val_loss: 0.0016\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1573e-04 - val_loss: 0.0014\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1473e-04 - val_loss: 0.0019\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1451e-04 - val_loss: 0.0012\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1215e-04 - val_loss: 0.0012\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1714e-04 - val_loss: 9.3438e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1750e-04 - val_loss: 5.7957e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1304e-04 - val_loss: 0.0010\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0193e-04 - val_loss: 8.8635e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0158e-04 - val_loss: 0.0010\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 3.0126e-04 - val_loss: 8.0454e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 3.1031e-04 - val_loss: 6.5798e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1570e-04 - val_loss: 8.0917e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9859e-04 - val_loss: 0.0011\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0376e-04 - val_loss: 6.1113e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9701e-04 - val_loss: 9.9360e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9926e-04 - val_loss: 9.1113e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0416e-04 - val_loss: 4.3967e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0733e-04 - val_loss: 6.8674e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9484e-04 - val_loss: 6.9393e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9398e-04 - val_loss: 7.7825e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9603e-04 - val_loss: 8.3088e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9309e-04 - val_loss: 6.4106e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9643e-04 - val_loss: 6.8564e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9656e-04 - val_loss: 4.5425e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1032e-04 - val_loss: 4.4101e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0241e-04 - val_loss: 5.5276e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9538e-04 - val_loss: 6.3983e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9449e-04 - val_loss: 7.2547e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0574e-04 - val_loss: 9.8379e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9854e-04 - val_loss: 7.3344e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8993e-04 - val_loss: 6.7176e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8442e-04 - val_loss: 7.3162e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9593e-04 - val_loss: 4.7818e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0534e-04 - val_loss: 4.4472e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8754e-04 - val_loss: 6.2384e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9091e-04 - val_loss: 6.5051e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8365e-04 - val_loss: 9.3826e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9824e-04 - val_loss: 4.9092e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8424e-04 - val_loss: 9.5326e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8728e-04 - val_loss: 6.1772e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8273e-04 - val_loss: 7.3204e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8443e-04 - val_loss: 4.5744e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8593e-04 - val_loss: 5.7690e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.8081e-04 - val_loss: 4.6265e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 2.8654e-04 - val_loss: 5.6657e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 2.8291e-04 - val_loss: 5.1466e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8466e-04 - val_loss: 4.7987e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 48ms/step - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 8.0603e-04 - val_loss: 0.0017\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.5520e-04 - val_loss: 0.0012\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.7698e-04 - val_loss: 0.0015\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5830e-04 - val_loss: 0.0021\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5081e-04 - val_loss: 0.0016\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3861e-04 - val_loss: 0.0014\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5176e-04 - val_loss: 0.0019\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1692e-04 - val_loss: 0.0012\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1446e-04 - val_loss: 0.0010\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0864e-04 - val_loss: 0.0013\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0815e-04 - val_loss: 0.0013\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0680e-04 - val_loss: 0.0014\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1622e-04 - val_loss: 9.3790e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9780e-04 - val_loss: 0.0012\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9424e-04 - val_loss: 8.2511e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9859e-04 - val_loss: 7.8755e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9591e-04 - val_loss: 0.0010\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9794e-04 - val_loss: 8.9772e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8582e-04 - val_loss: 8.5722e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8789e-04 - val_loss: 0.0011\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8852e-04 - val_loss: 8.1053e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9168e-04 - val_loss: 9.1593e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9013e-04 - val_loss: 9.5818e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8279e-04 - val_loss: 7.3005e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8824e-04 - val_loss: 9.2085e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9091e-04 - val_loss: 9.9167e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9015e-04 - val_loss: 8.5345e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7786e-04 - val_loss: 9.0293e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8569e-04 - val_loss: 0.0015\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9530e-04 - val_loss: 0.0010\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9143e-04 - val_loss: 0.0010\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7783e-04 - val_loss: 8.5782e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8008e-04 - val_loss: 7.7434e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8099e-04 - val_loss: 7.4416e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 2.7340e-04 - val_loss: 7.9018e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 2.6978e-04 - val_loss: 7.8688e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8010e-04 - val_loss: 0.0011\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7053e-04 - val_loss: 7.0102e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7118e-04 - val_loss: 7.9383e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8277e-04 - val_loss: 8.6298e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7208e-04 - val_loss: 7.3997e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7681e-04 - val_loss: 0.0011\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7128e-04 - val_loss: 7.2484e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6494e-04 - val_loss: 7.7444e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7866e-04 - val_loss: 7.9852e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7267e-04 - val_loss: 8.7923e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7870e-04 - val_loss: 8.0181e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6534e-04 - val_loss: 7.1011e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6707e-04 - val_loss: 7.3721e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6845e-04 - val_loss: 0.0013\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9740e-04 - val_loss: 7.1091e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6291e-04 - val_loss: 7.4464e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6505e-04 - val_loss: 8.8960e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5857e-04 - val_loss: 7.6841e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5868e-04 - val_loss: 7.6136e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7182e-04 - val_loss: 7.8139e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5655e-04 - val_loss: 7.0393e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7131e-04 - val_loss: 6.9909e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6763e-04 - val_loss: 0.0010\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6294e-04 - val_loss: 7.4388e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6062e-04 - val_loss: 7.3877e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5728e-04 - val_loss: 8.6442e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6278e-04 - val_loss: 7.5586e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6330e-04 - val_loss: 7.9977e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6306e-04 - val_loss: 7.2174e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6041e-04 - val_loss: 8.5056e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5382e-04 - val_loss: 7.7570e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5521e-04 - val_loss: 8.4173e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6159e-04 - val_loss: 7.8910e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5069e-04 - val_loss: 0.0011\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7436e-04 - val_loss: 0.0010\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6826e-04 - val_loss: 7.6196e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5580e-04 - val_loss: 7.0166e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7163e-04 - val_loss: 6.6980e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5587e-04 - val_loss: 8.0441e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6288e-04 - val_loss: 7.6048e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5290e-04 - val_loss: 7.1372e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4738e-04 - val_loss: 7.8867e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5417e-04 - val_loss: 0.0010\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5703e-04 - val_loss: 7.0508e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4808e-04 - val_loss: 7.4468e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5179e-04 - val_loss: 9.0735e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4761e-04 - val_loss: 9.5894e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6028e-04 - val_loss: 8.5640e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5298e-04 - val_loss: 8.4926e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4759e-04 - val_loss: 7.4600e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4701e-04 - val_loss: 7.2994e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6583e-04 - val_loss: 7.0606e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5932e-04 - val_loss: 9.0633e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4737e-04 - val_loss: 8.4687e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5493e-04 - val_loss: 8.0484e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4027e-04 - val_loss: 0.0010\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4311e-04 - val_loss: 9.9588e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5369e-04 - val_loss: 8.8995e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4512e-04 - val_loss: 8.0654e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5896e-04 - val_loss: 7.4977e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4683e-04 - val_loss: 8.1682e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5763e-04 - val_loss: 7.2412e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4480e-04 - val_loss: 6.7931e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.3958e-04 - val_loss: 9.0033e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4159e-04 - val_loss: 7.2414e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4371e-04 - val_loss: 7.4386e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5568e-04 - val_loss: 8.4311e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4783e-04 - val_loss: 7.6553e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_42_layer_call_fn, lstm_cell_42_layer_call_and_return_conditional_losses, lstm_cell_43_layer_call_fn, lstm_cell_43_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 48ms/step - loss: 0.0382 - val_loss: 0.0104\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 7.4455e-04 - val_loss: 0.0023\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5.7514e-04 - val_loss: 0.0019\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.8161e-04 - val_loss: 0.0019\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.3047e-04 - val_loss: 0.0017\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.9802e-04 - val_loss: 0.0017\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.7332e-04 - val_loss: 0.0014\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.5714e-04 - val_loss: 0.0012\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.4885e-04 - val_loss: 0.0011\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.3455e-04 - val_loss: 0.0010\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2808e-04 - val_loss: 9.1451e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.2541e-04 - val_loss: 8.6474e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1884e-04 - val_loss: 8.4704e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1215e-04 - val_loss: 8.7793e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0913e-04 - val_loss: 9.0174e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1057e-04 - val_loss: 7.6373e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0331e-04 - val_loss: 8.0514e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0188e-04 - val_loss: 7.3033e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9683e-04 - val_loss: 8.6222e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9799e-04 - val_loss: 9.4126e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9913e-04 - val_loss: 8.5233e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0301e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0005e-04 - val_loss: 6.0392e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0341e-04 - val_loss: 9.8116e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9226e-04 - val_loss: 7.6366e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9316e-04 - val_loss: 0.0010\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9247e-04 - val_loss: 8.5293e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9094e-04 - val_loss: 7.0189e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9743e-04 - val_loss: 5.9064e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9450e-04 - val_loss: 6.0673e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9148e-04 - val_loss: 7.9926e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9012e-04 - val_loss: 6.2014e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8659e-04 - val_loss: 6.9919e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9142e-04 - val_loss: 7.0213e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8958e-04 - val_loss: 7.4533e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8411e-04 - val_loss: 9.2162e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9406e-04 - val_loss: 6.0008e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9471e-04 - val_loss: 5.9256e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8696e-04 - val_loss: 9.4997e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9666e-04 - val_loss: 6.3802e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8360e-04 - val_loss: 5.8754e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0272e-04 - val_loss: 4.5934e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8919e-04 - val_loss: 5.9741e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8244e-04 - val_loss: 5.6034e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8111e-04 - val_loss: 5.6837e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8070e-04 - val_loss: 6.6275e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8084e-04 - val_loss: 9.6596e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0489e-04 - val_loss: 7.4695e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8416e-04 - val_loss: 5.7541e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9113e-04 - val_loss: 6.2483e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8410e-04 - val_loss: 5.3741e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8090e-04 - val_loss: 5.1384e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8204e-04 - val_loss: 5.5554e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8420e-04 - val_loss: 4.5165e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8495e-04 - val_loss: 8.4422e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9848e-04 - val_loss: 6.0379e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8902e-04 - val_loss: 5.1230e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8062e-04 - val_loss: 6.1587e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8619e-04 - val_loss: 5.7277e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8703e-04 - val_loss: 4.8332e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8796e-04 - val_loss: 5.6124e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8006e-04 - val_loss: 4.7820e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7469e-04 - val_loss: 6.0672e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7708e-04 - val_loss: 4.5895e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7753e-04 - val_loss: 6.3400e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7875e-04 - val_loss: 6.0239e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7618e-04 - val_loss: 6.2175e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8259e-04 - val_loss: 6.3451e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7733e-04 - val_loss: 4.9112e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8018e-04 - val_loss: 4.6618e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7512e-04 - val_loss: 4.9722e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7633e-04 - val_loss: 4.4655e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7745e-04 - val_loss: 5.1884e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6933e-04 - val_loss: 4.6348e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6859e-04 - val_loss: 6.1426e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7730e-04 - val_loss: 7.4006e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7959e-04 - val_loss: 6.1145e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6437e-04 - val_loss: 4.8387e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6867e-04 - val_loss: 5.9632e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7366e-04 - val_loss: 4.6063e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7331e-04 - val_loss: 5.4138e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6876e-04 - val_loss: 4.3908e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7965e-04 - val_loss: 4.9633e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7514e-04 - val_loss: 8.4553e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8324e-04 - val_loss: 5.0193e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6438e-04 - val_loss: 4.8148e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6442e-04 - val_loss: 4.5344e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7737e-04 - val_loss: 4.8197e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8664e-04 - val_loss: 4.9219e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.6276e-04 - val_loss: 4.3759e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 2.6811e-04 - val_loss: 6.0659e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 2.6727e-04 - val_loss: 5.1210e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6705e-04 - val_loss: 4.7530e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8293e-04 - val_loss: 5.7334e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7216e-04 - val_loss: 4.7014e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7454e-04 - val_loss: 4.7820e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6020e-04 - val_loss: 5.5806e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6275e-04 - val_loss: 4.9639e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6010e-04 - val_loss: 5.1388e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5846e-04 - val_loss: 4.7945e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5890e-04 - val_loss: 6.7985e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6264e-04 - val_loss: 4.4700e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6071e-04 - val_loss: 5.3243e-04\n",
      "Epoch 106/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5649e-04 - val_loss: 4.7827e-04\n",
      "Epoch 107/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5363e-04 - val_loss: 5.9384e-04\n",
      "Epoch 108/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6223e-04 - val_loss: 6.8552e-04\n",
      "Epoch 109/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7665e-04 - val_loss: 5.4399e-04\n",
      "Epoch 110/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7680e-04 - val_loss: 5.7430e-04\n",
      "Epoch 111/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6989e-04 - val_loss: 5.7773e-04\n",
      "Epoch 112/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7532e-04 - val_loss: 4.6905e-04\n",
      "Epoch 113/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5498e-04 - val_loss: 4.2006e-04\n",
      "Epoch 114/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7285e-04 - val_loss: 4.3032e-04\n",
      "Epoch 115/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5366e-04 - val_loss: 4.6864e-04\n",
      "Epoch 116/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6154e-04 - val_loss: 4.8906e-04\n",
      "Epoch 117/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5543e-04 - val_loss: 4.5656e-04\n",
      "Epoch 118/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6405e-04 - val_loss: 5.1500e-04\n",
      "Epoch 119/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6092e-04 - val_loss: 5.2400e-04\n",
      "Epoch 120/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5600e-04 - val_loss: 4.8072e-04\n",
      "Epoch 121/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5512e-04 - val_loss: 4.2365e-04\n",
      "Epoch 122/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5587e-04 - val_loss: 4.6406e-04\n",
      "Epoch 123/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5160e-04 - val_loss: 4.3216e-04\n",
      "Epoch 124/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6931e-04 - val_loss: 5.6238e-04\n",
      "Epoch 125/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6423e-04 - val_loss: 4.3333e-04\n",
      "Epoch 126/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6015e-04 - val_loss: 5.9668e-04\n",
      "Epoch 127/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6085e-04 - val_loss: 4.5013e-04\n",
      "Epoch 128/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5558e-04 - val_loss: 4.2165e-04\n",
      "Epoch 129/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4811e-04 - val_loss: 5.5366e-04\n",
      "Epoch 130/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6915e-04 - val_loss: 4.1074e-04\n",
      "Epoch 131/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5100e-04 - val_loss: 4.1854e-04\n",
      "Epoch 132/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4729e-04 - val_loss: 4.2643e-04\n",
      "Epoch 133/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5984e-04 - val_loss: 4.2208e-04\n",
      "Epoch 134/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6218e-04 - val_loss: 6.1544e-04\n",
      "Epoch 135/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5074e-04 - val_loss: 4.6906e-04\n",
      "Epoch 136/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5677e-04 - val_loss: 4.2482e-04\n",
      "Epoch 137/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5587e-04 - val_loss: 4.2017e-04\n",
      "Epoch 138/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6112e-04 - val_loss: 4.0037e-04\n",
      "Epoch 139/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5628e-04 - val_loss: 4.0828e-04\n",
      "Epoch 140/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4823e-04 - val_loss: 4.0342e-04\n",
      "Epoch 141/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4805e-04 - val_loss: 4.0098e-04\n",
      "Epoch 142/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4893e-04 - val_loss: 4.3628e-04\n",
      "Epoch 143/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4509e-04 - val_loss: 4.1969e-04\n",
      "Epoch 144/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4638e-04 - val_loss: 4.0126e-04\n",
      "Epoch 145/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5288e-04 - val_loss: 4.3602e-04\n",
      "Epoch 146/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5253e-04 - val_loss: 4.2827e-04\n",
      "Epoch 147/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4758e-04 - val_loss: 4.3855e-04\n",
      "Epoch 148/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4807e-04 - val_loss: 4.3363e-04\n",
      "Epoch 149/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4546e-04 - val_loss: 4.4834e-04\n",
      "Epoch 150/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5223e-04 - val_loss: 4.0324e-04\n",
      "Epoch 151/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5568e-04 - val_loss: 4.0603e-04\n",
      "Epoch 152/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5520e-04 - val_loss: 4.1652e-04\n",
      "Epoch 153/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5417e-04 - val_loss: 4.4425e-04\n",
      "Epoch 154/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4782e-04 - val_loss: 4.1207e-04\n",
      "Epoch 155/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4800e-04 - val_loss: 4.0997e-04\n",
      "Epoch 156/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4340e-04 - val_loss: 4.1881e-04\n",
      "Epoch 157/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4853e-04 - val_loss: 4.1169e-04\n",
      "Epoch 158/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5975e-04 - val_loss: 4.7398e-04\n",
      "Epoch 159/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4514e-04 - val_loss: 4.3884e-04\n",
      "Epoch 160/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4737e-04 - val_loss: 4.4724e-04\n",
      "Epoch 161/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5828e-04 - val_loss: 4.3244e-04\n",
      "Epoch 162/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4189e-04 - val_loss: 4.6860e-04\n",
      "Epoch 163/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5883e-04 - val_loss: 4.6015e-04\n",
      "Epoch 164/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6177e-04 - val_loss: 4.3956e-04\n",
      "Epoch 165/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4639e-04 - val_loss: 4.2749e-04\n",
      "Epoch 166/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5250e-04 - val_loss: 4.3016e-04\n",
      "Epoch 167/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4435e-04 - val_loss: 4.4710e-04\n",
      "Epoch 168/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4437e-04 - val_loss: 4.2540e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_44_layer_call_fn, lstm_cell_44_layer_call_and_return_conditional_losses, lstm_cell_45_layer_call_fn, lstm_cell_45_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 6s 47ms/step - loss: 0.0531 - val_loss: 0.0140\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0022 - val_loss: 0.0218\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0013 - val_loss: 0.0182\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 9.8969e-04 - val_loss: 0.0165\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 7.8981e-04 - val_loss: 0.0142\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 6.3817e-04 - val_loss: 0.0134\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5.3534e-04 - val_loss: 0.0113\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.8019e-04 - val_loss: 0.0099\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.5307e-04 - val_loss: 0.0092\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.0998e-04 - val_loss: 0.0074\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.8595e-04 - val_loss: 0.0071\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.6845e-04 - val_loss: 0.0049\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5325e-04 - val_loss: 0.0044\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3782e-04 - val_loss: 0.0041\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 3.2715e-04 - val_loss: 0.0033\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 3.2249e-04 - val_loss: 0.0035\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 3.1328e-04 - val_loss: 0.0026\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1263e-04 - val_loss: 0.0031\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1039e-04 - val_loss: 0.0022\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2069e-04 - val_loss: 0.0019\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9865e-04 - val_loss: 0.0021\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0046e-04 - val_loss: 0.0019\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9327e-04 - val_loss: 0.0015\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0576e-04 - val_loss: 0.0015\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8621e-04 - val_loss: 0.0015\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.9964e-04 - val_loss: 0.0015\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9420e-04 - val_loss: 0.0017\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8662e-04 - val_loss: 0.0017\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8548e-04 - val_loss: 0.0013\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8762e-04 - val_loss: 0.0014\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8561e-04 - val_loss: 8.9579e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8668e-04 - val_loss: 0.0011\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8973e-04 - val_loss: 0.0011\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7573e-04 - val_loss: 0.0011\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7480e-04 - val_loss: 0.0010\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8409e-04 - val_loss: 0.0011\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8444e-04 - val_loss: 0.0017\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8304e-04 - val_loss: 0.0012\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7524e-04 - val_loss: 0.0012\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7600e-04 - val_loss: 8.8777e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7600e-04 - val_loss: 0.0011\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7847e-04 - val_loss: 7.9551e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7345e-04 - val_loss: 0.0012\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7134e-04 - val_loss: 8.7052e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8682e-04 - val_loss: 0.0013\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9434e-04 - val_loss: 6.8330e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7764e-04 - val_loss: 8.1632e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6906e-04 - val_loss: 8.4540e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7942e-04 - val_loss: 8.3593e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7209e-04 - val_loss: 8.0218e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7513e-04 - val_loss: 0.0013\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6968e-04 - val_loss: 9.4530e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7278e-04 - val_loss: 9.6819e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7461e-04 - val_loss: 8.2618e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6977e-04 - val_loss: 0.0012\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6850e-04 - val_loss: 8.0407e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6779e-04 - val_loss: 9.3004e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7480e-04 - val_loss: 0.0011\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7892e-04 - val_loss: 0.0013\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8315e-04 - val_loss: 5.8377e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7502e-04 - val_loss: 8.6051e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 2.6600e-04 - val_loss: 8.0499e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 2.6825e-04 - val_loss: 8.7134e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.6259e-04 - val_loss: 9.9728e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6334e-04 - val_loss: 7.0281e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7052e-04 - val_loss: 5.4945e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7266e-04 - val_loss: 9.7574e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6946e-04 - val_loss: 7.1044e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7847e-04 - val_loss: 6.8818e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7987e-04 - val_loss: 0.0013\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7253e-04 - val_loss: 9.0377e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6403e-04 - val_loss: 5.9673e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6314e-04 - val_loss: 7.3247e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6471e-04 - val_loss: 6.6533e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6424e-04 - val_loss: 9.6647e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6386e-04 - val_loss: 8.6701e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6485e-04 - val_loss: 6.6365e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7546e-04 - val_loss: 7.5270e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6136e-04 - val_loss: 8.9496e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5937e-04 - val_loss: 9.9993e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6371e-04 - val_loss: 6.5849e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6188e-04 - val_loss: 7.1352e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6228e-04 - val_loss: 9.3628e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6317e-04 - val_loss: 6.8155e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6035e-04 - val_loss: 9.6168e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7055e-04 - val_loss: 5.4865e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6439e-04 - val_loss: 5.7525e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6141e-04 - val_loss: 7.7254e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6820e-04 - val_loss: 7.7924e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7243e-04 - val_loss: 0.0013\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9825e-04 - val_loss: 7.1282e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5802e-04 - val_loss: 6.9020e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5533e-04 - val_loss: 8.3435e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7669e-04 - val_loss: 7.3730e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5679e-04 - val_loss: 6.4466e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6046e-04 - val_loss: 7.2279e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6473e-04 - val_loss: 5.5435e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5787e-04 - val_loss: 0.0011\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8382e-04 - val_loss: 5.9627e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5847e-04 - val_loss: 5.6854e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8021e-04 - val_loss: 5.8205e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5595e-04 - val_loss: 8.7236e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5593e-04 - val_loss: 9.2167e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5629e-04 - val_loss: 6.2849e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5847e-04 - val_loss: 5.8120e-04\n",
      "Epoch 106/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5266e-04 - val_loss: 6.7207e-04\n",
      "Epoch 107/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6016e-04 - val_loss: 6.2522e-04\n",
      "Epoch 108/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5472e-04 - val_loss: 7.2435e-04\n",
      "Epoch 109/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6130e-04 - val_loss: 6.6390e-04\n",
      "Epoch 110/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5272e-04 - val_loss: 5.7810e-04\n",
      "Epoch 111/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5337e-04 - val_loss: 6.2446e-04\n",
      "Epoch 112/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5627e-04 - val_loss: 0.0011\n",
      "Epoch 113/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6821e-04 - val_loss: 5.6249e-04\n",
      "Epoch 114/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5786e-04 - val_loss: 6.0967e-04\n",
      "Epoch 115/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5957e-04 - val_loss: 6.9078e-04\n",
      "Epoch 116/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5429e-04 - val_loss: 8.7927e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_46_layer_call_fn, lstm_cell_46_layer_call_and_return_conditional_losses, lstm_cell_47_layer_call_fn, lstm_cell_47_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 48ms/step - loss: 0.0462 - val_loss: 0.0271\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0017 - val_loss: 0.0154\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0010 - val_loss: 0.0089\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 7.3862e-04 - val_loss: 0.0050\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.9423e-04 - val_loss: 0.0037\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.9005e-04 - val_loss: 0.0027\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.1830e-04 - val_loss: 0.0018\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.7386e-04 - val_loss: 0.0018\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4705e-04 - val_loss: 0.0013\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3473e-04 - val_loss: 0.0014\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2662e-04 - val_loss: 0.0013\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2526e-04 - val_loss: 0.0013\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1451e-04 - val_loss: 0.0012\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1092e-04 - val_loss: 0.0013\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1237e-04 - val_loss: 0.0011\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0556e-04 - val_loss: 0.0010\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0457e-04 - val_loss: 0.0010\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0312e-04 - val_loss: 9.8941e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9913e-04 - val_loss: 9.3690e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0006e-04 - val_loss: 8.8139e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9960e-04 - val_loss: 8.7611e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9455e-04 - val_loss: 8.4918e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9605e-04 - val_loss: 9.0267e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9788e-04 - val_loss: 8.6419e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9715e-04 - val_loss: 7.8068e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9469e-04 - val_loss: 7.7097e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9668e-04 - val_loss: 7.6394e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 2.9177e-04 - val_loss: 7.9596e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 2.8962e-04 - val_loss: 7.3128e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.9022e-04 - val_loss: 7.7000e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9003e-04 - val_loss: 7.3101e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8618e-04 - val_loss: 7.7909e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8962e-04 - val_loss: 7.2946e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8817e-04 - val_loss: 7.1138e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8609e-04 - val_loss: 7.5793e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8414e-04 - val_loss: 7.6505e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8873e-04 - val_loss: 7.2398e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9918e-04 - val_loss: 6.9487e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8588e-04 - val_loss: 8.1689e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9117e-04 - val_loss: 7.4313e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8355e-04 - val_loss: 8.0917e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8130e-04 - val_loss: 6.8020e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8121e-04 - val_loss: 6.9449e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8119e-04 - val_loss: 7.3181e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8585e-04 - val_loss: 6.9186e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8167e-04 - val_loss: 6.9327e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8534e-04 - val_loss: 7.0315e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8902e-04 - val_loss: 6.7684e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8533e-04 - val_loss: 8.4115e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7893e-04 - val_loss: 8.2626e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9140e-04 - val_loss: 6.1881e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7990e-04 - val_loss: 7.5787e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7510e-04 - val_loss: 7.1484e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9222e-04 - val_loss: 6.4448e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8319e-04 - val_loss: 6.6307e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7639e-04 - val_loss: 6.6773e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8082e-04 - val_loss: 6.4998e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7373e-04 - val_loss: 7.3297e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7073e-04 - val_loss: 6.2961e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7782e-04 - val_loss: 6.3136e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8101e-04 - val_loss: 6.3111e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8105e-04 - val_loss: 7.3603e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9048e-04 - val_loss: 6.4236e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8863e-04 - val_loss: 7.7369e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7475e-04 - val_loss: 6.9194e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7144e-04 - val_loss: 8.2960e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8859e-04 - val_loss: 6.5702e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9205e-04 - val_loss: 7.0463e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7312e-04 - val_loss: 6.5561e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7094e-04 - val_loss: 6.2947e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6850e-04 - val_loss: 6.7987e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7289e-04 - val_loss: 6.5430e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7278e-04 - val_loss: 6.2640e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6782e-04 - val_loss: 6.3464e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7167e-04 - val_loss: 6.4202e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7014e-04 - val_loss: 6.6390e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8075e-04 - val_loss: 6.1555e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8490e-04 - val_loss: 7.0667e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7352e-04 - val_loss: 6.1385e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7991e-04 - val_loss: 6.3749e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6661e-04 - val_loss: 6.1188e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6836e-04 - val_loss: 6.6741e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7855e-04 - val_loss: 6.0437e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7323e-04 - val_loss: 6.5130e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6987e-04 - val_loss: 6.1529e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6801e-04 - val_loss: 6.2761e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7220e-04 - val_loss: 6.3402e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6672e-04 - val_loss: 5.7893e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6558e-04 - val_loss: 6.1007e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6415e-04 - val_loss: 5.8518e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7077e-04 - val_loss: 5.8340e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6652e-04 - val_loss: 6.1158e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6184e-04 - val_loss: 6.1588e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6800e-04 - val_loss: 5.9708e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6817e-04 - val_loss: 6.6071e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6291e-04 - val_loss: 5.7541e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8085e-04 - val_loss: 6.1603e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8760e-04 - val_loss: 6.1761e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6903e-04 - val_loss: 6.1583e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6131e-04 - val_loss: 6.6142e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6716e-04 - val_loss: 5.9926e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6329e-04 - val_loss: 5.6393e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6626e-04 - val_loss: 6.0304e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6895e-04 - val_loss: 6.2019e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5817e-04 - val_loss: 6.0696e-04\n",
      "Epoch 106/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6944e-04 - val_loss: 5.7810e-04\n",
      "Epoch 107/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6213e-04 - val_loss: 6.3258e-04\n",
      "Epoch 108/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7108e-04 - val_loss: 6.1320e-04\n",
      "Epoch 109/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6632e-04 - val_loss: 5.9753e-04\n",
      "Epoch 110/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7292e-04 - val_loss: 6.0482e-04\n",
      "Epoch 111/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5929e-04 - val_loss: 5.8836e-04\n",
      "Epoch 112/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5888e-04 - val_loss: 6.0651e-04\n",
      "Epoch 113/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6701e-04 - val_loss: 8.3782e-04\n",
      "Epoch 114/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7902e-04 - val_loss: 5.5060e-04\n",
      "Epoch 115/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5979e-04 - val_loss: 5.9498e-04\n",
      "Epoch 116/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5723e-04 - val_loss: 6.3547e-04\n",
      "Epoch 117/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6124e-04 - val_loss: 6.4020e-04\n",
      "Epoch 118/2000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 2.6697e-04 - val_loss: 5.7987e-04\n",
      "Epoch 119/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 2.6770e-04 - val_loss: 5.3086e-04\n",
      "Epoch 120/2000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 2.6101e-04 - val_loss: 5.9139e-04\n",
      "Epoch 121/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5580e-04 - val_loss: 6.0164e-04\n",
      "Epoch 122/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5801e-04 - val_loss: 6.4468e-04\n",
      "Epoch 123/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6642e-04 - val_loss: 5.6101e-04\n",
      "Epoch 124/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5884e-04 - val_loss: 6.2053e-04\n",
      "Epoch 125/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6355e-04 - val_loss: 6.1365e-04\n",
      "Epoch 126/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5846e-04 - val_loss: 6.0653e-04\n",
      "Epoch 127/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5277e-04 - val_loss: 6.4569e-04\n",
      "Epoch 128/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5797e-04 - val_loss: 5.9919e-04\n",
      "Epoch 129/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6505e-04 - val_loss: 6.8066e-04\n",
      "Epoch 130/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5830e-04 - val_loss: 6.0723e-04\n",
      "Epoch 131/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5931e-04 - val_loss: 7.0070e-04\n",
      "Epoch 132/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6193e-04 - val_loss: 5.9120e-04\n",
      "Epoch 133/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5973e-04 - val_loss: 5.7132e-04\n",
      "Epoch 134/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5485e-04 - val_loss: 5.5769e-04\n",
      "Epoch 135/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5356e-04 - val_loss: 5.9380e-04\n",
      "Epoch 136/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5332e-04 - val_loss: 6.2368e-04\n",
      "Epoch 137/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5339e-04 - val_loss: 5.8066e-04\n",
      "Epoch 138/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4824e-04 - val_loss: 6.4681e-04\n",
      "Epoch 139/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5944e-04 - val_loss: 5.6454e-04\n",
      "Epoch 140/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6602e-04 - val_loss: 5.9220e-04\n",
      "Epoch 141/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4955e-04 - val_loss: 6.1451e-04\n",
      "Epoch 142/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6658e-04 - val_loss: 5.6946e-04\n",
      "Epoch 143/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5784e-04 - val_loss: 5.8694e-04\n",
      "Epoch 144/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5605e-04 - val_loss: 5.7374e-04\n",
      "Epoch 145/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5871e-04 - val_loss: 5.5208e-04\n",
      "Epoch 146/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5887e-04 - val_loss: 5.8410e-04\n",
      "Epoch 147/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5565e-04 - val_loss: 6.8474e-04\n",
      "Epoch 148/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6628e-04 - val_loss: 5.8596e-04\n",
      "Epoch 149/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5848e-04 - val_loss: 6.5255e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_48_layer_call_fn, lstm_cell_48_layer_call_and_return_conditional_losses, lstm_cell_49_layer_call_fn, lstm_cell_49_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 6s 69ms/step - loss: 0.0203 - val_loss: 0.0030\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0012 - val_loss: 6.2040e-04\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.9584e-04 - val_loss: 4.6298e-04\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4085e-04 - val_loss: 5.0989e-04\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1938e-04 - val_loss: 5.2126e-04\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1369e-04 - val_loss: 5.2656e-04\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0869e-04 - val_loss: 5.2289e-04\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0032e-04 - val_loss: 5.2120e-04\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0036e-04 - val_loss: 5.6265e-04\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9716e-04 - val_loss: 5.3966e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9749e-04 - val_loss: 5.4209e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9408e-04 - val_loss: 5.5234e-04\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9740e-04 - val_loss: 6.0193e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8946e-04 - val_loss: 5.8272e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8785e-04 - val_loss: 5.9248e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8836e-04 - val_loss: 5.7691e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9012e-04 - val_loss: 5.8717e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8656e-04 - val_loss: 6.3922e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8610e-04 - val_loss: 6.1508e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8155e-04 - val_loss: 6.3215e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8243e-04 - val_loss: 6.1680e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7957e-04 - val_loss: 6.3901e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8746e-04 - val_loss: 6.7519e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9209e-04 - val_loss: 6.6711e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8354e-04 - val_loss: 7.2511e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8317e-04 - val_loss: 7.0960e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8388e-04 - val_loss: 7.4176e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8612e-04 - val_loss: 6.9542e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0242e-04 - val_loss: 9.2366e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8208e-04 - val_loss: 7.0856e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8432e-04 - val_loss: 6.8104e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8114e-04 - val_loss: 6.7056e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8049e-04 - val_loss: 7.5038e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_50_layer_call_fn, lstm_cell_50_layer_call_and_return_conditional_losses, lstm_cell_51_layer_call_fn, lstm_cell_51_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 47ms/step - loss: 0.0351 - val_loss: 0.0234\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0015 - val_loss: 0.0106\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 9.7558e-04 - val_loss: 0.0091\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 8.0713e-04 - val_loss: 0.0083\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.7982e-04 - val_loss: 0.0073\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.7171e-04 - val_loss: 0.0066\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.9034e-04 - val_loss: 0.0057\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.3932e-04 - val_loss: 0.0048\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.1628e-04 - val_loss: 0.0051\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 3.9421e-04 - val_loss: 0.0039\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 3.7880e-04 - val_loss: 0.0035\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 3.7032e-04 - val_loss: 0.0028\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.6862e-04 - val_loss: 0.0023\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5074e-04 - val_loss: 0.0027\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4426e-04 - val_loss: 0.0023\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3379e-04 - val_loss: 0.0023\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3306e-04 - val_loss: 0.0022\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2887e-04 - val_loss: 0.0019\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2129e-04 - val_loss: 0.0014\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2034e-04 - val_loss: 0.0014\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3288e-04 - val_loss: 0.0011\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0643e-04 - val_loss: 0.0018\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1368e-04 - val_loss: 0.0013\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2441e-04 - val_loss: 9.5858e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1429e-04 - val_loss: 0.0011\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0747e-04 - val_loss: 8.8441e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9776e-04 - val_loss: 9.3234e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0441e-04 - val_loss: 7.2955e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9728e-04 - val_loss: 7.3553e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9380e-04 - val_loss: 9.3962e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1558e-04 - val_loss: 0.0010\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0293e-04 - val_loss: 8.0830e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1312e-04 - val_loss: 8.7538e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9219e-04 - val_loss: 7.9017e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8887e-04 - val_loss: 9.0738e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0024e-04 - val_loss: 8.2364e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9436e-04 - val_loss: 5.5729e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9204e-04 - val_loss: 6.2396e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9888e-04 - val_loss: 5.3650e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9290e-04 - val_loss: 6.3674e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9025e-04 - val_loss: 7.9315e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9991e-04 - val_loss: 7.8785e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9136e-04 - val_loss: 6.6987e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0381e-04 - val_loss: 6.5816e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8140e-04 - val_loss: 5.5746e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9133e-04 - val_loss: 7.1559e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8983e-04 - val_loss: 5.5650e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8690e-04 - val_loss: 6.4158e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9726e-04 - val_loss: 6.6240e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9848e-04 - val_loss: 7.2793e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8388e-04 - val_loss: 8.2416e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9586e-04 - val_loss: 7.4502e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8725e-04 - val_loss: 6.1882e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9754e-04 - val_loss: 5.3683e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8638e-04 - val_loss: 5.3337e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8506e-04 - val_loss: 5.9475e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8168e-04 - val_loss: 5.2647e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8318e-04 - val_loss: 5.2236e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1190e-04 - val_loss: 6.4209e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7914e-04 - val_loss: 5.3417e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8141e-04 - val_loss: 6.7459e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8223e-04 - val_loss: 6.0813e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8010e-04 - val_loss: 8.2932e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7854e-04 - val_loss: 5.6412e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7270e-04 - val_loss: 5.9198e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7946e-04 - val_loss: 5.6707e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8474e-04 - val_loss: 6.1862e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8459e-04 - val_loss: 5.1738e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7166e-04 - val_loss: 5.5499e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7834e-04 - val_loss: 5.2693e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7749e-04 - val_loss: 6.0043e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7854e-04 - val_loss: 5.3268e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8840e-04 - val_loss: 5.4661e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8538e-04 - val_loss: 7.1805e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7026e-04 - val_loss: 7.2821e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7959e-04 - val_loss: 5.4937e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7982e-04 - val_loss: 5.4825e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9260e-04 - val_loss: 5.9253e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7210e-04 - val_loss: 5.5778e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7459e-04 - val_loss: 6.2532e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6773e-04 - val_loss: 5.3119e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7319e-04 - val_loss: 7.7874e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7028e-04 - val_loss: 5.3328e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6866e-04 - val_loss: 5.3465e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6995e-04 - val_loss: 5.3554e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7566e-04 - val_loss: 4.9471e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6954e-04 - val_loss: 7.0125e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7083e-04 - val_loss: 5.3239e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7249e-04 - val_loss: 7.7734e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8097e-04 - val_loss: 5.3891e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6880e-04 - val_loss: 7.3144e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7801e-04 - val_loss: 6.9361e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8790e-04 - val_loss: 7.0279e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7818e-04 - val_loss: 6.1184e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7283e-04 - val_loss: 6.2370e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8211e-04 - val_loss: 5.4519e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7593e-04 - val_loss: 6.0521e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6017e-04 - val_loss: 5.4122e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6889e-04 - val_loss: 4.7806e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 2.7236e-04 - val_loss: 5.8106e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 2.8906e-04 - val_loss: 6.8040e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.7164e-04 - val_loss: 4.9595e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6636e-04 - val_loss: 5.2751e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7192e-04 - val_loss: 6.3180e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6002e-04 - val_loss: 6.8572e-04\n",
      "Epoch 106/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6370e-04 - val_loss: 5.4077e-04\n",
      "Epoch 107/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5906e-04 - val_loss: 5.3887e-04\n",
      "Epoch 108/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6199e-04 - val_loss: 5.1275e-04\n",
      "Epoch 109/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6280e-04 - val_loss: 6.6195e-04\n",
      "Epoch 110/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5771e-04 - val_loss: 5.7122e-04\n",
      "Epoch 111/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6748e-04 - val_loss: 6.7976e-04\n",
      "Epoch 112/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6351e-04 - val_loss: 6.1474e-04\n",
      "Epoch 113/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7669e-04 - val_loss: 6.0059e-04\n",
      "Epoch 114/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7252e-04 - val_loss: 5.6898e-04\n",
      "Epoch 115/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6478e-04 - val_loss: 6.9609e-04\n",
      "Epoch 116/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6834e-04 - val_loss: 4.9945e-04\n",
      "Epoch 117/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6943e-04 - val_loss: 6.9048e-04\n",
      "Epoch 118/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6289e-04 - val_loss: 5.3581e-04\n",
      "Epoch 119/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5518e-04 - val_loss: 5.3537e-04\n",
      "Epoch 120/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6583e-04 - val_loss: 7.2123e-04\n",
      "Epoch 121/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7084e-04 - val_loss: 5.7232e-04\n",
      "Epoch 122/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6194e-04 - val_loss: 7.6256e-04\n",
      "Epoch 123/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6937e-04 - val_loss: 5.9844e-04\n",
      "Epoch 124/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6507e-04 - val_loss: 7.5992e-04\n",
      "Epoch 125/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5981e-04 - val_loss: 5.8628e-04\n",
      "Epoch 126/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7856e-04 - val_loss: 5.5702e-04\n",
      "Epoch 127/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5713e-04 - val_loss: 6.9936e-04\n",
      "Epoch 128/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5748e-04 - val_loss: 5.6555e-04\n",
      "Epoch 129/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5381e-04 - val_loss: 6.5615e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_52_layer_call_fn, lstm_cell_52_layer_call_and_return_conditional_losses, lstm_cell_53_layer_call_fn, lstm_cell_53_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 48ms/step - loss: 0.0061 - val_loss: 0.0015\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 7.2753e-04 - val_loss: 0.0043\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.2770e-04 - val_loss: 0.0042\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.6894e-04 - val_loss: 0.0038\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.4391e-04 - val_loss: 0.0033\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.3514e-04 - val_loss: 0.0036\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2791e-04 - val_loss: 0.0044\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3192e-04 - val_loss: 0.0023\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1919e-04 - val_loss: 0.0022\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1198e-04 - val_loss: 0.0028\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0581e-04 - val_loss: 0.0025\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0965e-04 - val_loss: 0.0015\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9904e-04 - val_loss: 0.0014\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0379e-04 - val_loss: 0.0018\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9566e-04 - val_loss: 0.0015\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9341e-04 - val_loss: 0.0017\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0355e-04 - val_loss: 0.0013\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8462e-04 - val_loss: 8.5306e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9854e-04 - val_loss: 0.0010\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0357e-04 - val_loss: 0.0013\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9300e-04 - val_loss: 7.7393e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 2.8300e-04 - val_loss: 8.9155e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 2.8690e-04 - val_loss: 0.0011\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8827e-04 - val_loss: 0.0011\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8034e-04 - val_loss: 6.4230e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8495e-04 - val_loss: 7.4904e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8474e-04 - val_loss: 5.5378e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9179e-04 - val_loss: 8.4742e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9419e-04 - val_loss: 8.5051e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7865e-04 - val_loss: 6.6117e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7219e-04 - val_loss: 7.1123e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7593e-04 - val_loss: 6.9622e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8024e-04 - val_loss: 8.2450e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9239e-04 - val_loss: 7.0896e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6910e-04 - val_loss: 6.5090e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6830e-04 - val_loss: 7.0490e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 2.6693e-04 - val_loss: 8.3548e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 2.7164e-04 - val_loss: 6.8333e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.6757e-04 - val_loss: 7.2297e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8667e-04 - val_loss: 6.5858e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6790e-04 - val_loss: 6.8390e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7128e-04 - val_loss: 6.8403e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8525e-04 - val_loss: 6.2019e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8133e-04 - val_loss: 6.5394e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7168e-04 - val_loss: 6.8682e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6100e-04 - val_loss: 6.9668e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6367e-04 - val_loss: 6.6337e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6641e-04 - val_loss: 6.5574e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7150e-04 - val_loss: 6.7128e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7571e-04 - val_loss: 7.3860e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6814e-04 - val_loss: 6.5508e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7349e-04 - val_loss: 7.1236e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6477e-04 - val_loss: 7.0702e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6350e-04 - val_loss: 7.1213e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8368e-04 - val_loss: 6.9693e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6382e-04 - val_loss: 7.4590e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5942e-04 - val_loss: 7.3299e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_54_layer_call_fn, lstm_cell_54_layer_call_and_return_conditional_losses, lstm_cell_55_layer_call_fn, lstm_cell_55_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 47ms/step - loss: 0.0123 - val_loss: 0.0019\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 8.0653e-04 - val_loss: 0.0012\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.9952e-04 - val_loss: 6.0751e-04\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.9325e-04 - val_loss: 5.7029e-04\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.7092e-04 - val_loss: 4.7793e-04\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.6202e-04 - val_loss: 5.2409e-04\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4979e-04 - val_loss: 5.3048e-04\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5125e-04 - val_loss: 4.5943e-04\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4688e-04 - val_loss: 4.8541e-04\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3320e-04 - val_loss: 6.6161e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2051e-04 - val_loss: 4.5498e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1655e-04 - val_loss: 5.7509e-04\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1929e-04 - val_loss: 4.4075e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3008e-04 - val_loss: 6.2825e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1378e-04 - val_loss: 5.8906e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0822e-04 - val_loss: 5.4875e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0290e-04 - val_loss: 7.6124e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0881e-04 - val_loss: 6.6150e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0287e-04 - val_loss: 6.6473e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0410e-04 - val_loss: 5.0774e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0274e-04 - val_loss: 4.3874e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9966e-04 - val_loss: 8.9868e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0861e-04 - val_loss: 5.2485e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9199e-04 - val_loss: 5.0774e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9355e-04 - val_loss: 5.4870e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0808e-04 - val_loss: 5.2534e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9432e-04 - val_loss: 5.8161e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9824e-04 - val_loss: 5.6141e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8876e-04 - val_loss: 5.5140e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0770e-04 - val_loss: 4.3461e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9684e-04 - val_loss: 5.3156e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9053e-04 - val_loss: 9.2419e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9349e-04 - val_loss: 6.4136e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8927e-04 - val_loss: 6.7789e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8265e-04 - val_loss: 4.3608e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8479e-04 - val_loss: 6.3526e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9092e-04 - val_loss: 7.5148e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8602e-04 - val_loss: 4.8606e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8830e-04 - val_loss: 6.0028e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8170e-04 - val_loss: 7.2238e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9608e-04 - val_loss: 4.5315e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7776e-04 - val_loss: 5.5291e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8043e-04 - val_loss: 4.9958e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7577e-04 - val_loss: 4.9065e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8060e-04 - val_loss: 4.5709e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8919e-04 - val_loss: 6.4526e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7709e-04 - val_loss: 5.0093e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7707e-04 - val_loss: 4.8431e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7925e-04 - val_loss: 7.0722e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8471e-04 - val_loss: 7.1617e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8151e-04 - val_loss: 4.3411e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7876e-04 - val_loss: 7.8162e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8482e-04 - val_loss: 4.8912e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7117e-04 - val_loss: 4.8781e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7343e-04 - val_loss: 5.3371e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7576e-04 - val_loss: 4.5188e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7867e-04 - val_loss: 5.3378e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7036e-04 - val_loss: 5.8473e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7636e-04 - val_loss: 4.3388e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8442e-04 - val_loss: 5.4214e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7342e-04 - val_loss: 6.3969e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9647e-04 - val_loss: 4.4121e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7950e-04 - val_loss: 5.9635e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6947e-04 - val_loss: 7.2311e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7283e-04 - val_loss: 6.8172e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8164e-04 - val_loss: 4.7174e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9270e-04 - val_loss: 5.0444e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7095e-04 - val_loss: 5.8597e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8020e-04 - val_loss: 5.2712e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6853e-04 - val_loss: 0.0011\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6794e-04 - val_loss: 8.6469e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6342e-04 - val_loss: 5.9092e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6987e-04 - val_loss: 8.1680e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7828e-04 - val_loss: 7.9192e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7118e-04 - val_loss: 6.4939e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6342e-04 - val_loss: 5.5366e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6516e-04 - val_loss: 6.1436e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6706e-04 - val_loss: 5.7459e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5839e-04 - val_loss: 6.7521e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6474e-04 - val_loss: 8.3068e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6583e-04 - val_loss: 4.7014e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6052e-04 - val_loss: 5.1221e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6067e-04 - val_loss: 6.1992e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5630e-04 - val_loss: 6.9226e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5765e-04 - val_loss: 8.5268e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6130e-04 - val_loss: 9.4475e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6778e-04 - val_loss: 6.9378e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5455e-04 - val_loss: 8.4079e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7204e-04 - val_loss: 7.8216e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_56_layer_call_fn, lstm_cell_56_layer_call_and_return_conditional_losses, lstm_cell_57_layer_call_fn, lstm_cell_57_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 42ms/step - loss: 0.0202 - val_loss: 0.0027\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.1321e-04 - val_loss: 7.0558e-04\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.8502e-04 - val_loss: 7.9421e-04\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.1669e-04 - val_loss: 0.0010\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.7285e-04 - val_loss: 0.0011\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4545e-04 - val_loss: 0.0011\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3190e-04 - val_loss: 0.0012\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2096e-04 - val_loss: 0.0014\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2175e-04 - val_loss: 0.0014\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0679e-04 - val_loss: 0.0014\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0898e-04 - val_loss: 0.0014\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0622e-04 - val_loss: 0.0015\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0729e-04 - val_loss: 0.0015\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0114e-04 - val_loss: 0.0013\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0794e-04 - val_loss: 0.0014\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9415e-04 - val_loss: 0.0013\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0148e-04 - val_loss: 0.0014\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0402e-04 - val_loss: 0.0013\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0453e-04 - val_loss: 0.0014\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9219e-04 - val_loss: 0.0013\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0166e-04 - val_loss: 0.0013\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0853e-04 - val_loss: 0.0012\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9681e-04 - val_loss: 0.0014\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8735e-04 - val_loss: 0.0012\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9006e-04 - val_loss: 0.0012\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8929e-04 - val_loss: 0.0014\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8694e-04 - val_loss: 0.0012\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9093e-04 - val_loss: 0.0016\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9961e-04 - val_loss: 0.0012\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8758e-04 - val_loss: 0.0011\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2538e-04 - val_loss: 0.0011\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9172e-04 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_58_layer_call_fn, lstm_cell_58_layer_call_and_return_conditional_losses, lstm_cell_59_layer_call_fn, lstm_cell_59_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 47ms/step - loss: 0.0157 - val_loss: 0.0016\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0011 - val_loss: 6.4290e-04\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.4169e-04 - val_loss: 5.2822e-04\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.0140e-04 - val_loss: 6.4032e-04\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5812e-04 - val_loss: 7.2054e-04\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4419e-04 - val_loss: 7.5079e-04\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3030e-04 - val_loss: 7.5445e-04\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2452e-04 - val_loss: 8.4545e-04\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1931e-04 - val_loss: 0.0011\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1497e-04 - val_loss: 0.0012\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1527e-04 - val_loss: 8.8450e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0987e-04 - val_loss: 0.0012\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0589e-04 - val_loss: 0.0010\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0532e-04 - val_loss: 0.0010\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0196e-04 - val_loss: 8.0650e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1452e-04 - val_loss: 8.4637e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9461e-04 - val_loss: 9.7677e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9505e-04 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0057e-04 - val_loss: 0.0011\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0713e-04 - val_loss: 8.8690e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9145e-04 - val_loss: 0.0010\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9163e-04 - val_loss: 0.0011\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9066e-04 - val_loss: 8.9230e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0631e-04 - val_loss: 8.4727e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8542e-04 - val_loss: 0.0010\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8986e-04 - val_loss: 0.0013\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9125e-04 - val_loss: 0.0010\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8307e-04 - val_loss: 7.4955e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8842e-04 - val_loss: 8.3231e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8913e-04 - val_loss: 8.6433e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8676e-04 - val_loss: 9.0799e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8278e-04 - val_loss: 7.8182e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8797e-04 - val_loss: 9.2508e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_60_layer_call_fn, lstm_cell_60_layer_call_and_return_conditional_losses, lstm_cell_61_layer_call_fn, lstm_cell_61_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 43ms/step - loss: 0.0808 - val_loss: 0.0055\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0067 - val_loss: 0.0033\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.4497e-04 - val_loss: 0.0011\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.2042e-04 - val_loss: 0.0012\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5442e-04 - val_loss: 0.0013\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2939e-04 - val_loss: 0.0015\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2692e-04 - val_loss: 0.0014\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1202e-04 - val_loss: 0.0017\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0755e-04 - val_loss: 0.0013\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0617e-04 - val_loss: 0.0014\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0895e-04 - val_loss: 0.0015\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0325e-04 - val_loss: 0.0012\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0073e-04 - val_loss: 0.0013\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9838e-04 - val_loss: 8.9146e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0511e-04 - val_loss: 0.0015\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9255e-04 - val_loss: 0.0015\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9206e-04 - val_loss: 0.0012\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9781e-04 - val_loss: 9.6146e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8835e-04 - val_loss: 0.0012\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9347e-04 - val_loss: 0.0014\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9507e-04 - val_loss: 0.0011\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8787e-04 - val_loss: 0.0012\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8565e-04 - val_loss: 0.0010\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8744e-04 - val_loss: 0.0011\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8210e-04 - val_loss: 9.9628e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8071e-04 - val_loss: 9.2734e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9052e-04 - val_loss: 0.0012\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9094e-04 - val_loss: 0.0011\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8884e-04 - val_loss: 8.8717e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9017e-04 - val_loss: 0.0012\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8479e-04 - val_loss: 0.0010\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9368e-04 - val_loss: 0.0011\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8414e-04 - val_loss: 9.0326e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8106e-04 - val_loss: 6.0599e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8237e-04 - val_loss: 7.7061e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7638e-04 - val_loss: 8.0963e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7975e-04 - val_loss: 9.5044e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.7718e-04 - val_loss: 0.0011\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7719e-04 - val_loss: 7.7678e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8238e-04 - val_loss: 6.9213e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8027e-04 - val_loss: 7.7615e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7931e-04 - val_loss: 7.6390e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7690e-04 - val_loss: 6.5927e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7782e-04 - val_loss: 8.0101e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8111e-04 - val_loss: 7.5039e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7679e-04 - val_loss: 8.6256e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8339e-04 - val_loss: 6.8435e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7823e-04 - val_loss: 6.5626e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7516e-04 - val_loss: 9.2025e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7505e-04 - val_loss: 6.3385e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7769e-04 - val_loss: 5.7528e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8758e-04 - val_loss: 7.1730e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7426e-04 - val_loss: 5.7379e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7730e-04 - val_loss: 6.7243e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8082e-04 - val_loss: 8.7806e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7529e-04 - val_loss: 7.0739e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7583e-04 - val_loss: 7.3437e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7311e-04 - val_loss: 6.1344e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7808e-04 - val_loss: 6.9628e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8753e-04 - val_loss: 6.0471e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7270e-04 - val_loss: 7.2156e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7904e-04 - val_loss: 5.2269e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8239e-04 - val_loss: 7.2705e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7371e-04 - val_loss: 5.6785e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7257e-04 - val_loss: 6.9039e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7265e-04 - val_loss: 8.2992e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7069e-04 - val_loss: 6.1606e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7331e-04 - val_loss: 5.5948e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7471e-04 - val_loss: 6.5919e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7300e-04 - val_loss: 7.0512e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7192e-04 - val_loss: 4.8444e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7709e-04 - val_loss: 6.7816e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6870e-04 - val_loss: 8.2377e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7353e-04 - val_loss: 9.1324e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7259e-04 - val_loss: 6.0429e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7284e-04 - val_loss: 5.3830e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7458e-04 - val_loss: 5.1211e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7180e-04 - val_loss: 8.1033e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7035e-04 - val_loss: 6.2094e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7129e-04 - val_loss: 5.7888e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7056e-04 - val_loss: 7.2790e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7369e-04 - val_loss: 8.7556e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7439e-04 - val_loss: 5.2468e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6748e-04 - val_loss: 5.9347e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6639e-04 - val_loss: 6.4570e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7877e-04 - val_loss: 6.2995e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8063e-04 - val_loss: 6.5578e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7066e-04 - val_loss: 6.7243e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7109e-04 - val_loss: 4.9368e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7115e-04 - val_loss: 4.9671e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7681e-04 - val_loss: 6.0848e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7155e-04 - val_loss: 5.3299e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7014e-04 - val_loss: 5.5200e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6630e-04 - val_loss: 6.5648e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6926e-04 - val_loss: 7.0267e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7168e-04 - val_loss: 9.6229e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7611e-04 - val_loss: 6.2376e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6706e-04 - val_loss: 5.3195e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6563e-04 - val_loss: 5.9723e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7363e-04 - val_loss: 5.0150e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6612e-04 - val_loss: 5.2541e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_62_layer_call_fn, lstm_cell_62_layer_call_and_return_conditional_losses, lstm_cell_63_layer_call_fn, lstm_cell_63_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_11\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 48ms/step - loss: 0.0076 - val_loss: 0.0022\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.4559e-04 - val_loss: 0.0024\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.8286e-04 - val_loss: 0.0022\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.1536e-04 - val_loss: 0.0029\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.8691e-04 - val_loss: 0.0026\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5662e-04 - val_loss: 0.0019\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4066e-04 - val_loss: 0.0024\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 3.3341e-04 - val_loss: 0.0022\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 3.1964e-04 - val_loss: 0.0017\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1614e-04 - val_loss: 0.0018\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1323e-04 - val_loss: 0.0015\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2333e-04 - val_loss: 0.0020\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2289e-04 - val_loss: 0.0014\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0104e-04 - val_loss: 0.0018\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0230e-04 - val_loss: 0.0015\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9618e-04 - val_loss: 0.0018\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9473e-04 - val_loss: 9.6757e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2594e-04 - val_loss: 0.0014\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9859e-04 - val_loss: 0.0011\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8954e-04 - val_loss: 0.0011\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9560e-04 - val_loss: 7.7581e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8945e-04 - val_loss: 9.9226e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9031e-04 - val_loss: 8.5806e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8270e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8358e-04 - val_loss: 9.8646e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8512e-04 - val_loss: 0.0013\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9137e-04 - val_loss: 9.8873e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7790e-04 - val_loss: 0.0011\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8773e-04 - val_loss: 0.0011\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7924e-04 - val_loss: 0.0011\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8279e-04 - val_loss: 0.0011\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7368e-04 - val_loss: 0.0013\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9034e-04 - val_loss: 0.0014\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8215e-04 - val_loss: 0.0010\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8848e-04 - val_loss: 9.3192e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8420e-04 - val_loss: 8.7245e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8331e-04 - val_loss: 9.1321e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8062e-04 - val_loss: 0.0012\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7702e-04 - val_loss: 0.0014\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9330e-04 - val_loss: 0.0012\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8541e-04 - val_loss: 7.3658e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8450e-04 - val_loss: 0.0013\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7522e-04 - val_loss: 0.0011\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7641e-04 - val_loss: 0.0012\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6894e-04 - val_loss: 0.0010\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7857e-04 - val_loss: 0.0010\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7231e-04 - val_loss: 8.5050e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7125e-04 - val_loss: 0.0010\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7434e-04 - val_loss: 9.3867e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6717e-04 - val_loss: 0.0011\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6511e-04 - val_loss: 0.0010\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6392e-04 - val_loss: 0.0012\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6914e-04 - val_loss: 8.3000e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6718e-04 - val_loss: 0.0010\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7211e-04 - val_loss: 0.0011\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7332e-04 - val_loss: 0.0012\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7053e-04 - val_loss: 0.0011\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6919e-04 - val_loss: 9.3822e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7652e-04 - val_loss: 7.8951e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7055e-04 - val_loss: 9.0565e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7633e-04 - val_loss: 0.0011\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7880e-04 - val_loss: 0.0011\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7048e-04 - val_loss: 8.0284e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9191e-04 - val_loss: 0.0012\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7501e-04 - val_loss: 0.0012\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6385e-04 - val_loss: 0.0011\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7383e-04 - val_loss: 9.9357e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7288e-04 - val_loss: 0.0013\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7529e-04 - val_loss: 9.1896e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5954e-04 - val_loss: 0.0014\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6947e-04 - val_loss: 8.9419e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_64_layer_call_fn, lstm_cell_64_layer_call_and_return_conditional_losses, lstm_cell_65_layer_call_fn, lstm_cell_65_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_12\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 6s 48ms/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.9393e-04 - val_loss: 0.0019\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.4887e-04 - val_loss: 0.0019\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.9193e-04 - val_loss: 0.0017\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.6067e-04 - val_loss: 0.0015\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3920e-04 - val_loss: 0.0010\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3149e-04 - val_loss: 9.8337e-04\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2784e-04 - val_loss: 9.8076e-04\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1256e-04 - val_loss: 8.9822e-04\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2127e-04 - val_loss: 8.9143e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0320e-04 - val_loss: 8.5436e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0043e-04 - val_loss: 6.2908e-04\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0191e-04 - val_loss: 6.2419e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9485e-04 - val_loss: 7.4997e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1177e-04 - val_loss: 5.4342e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0226e-04 - val_loss: 6.4417e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9168e-04 - val_loss: 5.8120e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9041e-04 - val_loss: 7.7394e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9933e-04 - val_loss: 5.4481e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 2.9671e-04 - val_loss: 6.7393e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 2.8479e-04 - val_loss: 7.7634e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.8127e-04 - val_loss: 6.8424e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9011e-04 - val_loss: 6.6137e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7881e-04 - val_loss: 8.3850e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0206e-04 - val_loss: 5.0192e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9027e-04 - val_loss: 7.4951e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8032e-04 - val_loss: 4.8879e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8733e-04 - val_loss: 6.6104e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7425e-04 - val_loss: 7.0779e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8265e-04 - val_loss: 8.8068e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9052e-04 - val_loss: 5.2214e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8469e-04 - val_loss: 6.3477e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8942e-04 - val_loss: 8.0440e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9860e-04 - val_loss: 6.9576e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8862e-04 - val_loss: 6.2923e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7449e-04 - val_loss: 6.9085e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8044e-04 - val_loss: 5.8485e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8398e-04 - val_loss: 6.1627e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8132e-04 - val_loss: 5.8480e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7088e-04 - val_loss: 5.8899e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6831e-04 - val_loss: 5.6707e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7140e-04 - val_loss: 7.2875e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0555e-04 - val_loss: 6.4237e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7642e-04 - val_loss: 6.0632e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7880e-04 - val_loss: 6.3667e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7109e-04 - val_loss: 5.8061e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6884e-04 - val_loss: 7.0539e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7644e-04 - val_loss: 8.5876e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9086e-04 - val_loss: 7.7021e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6975e-04 - val_loss: 8.1223e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8498e-04 - val_loss: 7.0831e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6909e-04 - val_loss: 6.0652e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7837e-04 - val_loss: 6.4774e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6740e-04 - val_loss: 6.4516e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6111e-04 - val_loss: 6.5107e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6151e-04 - val_loss: 7.2071e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6151e-04 - val_loss: 6.4214e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_66_layer_call_fn, lstm_cell_66_layer_call_and_return_conditional_losses, lstm_cell_67_layer_call_fn, lstm_cell_67_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_13\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_13\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 47ms/step - loss: 0.0146 - val_loss: 0.0072\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 8.2316e-04 - val_loss: 0.0023\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.4869e-04 - val_loss: 0.0022\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.2930e-04 - val_loss: 0.0018\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.4697e-04 - val_loss: 0.0016\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.0075e-04 - val_loss: 0.0015\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.7657e-04 - val_loss: 0.0015\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.6110e-04 - val_loss: 0.0013\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5401e-04 - val_loss: 0.0013\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4589e-04 - val_loss: 0.0012\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4313e-04 - val_loss: 0.0010\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 3.4030e-04 - val_loss: 0.0011\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 3.3066e-04 - val_loss: 0.0010\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2922e-04 - val_loss: 0.0010\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2886e-04 - val_loss: 9.9205e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2102e-04 - val_loss: 9.6725e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2518e-04 - val_loss: 8.9179e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1361e-04 - val_loss: 8.7157e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1488e-04 - val_loss: 7.7385e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1136e-04 - val_loss: 9.9867e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0464e-04 - val_loss: 7.7070e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0247e-04 - val_loss: 7.6274e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0505e-04 - val_loss: 8.6996e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0118e-04 - val_loss: 7.9567e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9764e-04 - val_loss: 8.0391e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9833e-04 - val_loss: 8.0611e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0594e-04 - val_loss: 0.0011\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1195e-04 - val_loss: 7.2082e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0141e-04 - val_loss: 7.3817e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9744e-04 - val_loss: 8.3226e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9258e-04 - val_loss: 7.3886e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9323e-04 - val_loss: 8.4473e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9172e-04 - val_loss: 9.0348e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9474e-04 - val_loss: 7.3159e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8963e-04 - val_loss: 8.2308e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8644e-04 - val_loss: 8.2103e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8754e-04 - val_loss: 6.7344e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9101e-04 - val_loss: 7.4099e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8258e-04 - val_loss: 7.7141e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8292e-04 - val_loss: 6.3651e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8599e-04 - val_loss: 6.0707e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8583e-04 - val_loss: 6.3092e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8472e-04 - val_loss: 9.1634e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8722e-04 - val_loss: 5.9685e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8377e-04 - val_loss: 5.8249e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9339e-04 - val_loss: 6.9621e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9290e-04 - val_loss: 7.9435e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7946e-04 - val_loss: 5.4492e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8456e-04 - val_loss: 5.3690e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0274e-04 - val_loss: 9.1643e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7672e-04 - val_loss: 7.0016e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8118e-04 - val_loss: 7.5181e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7553e-04 - val_loss: 7.3566e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7903e-04 - val_loss: 6.8043e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8329e-04 - val_loss: 7.0774e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7572e-04 - val_loss: 8.6263e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7360e-04 - val_loss: 6.9231e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9256e-04 - val_loss: 7.1858e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7295e-04 - val_loss: 6.0714e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7210e-04 - val_loss: 7.4584e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6913e-04 - val_loss: 5.9236e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7941e-04 - val_loss: 8.5224e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8536e-04 - val_loss: 7.1755e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7021e-04 - val_loss: 6.5984e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7038e-04 - val_loss: 8.1581e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8090e-04 - val_loss: 6.9261e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7172e-04 - val_loss: 5.9467e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7472e-04 - val_loss: 7.0379e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7886e-04 - val_loss: 7.0551e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7824e-04 - val_loss: 6.3601e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7534e-04 - val_loss: 7.1172e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6326e-04 - val_loss: 5.7754e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 2.7121e-04 - val_loss: 8.6253e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 2.7077e-04 - val_loss: 7.1871e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.8551e-04 - val_loss: 7.4913e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6838e-04 - val_loss: 5.7378e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7804e-04 - val_loss: 7.3361e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6336e-04 - val_loss: 6.8188e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8038e-04 - val_loss: 5.9344e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_68_layer_call_fn, lstm_cell_68_layer_call_and_return_conditional_losses, lstm_cell_69_layer_call_fn, lstm_cell_69_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_14\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_14\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 48ms/step - loss: 0.0200 - val_loss: 0.0170\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0010 - val_loss: 0.0114\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.6868e-04 - val_loss: 0.0092\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.3111e-04 - val_loss: 0.0077\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.6076e-04 - val_loss: 0.0066\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.2973e-04 - val_loss: 0.0057\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.0804e-04 - val_loss: 0.0058\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.9035e-04 - val_loss: 0.0040\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.8510e-04 - val_loss: 0.0037\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.6418e-04 - val_loss: 0.0042\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5553e-04 - val_loss: 0.0030\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4597e-04 - val_loss: 0.0025\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4387e-04 - val_loss: 0.0028\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4124e-04 - val_loss: 0.0019\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2862e-04 - val_loss: 0.0015\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2358e-04 - val_loss: 0.0014\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1572e-04 - val_loss: 0.0016\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1146e-04 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1166e-04 - val_loss: 0.0012\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1588e-04 - val_loss: 0.0013\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0329e-04 - val_loss: 8.6625e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0357e-04 - val_loss: 7.8022e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0250e-04 - val_loss: 8.6167e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9831e-04 - val_loss: 0.0010\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9893e-04 - val_loss: 8.3153e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9502e-04 - val_loss: 4.7469e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0220e-04 - val_loss: 8.4651e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9567e-04 - val_loss: 7.2670e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0201e-04 - val_loss: 4.6215e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9139e-04 - val_loss: 6.6201e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0053e-04 - val_loss: 4.1906e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9362e-04 - val_loss: 5.7993e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9310e-04 - val_loss: 6.3093e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8667e-04 - val_loss: 5.2830e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9063e-04 - val_loss: 4.5730e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8367e-04 - val_loss: 5.8960e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9423e-04 - val_loss: 5.0700e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8532e-04 - val_loss: 5.4419e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9369e-04 - val_loss: 4.2390e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8151e-04 - val_loss: 7.5633e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9331e-04 - val_loss: 4.4742e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8939e-04 - val_loss: 4.0988e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8389e-04 - val_loss: 4.8324e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7980e-04 - val_loss: 3.9892e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7885e-04 - val_loss: 4.9592e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.7878e-04 - val_loss: 7.1961e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8927e-04 - val_loss: 5.5166e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7589e-04 - val_loss: 4.1509e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7712e-04 - val_loss: 4.1050e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7748e-04 - val_loss: 4.2733e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8508e-04 - val_loss: 6.3455e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8209e-04 - val_loss: 4.5349e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7587e-04 - val_loss: 4.4658e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7833e-04 - val_loss: 4.1163e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7224e-04 - val_loss: 6.4333e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7158e-04 - val_loss: 4.6364e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7045e-04 - val_loss: 5.1415e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8122e-04 - val_loss: 3.8992e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8723e-04 - val_loss: 4.2122e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7384e-04 - val_loss: 6.3089e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6984e-04 - val_loss: 5.0404e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7199e-04 - val_loss: 4.5993e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8000e-04 - val_loss: 5.5967e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6636e-04 - val_loss: 4.8177e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7923e-04 - val_loss: 4.2608e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7212e-04 - val_loss: 6.2699e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7452e-04 - val_loss: 6.1392e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9455e-04 - val_loss: 6.0032e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7545e-04 - val_loss: 6.0193e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8458e-04 - val_loss: 4.4688e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6734e-04 - val_loss: 4.6948e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7798e-04 - val_loss: 4.8942e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6701e-04 - val_loss: 5.0663e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6067e-04 - val_loss: 4.2929e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6368e-04 - val_loss: 4.4787e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6058e-04 - val_loss: 4.2841e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6628e-04 - val_loss: 5.1825e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5999e-04 - val_loss: 5.2580e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6779e-04 - val_loss: 4.4143e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6725e-04 - val_loss: 4.2879e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6244e-04 - val_loss: 4.2242e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6493e-04 - val_loss: 9.2048e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6958e-04 - val_loss: 4.1665e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6238e-04 - val_loss: 4.2267e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7030e-04 - val_loss: 4.4407e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5783e-04 - val_loss: 6.0919e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6543e-04 - val_loss: 4.0131e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6427e-04 - val_loss: 5.3871e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_70_layer_call_fn, lstm_cell_70_layer_call_and_return_conditional_losses, lstm_cell_71_layer_call_fn, lstm_cell_71_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_15\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_15\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 6s 77ms/step - loss: 0.0278 - val_loss: 0.0075\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0014 - val_loss: 0.0062\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.0010 - val_loss: 0.0049\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 8.4848e-04 - val_loss: 0.0046\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 6.8542e-04 - val_loss: 0.0038\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.5388e-04 - val_loss: 0.0043\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.6074e-04 - val_loss: 0.0037\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.1458e-04 - val_loss: 0.0038\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.8730e-04 - val_loss: 0.0031\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.7812e-04 - val_loss: 0.0035\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.6132e-04 - val_loss: 0.0019\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.6169e-04 - val_loss: 0.0027\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5529e-04 - val_loss: 0.0023\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4296e-04 - val_loss: 0.0022\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3844e-04 - val_loss: 0.0017\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2861e-04 - val_loss: 0.0022\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.2324e-04 - val_loss: 0.0019\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3257e-04 - val_loss: 0.0019\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1607e-04 - val_loss: 0.0019\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1448e-04 - val_loss: 0.0015\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.2049e-04 - val_loss: 0.0013\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0879e-04 - val_loss: 0.0011\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0629e-04 - val_loss: 0.0016\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0852e-04 - val_loss: 0.0011\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0568e-04 - val_loss: 0.0011\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0622e-04 - val_loss: 0.0012\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0421e-04 - val_loss: 0.0014\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0355e-04 - val_loss: 0.0012\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1678e-04 - val_loss: 8.2782e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9695e-04 - val_loss: 9.7427e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0081e-04 - val_loss: 8.3573e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9791e-04 - val_loss: 6.4710e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0528e-04 - val_loss: 9.5209e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8991e-04 - val_loss: 9.0979e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0396e-04 - val_loss: 8.4768e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8887e-04 - val_loss: 5.2148e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8561e-04 - val_loss: 6.3206e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8814e-04 - val_loss: 5.1600e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9477e-04 - val_loss: 4.8393e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8425e-04 - val_loss: 5.0546e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9622e-04 - val_loss: 4.5454e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8492e-04 - val_loss: 6.5928e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9216e-04 - val_loss: 4.6135e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8582e-04 - val_loss: 4.6614e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8440e-04 - val_loss: 4.3151e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8510e-04 - val_loss: 5.7404e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8096e-04 - val_loss: 5.1130e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8107e-04 - val_loss: 4.5527e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8066e-04 - val_loss: 4.4344e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7752e-04 - val_loss: 5.0970e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8776e-04 - val_loss: 4.6613e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8085e-04 - val_loss: 4.4491e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8343e-04 - val_loss: 4.6247e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7926e-04 - val_loss: 4.4810e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9626e-04 - val_loss: 5.7406e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8132e-04 - val_loss: 4.3690e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7585e-04 - val_loss: 4.6832e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8525e-04 - val_loss: 5.2011e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7714e-04 - val_loss: 4.3929e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8228e-04 - val_loss: 5.9735e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7980e-04 - val_loss: 4.8776e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7385e-04 - val_loss: 5.8111e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8389e-04 - val_loss: 5.7212e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7519e-04 - val_loss: 4.9771e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7305e-04 - val_loss: 4.7250e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9775e-04 - val_loss: 5.4281e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8346e-04 - val_loss: 5.9766e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7998e-04 - val_loss: 4.8296e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7447e-04 - val_loss: 4.5872e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7592e-04 - val_loss: 5.0945e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8037e-04 - val_loss: 5.9781e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9452e-04 - val_loss: 4.5380e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7582e-04 - val_loss: 4.4230e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7665e-04 - val_loss: 4.7901e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8302e-04 - val_loss: 4.5995e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_72_layer_call_fn, lstm_cell_72_layer_call_and_return_conditional_losses, lstm_cell_73_layer_call_fn, lstm_cell_73_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 49ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.5018e-04 - val_loss: 0.0016\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.6906e-04 - val_loss: 0.0021\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.4774e-04 - val_loss: 0.0014\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.1411e-04 - val_loss: 0.0011\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.7884e-04 - val_loss: 5.9104e-04\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.7270e-04 - val_loss: 5.6769e-04\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.5584e-04 - val_loss: 5.7986e-04\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3385e-04 - val_loss: 5.3243e-04\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4686e-04 - val_loss: 5.3304e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2212e-04 - val_loss: 5.3523e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.2592e-04 - val_loss: 5.0688e-04\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2240e-04 - val_loss: 4.9982e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1878e-04 - val_loss: 6.4463e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2909e-04 - val_loss: 5.0678e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0817e-04 - val_loss: 4.9838e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0889e-04 - val_loss: 7.1141e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0768e-04 - val_loss: 4.9904e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0482e-04 - val_loss: 4.9890e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0057e-04 - val_loss: 5.2237e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9640e-04 - val_loss: 5.0762e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9582e-04 - val_loss: 5.0583e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1842e-04 - val_loss: 7.7711e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0120e-04 - val_loss: 4.9135e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1502e-04 - val_loss: 5.5035e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0803e-04 - val_loss: 5.7615e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9191e-04 - val_loss: 5.1688e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9002e-04 - val_loss: 5.9914e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9809e-04 - val_loss: 5.1767e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8828e-04 - val_loss: 5.8038e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9945e-04 - val_loss: 4.9900e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9131e-04 - val_loss: 4.8830e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9540e-04 - val_loss: 4.8851e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8783e-04 - val_loss: 5.4697e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0257e-04 - val_loss: 4.8975e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9796e-04 - val_loss: 5.1039e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8569e-04 - val_loss: 4.9824e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9157e-04 - val_loss: 5.6401e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0976e-04 - val_loss: 5.1360e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8214e-04 - val_loss: 4.9561e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8917e-04 - val_loss: 4.8926e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8054e-04 - val_loss: 5.2804e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8175e-04 - val_loss: 4.8992e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8898e-04 - val_loss: 4.9572e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8148e-04 - val_loss: 6.1871e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7717e-04 - val_loss: 5.1668e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8476e-04 - val_loss: 5.2255e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9356e-04 - val_loss: 5.6595e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8334e-04 - val_loss: 5.1150e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9126e-04 - val_loss: 4.9542e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8589e-04 - val_loss: 4.7894e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8850e-04 - val_loss: 4.8240e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8212e-04 - val_loss: 5.0170e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8814e-04 - val_loss: 5.8075e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7398e-04 - val_loss: 5.5404e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7956e-04 - val_loss: 5.2257e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7457e-04 - val_loss: 5.2066e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7313e-04 - val_loss: 5.2371e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7599e-04 - val_loss: 5.2370e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6741e-04 - val_loss: 5.0177e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8107e-04 - val_loss: 4.9376e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7306e-04 - val_loss: 6.0942e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7786e-04 - val_loss: 5.4676e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8755e-04 - val_loss: 5.3867e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8502e-04 - val_loss: 5.1906e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7725e-04 - val_loss: 5.0124e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7877e-04 - val_loss: 5.1293e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6707e-04 - val_loss: 4.8252e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6959e-04 - val_loss: 4.7926e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6746e-04 - val_loss: 5.0112e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6400e-04 - val_loss: 7.1540e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7696e-04 - val_loss: 5.1973e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6338e-04 - val_loss: 5.0556e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7238e-04 - val_loss: 5.0566e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8676e-04 - val_loss: 4.8214e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6104e-04 - val_loss: 5.0589e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7159e-04 - val_loss: 5.0397e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7131e-04 - val_loss: 5.1196e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6510e-04 - val_loss: 5.4295e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6449e-04 - val_loss: 5.3030e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6857e-04 - val_loss: 5.0724e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_74_layer_call_fn, lstm_cell_74_layer_call_and_return_conditional_losses, lstm_cell_75_layer_call_fn, lstm_cell_75_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_17\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_17\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 5s 47ms/step - loss: 0.0076 - val_loss: 0.0040\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 8.9566e-04 - val_loss: 0.0020\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.3420e-04 - val_loss: 0.0012\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.2728e-04 - val_loss: 0.0011\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.5022e-04 - val_loss: 8.4952e-04\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.0310e-04 - val_loss: 8.8848e-04\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.7197e-04 - val_loss: 8.1989e-04\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.6048e-04 - val_loss: 7.5764e-04\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4272e-04 - val_loss: 9.4062e-04\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4290e-04 - val_loss: 9.2234e-04\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.3179e-04 - val_loss: 9.3454e-04\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 3.3277e-04 - val_loss: 7.4885e-04\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 3.2313e-04 - val_loss: 6.1706e-04\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2260e-04 - val_loss: 7.8889e-04\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1482e-04 - val_loss: 9.5784e-04\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1335e-04 - val_loss: 7.5229e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1733e-04 - val_loss: 9.2267e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0815e-04 - val_loss: 9.6790e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0346e-04 - val_loss: 8.2565e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0568e-04 - val_loss: 7.4477e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0318e-04 - val_loss: 0.0010\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0043e-04 - val_loss: 6.2164e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0028e-04 - val_loss: 7.6118e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9890e-04 - val_loss: 7.0889e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9196e-04 - val_loss: 7.6825e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9735e-04 - val_loss: 7.8045e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9650e-04 - val_loss: 7.1945e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9056e-04 - val_loss: 7.6170e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9157e-04 - val_loss: 9.0683e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9231e-04 - val_loss: 7.7511e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8619e-04 - val_loss: 8.8415e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8362e-04 - val_loss: 7.7916e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8464e-04 - val_loss: 7.5326e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8409e-04 - val_loss: 7.5822e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8584e-04 - val_loss: 6.0780e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8035e-04 - val_loss: 7.7415e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7830e-04 - val_loss: 6.5599e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8676e-04 - val_loss: 6.2112e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8907e-04 - val_loss: 6.9742e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8789e-04 - val_loss: 7.7625e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8306e-04 - val_loss: 6.4215e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8810e-04 - val_loss: 7.1144e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7817e-04 - val_loss: 6.6665e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7503e-04 - val_loss: 6.7336e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7725e-04 - val_loss: 8.2980e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7905e-04 - val_loss: 8.5742e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8047e-04 - val_loss: 7.6377e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7781e-04 - val_loss: 8.3137e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7623e-04 - val_loss: 6.1650e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7278e-04 - val_loss: 8.2980e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7080e-04 - val_loss: 7.9194e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7783e-04 - val_loss: 6.1872e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7446e-04 - val_loss: 6.4763e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8081e-04 - val_loss: 7.7262e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8023e-04 - val_loss: 6.9937e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7372e-04 - val_loss: 8.0513e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7565e-04 - val_loss: 6.4288e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8506e-04 - val_loss: 7.0904e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7652e-04 - val_loss: 6.4043e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7540e-04 - val_loss: 8.1958e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8605e-04 - val_loss: 8.3288e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6747e-04 - val_loss: 7.9673e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6977e-04 - val_loss: 5.7495e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8336e-04 - val_loss: 5.8604e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6372e-04 - val_loss: 8.2598e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6310e-04 - val_loss: 6.5468e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6619e-04 - val_loss: 0.0010\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7475e-04 - val_loss: 6.1546e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6842e-04 - val_loss: 7.2393e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6738e-04 - val_loss: 9.0582e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7001e-04 - val_loss: 6.1662e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6707e-04 - val_loss: 8.9044e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6833e-04 - val_loss: 7.4856e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6214e-04 - val_loss: 8.2448e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6792e-04 - val_loss: 6.6129e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6703e-04 - val_loss: 7.7572e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6513e-04 - val_loss: 5.5964e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6889e-04 - val_loss: 7.1355e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6661e-04 - val_loss: 8.0203e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6505e-04 - val_loss: 6.1550e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6398e-04 - val_loss: 9.8079e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7262e-04 - val_loss: 7.6623e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6560e-04 - val_loss: 7.4342e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6426e-04 - val_loss: 7.0204e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7289e-04 - val_loss: 8.8339e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6754e-04 - val_loss: 6.2492e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6401e-04 - val_loss: 8.3686e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6961e-04 - val_loss: 4.9857e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7303e-04 - val_loss: 6.5719e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6808e-04 - val_loss: 7.4945e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6341e-04 - val_loss: 5.7675e-04\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6150e-04 - val_loss: 5.0322e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6184e-04 - val_loss: 4.8524e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7083e-04 - val_loss: 6.9968e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6154e-04 - val_loss: 6.0914e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5341e-04 - val_loss: 6.7314e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.6183e-04 - val_loss: 6.8749e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 2.6528e-04 - val_loss: 7.3598e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.5975e-04 - val_loss: 7.5577e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.7019e-04 - val_loss: 6.8715e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.5572e-04 - val_loss: 7.9078e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.6032e-04 - val_loss: 7.4118e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.6489e-04 - val_loss: 6.0399e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 2.4958e-04 - val_loss: 6.9548e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 2.5506e-04 - val_loss: 9.2096e-04\n",
      "Epoch 106/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.6518e-04 - val_loss: 4.9321e-04\n",
      "Epoch 107/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.6514e-04 - val_loss: 7.4555e-04\n",
      "Epoch 108/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.5725e-04 - val_loss: 9.0265e-04\n",
      "Epoch 109/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.5678e-04 - val_loss: 7.0736e-04\n",
      "Epoch 110/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.4922e-04 - val_loss: 8.0901e-04\n",
      "Epoch 111/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.5067e-04 - val_loss: 6.1606e-04\n",
      "Epoch 112/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.5758e-04 - val_loss: 7.7346e-04\n",
      "Epoch 113/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.5422e-04 - val_loss: 8.8642e-04\n",
      "Epoch 114/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.5134e-04 - val_loss: 8.8809e-04\n",
      "Epoch 115/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.5030e-04 - val_loss: 7.2992e-04\n",
      "Epoch 116/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.6139e-04 - val_loss: 6.2368e-04\n",
      "Epoch 117/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.6506e-04 - val_loss: 8.5444e-04\n",
      "Epoch 118/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.6038e-04 - val_loss: 0.0013\n",
      "Epoch 119/2000\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 2.5557e-04 - val_loss: 6.5271e-04\n",
      "Epoch 120/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.4873e-04 - val_loss: 9.3968e-04\n",
      "Epoch 121/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.4798e-04 - val_loss: 6.7115e-04\n",
      "Epoch 122/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.4841e-04 - val_loss: 7.0906e-04\n",
      "Epoch 123/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 2.4147e-04 - val_loss: 8.0670e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_76_layer_call_fn, lstm_cell_76_layer_call_and_return_conditional_losses, lstm_cell_77_layer_call_fn, lstm_cell_77_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_18\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_18\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "46/46 [==============================] - 4s 38ms/step - loss: 0.0343 - val_loss: 0.0152\n",
      "Epoch 2/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 3/2000\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 4/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 6.5617e-04 - val_loss: 0.0017\n",
      "Epoch 5/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 5.0779e-04 - val_loss: 0.0019\n",
      "Epoch 6/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 4.4327e-04 - val_loss: 0.0015\n",
      "Epoch 7/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 4.0204e-04 - val_loss: 0.0013\n",
      "Epoch 8/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 3.7695e-04 - val_loss: 0.0014\n",
      "Epoch 9/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 3.5481e-04 - val_loss: 0.0011\n",
      "Epoch 10/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 3.4553e-04 - val_loss: 0.0013\n",
      "Epoch 11/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 3.3715e-04 - val_loss: 0.0010\n",
      "Epoch 12/2000\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 3.2994e-04 - val_loss: 0.0011\n",
      "Epoch 13/2000\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 3.2559e-04 - val_loss: 0.0010\n",
      "Epoch 14/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 3.2586e-04 - val_loss: 0.0011\n",
      "Epoch 15/2000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 3.3104e-04 - val_loss: 0.0011\n",
      "Epoch 16/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1667e-04 - val_loss: 8.5549e-04\n",
      "Epoch 17/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1191e-04 - val_loss: 7.6276e-04\n",
      "Epoch 18/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.1147e-04 - val_loss: 6.0402e-04\n",
      "Epoch 19/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1460e-04 - val_loss: 9.2294e-04\n",
      "Epoch 20/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1395e-04 - val_loss: 7.6078e-04\n",
      "Epoch 21/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2119e-04 - val_loss: 7.0046e-04\n",
      "Epoch 22/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2392e-04 - val_loss: 6.9675e-04\n",
      "Epoch 23/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0380e-04 - val_loss: 7.5607e-04\n",
      "Epoch 24/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0216e-04 - val_loss: 5.9629e-04\n",
      "Epoch 25/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9999e-04 - val_loss: 8.6001e-04\n",
      "Epoch 26/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9813e-04 - val_loss: 7.0268e-04\n",
      "Epoch 27/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0376e-04 - val_loss: 5.7687e-04\n",
      "Epoch 28/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9765e-04 - val_loss: 5.8925e-04\n",
      "Epoch 29/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0048e-04 - val_loss: 7.0824e-04\n",
      "Epoch 30/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9725e-04 - val_loss: 7.2523e-04\n",
      "Epoch 31/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0328e-04 - val_loss: 6.4850e-04\n",
      "Epoch 32/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0022e-04 - val_loss: 7.6328e-04\n",
      "Epoch 33/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9522e-04 - val_loss: 9.7432e-04\n",
      "Epoch 34/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0338e-04 - val_loss: 6.0130e-04\n",
      "Epoch 35/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9791e-04 - val_loss: 6.7892e-04\n",
      "Epoch 36/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0490e-04 - val_loss: 7.6010e-04\n",
      "Epoch 37/2000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.8788e-04 - val_loss: 7.0403e-04\n",
      "Epoch 38/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8800e-04 - val_loss: 5.4956e-04\n",
      "Epoch 39/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8723e-04 - val_loss: 6.0512e-04\n",
      "Epoch 40/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9159e-04 - val_loss: 7.9178e-04\n",
      "Epoch 41/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9535e-04 - val_loss: 5.4368e-04\n",
      "Epoch 42/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8891e-04 - val_loss: 5.0078e-04\n",
      "Epoch 43/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9520e-04 - val_loss: 6.4055e-04\n",
      "Epoch 44/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8709e-04 - val_loss: 5.7719e-04\n",
      "Epoch 45/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9086e-04 - val_loss: 7.7666e-04\n",
      "Epoch 46/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8375e-04 - val_loss: 4.9324e-04\n",
      "Epoch 47/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9035e-04 - val_loss: 6.6509e-04\n",
      "Epoch 48/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9057e-04 - val_loss: 6.2686e-04\n",
      "Epoch 49/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8231e-04 - val_loss: 5.7422e-04\n",
      "Epoch 50/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7899e-04 - val_loss: 6.4766e-04\n",
      "Epoch 51/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7906e-04 - val_loss: 5.1031e-04\n",
      "Epoch 52/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0450e-04 - val_loss: 5.1055e-04\n",
      "Epoch 53/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8614e-04 - val_loss: 5.9403e-04\n",
      "Epoch 54/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8937e-04 - val_loss: 7.1207e-04\n",
      "Epoch 55/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8059e-04 - val_loss: 5.9556e-04\n",
      "Epoch 56/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8398e-04 - val_loss: 6.0887e-04\n",
      "Epoch 57/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8264e-04 - val_loss: 5.2432e-04\n",
      "Epoch 58/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7759e-04 - val_loss: 5.2553e-04\n",
      "Epoch 59/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8594e-04 - val_loss: 8.4712e-04\n",
      "Epoch 60/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8563e-04 - val_loss: 4.7835e-04\n",
      "Epoch 61/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8494e-04 - val_loss: 4.5824e-04\n",
      "Epoch 62/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9562e-04 - val_loss: 6.6023e-04\n",
      "Epoch 63/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7998e-04 - val_loss: 4.6828e-04\n",
      "Epoch 64/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9659e-04 - val_loss: 6.4051e-04\n",
      "Epoch 65/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9099e-04 - val_loss: 4.9730e-04\n",
      "Epoch 66/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8276e-04 - val_loss: 4.8112e-04\n",
      "Epoch 67/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8347e-04 - val_loss: 7.4135e-04\n",
      "Epoch 68/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7614e-04 - val_loss: 6.9604e-04\n",
      "Epoch 69/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7511e-04 - val_loss: 5.7034e-04\n",
      "Epoch 70/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6872e-04 - val_loss: 6.9367e-04\n",
      "Epoch 71/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7055e-04 - val_loss: 5.4288e-04\n",
      "Epoch 72/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9778e-04 - val_loss: 5.0519e-04\n",
      "Epoch 73/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8133e-04 - val_loss: 5.8434e-04\n",
      "Epoch 74/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7147e-04 - val_loss: 6.1276e-04\n",
      "Epoch 75/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7726e-04 - val_loss: 5.2114e-04\n",
      "Epoch 76/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7106e-04 - val_loss: 6.5232e-04\n",
      "Epoch 77/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7956e-04 - val_loss: 6.6137e-04\n",
      "Epoch 78/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7766e-04 - val_loss: 4.4428e-04\n",
      "Epoch 79/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8180e-04 - val_loss: 7.6654e-04\n",
      "Epoch 80/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8482e-04 - val_loss: 5.8620e-04\n",
      "Epoch 81/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6761e-04 - val_loss: 6.2382e-04\n",
      "Epoch 82/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8200e-04 - val_loss: 5.1158e-04\n",
      "Epoch 83/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8108e-04 - val_loss: 6.2671e-04\n",
      "Epoch 84/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7376e-04 - val_loss: 6.1666e-04\n",
      "Epoch 85/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7122e-04 - val_loss: 6.4577e-04\n",
      "Epoch 86/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6757e-04 - val_loss: 5.3707e-04\n",
      "Epoch 87/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7182e-04 - val_loss: 5.8752e-04\n",
      "Epoch 88/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6576e-04 - val_loss: 7.1389e-04\n",
      "Epoch 89/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6598e-04 - val_loss: 5.1961e-04\n",
      "Epoch 90/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7551e-04 - val_loss: 6.6287e-04\n",
      "Epoch 91/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8718e-04 - val_loss: 0.0010\n",
      "Epoch 92/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9706e-04 - val_loss: 7.8194e-04\n",
      "Epoch 93/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7395e-04 - val_loss: 5.4445e-04\n",
      "Epoch 94/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6321e-04 - val_loss: 6.6647e-04\n",
      "Epoch 95/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6551e-04 - val_loss: 7.1400e-04\n",
      "Epoch 96/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7655e-04 - val_loss: 5.0881e-04\n",
      "Epoch 97/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6909e-04 - val_loss: 5.4193e-04\n",
      "Epoch 98/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6759e-04 - val_loss: 5.1315e-04\n",
      "Epoch 99/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6819e-04 - val_loss: 4.9598e-04\n",
      "Epoch 100/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6811e-04 - val_loss: 6.5055e-04\n",
      "Epoch 101/2000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 2.7317e-04 - val_loss: 6.1613e-04\n",
      "Epoch 102/2000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 2.6981e-04 - val_loss: 6.4278e-04\n",
      "Epoch 103/2000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.6960e-04 - val_loss: 7.4701e-04\n",
      "Epoch 104/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7862e-04 - val_loss: 5.7060e-04\n",
      "Epoch 105/2000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7699e-04 - val_loss: 7.2351e-04\n",
      "Epoch 106/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6641e-04 - val_loss: 5.9882e-04\n",
      "Epoch 107/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7111e-04 - val_loss: 6.7051e-04\n",
      "Epoch 108/2000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7027e-04 - val_loss: 5.2354e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_78_layer_call_fn, lstm_cell_78_layer_call_and_return_conditional_losses, lstm_cell_79_layer_call_fn, lstm_cell_79_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_19\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_memory = 100\n",
    "\n",
    "trainInputX, trainInputY = sf.prepareData(trainX, trainY, lstm_memory)\n",
    "testInputX, testInputY = sf.prepareData(testX, testY, lstm_memory)\n",
    "print(trainInputX.shape)\n",
    "print(trainInputY.shape)\n",
    "print(testInputX.shape)\n",
    "print(testInputY.shape)\n",
    "\n",
    "#validacao tamanho apos tratamentos\n",
    "print(len(trainX))\n",
    "print(len(trainInputX))\n",
    "\n",
    "print(len(trainY))\n",
    "print(len(trainInputY))\n",
    "\n",
    "trainInputX = trainInputX [:,:,0:14]\n",
    "testInputX = testInputX [:,:,0:14]\n",
    "print(trainInputX.shape)\n",
    "\n",
    "trained_models_lstm_100 = []\n",
    "trained_models_lstm_100_history = []\n",
    "\n",
    "for i in range(0,20):\n",
    "\n",
    "    #giving it reproducibility\n",
    "    seed = (i+1000)\n",
    "\n",
    "    os.environ['PYTHONHASHseed']=str(seed)\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    batch_size = 256\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "    \n",
    "    trained_models_lstm_100.append(kr.Sequential())\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_100[i].add(kr.layers.LSTM(14,return_sequences = True))\n",
    "    trained_models_lstm_100[i].add(kr.layers.LSTM(8))\n",
    "    # lstm_model.add(kr.layers.Simplelstm(5,input_shape=(trainInputX.shape[1],trainInputX.shape[2])))\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_100[i].add(kr.layers.Dense(1))\n",
    "    trained_models_lstm_100[i].compile(loss='mean_squared_error',optimizer='adam')\n",
    "    \n",
    "    trained_models_lstm_100_history.append(trained_models_lstm_100[i].fit(trainInputX, trainInputY, epochs=2000, batch_size=batch_size, verbose = 1, validation_data=(testInputX,testInputY),  callbacks=[callback]))\n",
    "    \n",
    "    trained_models_lstm_100[i].save('C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_100_batch_256_earlystop_valloss_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4958670c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11490, 200, 14)\n",
      "(11490,)\n",
      "(2723, 200, 14)\n",
      "(2723,)\n",
      "11690\n",
      "11490\n",
      "11690\n",
      "11490\n",
      "(11490, 200, 14)\n",
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 83ms/step - loss: 0.0482 - val_loss: 0.0028\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 7.3434e-04 - val_loss: 0.0032\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 5.6191e-04 - val_loss: 0.0037\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 4.9494e-04 - val_loss: 0.0041\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.5062e-04 - val_loss: 0.0038\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.1532e-04 - val_loss: 0.0035\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.9278e-04 - val_loss: 0.0030\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.7110e-04 - val_loss: 0.0029\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5244e-04 - val_loss: 0.0027\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.4517e-04 - val_loss: 0.0029\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.3660e-04 - val_loss: 0.0023\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2856e-04 - val_loss: 0.0021\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2473e-04 - val_loss: 0.0017\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.2103e-04 - val_loss: 0.0018\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2371e-04 - val_loss: 0.0018\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.1865e-04 - val_loss: 0.0011\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.1498e-04 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1554e-04 - val_loss: 0.0011\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.1920e-04 - val_loss: 0.0019\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.2206e-04 - val_loss: 0.0018\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0914e-04 - val_loss: 0.0011\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0632e-04 - val_loss: 6.4698e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1633e-04 - val_loss: 9.3678e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1145e-04 - val_loss: 0.0013\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2095e-04 - val_loss: 9.5977e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0500e-04 - val_loss: 8.7618e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.1363e-04 - val_loss: 7.1425e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.0241e-04 - val_loss: 7.9219e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1323e-04 - val_loss: 7.0880e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9826e-04 - val_loss: 6.0800e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.0008e-04 - val_loss: 7.2833e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.0342e-04 - val_loss: 7.0642e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9705e-04 - val_loss: 5.5885e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0270e-04 - val_loss: 5.4604e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0128e-04 - val_loss: 8.5859e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.0323e-04 - val_loss: 4.7936e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0104e-04 - val_loss: 6.8023e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9753e-04 - val_loss: 9.3216e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.9824e-04 - val_loss: 5.9492e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9531e-04 - val_loss: 3.8350e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.0304e-04 - val_loss: 6.4204e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9033e-04 - val_loss: 5.5487e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9149e-04 - val_loss: 7.7994e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0899e-04 - val_loss: 4.1068e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 66ms/step - loss: 2.9804e-04 - val_loss: 5.9350e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 68ms/step - loss: 2.9785e-04 - val_loss: 6.9623e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9628e-04 - val_loss: 5.8368e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0200e-04 - val_loss: 4.2209e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9066e-04 - val_loss: 4.9993e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9118e-04 - val_loss: 5.7901e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8861e-04 - val_loss: 5.8199e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9109e-04 - val_loss: 5.1582e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9360e-04 - val_loss: 4.7460e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8873e-04 - val_loss: 5.5605e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9234e-04 - val_loss: 4.4294e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8874e-04 - val_loss: 5.7576e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8580e-04 - val_loss: 3.9775e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9480e-04 - val_loss: 4.6391e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1890e-04 - val_loss: 4.5992e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9649e-04 - val_loss: 4.1238e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8990e-04 - val_loss: 4.7319e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8865e-04 - val_loss: 4.3648e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.9039e-04 - val_loss: 6.6852e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8961e-04 - val_loss: 7.2545e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8675e-04 - val_loss: 8.0598e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8776e-04 - val_loss: 4.7281e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8806e-04 - val_loss: 7.7735e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8281e-04 - val_loss: 5.3542e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9674e-04 - val_loss: 4.1704e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8559e-04 - val_loss: 3.6677e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8096e-04 - val_loss: 5.3663e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8021e-04 - val_loss: 5.1163e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8534e-04 - val_loss: 4.7153e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8457e-04 - val_loss: 5.2366e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.8255e-04 - val_loss: 4.6198e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8562e-04 - val_loss: 5.6605e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8631e-04 - val_loss: 4.5307e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7723e-04 - val_loss: 4.4894e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7591e-04 - val_loss: 5.8284e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7774e-04 - val_loss: 4.2824e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8298e-04 - val_loss: 6.3072e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.8625e-04 - val_loss: 5.7913e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7712e-04 - val_loss: 4.2041e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8634e-04 - val_loss: 4.2009e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8846e-04 - val_loss: 7.1012e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7592e-04 - val_loss: 3.7788e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7124e-04 - val_loss: 5.9979e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8578e-04 - val_loss: 7.5921e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.9619e-04 - val_loss: 6.2963e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.7624e-04 - val_loss: 3.8943e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7359e-04 - val_loss: 4.3761e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7560e-04 - val_loss: 4.3335e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7059e-04 - val_loss: 5.8904e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7566e-04 - val_loss: 3.5853e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9181e-04 - val_loss: 5.6454e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7634e-04 - val_loss: 5.2800e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7616e-04 - val_loss: 6.4921e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7483e-04 - val_loss: 4.5554e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7317e-04 - val_loss: 5.2164e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.7775e-04 - val_loss: 4.1195e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7438e-04 - val_loss: 6.1362e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7875e-04 - val_loss: 4.4203e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7296e-04 - val_loss: 3.6344e-04\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8417e-04 - val_loss: 3.9697e-04\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6822e-04 - val_loss: 6.1957e-04\n",
      "Epoch 107/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.7100e-04 - val_loss: 4.6748e-04\n",
      "Epoch 108/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7813e-04 - val_loss: 5.8864e-04\n",
      "Epoch 109/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6904e-04 - val_loss: 5.0136e-04\n",
      "Epoch 110/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.7163e-04 - val_loss: 4.3618e-04\n",
      "Epoch 111/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6530e-04 - val_loss: 4.7989e-04\n",
      "Epoch 112/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6659e-04 - val_loss: 3.8578e-04\n",
      "Epoch 113/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6582e-04 - val_loss: 4.0669e-04\n",
      "Epoch 114/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6955e-04 - val_loss: 4.5697e-04\n",
      "Epoch 115/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7186e-04 - val_loss: 4.6883e-04\n",
      "Epoch 116/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6607e-04 - val_loss: 4.1293e-04\n",
      "Epoch 117/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.6302e-04 - val_loss: 3.7193e-04\n",
      "Epoch 118/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7670e-04 - val_loss: 4.8474e-04\n",
      "Epoch 119/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7276e-04 - val_loss: 3.5943e-04\n",
      "Epoch 120/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7906e-04 - val_loss: 6.4974e-04\n",
      "Epoch 121/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7143e-04 - val_loss: 4.2541e-04\n",
      "Epoch 122/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7973e-04 - val_loss: 3.5697e-04\n",
      "Epoch 123/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7605e-04 - val_loss: 4.1202e-04\n",
      "Epoch 124/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.6556e-04 - val_loss: 4.1613e-04\n",
      "Epoch 125/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7167e-04 - val_loss: 4.7318e-04\n",
      "Epoch 126/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.7681e-04 - val_loss: 3.8149e-04\n",
      "Epoch 127/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8849e-04 - val_loss: 5.9668e-04\n",
      "Epoch 128/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7115e-04 - val_loss: 3.7007e-04\n",
      "Epoch 129/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8708e-04 - val_loss: 5.4168e-04\n",
      "Epoch 130/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6824e-04 - val_loss: 5.6963e-04\n",
      "Epoch 131/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.6611e-04 - val_loss: 6.6409e-04\n",
      "Epoch 132/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8101e-04 - val_loss: 3.8410e-04\n",
      "Epoch 133/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6604e-04 - val_loss: 4.6299e-04\n",
      "Epoch 134/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6219e-04 - val_loss: 3.9479e-04\n",
      "Epoch 135/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6102e-04 - val_loss: 3.7377e-04\n",
      "Epoch 136/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6646e-04 - val_loss: 4.0010e-04\n",
      "Epoch 137/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5911e-04 - val_loss: 4.3768e-04\n",
      "Epoch 138/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6115e-04 - val_loss: 3.7666e-04\n",
      "Epoch 139/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.6420e-04 - val_loss: 6.1727e-04\n",
      "Epoch 140/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6318e-04 - val_loss: 4.4630e-04\n",
      "Epoch 141/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.6759e-04 - val_loss: 4.2126e-04\n",
      "Epoch 142/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.7187e-04 - val_loss: 3.6719e-04\n",
      "Epoch 143/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5410e-04 - val_loss: 4.5028e-04\n",
      "Epoch 144/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.5604e-04 - val_loss: 3.7034e-04\n",
      "Epoch 145/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7000e-04 - val_loss: 3.9718e-04\n",
      "Epoch 146/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5363e-04 - val_loss: 3.7191e-04\n",
      "Epoch 147/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5766e-04 - val_loss: 4.3661e-04\n",
      "Epoch 148/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5664e-04 - val_loss: 4.0160e-04\n",
      "Epoch 149/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.6242e-04 - val_loss: 4.1044e-04\n",
      "Epoch 150/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5522e-04 - val_loss: 4.2024e-04\n",
      "Epoch 151/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5431e-04 - val_loss: 3.7243e-04\n",
      "Epoch 152/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5937e-04 - val_loss: 3.7882e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_80_layer_call_fn, lstm_cell_80_layer_call_and_return_conditional_losses, lstm_cell_81_layer_call_fn, lstm_cell_81_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 84ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 7.6563e-04 - val_loss: 0.0020\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.4216e-04 - val_loss: 0.0015\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.9245e-04 - val_loss: 0.0018\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5675e-04 - val_loss: 0.0010\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.5842e-04 - val_loss: 0.0017\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2828e-04 - val_loss: 0.0013\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.3301e-04 - val_loss: 0.0013\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.3468e-04 - val_loss: 0.0013\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2659e-04 - val_loss: 0.0014\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1643e-04 - val_loss: 0.0011\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1316e-04 - val_loss: 8.2261e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0528e-04 - val_loss: 0.0014\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1104e-04 - val_loss: 9.1173e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0452e-04 - val_loss: 0.0011\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1176e-04 - val_loss: 0.0010\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9959e-04 - val_loss: 7.7029e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0887e-04 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9119e-04 - val_loss: 8.6460e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8934e-04 - val_loss: 9.6305e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9068e-04 - val_loss: 0.0010\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0589e-04 - val_loss: 0.0011\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8739e-04 - val_loss: 7.4281e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8937e-04 - val_loss: 8.6085e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9505e-04 - val_loss: 0.0011\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8613e-04 - val_loss: 9.0128e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8126e-04 - val_loss: 8.9271e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8568e-04 - val_loss: 7.9779e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8787e-04 - val_loss: 7.2950e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8484e-04 - val_loss: 6.9434e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0088e-04 - val_loss: 7.6563e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8469e-04 - val_loss: 6.1945e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 2.8030e-04 - val_loss: 9.2320e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.7737e-04 - val_loss: 9.1762e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7893e-04 - val_loss: 9.6548e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8182e-04 - val_loss: 7.9565e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7416e-04 - val_loss: 7.1876e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7612e-04 - val_loss: 6.2617e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7074e-04 - val_loss: 7.0329e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7152e-04 - val_loss: 7.9543e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6904e-04 - val_loss: 6.4440e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7403e-04 - val_loss: 6.9789e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6918e-04 - val_loss: 8.7181e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7890e-04 - val_loss: 8.0165e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6882e-04 - val_loss: 8.1624e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7067e-04 - val_loss: 6.8527e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8072e-04 - val_loss: 7.4323e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6876e-04 - val_loss: 5.8679e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7872e-04 - val_loss: 8.2954e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6041e-04 - val_loss: 5.8699e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6435e-04 - val_loss: 6.8813e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7602e-04 - val_loss: 5.9269e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9876e-04 - val_loss: 5.9847e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8543e-04 - val_loss: 7.3059e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6891e-04 - val_loss: 6.9650e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6713e-04 - val_loss: 6.9443e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6059e-04 - val_loss: 6.5111e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5776e-04 - val_loss: 6.8608e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6402e-04 - val_loss: 5.4320e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6868e-04 - val_loss: 6.9928e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7772e-04 - val_loss: 8.3133e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6383e-04 - val_loss: 7.6721e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6944e-04 - val_loss: 6.6660e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6126e-04 - val_loss: 7.1612e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5646e-04 - val_loss: 6.0702e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5904e-04 - val_loss: 9.2789e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6502e-04 - val_loss: 7.9096e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5688e-04 - val_loss: 6.5348e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5027e-04 - val_loss: 6.4028e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6308e-04 - val_loss: 6.6557e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5602e-04 - val_loss: 8.1098e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6160e-04 - val_loss: 7.0197e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5773e-04 - val_loss: 8.5053e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6444e-04 - val_loss: 7.4272e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5642e-04 - val_loss: 5.9488e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7207e-04 - val_loss: 6.1282e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7561e-04 - val_loss: 8.6459e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5335e-04 - val_loss: 8.4597e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5502e-04 - val_loss: 9.4961e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6446e-04 - val_loss: 6.9378e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6019e-04 - val_loss: 9.1312e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6255e-04 - val_loss: 6.5123e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5523e-04 - val_loss: 6.9050e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.4994e-04 - val_loss: 6.6136e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.4953e-04 - val_loss: 7.8326e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5100e-04 - val_loss: 5.9224e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.4830e-04 - val_loss: 7.2681e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.4498e-04 - val_loss: 8.7654e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.4923e-04 - val_loss: 8.2460e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_82_layer_call_fn, lstm_cell_82_layer_call_and_return_conditional_losses, lstm_cell_83_layer_call_fn, lstm_cell_83_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 85ms/step - loss: 0.0398 - val_loss: 0.0107\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 7.6571e-04 - val_loss: 0.0019\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 5.8802e-04 - val_loss: 0.0013\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.9555e-04 - val_loss: 0.0014\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.4082e-04 - val_loss: 0.0011\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.0545e-04 - val_loss: 0.0013\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.7963e-04 - val_loss: 0.0010\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.6277e-04 - val_loss: 8.9736e-04\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5588e-04 - val_loss: 8.4467e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.4743e-04 - val_loss: 7.7470e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.3222e-04 - val_loss: 7.0578e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2783e-04 - val_loss: 6.7560e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2215e-04 - val_loss: 6.2071e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1673e-04 - val_loss: 6.2798e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1158e-04 - val_loss: 6.3184e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0977e-04 - val_loss: 6.6324e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0796e-04 - val_loss: 6.1083e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1053e-04 - val_loss: 7.5532e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0435e-04 - val_loss: 7.3367e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0727e-04 - val_loss: 7.8470e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9802e-04 - val_loss: 7.4740e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0524e-04 - val_loss: 6.4947e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9980e-04 - val_loss: 6.9641e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0978e-04 - val_loss: 8.5049e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0131e-04 - val_loss: 8.1958e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9446e-04 - val_loss: 8.7880e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0040e-04 - val_loss: 7.8239e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0005e-04 - val_loss: 7.1112e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9366e-04 - val_loss: 7.6742e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9213e-04 - val_loss: 7.1746e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9250e-04 - val_loss: 7.9784e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9514e-04 - val_loss: 7.5672e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 68ms/step - loss: 2.9748e-04 - val_loss: 6.7776e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 65ms/step - loss: 3.2667e-04 - val_loss: 6.1726e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9716e-04 - val_loss: 7.0520e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9744e-04 - val_loss: 5.3740e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9113e-04 - val_loss: 8.1846e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9770e-04 - val_loss: 5.9420e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8936e-04 - val_loss: 6.5107e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9427e-04 - val_loss: 4.3173e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9426e-04 - val_loss: 6.5278e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9082e-04 - val_loss: 8.6049e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9311e-04 - val_loss: 4.0507e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9506e-04 - val_loss: 8.6644e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9010e-04 - val_loss: 6.9005e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8649e-04 - val_loss: 4.0869e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9156e-04 - val_loss: 4.5618e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9111e-04 - val_loss: 7.1017e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8540e-04 - val_loss: 5.9930e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8387e-04 - val_loss: 5.8406e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8509e-04 - val_loss: 5.9235e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8531e-04 - val_loss: 7.0526e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8292e-04 - val_loss: 5.0296e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9271e-04 - val_loss: 5.1878e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8649e-04 - val_loss: 7.1135e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8981e-04 - val_loss: 5.9617e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9501e-04 - val_loss: 5.2918e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7800e-04 - val_loss: 5.0927e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7805e-04 - val_loss: 4.4639e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7659e-04 - val_loss: 4.9664e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8443e-04 - val_loss: 3.6256e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9042e-04 - val_loss: 7.9323e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8276e-04 - val_loss: 4.6010e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7543e-04 - val_loss: 5.7127e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8632e-04 - val_loss: 4.8417e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7576e-04 - val_loss: 3.6887e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9405e-04 - val_loss: 4.2986e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7995e-04 - val_loss: 4.9807e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8118e-04 - val_loss: 6.0298e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8178e-04 - val_loss: 3.6268e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.8477e-04 - val_loss: 4.9780e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7798e-04 - val_loss: 4.4154e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8096e-04 - val_loss: 7.2302e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7996e-04 - val_loss: 4.2743e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8002e-04 - val_loss: 3.8787e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8389e-04 - val_loss: 3.8777e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8205e-04 - val_loss: 5.6608e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8095e-04 - val_loss: 6.6039e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.9505e-04 - val_loss: 3.9036e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7302e-04 - val_loss: 4.4932e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7610e-04 - val_loss: 5.9697e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6858e-04 - val_loss: 5.3198e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7269e-04 - val_loss: 6.3275e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7297e-04 - val_loss: 5.5197e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6799e-04 - val_loss: 4.9489e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 3s 67ms/step - loss: 2.7496e-04 - val_loss: 6.5281e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 3s 68ms/step - loss: 2.7580e-04 - val_loss: 6.0028e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7545e-04 - val_loss: 4.1636e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7057e-04 - val_loss: 4.0792e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6589e-04 - val_loss: 4.9267e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7890e-04 - val_loss: 4.2482e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_84_layer_call_fn, lstm_cell_84_layer_call_and_return_conditional_losses, lstm_cell_85_layer_call_fn, lstm_cell_85_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 84ms/step - loss: 0.0506 - val_loss: 0.0148\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 0.0021 - val_loss: 0.0222\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 0.0013 - val_loss: 0.0179\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 9.8793e-04 - val_loss: 0.0176\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 7.9510e-04 - val_loss: 0.0130\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 6.4805e-04 - val_loss: 0.0134\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 5.4271e-04 - val_loss: 0.0109\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.9152e-04 - val_loss: 0.0094\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.4715e-04 - val_loss: 0.0078\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.1137e-04 - val_loss: 0.0067\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.8664e-04 - val_loss: 0.0055\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.7631e-04 - val_loss: 0.0044\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.5167e-04 - val_loss: 0.0040\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.4136e-04 - val_loss: 0.0035\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2815e-04 - val_loss: 0.0029\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1984e-04 - val_loss: 0.0029\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1451e-04 - val_loss: 0.0025\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0613e-04 - val_loss: 0.0022\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 3.1220e-04 - val_loss: 0.0028\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0378e-04 - val_loss: 0.0021\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9887e-04 - val_loss: 0.0015\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0743e-04 - val_loss: 0.0019\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0119e-04 - val_loss: 0.0011\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9677e-04 - val_loss: 0.0015\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9395e-04 - val_loss: 0.0012\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9080e-04 - val_loss: 0.0010\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8585e-04 - val_loss: 0.0012\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8666e-04 - val_loss: 0.0012\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9246e-04 - val_loss: 0.0014\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9104e-04 - val_loss: 0.0012\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8043e-04 - val_loss: 9.3139e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9109e-04 - val_loss: 8.2410e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9371e-04 - val_loss: 9.1579e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8982e-04 - val_loss: 0.0011\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8044e-04 - val_loss: 0.0012\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8087e-04 - val_loss: 0.0011\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8106e-04 - val_loss: 0.0011\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7806e-04 - val_loss: 7.6691e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8328e-04 - val_loss: 9.2256e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7879e-04 - val_loss: 9.6181e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7811e-04 - val_loss: 8.8360e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7896e-04 - val_loss: 9.5328e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8796e-04 - val_loss: 9.2096e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8031e-04 - val_loss: 0.0010\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8163e-04 - val_loss: 0.0010\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 69ms/step - loss: 2.8477e-04 - val_loss: 8.7373e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 66ms/step - loss: 2.7223e-04 - val_loss: 8.2706e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7445e-04 - val_loss: 7.3306e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8059e-04 - val_loss: 0.0010\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7073e-04 - val_loss: 7.6905e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7119e-04 - val_loss: 8.5655e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7313e-04 - val_loss: 8.0856e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7161e-04 - val_loss: 7.0080e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7097e-04 - val_loss: 8.5494e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7588e-04 - val_loss: 9.1568e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7127e-04 - val_loss: 9.1672e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6873e-04 - val_loss: 0.0011\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8211e-04 - val_loss: 8.6090e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7367e-04 - val_loss: 9.2912e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7136e-04 - val_loss: 7.0563e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6964e-04 - val_loss: 6.8053e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6848e-04 - val_loss: 9.0451e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6436e-04 - val_loss: 7.3535e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6376e-04 - val_loss: 9.7296e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6531e-04 - val_loss: 9.2186e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7347e-04 - val_loss: 6.0237e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7829e-04 - val_loss: 6.0697e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6969e-04 - val_loss: 7.4223e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6718e-04 - val_loss: 9.8487e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6832e-04 - val_loss: 7.5426e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7318e-04 - val_loss: 6.7421e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8130e-04 - val_loss: 7.3258e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6981e-04 - val_loss: 5.7170e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6938e-04 - val_loss: 8.7037e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7361e-04 - val_loss: 6.0636e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7904e-04 - val_loss: 9.8329e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6669e-04 - val_loss: 7.3521e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7312e-04 - val_loss: 6.8398e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6369e-04 - val_loss: 7.7049e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6899e-04 - val_loss: 6.8970e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.6741e-04 - val_loss: 0.0011\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6698e-04 - val_loss: 0.0013\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7630e-04 - val_loss: 6.2021e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7137e-04 - val_loss: 6.6217e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6400e-04 - val_loss: 9.1758e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6304e-04 - val_loss: 9.3712e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6552e-04 - val_loss: 6.9031e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6593e-04 - val_loss: 5.5599e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6641e-04 - val_loss: 7.7076e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6129e-04 - val_loss: 7.1568e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6768e-04 - val_loss: 8.5744e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5749e-04 - val_loss: 6.7606e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6423e-04 - val_loss: 5.6299e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6178e-04 - val_loss: 6.7038e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6535e-04 - val_loss: 5.6726e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6629e-04 - val_loss: 5.4634e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7719e-04 - val_loss: 4.6544e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5971e-04 - val_loss: 7.8524e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5868e-04 - val_loss: 5.2362e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5888e-04 - val_loss: 8.5660e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7620e-04 - val_loss: 5.2993e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6653e-04 - val_loss: 6.9771e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7815e-04 - val_loss: 6.9618e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6242e-04 - val_loss: 7.6885e-04\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6111e-04 - val_loss: 5.8776e-04\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9454e-04 - val_loss: 0.0012\n",
      "Epoch 107/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8413e-04 - val_loss: 8.8516e-04\n",
      "Epoch 108/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6297e-04 - val_loss: 7.8681e-04\n",
      "Epoch 109/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5281e-04 - val_loss: 7.9227e-04\n",
      "Epoch 110/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5591e-04 - val_loss: 6.9837e-04\n",
      "Epoch 111/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6294e-04 - val_loss: 5.3089e-04\n",
      "Epoch 112/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5626e-04 - val_loss: 0.0010\n",
      "Epoch 113/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5981e-04 - val_loss: 6.7671e-04\n",
      "Epoch 114/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5058e-04 - val_loss: 7.2911e-04\n",
      "Epoch 115/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.4846e-04 - val_loss: 7.4590e-04\n",
      "Epoch 116/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5104e-04 - val_loss: 6.6313e-04\n",
      "Epoch 117/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5415e-04 - val_loss: 6.8182e-04\n",
      "Epoch 118/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5233e-04 - val_loss: 6.1850e-04\n",
      "Epoch 119/2000\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 2.5728e-04 - val_loss: 9.0876e-04\n",
      "Epoch 120/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.4870e-04 - val_loss: 5.7446e-04\n",
      "Epoch 121/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5207e-04 - val_loss: 5.5628e-04\n",
      "Epoch 122/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8085e-04 - val_loss: 7.4559e-04\n",
      "Epoch 123/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.5182e-04 - val_loss: 8.7364e-04\n",
      "Epoch 124/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6431e-04 - val_loss: 6.2646e-04\n",
      "Epoch 125/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6599e-04 - val_loss: 5.8394e-04\n",
      "Epoch 126/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.5616e-04 - val_loss: 7.9209e-04\n",
      "Epoch 127/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5579e-04 - val_loss: 7.8713e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_86_layer_call_fn, lstm_cell_86_layer_call_and_return_conditional_losses, lstm_cell_87_layer_call_fn, lstm_cell_87_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 84ms/step - loss: 0.0449 - val_loss: 0.0262\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 0.0018 - val_loss: 0.0145\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 0.0010 - val_loss: 0.0079\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 7.5496e-04 - val_loss: 0.0061\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 6.0859e-04 - val_loss: 0.0039\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 5.0807e-04 - val_loss: 0.0025\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.3500e-04 - val_loss: 0.0015\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.8458e-04 - val_loss: 0.0012\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5252e-04 - val_loss: 0.0011\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.3847e-04 - val_loss: 0.0010\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2804e-04 - val_loss: 0.0011\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.3066e-04 - val_loss: 0.0011\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2045e-04 - val_loss: 8.3662e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.3521e-04 - val_loss: 9.1691e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1109e-04 - val_loss: 8.1762e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1291e-04 - val_loss: 7.9446e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0984e-04 - val_loss: 7.9031e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1075e-04 - val_loss: 7.3425e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0901e-04 - val_loss: 7.2534e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0394e-04 - val_loss: 6.7885e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0154e-04 - val_loss: 6.8980e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0334e-04 - val_loss: 7.0489e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9852e-04 - val_loss: 6.8397e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9889e-04 - val_loss: 6.3394e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9775e-04 - val_loss: 6.3111e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9903e-04 - val_loss: 6.2393e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9558e-04 - val_loss: 6.4869e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9904e-04 - val_loss: 6.3123e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9109e-04 - val_loss: 6.0500e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8962e-04 - val_loss: 7.0474e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9459e-04 - val_loss: 6.0238e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1083e-04 - val_loss: 5.9442e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8834e-04 - val_loss: 6.0643e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9106e-04 - val_loss: 5.9935e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8742e-04 - val_loss: 6.1436e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8988e-04 - val_loss: 7.2304e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9090e-04 - val_loss: 6.3452e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8515e-04 - val_loss: 5.7665e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8722e-04 - val_loss: 5.9457e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9255e-04 - val_loss: 6.0120e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8547e-04 - val_loss: 6.4168e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8796e-04 - val_loss: 5.7284e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9240e-04 - val_loss: 5.5442e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8278e-04 - val_loss: 5.6249e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9258e-04 - val_loss: 7.8307e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0263e-04 - val_loss: 5.4557e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9434e-04 - val_loss: 5.6822e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8845e-04 - val_loss: 5.9772e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9294e-04 - val_loss: 5.8196e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8294e-04 - val_loss: 5.7684e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8701e-04 - val_loss: 6.3225e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8766e-04 - val_loss: 5.5101e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8121e-04 - val_loss: 5.5814e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7951e-04 - val_loss: 5.5886e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9004e-04 - val_loss: 5.5951e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8091e-04 - val_loss: 5.1885e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8251e-04 - val_loss: 5.8928e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8228e-04 - val_loss: 5.1299e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7699e-04 - val_loss: 6.6529e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7666e-04 - val_loss: 6.4284e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8330e-04 - val_loss: 5.5195e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8322e-04 - val_loss: 5.2979e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7806e-04 - val_loss: 5.4583e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7923e-04 - val_loss: 6.9022e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7687e-04 - val_loss: 5.5068e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7925e-04 - val_loss: 5.8451e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8235e-04 - val_loss: 5.3428e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7879e-04 - val_loss: 5.5555e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7456e-04 - val_loss: 5.5154e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8617e-04 - val_loss: 5.0404e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7299e-04 - val_loss: 6.0607e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8338e-04 - val_loss: 5.9125e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7893e-04 - val_loss: 5.4492e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7116e-04 - val_loss: 5.3675e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6971e-04 - val_loss: 5.4212e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7249e-04 - val_loss: 5.1947e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6890e-04 - val_loss: 5.1160e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8182e-04 - val_loss: 5.2670e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8211e-04 - val_loss: 5.4568e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7885e-04 - val_loss: 4.9398e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 3s 66ms/step - loss: 2.8533e-04 - val_loss: 6.0852e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 3s 70ms/step - loss: 2.7218e-04 - val_loss: 5.5072e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7296e-04 - val_loss: 5.0510e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7057e-04 - val_loss: 5.2956e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7179e-04 - val_loss: 5.0342e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9594e-04 - val_loss: 4.9809e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.7646e-04 - val_loss: 5.7900e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7349e-04 - val_loss: 5.3700e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7278e-04 - val_loss: 5.5348e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7801e-04 - val_loss: 5.5156e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8760e-04 - val_loss: 5.6654e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7390e-04 - val_loss: 5.1611e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6817e-04 - val_loss: 5.6279e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6838e-04 - val_loss: 4.8562e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6912e-04 - val_loss: 5.3370e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6806e-04 - val_loss: 5.5846e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7138e-04 - val_loss: 6.1267e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7498e-04 - val_loss: 5.9498e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6811e-04 - val_loss: 5.4476e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7521e-04 - val_loss: 5.2291e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6111e-04 - val_loss: 5.1121e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6479e-04 - val_loss: 5.3560e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6843e-04 - val_loss: 5.1906e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6781e-04 - val_loss: 5.0155e-04\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5837e-04 - val_loss: 5.2228e-04\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6967e-04 - val_loss: 5.2879e-04\n",
      "Epoch 107/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6690e-04 - val_loss: 5.0604e-04\n",
      "Epoch 108/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6820e-04 - val_loss: 5.2655e-04\n",
      "Epoch 109/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5866e-04 - val_loss: 5.8501e-04\n",
      "Epoch 110/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6686e-04 - val_loss: 5.3472e-04\n",
      "Epoch 111/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6636e-04 - val_loss: 5.0503e-04\n",
      "Epoch 112/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6519e-04 - val_loss: 4.8579e-04\n",
      "Epoch 113/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6331e-04 - val_loss: 4.6481e-04\n",
      "Epoch 114/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7192e-04 - val_loss: 6.2355e-04\n",
      "Epoch 115/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6802e-04 - val_loss: 5.1371e-04\n",
      "Epoch 116/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6159e-04 - val_loss: 4.8833e-04\n",
      "Epoch 117/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6135e-04 - val_loss: 5.2377e-04\n",
      "Epoch 118/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6166e-04 - val_loss: 5.7626e-04\n",
      "Epoch 119/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7061e-04 - val_loss: 4.9066e-04\n",
      "Epoch 120/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6686e-04 - val_loss: 4.8263e-04\n",
      "Epoch 121/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.7042e-04 - val_loss: 5.9234e-04\n",
      "Epoch 122/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7845e-04 - val_loss: 4.9641e-04\n",
      "Epoch 123/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5835e-04 - val_loss: 4.9297e-04\n",
      "Epoch 124/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6812e-04 - val_loss: 4.7730e-04\n",
      "Epoch 125/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5872e-04 - val_loss: 5.0174e-04\n",
      "Epoch 126/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6159e-04 - val_loss: 4.8351e-04\n",
      "Epoch 127/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6340e-04 - val_loss: 5.3553e-04\n",
      "Epoch 128/2000\n",
      "45/45 [==============================] - 3s 67ms/step - loss: 2.6420e-04 - val_loss: 5.1306e-04\n",
      "Epoch 129/2000\n",
      "45/45 [==============================] - 3s 65ms/step - loss: 2.6832e-04 - val_loss: 5.5404e-04\n",
      "Epoch 130/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5722e-04 - val_loss: 4.4325e-04\n",
      "Epoch 131/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6711e-04 - val_loss: 4.5956e-04\n",
      "Epoch 132/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5827e-04 - val_loss: 5.0997e-04\n",
      "Epoch 133/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6193e-04 - val_loss: 4.6912e-04\n",
      "Epoch 134/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6233e-04 - val_loss: 5.4824e-04\n",
      "Epoch 135/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6824e-04 - val_loss: 5.4654e-04\n",
      "Epoch 136/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6224e-04 - val_loss: 5.0070e-04\n",
      "Epoch 137/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5281e-04 - val_loss: 5.0090e-04\n",
      "Epoch 138/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6533e-04 - val_loss: 5.2173e-04\n",
      "Epoch 139/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6292e-04 - val_loss: 5.5942e-04\n",
      "Epoch 140/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5819e-04 - val_loss: 5.0024e-04\n",
      "Epoch 141/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6306e-04 - val_loss: 5.0184e-04\n",
      "Epoch 142/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7206e-04 - val_loss: 5.1608e-04\n",
      "Epoch 143/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6803e-04 - val_loss: 4.7369e-04\n",
      "Epoch 144/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5200e-04 - val_loss: 4.9892e-04\n",
      "Epoch 145/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5314e-04 - val_loss: 4.8795e-04\n",
      "Epoch 146/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5639e-04 - val_loss: 6.0009e-04\n",
      "Epoch 147/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7561e-04 - val_loss: 5.4943e-04\n",
      "Epoch 148/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7366e-04 - val_loss: 5.2693e-04\n",
      "Epoch 149/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5287e-04 - val_loss: 4.9302e-04\n",
      "Epoch 150/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6559e-04 - val_loss: 5.7104e-04\n",
      "Epoch 151/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5330e-04 - val_loss: 5.1457e-04\n",
      "Epoch 152/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6797e-04 - val_loss: 5.4720e-04\n",
      "Epoch 153/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6221e-04 - val_loss: 5.1374e-04\n",
      "Epoch 154/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.4940e-04 - val_loss: 5.6643e-04\n",
      "Epoch 155/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5977e-04 - val_loss: 5.2667e-04\n",
      "Epoch 156/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6418e-04 - val_loss: 5.2861e-04\n",
      "Epoch 157/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6308e-04 - val_loss: 4.9643e-04\n",
      "Epoch 158/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5457e-04 - val_loss: 5.1026e-04\n",
      "Epoch 159/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.4637e-04 - val_loss: 4.9921e-04\n",
      "Epoch 160/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5121e-04 - val_loss: 4.9831e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_88_layer_call_fn, lstm_cell_88_layer_call_and_return_conditional_losses, lstm_cell_89_layer_call_fn, lstm_cell_89_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 84ms/step - loss: 0.0204 - val_loss: 0.0037\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 0.0012 - val_loss: 7.9390e-04\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 5.2343e-04 - val_loss: 4.2532e-04\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.4772e-04 - val_loss: 4.5752e-04\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2088e-04 - val_loss: 4.5925e-04\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1550e-04 - val_loss: 6.3306e-04\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1561e-04 - val_loss: 4.7264e-04\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0613e-04 - val_loss: 5.4428e-04\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1622e-04 - val_loss: 4.9902e-04\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0146e-04 - val_loss: 4.8402e-04\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9599e-04 - val_loss: 5.1261e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9690e-04 - val_loss: 5.2615e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9519e-04 - val_loss: 5.4753e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9226e-04 - val_loss: 5.2701e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9552e-04 - val_loss: 5.2794e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9383e-04 - val_loss: 5.7416e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9020e-04 - val_loss: 5.4382e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9042e-04 - val_loss: 5.6152e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8859e-04 - val_loss: 5.8841e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9634e-04 - val_loss: 5.5643e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8147e-04 - val_loss: 5.5188e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8806e-04 - val_loss: 5.6173e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 70ms/step - loss: 2.8571e-04 - val_loss: 6.1584e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 66ms/step - loss: 2.8576e-04 - val_loss: 5.9204e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8086e-04 - val_loss: 5.8927e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8315e-04 - val_loss: 5.9527e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8803e-04 - val_loss: 5.6955e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8399e-04 - val_loss: 5.8310e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8437e-04 - val_loss: 6.3085e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8658e-04 - val_loss: 6.3275e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7933e-04 - val_loss: 6.3499e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8188e-04 - val_loss: 6.5588e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9191e-04 - val_loss: 6.6517e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_90_layer_call_fn, lstm_cell_90_layer_call_and_return_conditional_losses, lstm_cell_91_layer_call_fn, lstm_cell_91_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 85ms/step - loss: 0.0343 - val_loss: 0.0214\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 0.0015 - val_loss: 0.0121\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 64ms/step - loss: 9.8649e-04 - val_loss: 0.0092\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 8.1190e-04 - val_loss: 0.0081\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 6.8772e-04 - val_loss: 0.0067\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 5.7607e-04 - val_loss: 0.0059\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.9299e-04 - val_loss: 0.0056\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.4731e-04 - val_loss: 0.0050\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.2578e-04 - val_loss: 0.0036\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.0219e-04 - val_loss: 0.0034\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.8431e-04 - val_loss: 0.0036\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.7522e-04 - val_loss: 0.0034\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.7096e-04 - val_loss: 0.0026\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.5604e-04 - val_loss: 0.0025\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.4631e-04 - val_loss: 0.0025\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.4049e-04 - val_loss: 0.0016\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.3395e-04 - val_loss: 0.0013\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.3178e-04 - val_loss: 0.0015\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.4277e-04 - val_loss: 0.0014\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2021e-04 - val_loss: 0.0015\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1551e-04 - val_loss: 0.0014\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1048e-04 - val_loss: 0.0012\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1948e-04 - val_loss: 0.0013\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 76ms/step - loss: 3.0892e-04 - val_loss: 0.0014\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 78ms/step - loss: 3.1232e-04 - val_loss: 9.4984e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0308e-04 - val_loss: 7.8958e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1437e-04 - val_loss: 9.7023e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9963e-04 - val_loss: 7.6251e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0119e-04 - val_loss: 0.0010\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0126e-04 - val_loss: 7.3835e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0188e-04 - val_loss: 6.9913e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9389e-04 - val_loss: 5.5255e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0583e-04 - val_loss: 6.3770e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9616e-04 - val_loss: 6.5470e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9385e-04 - val_loss: 6.8802e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9607e-04 - val_loss: 7.5120e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9266e-04 - val_loss: 7.7963e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9427e-04 - val_loss: 6.0830e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1236e-04 - val_loss: 6.3160e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9377e-04 - val_loss: 6.6561e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9166e-04 - val_loss: 5.4328e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8551e-04 - val_loss: 9.1012e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0499e-04 - val_loss: 6.5299e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8444e-04 - val_loss: 5.7480e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9059e-04 - val_loss: 5.3564e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8490e-04 - val_loss: 6.0430e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8955e-04 - val_loss: 4.9395e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8895e-04 - val_loss: 5.0037e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0402e-04 - val_loss: 8.7204e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8513e-04 - val_loss: 5.2562e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8354e-04 - val_loss: 6.8033e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8307e-04 - val_loss: 5.1945e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8069e-04 - val_loss: 5.0127e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.8205e-04 - val_loss: 6.0865e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.8172e-04 - val_loss: 4.6790e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 76ms/step - loss: 2.7821e-04 - val_loss: 5.0555e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 77ms/step - loss: 2.7984e-04 - val_loss: 4.8948e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 4s 78ms/step - loss: 2.7977e-04 - val_loss: 5.7049e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 4s 79ms/step - loss: 2.8018e-04 - val_loss: 5.4710e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 4s 78ms/step - loss: 2.9901e-04 - val_loss: 5.7878e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 78ms/step - loss: 2.7803e-04 - val_loss: 5.7251e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8096e-04 - val_loss: 5.4591e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7560e-04 - val_loss: 5.7150e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9408e-04 - val_loss: 4.8673e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8393e-04 - val_loss: 5.2019e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8331e-04 - val_loss: 6.9889e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7886e-04 - val_loss: 5.6167e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7881e-04 - val_loss: 4.7886e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7791e-04 - val_loss: 5.2368e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7585e-04 - val_loss: 6.3763e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9150e-04 - val_loss: 5.8804e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8764e-04 - val_loss: 4.9451e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7503e-04 - val_loss: 5.9965e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7270e-04 - val_loss: 4.8151e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7136e-04 - val_loss: 5.6261e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9248e-04 - val_loss: 5.4019e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7635e-04 - val_loss: 5.9167e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8278e-04 - val_loss: 5.3873e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8302e-04 - val_loss: 4.6091e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7605e-04 - val_loss: 5.6385e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7731e-04 - val_loss: 4.5186e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.8572e-04 - val_loss: 4.5522e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7071e-04 - val_loss: 4.9634e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9557e-04 - val_loss: 8.1180e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7529e-04 - val_loss: 5.1096e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7277e-04 - val_loss: 4.7858e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6762e-04 - val_loss: 5.6169e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8419e-04 - val_loss: 6.6469e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7248e-04 - val_loss: 4.8471e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6847e-04 - val_loss: 4.9241e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8033e-04 - val_loss: 6.6302e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7852e-04 - val_loss: 5.0527e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7644e-04 - val_loss: 4.9876e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8295e-04 - val_loss: 5.1833e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8247e-04 - val_loss: 6.2041e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6868e-04 - val_loss: 5.3354e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7168e-04 - val_loss: 6.7059e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6888e-04 - val_loss: 4.9843e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7740e-04 - val_loss: 5.9167e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7425e-04 - val_loss: 4.7983e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7988e-04 - val_loss: 5.1084e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7509e-04 - val_loss: 4.8408e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6677e-04 - val_loss: 4.8655e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6878e-04 - val_loss: 5.1940e-04\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6306e-04 - val_loss: 5.1781e-04\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6301e-04 - val_loss: 5.4765e-04\n",
      "Epoch 107/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7189e-04 - val_loss: 6.1336e-04\n",
      "Epoch 108/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7193e-04 - val_loss: 5.1028e-04\n",
      "Epoch 109/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6220e-04 - val_loss: 4.9778e-04\n",
      "Epoch 110/2000\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 2.6962e-04 - val_loss: 6.0524e-04\n",
      "Epoch 111/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8570e-04 - val_loss: 5.3244e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_92_layer_call_fn, lstm_cell_92_layer_call_and_return_conditional_losses, lstm_cell_93_layer_call_fn, lstm_cell_93_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 85ms/step - loss: 0.0061 - val_loss: 0.0014\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 7.5176e-04 - val_loss: 0.0044\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.4123e-04 - val_loss: 0.0035\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.7803e-04 - val_loss: 0.0044\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5515e-04 - val_loss: 0.0041\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.4313e-04 - val_loss: 0.0052\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.4044e-04 - val_loss: 0.0035\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2854e-04 - val_loss: 0.0040\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2125e-04 - val_loss: 0.0027\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1873e-04 - val_loss: 0.0021\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1582e-04 - val_loss: 0.0021\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0442e-04 - val_loss: 0.0025\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1687e-04 - val_loss: 0.0015\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2033e-04 - val_loss: 0.0021\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9925e-04 - val_loss: 0.0015\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9484e-04 - val_loss: 0.0014\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9197e-04 - val_loss: 0.0011\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0104e-04 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8870e-04 - val_loss: 9.5406e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8894e-04 - val_loss: 0.0012\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9798e-04 - val_loss: 0.0011\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9052e-04 - val_loss: 9.8694e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8757e-04 - val_loss: 0.0010\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8288e-04 - val_loss: 0.0011\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8800e-04 - val_loss: 9.0083e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8694e-04 - val_loss: 5.7597e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8972e-04 - val_loss: 6.8843e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7955e-04 - val_loss: 7.9441e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8602e-04 - val_loss: 6.3167e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7906e-04 - val_loss: 6.4984e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7895e-04 - val_loss: 7.7435e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8469e-04 - val_loss: 6.3931e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7876e-04 - val_loss: 5.9532e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7327e-04 - val_loss: 6.2028e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9936e-04 - val_loss: 5.3184e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7683e-04 - val_loss: 5.3684e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8153e-04 - val_loss: 5.7124e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7463e-04 - val_loss: 5.5453e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7205e-04 - val_loss: 6.9101e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7758e-04 - val_loss: 6.8335e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7838e-04 - val_loss: 5.5537e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7200e-04 - val_loss: 5.9766e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7827e-04 - val_loss: 6.0714e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7980e-04 - val_loss: 5.4552e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7325e-04 - val_loss: 6.2848e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6963e-04 - val_loss: 6.1056e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6473e-04 - val_loss: 5.7510e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7092e-04 - val_loss: 6.0619e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6625e-04 - val_loss: 6.2714e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7010e-04 - val_loss: 6.5540e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7162e-04 - val_loss: 6.3137e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6180e-04 - val_loss: 5.9449e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6348e-04 - val_loss: 5.7289e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6269e-04 - val_loss: 6.1984e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6273e-04 - val_loss: 6.3563e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7643e-04 - val_loss: 5.9187e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6252e-04 - val_loss: 5.9424e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7102e-04 - val_loss: 6.0767e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6745e-04 - val_loss: 6.4322e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7026e-04 - val_loss: 5.9468e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0400e-04 - val_loss: 6.2550e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7085e-04 - val_loss: 6.6346e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6490e-04 - val_loss: 6.6031e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5769e-04 - val_loss: 6.5188e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5686e-04 - val_loss: 6.4938e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_94_layer_call_fn, lstm_cell_94_layer_call_and_return_conditional_losses, lstm_cell_95_layer_call_fn, lstm_cell_95_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 83ms/step - loss: 0.0130 - val_loss: 0.0020\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 8.5303e-04 - val_loss: 0.0011\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 5.2622e-04 - val_loss: 5.8304e-04\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.0880e-04 - val_loss: 4.8443e-04\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.7280e-04 - val_loss: 4.7934e-04\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.7387e-04 - val_loss: 5.5362e-04\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.4668e-04 - val_loss: 4.4545e-04\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.3826e-04 - val_loss: 8.9343e-04\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 3.3715e-04 - val_loss: 6.0903e-04\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 70ms/step - loss: 3.2624e-04 - val_loss: 5.0261e-04\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.4086e-04 - val_loss: 5.2494e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.3620e-04 - val_loss: 4.4841e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1862e-04 - val_loss: 3.8755e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1393e-04 - val_loss: 4.0264e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1619e-04 - val_loss: 4.5954e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1526e-04 - val_loss: 5.7833e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1205e-04 - val_loss: 7.2230e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2156e-04 - val_loss: 3.9569e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0456e-04 - val_loss: 4.7896e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0359e-04 - val_loss: 4.8409e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0096e-04 - val_loss: 3.9179e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9710e-04 - val_loss: 4.0128e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0029e-04 - val_loss: 4.4818e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9706e-04 - val_loss: 5.6390e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0258e-04 - val_loss: 6.9990e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9831e-04 - val_loss: 4.1858e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9999e-04 - val_loss: 3.7736e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0127e-04 - val_loss: 4.5114e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9865e-04 - val_loss: 3.9696e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9889e-04 - val_loss: 5.5611e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0705e-04 - val_loss: 4.0068e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9462e-04 - val_loss: 4.9112e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8906e-04 - val_loss: 6.5855e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8654e-04 - val_loss: 4.8864e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8474e-04 - val_loss: 4.9041e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0028e-04 - val_loss: 7.2361e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9459e-04 - val_loss: 5.3206e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8962e-04 - val_loss: 5.5725e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8447e-04 - val_loss: 5.2937e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8538e-04 - val_loss: 5.5617e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8061e-04 - val_loss: 4.7778e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8047e-04 - val_loss: 4.7522e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8261e-04 - val_loss: 6.0241e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7627e-04 - val_loss: 5.4487e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8385e-04 - val_loss: 7.2449e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8566e-04 - val_loss: 4.6450e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8126e-04 - val_loss: 3.6987e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9159e-04 - val_loss: 5.5008e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8815e-04 - val_loss: 4.3634e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8166e-04 - val_loss: 4.9631e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8092e-04 - val_loss: 5.1647e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8411e-04 - val_loss: 7.0027e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8831e-04 - val_loss: 5.6751e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8923e-04 - val_loss: 3.7466e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7643e-04 - val_loss: 8.1687e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8684e-04 - val_loss: 5.7093e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7243e-04 - val_loss: 5.7000e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7019e-04 - val_loss: 5.6630e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7552e-04 - val_loss: 5.4905e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8099e-04 - val_loss: 6.4264e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7212e-04 - val_loss: 6.6164e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7034e-04 - val_loss: 5.1124e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8337e-04 - val_loss: 3.9506e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7289e-04 - val_loss: 4.6901e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7008e-04 - val_loss: 6.4706e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7942e-04 - val_loss: 5.6503e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6922e-04 - val_loss: 6.3632e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6946e-04 - val_loss: 6.0381e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7522e-04 - val_loss: 4.5324e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9222e-04 - val_loss: 9.8315e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6969e-04 - val_loss: 5.4980e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6611e-04 - val_loss: 6.5522e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8351e-04 - val_loss: 7.5509e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7780e-04 - val_loss: 8.2613e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6820e-04 - val_loss: 6.1086e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7487e-04 - val_loss: 5.8743e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6892e-04 - val_loss: 6.4352e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_96_layer_call_fn, lstm_cell_96_layer_call_and_return_conditional_losses, lstm_cell_97_layer_call_fn, lstm_cell_97_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 85ms/step - loss: 0.0202 - val_loss: 0.0023\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 6.2579e-04 - val_loss: 6.9240e-04\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.9436e-04 - val_loss: 7.4902e-04\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.2448e-04 - val_loss: 7.7962e-04\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.7164e-04 - val_loss: 0.0010\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.4686e-04 - val_loss: 0.0010\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.3242e-04 - val_loss: 0.0010\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1890e-04 - val_loss: 0.0011\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1576e-04 - val_loss: 0.0011\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1311e-04 - val_loss: 0.0010\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2215e-04 - val_loss: 0.0014\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0692e-04 - val_loss: 0.0012\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0304e-04 - val_loss: 0.0012\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9972e-04 - val_loss: 0.0011\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1039e-04 - val_loss: 0.0011\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1265e-04 - val_loss: 0.0015\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0735e-04 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9708e-04 - val_loss: 0.0011\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9429e-04 - val_loss: 0.0010\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0632e-04 - val_loss: 0.0010\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9198e-04 - val_loss: 0.0012\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0811e-04 - val_loss: 9.5233e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9962e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0838e-04 - val_loss: 9.6321e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9168e-04 - val_loss: 0.0011\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9640e-04 - val_loss: 9.9342e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9886e-04 - val_loss: 9.2420e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0205e-04 - val_loss: 0.0010\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8776e-04 - val_loss: 0.0011\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9932e-04 - val_loss: 0.0011\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9278e-04 - val_loss: 9.6805e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1400e-04 - val_loss: 9.6774e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_98_layer_call_fn, lstm_cell_98_layer_call_and_return_conditional_losses, lstm_cell_99_layer_call_fn, lstm_cell_99_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 85ms/step - loss: 0.0167 - val_loss: 0.0027\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 0.0012 - val_loss: 6.8101e-04\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 5.5960e-04 - val_loss: 4.8540e-04\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.1106e-04 - val_loss: 5.3767e-04\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.6431e-04 - val_loss: 6.7723e-04\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.5863e-04 - val_loss: 5.5617e-04\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.3408e-04 - val_loss: 8.6203e-04\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2918e-04 - val_loss: 8.2661e-04\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2300e-04 - val_loss: 8.1025e-04\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2088e-04 - val_loss: 8.7923e-04\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1707e-04 - val_loss: 9.3625e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 3.1295e-04 - val_loss: 8.1359e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1231e-04 - val_loss: 0.0011\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0834e-04 - val_loss: 8.2626e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 64ms/step - loss: 3.0483e-04 - val_loss: 0.0011\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0199e-04 - val_loss: 9.2771e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0073e-04 - val_loss: 9.8582e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0314e-04 - val_loss: 0.0010\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9752e-04 - val_loss: 8.9396e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.9484e-04 - val_loss: 0.0011\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9389e-04 - val_loss: 0.0011\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0211e-04 - val_loss: 0.0013\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0777e-04 - val_loss: 0.0010\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9250e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8972e-04 - val_loss: 9.3745e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8790e-04 - val_loss: 0.0010\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8654e-04 - val_loss: 9.1838e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8842e-04 - val_loss: 9.2249e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.9113e-04 - val_loss: 0.0010\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 3.0247e-04 - val_loss: 5.9133e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9424e-04 - val_loss: 7.4304e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8618e-04 - val_loss: 8.3331e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8567e-04 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_100_layer_call_fn, lstm_cell_100_layer_call_and_return_conditional_losses, lstm_cell_101_layer_call_fn, lstm_cell_101_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 85ms/step - loss: 0.0815 - val_loss: 0.0056\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 0.0072 - val_loss: 0.0039\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 6.8308e-04 - val_loss: 0.0011\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.4911e-04 - val_loss: 9.5763e-04\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.6578e-04 - val_loss: 0.0013\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.3599e-04 - val_loss: 0.0014\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2390e-04 - val_loss: 0.0016\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1905e-04 - val_loss: 0.0014\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1240e-04 - val_loss: 0.0011\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1318e-04 - val_loss: 0.0013\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0858e-04 - val_loss: 0.0012\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0818e-04 - val_loss: 0.0012\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0100e-04 - val_loss: 0.0015\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0020e-04 - val_loss: 9.5157e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0237e-04 - val_loss: 7.8353e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9797e-04 - val_loss: 0.0010\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0514e-04 - val_loss: 0.0013\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9957e-04 - val_loss: 0.0014\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9137e-04 - val_loss: 0.0013\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8927e-04 - val_loss: 0.0014\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8966e-04 - val_loss: 8.5817e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8929e-04 - val_loss: 7.7260e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8913e-04 - val_loss: 0.0013\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9707e-04 - val_loss: 9.6700e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9212e-04 - val_loss: 8.7679e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8793e-04 - val_loss: 9.1402e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8676e-04 - val_loss: 9.4426e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8491e-04 - val_loss: 8.3634e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8633e-04 - val_loss: 7.5466e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9040e-04 - val_loss: 9.5849e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8722e-04 - val_loss: 8.0787e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8222e-04 - val_loss: 0.0010\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8448e-04 - val_loss: 8.3543e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8498e-04 - val_loss: 8.8061e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8411e-04 - val_loss: 7.3602e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8335e-04 - val_loss: 8.2154e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 64ms/step - loss: 2.8147e-04 - val_loss: 7.9164e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 67ms/step - loss: 2.8424e-04 - val_loss: 7.1354e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8147e-04 - val_loss: 6.0331e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8474e-04 - val_loss: 7.8370e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7772e-04 - val_loss: 8.1274e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8075e-04 - val_loss: 6.3247e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8131e-04 - val_loss: 6.8185e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8179e-04 - val_loss: 5.7137e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8027e-04 - val_loss: 6.6993e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8298e-04 - val_loss: 7.4410e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8125e-04 - val_loss: 6.2570e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8258e-04 - val_loss: 6.7373e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7769e-04 - val_loss: 8.7927e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8790e-04 - val_loss: 5.6268e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7996e-04 - val_loss: 7.2392e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7856e-04 - val_loss: 5.6380e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8107e-04 - val_loss: 6.8635e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8482e-04 - val_loss: 5.7589e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8391e-04 - val_loss: 8.5063e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 76ms/step - loss: 2.8861e-04 - val_loss: 8.2332e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7901e-04 - val_loss: 5.8087e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7642e-04 - val_loss: 6.9251e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7801e-04 - val_loss: 6.0830e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7185e-04 - val_loss: 5.0238e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7345e-04 - val_loss: 6.5194e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8732e-04 - val_loss: 5.8841e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7335e-04 - val_loss: 5.9356e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8337e-04 - val_loss: 5.7280e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8027e-04 - val_loss: 6.2268e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7803e-04 - val_loss: 6.7890e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7546e-04 - val_loss: 5.9716e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7590e-04 - val_loss: 5.1744e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7642e-04 - val_loss: 5.6638e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7386e-04 - val_loss: 4.4519e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7866e-04 - val_loss: 4.8256e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8250e-04 - val_loss: 7.4223e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8039e-04 - val_loss: 5.2479e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7742e-04 - val_loss: 6.5644e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8011e-04 - val_loss: 5.5070e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8465e-04 - val_loss: 7.8089e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8200e-04 - val_loss: 4.5093e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9200e-04 - val_loss: 8.0499e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7263e-04 - val_loss: 5.7186e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7149e-04 - val_loss: 5.2758e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7353e-04 - val_loss: 4.7492e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7687e-04 - val_loss: 5.1422e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7325e-04 - val_loss: 4.9973e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7269e-04 - val_loss: 7.3879e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7604e-04 - val_loss: 5.5957e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7283e-04 - val_loss: 6.2840e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7484e-04 - val_loss: 4.8405e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6937e-04 - val_loss: 5.6649e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7204e-04 - val_loss: 4.6355e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7463e-04 - val_loss: 4.6314e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7060e-04 - val_loss: 4.5874e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7062e-04 - val_loss: 7.2120e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7440e-04 - val_loss: 5.5911e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7285e-04 - val_loss: 4.8539e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7029e-04 - val_loss: 6.8164e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6982e-04 - val_loss: 5.2429e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7072e-04 - val_loss: 4.9860e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7742e-04 - val_loss: 4.2437e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9071e-04 - val_loss: 6.7308e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 2.6987e-04 - val_loss: 4.7660e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7171e-04 - val_loss: 5.6506e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7507e-04 - val_loss: 5.2106e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7326e-04 - val_loss: 4.8032e-04\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6694e-04 - val_loss: 5.6312e-04\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6905e-04 - val_loss: 5.9573e-04\n",
      "Epoch 107/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6798e-04 - val_loss: 4.5765e-04\n",
      "Epoch 108/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6938e-04 - val_loss: 7.8477e-04\n",
      "Epoch 109/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6702e-04 - val_loss: 5.9775e-04\n",
      "Epoch 110/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7140e-04 - val_loss: 4.9072e-04\n",
      "Epoch 111/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7243e-04 - val_loss: 5.1948e-04\n",
      "Epoch 112/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6662e-04 - val_loss: 6.3884e-04\n",
      "Epoch 113/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7276e-04 - val_loss: 5.8020e-04\n",
      "Epoch 114/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7826e-04 - val_loss: 5.4284e-04\n",
      "Epoch 115/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6825e-04 - val_loss: 5.7290e-04\n",
      "Epoch 116/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6596e-04 - val_loss: 6.5527e-04\n",
      "Epoch 117/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6963e-04 - val_loss: 4.7571e-04\n",
      "Epoch 118/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6943e-04 - val_loss: 6.6754e-04\n",
      "Epoch 119/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6697e-04 - val_loss: 5.6935e-04\n",
      "Epoch 120/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7479e-04 - val_loss: 7.2970e-04\n",
      "Epoch 121/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7224e-04 - val_loss: 5.8487e-04\n",
      "Epoch 122/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6368e-04 - val_loss: 5.4980e-04\n",
      "Epoch 123/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6499e-04 - val_loss: 5.8714e-04\n",
      "Epoch 124/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6772e-04 - val_loss: 6.5985e-04\n",
      "Epoch 125/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6868e-04 - val_loss: 6.4007e-04\n",
      "Epoch 126/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7778e-04 - val_loss: 6.2911e-04\n",
      "Epoch 127/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7527e-04 - val_loss: 5.2591e-04\n",
      "Epoch 128/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6192e-04 - val_loss: 4.9092e-04\n",
      "Epoch 129/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6072e-04 - val_loss: 5.8062e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_102_layer_call_fn, lstm_cell_102_layer_call_and_return_conditional_losses, lstm_cell_103_layer_call_fn, lstm_cell_103_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_11\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 84ms/step - loss: 0.0078 - val_loss: 0.0025\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 6.5047e-04 - val_loss: 0.0028\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.8672e-04 - val_loss: 0.0020\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.1969e-04 - val_loss: 0.0023\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.8558e-04 - val_loss: 0.0024\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5470e-04 - val_loss: 0.0027\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.4509e-04 - val_loss: 0.0022\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 3.3557e-04 - val_loss: 0.0021\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2989e-04 - val_loss: 0.0019\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1860e-04 - val_loss: 0.0022\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2312e-04 - val_loss: 0.0016\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2003e-04 - val_loss: 0.0015\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1101e-04 - val_loss: 0.0011\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1127e-04 - val_loss: 0.0014\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0553e-04 - val_loss: 0.0017\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0482e-04 - val_loss: 0.0011\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9650e-04 - val_loss: 0.0011\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9168e-04 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1261e-04 - val_loss: 0.0012\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0328e-04 - val_loss: 7.9629e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9575e-04 - val_loss: 9.0896e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9294e-04 - val_loss: 8.2659e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0528e-04 - val_loss: 8.6357e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8901e-04 - val_loss: 7.7792e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8894e-04 - val_loss: 0.0012\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9467e-04 - val_loss: 0.0011\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8319e-04 - val_loss: 8.6082e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 70ms/step - loss: 2.7973e-04 - val_loss: 9.6225e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 65ms/step - loss: 2.8604e-04 - val_loss: 0.0011\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0021e-04 - val_loss: 8.1634e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8691e-04 - val_loss: 0.0010\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8229e-04 - val_loss: 9.6154e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8614e-04 - val_loss: 8.5888e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8622e-04 - val_loss: 9.9076e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8251e-04 - val_loss: 8.4934e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8198e-04 - val_loss: 0.0012\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7645e-04 - val_loss: 9.1060e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8346e-04 - val_loss: 8.2390e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8006e-04 - val_loss: 8.6786e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8211e-04 - val_loss: 0.0010\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7639e-04 - val_loss: 9.3180e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7658e-04 - val_loss: 8.7174e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8007e-04 - val_loss: 9.3262e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7197e-04 - val_loss: 0.0010\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7876e-04 - val_loss: 0.0010\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7099e-04 - val_loss: 0.0010\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8240e-04 - val_loss: 8.7711e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7091e-04 - val_loss: 9.7608e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6872e-04 - val_loss: 8.2950e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8520e-04 - val_loss: 9.1229e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7715e-04 - val_loss: 0.0012\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7182e-04 - val_loss: 9.2682e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6982e-04 - val_loss: 7.8470e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7221e-04 - val_loss: 9.5519e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_104_layer_call_fn, lstm_cell_104_layer_call_and_return_conditional_losses, lstm_cell_105_layer_call_fn, lstm_cell_105_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_12\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 84ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 6.2380e-04 - val_loss: 0.0026\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.5498e-04 - val_loss: 0.0021\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.9305e-04 - val_loss: 0.0016\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.6343e-04 - val_loss: 0.0017\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.4838e-04 - val_loss: 0.0012\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.3028e-04 - val_loss: 0.0010\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2410e-04 - val_loss: 7.6546e-04\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2485e-04 - val_loss: 0.0012\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1988e-04 - val_loss: 8.0507e-04\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0295e-04 - val_loss: 5.5351e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0713e-04 - val_loss: 6.6465e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0441e-04 - val_loss: 5.0415e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1302e-04 - val_loss: 6.0071e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0464e-04 - val_loss: 8.4950e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0270e-04 - val_loss: 8.2122e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9930e-04 - val_loss: 6.4292e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8938e-04 - val_loss: 6.3524e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0151e-04 - val_loss: 7.5893e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9087e-04 - val_loss: 6.7262e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9261e-04 - val_loss: 5.7436e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9962e-04 - val_loss: 7.0579e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9163e-04 - val_loss: 4.5559e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9276e-04 - val_loss: 6.9874e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8337e-04 - val_loss: 5.4171e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8218e-04 - val_loss: 5.0591e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7770e-04 - val_loss: 5.9113e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7778e-04 - val_loss: 5.4912e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7800e-04 - val_loss: 6.4677e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8271e-04 - val_loss: 4.7814e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9907e-04 - val_loss: 7.8279e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9184e-04 - val_loss: 6.6508e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8203e-04 - val_loss: 5.2874e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9328e-04 - val_loss: 6.3913e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7987e-04 - val_loss: 6.1009e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8759e-04 - val_loss: 4.9265e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8018e-04 - val_loss: 5.3491e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7396e-04 - val_loss: 6.6733e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7613e-04 - val_loss: 6.3401e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7783e-04 - val_loss: 5.6135e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7471e-04 - val_loss: 5.1862e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8022e-04 - val_loss: 6.5042e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7218e-04 - val_loss: 7.1478e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7072e-04 - val_loss: 5.3488e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0414e-04 - val_loss: 6.5677e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7298e-04 - val_loss: 5.5602e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7406e-04 - val_loss: 5.9372e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8552e-04 - val_loss: 5.2774e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6430e-04 - val_loss: 6.2944e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6455e-04 - val_loss: 5.9282e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7092e-04 - val_loss: 7.0486e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7549e-04 - val_loss: 5.7398e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6490e-04 - val_loss: 5.2775e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_106_layer_call_fn, lstm_cell_106_layer_call_and_return_conditional_losses, lstm_cell_107_layer_call_fn, lstm_cell_107_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_13\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_13\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 84ms/step - loss: 0.0144 - val_loss: 0.0072\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 8.3180e-04 - val_loss: 0.0015\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 6.5158e-04 - val_loss: 0.0015\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 5.3648e-04 - val_loss: 0.0012\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.5253e-04 - val_loss: 0.0011\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.0653e-04 - val_loss: 0.0011\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.8792e-04 - val_loss: 9.6317e-04\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.6863e-04 - val_loss: 0.0011\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5959e-04 - val_loss: 8.9317e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.5329e-04 - val_loss: 8.6021e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.4637e-04 - val_loss: 8.7002e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 65ms/step - loss: 3.3970e-04 - val_loss: 9.5353e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.3548e-04 - val_loss: 7.4789e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2895e-04 - val_loss: 9.6761e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2862e-04 - val_loss: 7.0078e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2778e-04 - val_loss: 7.2382e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2728e-04 - val_loss: 7.3398e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2008e-04 - val_loss: 8.7945e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1661e-04 - val_loss: 7.9647e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1424e-04 - val_loss: 9.9060e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1525e-04 - val_loss: 9.8491e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1427e-04 - val_loss: 0.0010\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1091e-04 - val_loss: 8.1755e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0487e-04 - val_loss: 7.5218e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0112e-04 - val_loss: 7.3663e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0532e-04 - val_loss: 7.6895e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0403e-04 - val_loss: 6.0171e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0374e-04 - val_loss: 0.0010\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0555e-04 - val_loss: 7.2598e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0148e-04 - val_loss: 5.6350e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0616e-04 - val_loss: 7.3500e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9288e-04 - val_loss: 6.4692e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9815e-04 - val_loss: 5.2591e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9992e-04 - val_loss: 8.4678e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0238e-04 - val_loss: 7.0549e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9105e-04 - val_loss: 6.2618e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9757e-04 - val_loss: 7.5205e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9480e-04 - val_loss: 5.9435e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9325e-04 - val_loss: 6.7466e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8886e-04 - val_loss: 5.8103e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9263e-04 - val_loss: 6.0868e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1099e-04 - val_loss: 6.5366e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9017e-04 - val_loss: 5.2744e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8914e-04 - val_loss: 7.4688e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8435e-04 - val_loss: 6.5354e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9092e-04 - val_loss: 6.5491e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8563e-04 - val_loss: 5.1848e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.7983e-04 - val_loss: 6.2525e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.8861e-04 - val_loss: 7.8387e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9769e-04 - val_loss: 5.4868e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7980e-04 - val_loss: 6.0580e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8558e-04 - val_loss: 7.4236e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8361e-04 - val_loss: 5.9130e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7783e-04 - val_loss: 6.7559e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8178e-04 - val_loss: 6.7802e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7886e-04 - val_loss: 8.3421e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7811e-04 - val_loss: 8.1888e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7784e-04 - val_loss: 5.6213e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7472e-04 - val_loss: 7.4517e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8001e-04 - val_loss: 6.5107e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7479e-04 - val_loss: 6.6842e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7369e-04 - val_loss: 7.1455e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7796e-04 - val_loss: 5.9362e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8261e-04 - val_loss: 5.0532e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7650e-04 - val_loss: 6.3367e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7390e-04 - val_loss: 5.5528e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7751e-04 - val_loss: 5.8401e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7635e-04 - val_loss: 5.8018e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7419e-04 - val_loss: 5.1893e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8447e-04 - val_loss: 7.6141e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7275e-04 - val_loss: 6.3815e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6862e-04 - val_loss: 5.3336e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7453e-04 - val_loss: 7.8755e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8015e-04 - val_loss: 7.1063e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7281e-04 - val_loss: 5.7364e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6906e-04 - val_loss: 6.0074e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6762e-04 - val_loss: 6.6328e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7041e-04 - val_loss: 6.4709e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6793e-04 - val_loss: 6.9702e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6680e-04 - val_loss: 5.4994e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7192e-04 - val_loss: 5.7288e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6854e-04 - val_loss: 5.4889e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8290e-04 - val_loss: 5.5897e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7186e-04 - val_loss: 7.9704e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7103e-04 - val_loss: 7.1953e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8123e-04 - val_loss: 5.7884e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6718e-04 - val_loss: 6.2087e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6420e-04 - val_loss: 6.7361e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7448e-04 - val_loss: 7.1924e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9370e-04 - val_loss: 6.2580e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9242e-04 - val_loss: 6.3194e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6890e-04 - val_loss: 5.6294e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6797e-04 - val_loss: 6.1809e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6184e-04 - val_loss: 6.2572e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_108_layer_call_fn, lstm_cell_108_layer_call_and_return_conditional_losses, lstm_cell_109_layer_call_fn, lstm_cell_109_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_14\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_14\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 85ms/step - loss: 0.0201 - val_loss: 0.0155\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 0.0010 - val_loss: 0.0095\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 6.9548e-04 - val_loss: 0.0077\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 5.5323e-04 - val_loss: 0.0077\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.7957e-04 - val_loss: 0.0067\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.3472e-04 - val_loss: 0.0060\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.0938e-04 - val_loss: 0.0049\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.0904e-04 - val_loss: 0.0039\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.8637e-04 - val_loss: 0.0038\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.6666e-04 - val_loss: 0.0032\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.6795e-04 - val_loss: 0.0029\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5003e-04 - val_loss: 0.0033\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.4276e-04 - val_loss: 0.0021\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.3851e-04 - val_loss: 0.0019\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2931e-04 - val_loss: 0.0016\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2403e-04 - val_loss: 0.0015\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1792e-04 - val_loss: 0.0011\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2161e-04 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1895e-04 - val_loss: 7.8433e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1033e-04 - val_loss: 9.1137e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1014e-04 - val_loss: 7.1786e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0858e-04 - val_loss: 9.0380e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0681e-04 - val_loss: 8.0660e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0542e-04 - val_loss: 7.8943e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0731e-04 - val_loss: 6.2321e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0148e-04 - val_loss: 5.1871e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0713e-04 - val_loss: 5.3997e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9653e-04 - val_loss: 5.5263e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0849e-04 - val_loss: 4.9502e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0467e-04 - val_loss: 6.1368e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9493e-04 - val_loss: 4.2379e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0165e-04 - val_loss: 5.5849e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8814e-04 - val_loss: 4.3366e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9768e-04 - val_loss: 4.2030e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9145e-04 - val_loss: 4.1174e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8845e-04 - val_loss: 4.3066e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9820e-04 - val_loss: 4.9209e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9203e-04 - val_loss: 4.7214e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8688e-04 - val_loss: 3.7202e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9212e-04 - val_loss: 4.3239e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8559e-04 - val_loss: 6.5292e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9206e-04 - val_loss: 4.5221e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8526e-04 - val_loss: 5.1952e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8201e-04 - val_loss: 4.7477e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8342e-04 - val_loss: 3.9577e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8147e-04 - val_loss: 5.9898e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8503e-04 - val_loss: 4.5106e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7549e-04 - val_loss: 3.9428e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8745e-04 - val_loss: 4.2686e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7897e-04 - val_loss: 4.6127e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7704e-04 - val_loss: 3.8335e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7825e-04 - val_loss: 3.8796e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7879e-04 - val_loss: 3.8195e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7606e-04 - val_loss: 5.9634e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7610e-04 - val_loss: 4.5443e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7290e-04 - val_loss: 3.8095e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9448e-04 - val_loss: 4.6574e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7606e-04 - val_loss: 6.2676e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8198e-04 - val_loss: 3.6674e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7155e-04 - val_loss: 5.5206e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7561e-04 - val_loss: 4.1097e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7074e-04 - val_loss: 4.1613e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6926e-04 - val_loss: 4.5778e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7654e-04 - val_loss: 4.7899e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7438e-04 - val_loss: 3.8874e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7196e-04 - val_loss: 3.9088e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7631e-04 - val_loss: 3.5786e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7293e-04 - val_loss: 3.9721e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7897e-04 - val_loss: 6.1970e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7262e-04 - val_loss: 3.9005e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9951e-04 - val_loss: 3.7569e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7186e-04 - val_loss: 4.5714e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6281e-04 - val_loss: 4.5908e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6383e-04 - val_loss: 4.2112e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6094e-04 - val_loss: 5.8727e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6901e-04 - val_loss: 3.4504e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8122e-04 - val_loss: 4.7888e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6963e-04 - val_loss: 5.1726e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 3s 76ms/step - loss: 2.7153e-04 - val_loss: 4.9718e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8424e-04 - val_loss: 3.5392e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7712e-04 - val_loss: 3.7322e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6593e-04 - val_loss: 3.5478e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6948e-04 - val_loss: 4.3838e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6453e-04 - val_loss: 3.8549e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6604e-04 - val_loss: 4.2012e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6679e-04 - val_loss: 4.1102e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6670e-04 - val_loss: 4.2739e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6272e-04 - val_loss: 5.0436e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5945e-04 - val_loss: 5.8632e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6603e-04 - val_loss: 5.8892e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7633e-04 - val_loss: 3.8276e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7458e-04 - val_loss: 3.6653e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8579e-04 - val_loss: 3.5831e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6805e-04 - val_loss: 4.8793e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6309e-04 - val_loss: 3.9340e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5850e-04 - val_loss: 4.2573e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5777e-04 - val_loss: 3.6890e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5948e-04 - val_loss: 4.7665e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6036e-04 - val_loss: 4.8778e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6161e-04 - val_loss: 4.0737e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7948e-04 - val_loss: 3.7917e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7585e-04 - val_loss: 3.8920e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5970e-04 - val_loss: 3.9587e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5836e-04 - val_loss: 4.5311e-04\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6842e-04 - val_loss: 3.8656e-04\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6023e-04 - val_loss: 4.1799e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_110_layer_call_fn, lstm_cell_110_layer_call_and_return_conditional_losses, lstm_cell_111_layer_call_fn, lstm_cell_111_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_15\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_15\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 83ms/step - loss: 0.0295 - val_loss: 0.0080\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 0.0015 - val_loss: 0.0071\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 8.7854e-04 - val_loss: 0.0049\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 7.1256e-04 - val_loss: 0.0052\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 5.7463e-04 - val_loss: 0.0042\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.7807e-04 - val_loss: 0.0042\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.2320e-04 - val_loss: 0.0037\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.9742e-04 - val_loss: 0.0032\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.7994e-04 - val_loss: 0.0024\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.7791e-04 - val_loss: 0.0029\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5275e-04 - val_loss: 0.0031\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5131e-04 - val_loss: 0.0030\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.4006e-04 - val_loss: 0.0024\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.3588e-04 - val_loss: 0.0022\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2772e-04 - val_loss: 0.0022\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.3102e-04 - val_loss: 0.0022\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2806e-04 - val_loss: 0.0020\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1734e-04 - val_loss: 0.0020\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2395e-04 - val_loss: 0.0015\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1418e-04 - val_loss: 0.0016\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1511e-04 - val_loss: 0.0012\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0521e-04 - val_loss: 0.0012\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1674e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1385e-04 - val_loss: 9.6809e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0471e-04 - val_loss: 0.0011\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9904e-04 - val_loss: 6.7190e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0245e-04 - val_loss: 7.3339e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9803e-04 - val_loss: 7.6556e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1505e-04 - val_loss: 6.7263e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1602e-04 - val_loss: 5.8594e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9970e-04 - val_loss: 8.9269e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9516e-04 - val_loss: 7.5374e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9589e-04 - val_loss: 6.9917e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9076e-04 - val_loss: 6.4951e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9047e-04 - val_loss: 7.1235e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0235e-04 - val_loss: 6.7027e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9251e-04 - val_loss: 5.0848e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8903e-04 - val_loss: 6.2843e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8618e-04 - val_loss: 3.9711e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9264e-04 - val_loss: 4.8136e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9241e-04 - val_loss: 7.0195e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9033e-04 - val_loss: 5.3266e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8513e-04 - val_loss: 4.5643e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9132e-04 - val_loss: 4.4574e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8480e-04 - val_loss: 5.0870e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9349e-04 - val_loss: 5.5574e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8050e-04 - val_loss: 4.0004e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8633e-04 - val_loss: 4.0039e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8539e-04 - val_loss: 3.9740e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8658e-04 - val_loss: 4.5174e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9356e-04 - val_loss: 4.3687e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8069e-04 - val_loss: 4.8277e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8194e-04 - val_loss: 4.6425e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8313e-04 - val_loss: 4.0233e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8936e-04 - val_loss: 5.6388e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8218e-04 - val_loss: 4.1365e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8597e-04 - val_loss: 4.0020e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7752e-04 - val_loss: 4.4273e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8204e-04 - val_loss: 4.6872e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.8001e-04 - val_loss: 5.6794e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7418e-04 - val_loss: 4.6334e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7995e-04 - val_loss: 4.1260e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8879e-04 - val_loss: 4.7092e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.1997e-04 - val_loss: 4.3129e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9071e-04 - val_loss: 4.3150e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0383e-04 - val_loss: 6.2851e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0090e-04 - val_loss: 4.8411e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7449e-04 - val_loss: 4.7240e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7426e-04 - val_loss: 4.2285e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_112_layer_call_fn, lstm_cell_112_layer_call_and_return_conditional_losses, lstm_cell_113_layer_call_fn, lstm_cell_113_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 83ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 5.6436e-04 - val_loss: 0.0022\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 4.8700e-04 - val_loss: 0.0013\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.3671e-04 - val_loss: 9.2359e-04\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.0904e-04 - val_loss: 6.9732e-04\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.9196e-04 - val_loss: 6.2844e-04\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.6656e-04 - val_loss: 4.9462e-04\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5987e-04 - val_loss: 4.8734e-04\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5413e-04 - val_loss: 4.6065e-04\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.3833e-04 - val_loss: 4.5043e-04\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2719e-04 - val_loss: 4.8837e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.3085e-04 - val_loss: 4.8066e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2084e-04 - val_loss: 4.4804e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1191e-04 - val_loss: 4.4756e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2014e-04 - val_loss: 4.9070e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1182e-04 - val_loss: 4.4391e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1798e-04 - val_loss: 4.5493e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0601e-04 - val_loss: 4.9055e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0695e-04 - val_loss: 5.4060e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0905e-04 - val_loss: 6.2701e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0003e-04 - val_loss: 4.4137e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1624e-04 - val_loss: 4.8959e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1257e-04 - val_loss: 5.1952e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0024e-04 - val_loss: 4.3045e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0353e-04 - val_loss: 4.2716e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9658e-04 - val_loss: 4.9688e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9132e-04 - val_loss: 4.3512e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9481e-04 - val_loss: 5.7539e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.1138e-04 - val_loss: 4.8931e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0965e-04 - val_loss: 4.4434e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9362e-04 - val_loss: 4.4430e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.9557e-04 - val_loss: 4.4880e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9868e-04 - val_loss: 4.8737e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.0288e-04 - val_loss: 4.5293e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0111e-04 - val_loss: 5.2301e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9710e-04 - val_loss: 4.2292e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8879e-04 - val_loss: 4.3981e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8541e-04 - val_loss: 4.4295e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9692e-04 - val_loss: 4.3939e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0374e-04 - val_loss: 4.3348e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8509e-04 - val_loss: 4.8250e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9469e-04 - val_loss: 6.1200e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0499e-04 - val_loss: 4.3425e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0450e-04 - val_loss: 4.3114e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8707e-04 - val_loss: 4.2907e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 65ms/step - loss: 2.8792e-04 - val_loss: 4.4418e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 71ms/step - loss: 3.1059e-04 - val_loss: 4.7250e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 3.0003e-04 - val_loss: 4.2596e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7864e-04 - val_loss: 4.1897e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8301e-04 - val_loss: 5.0195e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7946e-04 - val_loss: 4.5249e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7927e-04 - val_loss: 4.2564e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8027e-04 - val_loss: 5.5565e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8143e-04 - val_loss: 4.3736e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7654e-04 - val_loss: 4.5332e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7598e-04 - val_loss: 4.7341e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9500e-04 - val_loss: 4.2378e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7315e-04 - val_loss: 5.0495e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0828e-04 - val_loss: 5.3285e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8953e-04 - val_loss: 4.2735e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7453e-04 - val_loss: 4.6191e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7420e-04 - val_loss: 4.6501e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7571e-04 - val_loss: 5.2330e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8016e-04 - val_loss: 4.3027e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7154e-04 - val_loss: 4.4272e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7521e-04 - val_loss: 4.9029e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8330e-04 - val_loss: 4.3361e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7364e-04 - val_loss: 4.4886e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7789e-04 - val_loss: 4.0485e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7606e-04 - val_loss: 4.3968e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6950e-04 - val_loss: 4.3508e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6704e-04 - val_loss: 4.3303e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6988e-04 - val_loss: 4.3365e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6702e-04 - val_loss: 4.2018e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7472e-04 - val_loss: 4.9079e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6590e-04 - val_loss: 4.6015e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6195e-04 - val_loss: 4.7552e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7204e-04 - val_loss: 4.2747e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7820e-04 - val_loss: 4.6488e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6469e-04 - val_loss: 4.3947e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6678e-04 - val_loss: 4.4299e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.6938e-04 - val_loss: 4.5297e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8018e-04 - val_loss: 4.3580e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6149e-04 - val_loss: 4.6369e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6290e-04 - val_loss: 5.3102e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7648e-04 - val_loss: 5.0771e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7316e-04 - val_loss: 4.5863e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6096e-04 - val_loss: 5.1248e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5817e-04 - val_loss: 4.3914e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6004e-04 - val_loss: 4.5638e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6639e-04 - val_loss: 4.5874e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8728e-04 - val_loss: 4.6151e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6903e-04 - val_loss: 5.4852e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7743e-04 - val_loss: 6.0448e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7807e-04 - val_loss: 5.4084e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5441e-04 - val_loss: 5.0639e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5757e-04 - val_loss: 4.6376e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6475e-04 - val_loss: 5.9273e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7257e-04 - val_loss: 5.2276e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_114_layer_call_fn, lstm_cell_114_layer_call_and_return_conditional_losses, lstm_cell_115_layer_call_fn, lstm_cell_115_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_17\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_17\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 85ms/step - loss: 0.0079 - val_loss: 0.0041\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 9.4520e-04 - val_loss: 0.0023\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 6.4906e-04 - val_loss: 0.0015\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 5.3845e-04 - val_loss: 0.0011\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.5449e-04 - val_loss: 7.5494e-04\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.1407e-04 - val_loss: 7.2193e-04\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.6849e-04 - val_loss: 7.7369e-04\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.6384e-04 - val_loss: 6.2861e-04\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.5582e-04 - val_loss: 6.9647e-04\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.4235e-04 - val_loss: 7.9955e-04\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.3009e-04 - val_loss: 8.0808e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.3614e-04 - val_loss: 6.3368e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2625e-04 - val_loss: 8.2420e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1855e-04 - val_loss: 7.2639e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2118e-04 - val_loss: 7.4093e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1312e-04 - val_loss: 6.2833e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1915e-04 - val_loss: 9.5017e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1183e-04 - val_loss: 6.7371e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1118e-04 - val_loss: 7.1832e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2309e-04 - val_loss: 8.6824e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0975e-04 - val_loss: 5.8446e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0331e-04 - val_loss: 7.2892e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9760e-04 - val_loss: 6.6759e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0112e-04 - val_loss: 8.3046e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9442e-04 - val_loss: 7.3594e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0636e-04 - val_loss: 8.6047e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9869e-04 - val_loss: 6.4796e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9526e-04 - val_loss: 7.4479e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 63ms/step - loss: 2.9591e-04 - val_loss: 6.6223e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9099e-04 - val_loss: 8.2027e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9595e-04 - val_loss: 7.1008e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8551e-04 - val_loss: 5.4508e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9773e-04 - val_loss: 5.5508e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8840e-04 - val_loss: 7.2160e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8474e-04 - val_loss: 6.0972e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8642e-04 - val_loss: 6.0162e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8941e-04 - val_loss: 6.2358e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8546e-04 - val_loss: 7.3123e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8614e-04 - val_loss: 6.4490e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8393e-04 - val_loss: 7.7385e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9127e-04 - val_loss: 6.3258e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8428e-04 - val_loss: 7.3876e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8623e-04 - val_loss: 6.0015e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8747e-04 - val_loss: 5.3798e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8089e-04 - val_loss: 6.8545e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8292e-04 - val_loss: 5.4498e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8515e-04 - val_loss: 6.9500e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7981e-04 - val_loss: 6.7440e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7809e-04 - val_loss: 6.7874e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9115e-04 - val_loss: 8.3244e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8823e-04 - val_loss: 5.9033e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8853e-04 - val_loss: 6.4317e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8455e-04 - val_loss: 5.5462e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7902e-04 - val_loss: 7.7072e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7902e-04 - val_loss: 6.7130e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7978e-04 - val_loss: 5.2768e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8266e-04 - val_loss: 5.7396e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7571e-04 - val_loss: 6.5235e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8096e-04 - val_loss: 6.0475e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.9751e-04 - val_loss: 5.7490e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7949e-04 - val_loss: 6.3889e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7139e-04 - val_loss: 6.0024e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.8623e-04 - val_loss: 5.5788e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7539e-04 - val_loss: 4.7162e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7638e-04 - val_loss: 7.7565e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8186e-04 - val_loss: 7.6399e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6816e-04 - val_loss: 4.8852e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8554e-04 - val_loss: 7.2308e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6780e-04 - val_loss: 5.5487e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7212e-04 - val_loss: 7.0636e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7134e-04 - val_loss: 6.6448e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7808e-04 - val_loss: 7.4253e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6942e-04 - val_loss: 5.2763e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6833e-04 - val_loss: 6.6841e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7192e-04 - val_loss: 6.5988e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7099e-04 - val_loss: 8.1534e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6852e-04 - val_loss: 5.3270e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7087e-04 - val_loss: 6.4794e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6475e-04 - val_loss: 5.5294e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7049e-04 - val_loss: 6.2083e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8111e-04 - val_loss: 6.0236e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6568e-04 - val_loss: 7.7116e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6514e-04 - val_loss: 6.7755e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9097e-04 - val_loss: 4.6584e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8714e-04 - val_loss: 7.0955e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7460e-04 - val_loss: 7.1772e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6466e-04 - val_loss: 7.8717e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6794e-04 - val_loss: 7.6292e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6752e-04 - val_loss: 5.8901e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6854e-04 - val_loss: 8.3894e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.7157e-04 - val_loss: 5.2306e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6329e-04 - val_loss: 7.1661e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6413e-04 - val_loss: 6.1407e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6087e-04 - val_loss: 8.3729e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6490e-04 - val_loss: 5.4633e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6133e-04 - val_loss: 7.4678e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5613e-04 - val_loss: 6.3593e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6000e-04 - val_loss: 6.3005e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6377e-04 - val_loss: 7.0999e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5922e-04 - val_loss: 8.5276e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6648e-04 - val_loss: 8.8948e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.6743e-04 - val_loss: 6.7631e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.7639e-04 - val_loss: 5.0412e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.5956e-04 - val_loss: 7.3136e-04\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 3s 69ms/step - loss: 2.6100e-04 - val_loss: 6.5626e-04\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 3s 62ms/step - loss: 2.6351e-04 - val_loss: 5.0166e-04\n",
      "Epoch 107/2000\n",
      "45/45 [==============================] - 3s 72ms/step - loss: 2.6657e-04 - val_loss: 7.1486e-04\n",
      "Epoch 108/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5558e-04 - val_loss: 6.8296e-04\n",
      "Epoch 109/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6128e-04 - val_loss: 4.8174e-04\n",
      "Epoch 110/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5581e-04 - val_loss: 6.9399e-04\n",
      "Epoch 111/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5765e-04 - val_loss: 4.9572e-04\n",
      "Epoch 112/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6551e-04 - val_loss: 5.6327e-04\n",
      "Epoch 113/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.5652e-04 - val_loss: 5.6451e-04\n",
      "Epoch 114/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.6199e-04 - val_loss: 7.0423e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_116_layer_call_fn, lstm_cell_116_layer_call_and_return_conditional_losses, lstm_cell_117_layer_call_fn, lstm_cell_117_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_18\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_18\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 6s 84ms/step - loss: 0.0338 - val_loss: 0.0165\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 6.6759e-04 - val_loss: 0.0016\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 5.1515e-04 - val_loss: 0.0020\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 4.3805e-04 - val_loss: 0.0014\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 4.0009e-04 - val_loss: 0.0014\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.8264e-04 - val_loss: 0.0015\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.5782e-04 - val_loss: 0.0013\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.5109e-04 - val_loss: 0.0011\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.4352e-04 - val_loss: 8.5890e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2967e-04 - val_loss: 0.0011\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2931e-04 - val_loss: 8.8091e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.3443e-04 - val_loss: 0.0010\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.4352e-04 - val_loss: 0.0010\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1930e-04 - val_loss: 8.4587e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1838e-04 - val_loss: 0.0010\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2257e-04 - val_loss: 6.5730e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.2409e-04 - val_loss: 6.8116e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0825e-04 - val_loss: 7.1359e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0950e-04 - val_loss: 7.9898e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1580e-04 - val_loss: 7.8524e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1865e-04 - val_loss: 5.5900e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1374e-04 - val_loss: 8.0341e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0573e-04 - val_loss: 6.4003e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0884e-04 - val_loss: 6.1989e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0565e-04 - val_loss: 6.5872e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9863e-04 - val_loss: 7.4106e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.2087e-04 - val_loss: 5.3775e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0161e-04 - val_loss: 7.3262e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.1657e-04 - val_loss: 4.1782e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 3.0089e-04 - val_loss: 6.1886e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9872e-04 - val_loss: 5.7895e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0455e-04 - val_loss: 5.3155e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 3.0202e-04 - val_loss: 5.8124e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9408e-04 - val_loss: 6.7093e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9370e-04 - val_loss: 4.7471e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9512e-04 - val_loss: 7.9067e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9738e-04 - val_loss: 7.0291e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9600e-04 - val_loss: 4.8924e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9004e-04 - val_loss: 5.8770e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8775e-04 - val_loss: 5.4927e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8955e-04 - val_loss: 6.4924e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8523e-04 - val_loss: 6.3304e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9199e-04 - val_loss: 6.4998e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 3s 76ms/step - loss: 2.9523e-04 - val_loss: 6.9148e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 3s 76ms/step - loss: 2.9658e-04 - val_loss: 4.8980e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9074e-04 - val_loss: 5.0770e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8610e-04 - val_loss: 6.1607e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8181e-04 - val_loss: 4.5332e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9007e-04 - val_loss: 5.9957e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9031e-04 - val_loss: 5.8997e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8316e-04 - val_loss: 8.2875e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9873e-04 - val_loss: 6.0483e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 3s 75ms/step - loss: 2.8482e-04 - val_loss: 7.2301e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9037e-04 - val_loss: 6.2398e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8450e-04 - val_loss: 7.5262e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 3s 73ms/step - loss: 2.8851e-04 - val_loss: 5.7184e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8191e-04 - val_loss: 4.7933e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.8347e-04 - val_loss: 8.9021e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 3s 74ms/step - loss: 2.9131e-04 - val_loss: 4.3506e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_118_layer_call_fn, lstm_cell_118_layer_call_and_return_conditional_losses, lstm_cell_119_layer_call_fn, lstm_cell_119_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_19\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_memory = 200\n",
    "\n",
    "trainInputX, trainInputY = sf.prepareData(trainX, trainY, lstm_memory)\n",
    "testInputX, testInputY = sf.prepareData(testX, testY, lstm_memory)\n",
    "print(trainInputX.shape)\n",
    "print(trainInputY.shape)\n",
    "print(testInputX.shape)\n",
    "print(testInputY.shape)\n",
    "\n",
    "#validacao tamanho apos tratamentos\n",
    "print(len(trainX))\n",
    "print(len(trainInputX))\n",
    "\n",
    "print(len(trainY))\n",
    "print(len(trainInputY))\n",
    "\n",
    "trainInputX = trainInputX [:,:,0:14]\n",
    "testInputX = testInputX [:,:,0:14]\n",
    "print(trainInputX.shape)\n",
    "\n",
    "trained_models_lstm_200 = []\n",
    "trained_models_lstm_200_history = []\n",
    "\n",
    "for i in range(0,20):\n",
    "\n",
    "    #giving it reproducibility\n",
    "    seed = (i+1000)\n",
    "\n",
    "    os.environ['PYTHONHASHseed']=str(seed)\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    batch_size = 256\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "    \n",
    "    trained_models_lstm_200.append(kr.Sequential())\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_200[i].add(kr.layers.LSTM(14,return_sequences = True))\n",
    "    trained_models_lstm_200[i].add(kr.layers.LSTM(8))\n",
    "    # lstm_model.add(kr.layers.Simplelstm(5,input_shape=(trainInputX.shape[1],trainInputX.shape[2])))\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_200[i].add(kr.layers.Dense(1))\n",
    "    trained_models_lstm_200[i].compile(loss='mean_squared_error',optimizer='adam')\n",
    "    \n",
    "    trained_models_lstm_200_history.append(trained_models_lstm_200[i].fit(trainInputX, trainInputY, epochs=2000, batch_size=batch_size, verbose = 1, validation_data=(testInputX,testInputY),  callbacks=[callback]))\n",
    "    \n",
    "    trained_models_lstm_200[i].save('C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_200_batch_256_earlystop_valloss_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04087f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11290, 400, 14)\n",
      "(11290,)\n",
      "(2523, 400, 14)\n",
      "(2523,)\n",
      "11690\n",
      "11290\n",
      "11690\n",
      "11290\n",
      "(11290, 400, 14)\n",
      "Epoch 1/2000\n",
      "45/45 [==============================] - 9s 154ms/step - loss: 0.0489 - val_loss: 0.0029\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 7.4320e-04 - val_loss: 0.0030\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 5.6988e-04 - val_loss: 0.0037\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 5.0594e-04 - val_loss: 0.0038\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 4.5923e-04 - val_loss: 0.0036\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 4.3070e-04 - val_loss: 0.0036\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.9572e-04 - val_loss: 0.0033\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.7683e-04 - val_loss: 0.0021\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.8661e-04 - val_loss: 0.0025\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.5240e-04 - val_loss: 0.0026\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.4484e-04 - val_loss: 0.0024\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.3612e-04 - val_loss: 0.0022\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 3.3118e-04 - val_loss: 0.0015\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.2936e-04 - val_loss: 0.0018\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2531e-04 - val_loss: 0.0020\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.3279e-04 - val_loss: 0.0015\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2419e-04 - val_loss: 9.1919e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.4032e-04 - val_loss: 0.0012\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 3.1495e-04 - val_loss: 0.0012\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.2603e-04 - val_loss: 0.0012\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 3.1587e-04 - val_loss: 8.8578e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1270e-04 - val_loss: 9.7558e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0850e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1174e-04 - val_loss: 7.7749e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.2026e-04 - val_loss: 7.6304e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1495e-04 - val_loss: 8.2401e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0717e-04 - val_loss: 5.9368e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.1010e-04 - val_loss: 7.2371e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0574e-04 - val_loss: 6.4225e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1741e-04 - val_loss: 8.8218e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.2019e-04 - val_loss: 6.7331e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0415e-04 - val_loss: 9.1840e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0156e-04 - val_loss: 9.7764e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0242e-04 - val_loss: 4.7892e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0829e-04 - val_loss: 5.5045e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0815e-04 - val_loss: 5.9740e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9851e-04 - val_loss: 6.4966e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0381e-04 - val_loss: 9.1931e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.1522e-04 - val_loss: 8.2079e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0353e-04 - val_loss: 6.4916e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9287e-04 - val_loss: 5.8133e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9542e-04 - val_loss: 6.2696e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9696e-04 - val_loss: 0.0010\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0233e-04 - val_loss: 7.2204e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0213e-04 - val_loss: 7.2209e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0445e-04 - val_loss: 7.2871e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9869e-04 - val_loss: 6.7768e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0089e-04 - val_loss: 7.7681e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0323e-04 - val_loss: 5.6827e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0344e-04 - val_loss: 9.8727e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1237e-04 - val_loss: 5.8470e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0231e-04 - val_loss: 6.1776e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9745e-04 - val_loss: 3.8422e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.3184e-04 - val_loss: 5.3002e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9965e-04 - val_loss: 6.0312e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9995e-04 - val_loss: 5.8403e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9349e-04 - val_loss: 4.2943e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9249e-04 - val_loss: 4.9662e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9139e-04 - val_loss: 3.8935e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1558e-04 - val_loss: 3.5096e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0853e-04 - val_loss: 4.7109e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8742e-04 - val_loss: 3.8492e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9827e-04 - val_loss: 5.1177e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1584e-04 - val_loss: 5.8758e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8781e-04 - val_loss: 5.2790e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9651e-04 - val_loss: 7.1598e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9409e-04 - val_loss: 6.0809e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8948e-04 - val_loss: 6.5334e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0012e-04 - val_loss: 5.5361e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0103e-04 - val_loss: 3.9102e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8556e-04 - val_loss: 4.6315e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9026e-04 - val_loss: 5.8094e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8452e-04 - val_loss: 3.7502e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8770e-04 - val_loss: 5.8211e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9752e-04 - val_loss: 4.6101e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8984e-04 - val_loss: 5.1602e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8290e-04 - val_loss: 9.5877e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.3731e-04 - val_loss: 7.9852e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.1223e-04 - val_loss: 4.7436e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8406e-04 - val_loss: 4.0911e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9523e-04 - val_loss: 4.2553e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8371e-04 - val_loss: 4.2293e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8109e-04 - val_loss: 3.7766e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8576e-04 - val_loss: 4.6515e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8636e-04 - val_loss: 3.7217e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8432e-04 - val_loss: 4.2660e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9259e-04 - val_loss: 6.9045e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8136e-04 - val_loss: 5.2769e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8301e-04 - val_loss: 3.6093e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0067e-04 - val_loss: 6.7357e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_120_layer_call_fn, lstm_cell_120_layer_call_and_return_conditional_losses, lstm_cell_121_layer_call_fn, lstm_cell_121_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 9s 154ms/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 8.2020e-04 - val_loss: 0.0012\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 4.6606e-04 - val_loss: 0.0022\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 4.2531e-04 - val_loss: 0.0019\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.7562e-04 - val_loss: 0.0016\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.4620e-04 - val_loss: 0.0012\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.4647e-04 - val_loss: 0.0014\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.3005e-04 - val_loss: 9.8481e-04\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.2514e-04 - val_loss: 0.0012\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2282e-04 - val_loss: 0.0014\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1270e-04 - val_loss: 0.0011\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0993e-04 - val_loss: 0.0012\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0785e-04 - val_loss: 7.4535e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2494e-04 - val_loss: 9.0584e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0389e-04 - val_loss: 9.8032e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2558e-04 - val_loss: 0.0012\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1819e-04 - val_loss: 8.8043e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9503e-04 - val_loss: 9.3315e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0114e-04 - val_loss: 9.2890e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1244e-04 - val_loss: 7.6745e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9812e-04 - val_loss: 9.5737e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9313e-04 - val_loss: 6.6171e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0025e-04 - val_loss: 9.2202e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9185e-04 - val_loss: 8.6362e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9422e-04 - val_loss: 9.3023e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9130e-04 - val_loss: 8.1268e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8509e-04 - val_loss: 7.2761e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8994e-04 - val_loss: 8.1317e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8214e-04 - val_loss: 9.9455e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9031e-04 - val_loss: 6.9441e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8601e-04 - val_loss: 8.0169e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9026e-04 - val_loss: 6.5107e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9194e-04 - val_loss: 6.4826e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8326e-04 - val_loss: 7.7050e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8209e-04 - val_loss: 6.3977e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9647e-04 - val_loss: 8.3334e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7698e-04 - val_loss: 6.9716e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8432e-04 - val_loss: 9.7312e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9590e-04 - val_loss: 8.3602e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7780e-04 - val_loss: 7.9177e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7799e-04 - val_loss: 7.3204e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7868e-04 - val_loss: 6.0138e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8118e-04 - val_loss: 9.6911e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7296e-04 - val_loss: 7.2793e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7228e-04 - val_loss: 6.6322e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7212e-04 - val_loss: 8.0115e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7698e-04 - val_loss: 6.0408e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8802e-04 - val_loss: 6.8661e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6544e-04 - val_loss: 8.2375e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9353e-04 - val_loss: 7.3592e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7081e-04 - val_loss: 7.2850e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7979e-04 - val_loss: 7.9012e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7938e-04 - val_loss: 0.0010\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7899e-04 - val_loss: 6.8545e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7688e-04 - val_loss: 7.7677e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7048e-04 - val_loss: 8.2045e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7699e-04 - val_loss: 7.1656e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6436e-04 - val_loss: 6.2375e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7935e-04 - val_loss: 6.3618e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8702e-04 - val_loss: 0.0010\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8513e-04 - val_loss: 6.3394e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7171e-04 - val_loss: 6.5137e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6059e-04 - val_loss: 6.8568e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6867e-04 - val_loss: 7.5031e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6873e-04 - val_loss: 7.9315e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6329e-04 - val_loss: 5.9932e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6755e-04 - val_loss: 9.6859e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9315e-04 - val_loss: 9.7146e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7688e-04 - val_loss: 7.1341e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6557e-04 - val_loss: 6.2788e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5596e-04 - val_loss: 6.2518e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5822e-04 - val_loss: 8.7434e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6166e-04 - val_loss: 6.3768e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6444e-04 - val_loss: 6.4695e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6518e-04 - val_loss: 6.6225e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.6128e-04 - val_loss: 7.6071e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5823e-04 - val_loss: 9.9446e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8923e-04 - val_loss: 0.0011\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5936e-04 - val_loss: 7.7830e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6771e-04 - val_loss: 6.5404e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5380e-04 - val_loss: 6.4752e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6427e-04 - val_loss: 6.7842e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6558e-04 - val_loss: 7.1412e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6123e-04 - val_loss: 9.9759e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.6094e-04 - val_loss: 6.6906e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5407e-04 - val_loss: 7.4414e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5147e-04 - val_loss: 6.8403e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6229e-04 - val_loss: 8.5288e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5604e-04 - val_loss: 7.0934e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5691e-04 - val_loss: 6.7081e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 2.5371e-04 - val_loss: 6.7593e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5469e-04 - val_loss: 7.3280e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5533e-04 - val_loss: 7.9184e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5548e-04 - val_loss: 7.0785e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7058e-04 - val_loss: 6.2484e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6280e-04 - val_loss: 5.6448e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6105e-04 - val_loss: 5.6546e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5037e-04 - val_loss: 7.4104e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5208e-04 - val_loss: 9.4375e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4967e-04 - val_loss: 6.0457e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6137e-04 - val_loss: 6.5234e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4882e-04 - val_loss: 6.5108e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5946e-04 - val_loss: 5.7844e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6704e-04 - val_loss: 7.0898e-04\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5650e-04 - val_loss: 7.4357e-04\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5984e-04 - val_loss: 6.7775e-04\n",
      "Epoch 107/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4630e-04 - val_loss: 6.2372e-04\n",
      "Epoch 108/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6036e-04 - val_loss: 6.7116e-04\n",
      "Epoch 109/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6789e-04 - val_loss: 6.8257e-04\n",
      "Epoch 110/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4845e-04 - val_loss: 6.7632e-04\n",
      "Epoch 111/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5095e-04 - val_loss: 5.4847e-04\n",
      "Epoch 112/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5318e-04 - val_loss: 7.3285e-04\n",
      "Epoch 113/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4465e-04 - val_loss: 7.7204e-04\n",
      "Epoch 114/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5103e-04 - val_loss: 6.9151e-04\n",
      "Epoch 115/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.4915e-04 - val_loss: 9.3673e-04\n",
      "Epoch 116/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6170e-04 - val_loss: 7.5756e-04\n",
      "Epoch 117/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4609e-04 - val_loss: 6.5526e-04\n",
      "Epoch 118/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5315e-04 - val_loss: 7.2470e-04\n",
      "Epoch 119/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.4829e-04 - val_loss: 5.6025e-04\n",
      "Epoch 120/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4393e-04 - val_loss: 5.9914e-04\n",
      "Epoch 121/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5232e-04 - val_loss: 8.0895e-04\n",
      "Epoch 122/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6615e-04 - val_loss: 0.0010\n",
      "Epoch 123/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5932e-04 - val_loss: 9.4631e-04\n",
      "Epoch 124/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4440e-04 - val_loss: 6.2607e-04\n",
      "Epoch 125/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4356e-04 - val_loss: 8.7114e-04\n",
      "Epoch 126/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4700e-04 - val_loss: 6.3636e-04\n",
      "Epoch 127/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.4363e-04 - val_loss: 6.7572e-04\n",
      "Epoch 128/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4185e-04 - val_loss: 7.5381e-04\n",
      "Epoch 129/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4725e-04 - val_loss: 5.6785e-04\n",
      "Epoch 130/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4112e-04 - val_loss: 5.4355e-04\n",
      "Epoch 131/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.4858e-04 - val_loss: 6.0580e-04\n",
      "Epoch 132/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4753e-04 - val_loss: 6.1924e-04\n",
      "Epoch 133/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.3869e-04 - val_loss: 5.6020e-04\n",
      "Epoch 134/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4492e-04 - val_loss: 6.0459e-04\n",
      "Epoch 135/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4782e-04 - val_loss: 6.6767e-04\n",
      "Epoch 136/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.3978e-04 - val_loss: 6.9238e-04\n",
      "Epoch 137/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4762e-04 - val_loss: 5.5919e-04\n",
      "Epoch 138/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4090e-04 - val_loss: 5.1265e-04\n",
      "Epoch 139/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.3939e-04 - val_loss: 5.2618e-04\n",
      "Epoch 140/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4142e-04 - val_loss: 6.1484e-04\n",
      "Epoch 141/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.3436e-04 - val_loss: 5.7132e-04\n",
      "Epoch 142/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.3517e-04 - val_loss: 5.6906e-04\n",
      "Epoch 143/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4200e-04 - val_loss: 8.4009e-04\n",
      "Epoch 144/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5025e-04 - val_loss: 5.8860e-04\n",
      "Epoch 145/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.3764e-04 - val_loss: 5.5981e-04\n",
      "Epoch 146/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.3756e-04 - val_loss: 7.2508e-04\n",
      "Epoch 147/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4180e-04 - val_loss: 5.0176e-04\n",
      "Epoch 148/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4597e-04 - val_loss: 5.1608e-04\n",
      "Epoch 149/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.3798e-04 - val_loss: 4.6456e-04\n",
      "Epoch 150/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.3894e-04 - val_loss: 6.1056e-04\n",
      "Epoch 151/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.3094e-04 - val_loss: 4.5913e-04\n",
      "Epoch 152/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.3490e-04 - val_loss: 4.4933e-04\n",
      "Epoch 153/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4290e-04 - val_loss: 5.4842e-04\n",
      "Epoch 154/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.3451e-04 - val_loss: 4.4700e-04\n",
      "Epoch 155/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7276e-04 - val_loss: 4.6892e-04\n",
      "Epoch 156/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.3857e-04 - val_loss: 5.6730e-04\n",
      "Epoch 157/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.2940e-04 - val_loss: 4.6831e-04\n",
      "Epoch 158/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.3268e-04 - val_loss: 4.3603e-04\n",
      "Epoch 159/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.4367e-04 - val_loss: 4.3786e-04\n",
      "Epoch 160/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.2162e-04 - val_loss: 4.4830e-04\n",
      "Epoch 161/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.3174e-04 - val_loss: 4.3882e-04\n",
      "Epoch 162/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.3349e-04 - val_loss: 6.0333e-04\n",
      "Epoch 163/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.2069e-04 - val_loss: 5.4445e-04\n",
      "Epoch 164/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.2415e-04 - val_loss: 5.9879e-04\n",
      "Epoch 165/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.2097e-04 - val_loss: 5.3249e-04\n",
      "Epoch 166/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.2244e-04 - val_loss: 5.0648e-04\n",
      "Epoch 167/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.2573e-04 - val_loss: 5.3732e-04\n",
      "Epoch 168/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.2515e-04 - val_loss: 6.1586e-04\n",
      "Epoch 169/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.2435e-04 - val_loss: 4.7619e-04\n",
      "Epoch 170/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.3220e-04 - val_loss: 5.9669e-04\n",
      "Epoch 171/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.1530e-04 - val_loss: 4.2922e-04\n",
      "Epoch 172/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.2995e-04 - val_loss: 5.3072e-04\n",
      "Epoch 173/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.0881e-04 - val_loss: 4.9895e-04\n",
      "Epoch 174/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.0975e-04 - val_loss: 4.8944e-04\n",
      "Epoch 175/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.0767e-04 - val_loss: 5.6119e-04\n",
      "Epoch 176/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.0416e-04 - val_loss: 4.8931e-04\n",
      "Epoch 177/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.1133e-04 - val_loss: 7.1918e-04\n",
      "Epoch 178/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.3426e-04 - val_loss: 4.1866e-04\n",
      "Epoch 179/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.2036e-04 - val_loss: 6.2921e-04\n",
      "Epoch 180/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.0878e-04 - val_loss: 6.1879e-04\n",
      "Epoch 181/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.0083e-04 - val_loss: 5.0749e-04\n",
      "Epoch 182/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.1367e-04 - val_loss: 4.9521e-04\n",
      "Epoch 183/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 1.9329e-04 - val_loss: 8.3205e-04\n",
      "Epoch 184/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.0420e-04 - val_loss: 5.8161e-04\n",
      "Epoch 185/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 1.8992e-04 - val_loss: 5.5065e-04\n",
      "Epoch 186/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 1.9135e-04 - val_loss: 4.4443e-04\n",
      "Epoch 187/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.1129e-04 - val_loss: 6.1136e-04\n",
      "Epoch 188/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 1.9605e-04 - val_loss: 6.0284e-04\n",
      "Epoch 189/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 1.8678e-04 - val_loss: 6.7578e-04\n",
      "Epoch 190/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 1.9113e-04 - val_loss: 5.5931e-04\n",
      "Epoch 191/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.0866e-04 - val_loss: 5.7979e-04\n",
      "Epoch 192/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.0504e-04 - val_loss: 7.2960e-04\n",
      "Epoch 193/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.0870e-04 - val_loss: 6.4074e-04\n",
      "Epoch 194/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 1.9585e-04 - val_loss: 4.3624e-04\n",
      "Epoch 195/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 1.9865e-04 - val_loss: 6.0764e-04\n",
      "Epoch 196/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 1.8562e-04 - val_loss: 7.8769e-04\n",
      "Epoch 197/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 1.8385e-04 - val_loss: 8.1158e-04\n",
      "Epoch 198/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 1.9129e-04 - val_loss: 7.6242e-04\n",
      "Epoch 199/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 1.8456e-04 - val_loss: 8.9313e-04\n",
      "Epoch 200/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 1.7648e-04 - val_loss: 6.7887e-04\n",
      "Epoch 201/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 1.8189e-04 - val_loss: 6.9186e-04\n",
      "Epoch 202/2000\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 1.7694e-04 - val_loss: 8.0423e-04\n",
      "Epoch 203/2000\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 1.7514e-04 - val_loss: 6.5889e-04\n",
      "Epoch 204/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 1.8300e-04 - val_loss: 6.0882e-04\n",
      "Epoch 205/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 1.8610e-04 - val_loss: 9.2348e-04\n",
      "Epoch 206/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.0765e-04 - val_loss: 7.3358e-04\n",
      "Epoch 207/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 1.7034e-04 - val_loss: 8.1574e-04\n",
      "Epoch 208/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 1.7906e-04 - val_loss: 6.2608e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_122_layer_call_fn, lstm_cell_122_layer_call_and_return_conditional_losses, lstm_cell_123_layer_call_fn, lstm_cell_123_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 9s 156ms/step - loss: 0.0387 - val_loss: 0.0103\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 7.4671e-04 - val_loss: 0.0016\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 5.7525e-04 - val_loss: 0.0016\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 4.9032e-04 - val_loss: 0.0013\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 4.3728e-04 - val_loss: 0.0012\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 4.0104e-04 - val_loss: 0.0011\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.7804e-04 - val_loss: 0.0010\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.7440e-04 - val_loss: 9.4527e-04\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.5563e-04 - val_loss: 7.9009e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.5506e-04 - val_loss: 7.1230e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.3602e-04 - val_loss: 6.7929e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.3694e-04 - val_loss: 6.5969e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.3234e-04 - val_loss: 6.1587e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2492e-04 - val_loss: 7.3703e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1635e-04 - val_loss: 5.4438e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2375e-04 - val_loss: 6.2187e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1435e-04 - val_loss: 6.0167e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1114e-04 - val_loss: 8.0196e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0842e-04 - val_loss: 7.0352e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0723e-04 - val_loss: 7.4843e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0491e-04 - val_loss: 9.0585e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0949e-04 - val_loss: 7.6321e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0405e-04 - val_loss: 8.2808e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0882e-04 - val_loss: 5.3043e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.1343e-04 - val_loss: 5.7437e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9842e-04 - val_loss: 8.8189e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0056e-04 - val_loss: 8.4408e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9754e-04 - val_loss: 5.8261e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0740e-04 - val_loss: 8.2247e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0395e-04 - val_loss: 6.2259e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0505e-04 - val_loss: 6.5574e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0211e-04 - val_loss: 6.6796e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0755e-04 - val_loss: 4.8625e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0728e-04 - val_loss: 5.9540e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9871e-04 - val_loss: 6.6412e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9902e-04 - val_loss: 8.9755e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9389e-04 - val_loss: 8.3618e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9252e-04 - val_loss: 7.5112e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9205e-04 - val_loss: 5.6968e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9524e-04 - val_loss: 5.7783e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9400e-04 - val_loss: 7.3857e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9239e-04 - val_loss: 8.3388e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0529e-04 - val_loss: 3.9336e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9231e-04 - val_loss: 6.8476e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9862e-04 - val_loss: 7.1687e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9324e-04 - val_loss: 7.9563e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.9305e-04 - val_loss: 7.1498e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9502e-04 - val_loss: 4.2267e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9627e-04 - val_loss: 5.6152e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9613e-04 - val_loss: 6.1034e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0124e-04 - val_loss: 4.9166e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9175e-04 - val_loss: 7.0144e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8747e-04 - val_loss: 4.3508e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9836e-04 - val_loss: 3.6811e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9286e-04 - val_loss: 3.7078e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9678e-04 - val_loss: 5.5494e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8855e-04 - val_loss: 3.6720e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9955e-04 - val_loss: 6.0242e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 2.8383e-04 - val_loss: 5.2552e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 2.8823e-04 - val_loss: 6.4421e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8536e-04 - val_loss: 3.9280e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8494e-04 - val_loss: 4.5925e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8821e-04 - val_loss: 8.1853e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8467e-04 - val_loss: 3.9096e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9529e-04 - val_loss: 4.5908e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7842e-04 - val_loss: 4.6818e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7824e-04 - val_loss: 4.2716e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8160e-04 - val_loss: 4.0406e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7936e-04 - val_loss: 5.0772e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9435e-04 - val_loss: 6.3770e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8802e-04 - val_loss: 4.8440e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8843e-04 - val_loss: 3.6606e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8516e-04 - val_loss: 7.8670e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8617e-04 - val_loss: 5.3607e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7977e-04 - val_loss: 4.1211e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8464e-04 - val_loss: 4.1998e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8522e-04 - val_loss: 3.8928e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8164e-04 - val_loss: 7.6994e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7924e-04 - val_loss: 5.1121e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8018e-04 - val_loss: 4.9504e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7535e-04 - val_loss: 5.2601e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7695e-04 - val_loss: 4.9382e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7811e-04 - val_loss: 3.8338e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8074e-04 - val_loss: 4.1014e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7269e-04 - val_loss: 6.4681e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.6868e-04 - val_loss: 4.5293e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7303e-04 - val_loss: 3.8156e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7909e-04 - val_loss: 4.3844e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7388e-04 - val_loss: 6.8967e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7730e-04 - val_loss: 5.6549e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7768e-04 - val_loss: 5.6758e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8212e-04 - val_loss: 4.2861e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7225e-04 - val_loss: 3.7909e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7010e-04 - val_loss: 4.9507e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7664e-04 - val_loss: 3.7248e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7003e-04 - val_loss: 5.8092e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6597e-04 - val_loss: 5.5988e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9114e-04 - val_loss: 3.8594e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7145e-04 - val_loss: 4.5203e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6535e-04 - val_loss: 6.1321e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.6916e-04 - val_loss: 4.8697e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9331e-04 - val_loss: 5.8542e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_124_layer_call_fn, lstm_cell_124_layer_call_and_return_conditional_losses, lstm_cell_125_layer_call_fn, lstm_cell_125_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 10s 156ms/step - loss: 0.0536 - val_loss: 0.0134\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 0.0023 - val_loss: 0.0220\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 0.0013 - val_loss: 0.0199\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 0.0010 - val_loss: 0.0183\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 8.2160e-04 - val_loss: 0.0139\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 6.6308e-04 - val_loss: 0.0147\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 5.6322e-04 - val_loss: 0.0106\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 4.9818e-04 - val_loss: 0.0100\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 4.4633e-04 - val_loss: 0.0084\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 4.2128e-04 - val_loss: 0.0085\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 4.0386e-04 - val_loss: 0.0070\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.7818e-04 - val_loss: 0.0050\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.6725e-04 - val_loss: 0.0032\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.5586e-04 - val_loss: 0.0035\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.5003e-04 - val_loss: 0.0040\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.3909e-04 - val_loss: 0.0034\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.2053e-04 - val_loss: 0.0027\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2246e-04 - val_loss: 0.0028\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1459e-04 - val_loss: 0.0029\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1173e-04 - val_loss: 0.0020\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0936e-04 - val_loss: 0.0024\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2811e-04 - val_loss: 0.0015\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1489e-04 - val_loss: 0.0014\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1144e-04 - val_loss: 0.0013\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9692e-04 - val_loss: 0.0018\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9438e-04 - val_loss: 0.0015\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9087e-04 - val_loss: 0.0011\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0588e-04 - val_loss: 0.0015\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9025e-04 - val_loss: 0.0011\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8721e-04 - val_loss: 0.0012\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1486e-04 - val_loss: 0.0014\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9835e-04 - val_loss: 0.0014\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8652e-04 - val_loss: 0.0012\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8482e-04 - val_loss: 0.0011\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9098e-04 - val_loss: 9.3908e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8412e-04 - val_loss: 0.0011\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9055e-04 - val_loss: 0.0014\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8045e-04 - val_loss: 0.0011\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8128e-04 - val_loss: 0.0012\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8259e-04 - val_loss: 0.0011\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7944e-04 - val_loss: 0.0011\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8350e-04 - val_loss: 9.0246e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 2.8704e-04 - val_loss: 0.0010\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7872e-04 - val_loss: 0.0010\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7568e-04 - val_loss: 0.0011\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9046e-04 - val_loss: 0.0017\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9602e-04 - val_loss: 7.2502e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9715e-04 - val_loss: 9.4284e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8158e-04 - val_loss: 0.0013\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8595e-04 - val_loss: 8.1553e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8046e-04 - val_loss: 8.3610e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8219e-04 - val_loss: 7.7383e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9121e-04 - val_loss: 8.5786e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8673e-04 - val_loss: 0.0012\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7415e-04 - val_loss: 9.6372e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7575e-04 - val_loss: 8.2486e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7664e-04 - val_loss: 0.0011\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7760e-04 - val_loss: 8.9778e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7927e-04 - val_loss: 7.7195e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7482e-04 - val_loss: 0.0012\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7831e-04 - val_loss: 9.0880e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8204e-04 - val_loss: 8.2362e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8657e-04 - val_loss: 5.6454e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1853e-04 - val_loss: 7.8601e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7177e-04 - val_loss: 7.2357e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8005e-04 - val_loss: 0.0010\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7725e-04 - val_loss: 9.5671e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7523e-04 - val_loss: 8.2089e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7263e-04 - val_loss: 9.8155e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6863e-04 - val_loss: 7.6044e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8315e-04 - val_loss: 7.6454e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7923e-04 - val_loss: 8.9764e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7119e-04 - val_loss: 7.2996e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7485e-04 - val_loss: 0.0012\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7920e-04 - val_loss: 7.1741e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7057e-04 - val_loss: 6.6225e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 2.8632e-04 - val_loss: 9.9808e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7501e-04 - val_loss: 7.9653e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7428e-04 - val_loss: 7.6932e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.6714e-04 - val_loss: 0.0010\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6856e-04 - val_loss: 6.8814e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6895e-04 - val_loss: 0.0011\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7510e-04 - val_loss: 6.5711e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7667e-04 - val_loss: 0.0010\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7014e-04 - val_loss: 7.1229e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7242e-04 - val_loss: 0.0011\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8842e-04 - val_loss: 0.0011\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7437e-04 - val_loss: 6.4753e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.6619e-04 - val_loss: 5.7353e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8307e-04 - val_loss: 0.0013\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7448e-04 - val_loss: 6.9861e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6647e-04 - val_loss: 5.4916e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0935e-04 - val_loss: 7.8797e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7273e-04 - val_loss: 0.0011\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6857e-04 - val_loss: 6.9563e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6801e-04 - val_loss: 0.0011\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9310e-04 - val_loss: 6.2368e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.6919e-04 - val_loss: 8.1692e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.6604e-04 - val_loss: 8.2138e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6297e-04 - val_loss: 6.2300e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6398e-04 - val_loss: 7.0911e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6479e-04 - val_loss: 6.2124e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.6094e-04 - val_loss: 5.8785e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9445e-04 - val_loss: 7.0059e-04\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8309e-04 - val_loss: 5.9577e-04\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7299e-04 - val_loss: 6.3183e-04\n",
      "Epoch 107/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.6975e-04 - val_loss: 7.9754e-04\n",
      "Epoch 108/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6478e-04 - val_loss: 0.0010\n",
      "Epoch 109/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7232e-04 - val_loss: 7.3133e-04\n",
      "Epoch 110/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.6033e-04 - val_loss: 7.1051e-04\n",
      "Epoch 111/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5991e-04 - val_loss: 5.4843e-04\n",
      "Epoch 112/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6737e-04 - val_loss: 6.3438e-04\n",
      "Epoch 113/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6575e-04 - val_loss: 8.8987e-04\n",
      "Epoch 114/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7321e-04 - val_loss: 8.4210e-04\n",
      "Epoch 115/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8591e-04 - val_loss: 6.8490e-04\n",
      "Epoch 116/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6869e-04 - val_loss: 9.1840e-04\n",
      "Epoch 117/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.5900e-04 - val_loss: 6.7879e-04\n",
      "Epoch 118/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7502e-04 - val_loss: 7.5074e-04\n",
      "Epoch 119/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5943e-04 - val_loss: 5.5741e-04\n",
      "Epoch 120/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6097e-04 - val_loss: 5.5414e-04\n",
      "Epoch 121/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5117e-04 - val_loss: 5.6244e-04\n",
      "Epoch 122/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6784e-04 - val_loss: 6.4581e-04\n",
      "Epoch 123/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5641e-04 - val_loss: 6.0995e-04\n",
      "Epoch 124/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5933e-04 - val_loss: 5.5108e-04\n",
      "Epoch 125/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6267e-04 - val_loss: 6.4120e-04\n",
      "Epoch 126/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6557e-04 - val_loss: 7.9529e-04\n",
      "Epoch 127/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5625e-04 - val_loss: 5.8114e-04\n",
      "Epoch 128/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5943e-04 - val_loss: 5.6178e-04\n",
      "Epoch 129/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5726e-04 - val_loss: 6.5356e-04\n",
      "Epoch 130/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5813e-04 - val_loss: 6.5332e-04\n",
      "Epoch 131/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5714e-04 - val_loss: 5.1712e-04\n",
      "Epoch 132/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6368e-04 - val_loss: 5.7440e-04\n",
      "Epoch 133/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5931e-04 - val_loss: 7.5172e-04\n",
      "Epoch 134/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5069e-04 - val_loss: 9.2228e-04\n",
      "Epoch 135/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5944e-04 - val_loss: 6.7160e-04\n",
      "Epoch 136/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.4670e-04 - val_loss: 6.4664e-04\n",
      "Epoch 137/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5519e-04 - val_loss: 8.7206e-04\n",
      "Epoch 138/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5214e-04 - val_loss: 0.0013\n",
      "Epoch 139/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4986e-04 - val_loss: 5.7778e-04\n",
      "Epoch 140/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5752e-04 - val_loss: 9.3398e-04\n",
      "Epoch 141/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5684e-04 - val_loss: 5.9930e-04\n",
      "Epoch 142/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4427e-04 - val_loss: 0.0018\n",
      "Epoch 143/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9148e-04 - val_loss: 5.5306e-04\n",
      "Epoch 144/2000\n",
      "45/45 [==============================] - 7s 147ms/step - loss: 2.6715e-04 - val_loss: 7.1280e-04\n",
      "Epoch 145/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6253e-04 - val_loss: 6.5049e-04\n",
      "Epoch 146/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.5047e-04 - val_loss: 6.1430e-04\n",
      "Epoch 147/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4775e-04 - val_loss: 7.6360e-04\n",
      "Epoch 148/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.6774e-04 - val_loss: 8.3788e-04\n",
      "Epoch 149/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4640e-04 - val_loss: 7.0301e-04\n",
      "Epoch 150/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5177e-04 - val_loss: 9.3573e-04\n",
      "Epoch 151/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7463e-04 - val_loss: 9.5147e-04\n",
      "Epoch 152/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.5480e-04 - val_loss: 8.9347e-04\n",
      "Epoch 153/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.5616e-04 - val_loss: 7.8117e-04\n",
      "Epoch 154/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4694e-04 - val_loss: 6.2736e-04\n",
      "Epoch 155/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4704e-04 - val_loss: 6.1179e-04\n",
      "Epoch 156/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.5350e-04 - val_loss: 9.4102e-04\n",
      "Epoch 157/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4370e-04 - val_loss: 6.3302e-04\n",
      "Epoch 158/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.4049e-04 - val_loss: 8.5550e-04\n",
      "Epoch 159/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.5223e-04 - val_loss: 0.0014\n",
      "Epoch 160/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.5827e-04 - val_loss: 0.0010\n",
      "Epoch 161/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.4029e-04 - val_loss: 8.8774e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_126_layer_call_fn, lstm_cell_126_layer_call_and_return_conditional_losses, lstm_cell_127_layer_call_fn, lstm_cell_127_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 9s 157ms/step - loss: 0.0477 - val_loss: 0.0267\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 0.0019 - val_loss: 0.0156\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 6s 128ms/step - loss: 7.7483e-04 - val_loss: 0.0059\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 6.2331e-04 - val_loss: 0.0040\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 5.1893e-04 - val_loss: 0.0024\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 4.4152e-04 - val_loss: 0.0017\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.8993e-04 - val_loss: 0.0014\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 3.6187e-04 - val_loss: 0.0012\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 3.4957e-04 - val_loss: 0.0012\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.3636e-04 - val_loss: 9.6932e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.3131e-04 - val_loss: 0.0012\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2872e-04 - val_loss: 9.9924e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2704e-04 - val_loss: 8.5555e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.1772e-04 - val_loss: 8.1459e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.1727e-04 - val_loss: 7.9891e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.1442e-04 - val_loss: 8.2674e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.1760e-04 - val_loss: 7.4092e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.1057e-04 - val_loss: 7.1886e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0984e-04 - val_loss: 7.9914e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0976e-04 - val_loss: 7.0921e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0857e-04 - val_loss: 6.6506e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0797e-04 - val_loss: 6.6507e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0809e-04 - val_loss: 6.5828e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0108e-04 - val_loss: 6.4313e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9985e-04 - val_loss: 6.6531e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0513e-04 - val_loss: 6.4173e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0375e-04 - val_loss: 6.6060e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9817e-04 - val_loss: 6.1783e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9802e-04 - val_loss: 8.6041e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 3.0057e-04 - val_loss: 6.7742e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9972e-04 - val_loss: 6.3389e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.9356e-04 - val_loss: 6.4116e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9851e-04 - val_loss: 6.0541e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.0235e-04 - val_loss: 6.5113e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 2.9525e-04 - val_loss: 6.8100e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9990e-04 - val_loss: 6.6693e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9466e-04 - val_loss: 6.0042e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9471e-04 - val_loss: 5.7614e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 2.8912e-04 - val_loss: 5.7394e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9812e-04 - val_loss: 5.8189e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9700e-04 - val_loss: 7.3259e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0437e-04 - val_loss: 6.2080e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0433e-04 - val_loss: 5.6696e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8943e-04 - val_loss: 5.7934e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 2.8772e-04 - val_loss: 5.7046e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8773e-04 - val_loss: 5.7568e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9062e-04 - val_loss: 6.0903e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8771e-04 - val_loss: 5.7264e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9625e-04 - val_loss: 5.7531e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8387e-04 - val_loss: 6.7182e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9284e-04 - val_loss: 5.9316e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8130e-04 - val_loss: 8.2079e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8907e-04 - val_loss: 5.9712e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9530e-04 - val_loss: 5.5477e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8862e-04 - val_loss: 6.9766e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0006e-04 - val_loss: 6.8136e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9434e-04 - val_loss: 6.0389e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8519e-04 - val_loss: 5.4956e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8095e-04 - val_loss: 7.3942e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8566e-04 - val_loss: 5.4064e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8097e-04 - val_loss: 5.9469e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8181e-04 - val_loss: 5.7850e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8388e-04 - val_loss: 7.3531e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8440e-04 - val_loss: 5.3372e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8968e-04 - val_loss: 5.4561e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8633e-04 - val_loss: 6.4721e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9548e-04 - val_loss: 5.6307e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7866e-04 - val_loss: 6.4059e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9766e-04 - val_loss: 6.3284e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8424e-04 - val_loss: 5.9538e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8192e-04 - val_loss: 7.9656e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.0547e-04 - val_loss: 5.6868e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8192e-04 - val_loss: 5.8530e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8005e-04 - val_loss: 5.1989e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9954e-04 - val_loss: 6.5205e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8153e-04 - val_loss: 5.4475e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8719e-04 - val_loss: 6.2908e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7773e-04 - val_loss: 5.6660e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8186e-04 - val_loss: 5.4614e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8011e-04 - val_loss: 6.1905e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.1167e-04 - val_loss: 5.5621e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7903e-04 - val_loss: 5.6319e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8329e-04 - val_loss: 6.5726e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8480e-04 - val_loss: 6.1797e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7565e-04 - val_loss: 6.3284e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7327e-04 - val_loss: 5.8857e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8937e-04 - val_loss: 6.1883e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7501e-04 - val_loss: 4.8965e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7544e-04 - val_loss: 7.1261e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8626e-04 - val_loss: 5.1921e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7669e-04 - val_loss: 6.7285e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 3.1124e-04 - val_loss: 4.8193e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7759e-04 - val_loss: 5.1048e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7502e-04 - val_loss: 5.5301e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7075e-04 - val_loss: 5.3365e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7475e-04 - val_loss: 5.4001e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7861e-04 - val_loss: 7.6112e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8214e-04 - val_loss: 5.0141e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8440e-04 - val_loss: 6.2421e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7637e-04 - val_loss: 5.4010e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7161e-04 - val_loss: 5.4567e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.7362e-04 - val_loss: 7.3088e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.8530e-04 - val_loss: 6.4737e-04\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 6s 141ms/step - loss: 2.7950e-04 - val_loss: 6.7785e-04\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9171e-04 - val_loss: 5.5768e-04\n",
      "Epoch 107/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.6812e-04 - val_loss: 5.2849e-04\n",
      "Epoch 108/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.7245e-04 - val_loss: 5.6010e-04\n",
      "Epoch 109/2000\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 2.9096e-04 - val_loss: 4.7790e-04\n",
      "Epoch 110/2000\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 2.8314e-04 - val_loss: 4.8074e-04\n",
      "Epoch 111/2000\n",
      "45/45 [==============================] - 6s 139ms/step - loss: 2.7161e-04 - val_loss: 5.1659e-04\n",
      "Epoch 112/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6890e-04 - val_loss: 5.1487e-04\n",
      "Epoch 113/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6710e-04 - val_loss: 5.4978e-04\n",
      "Epoch 114/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6761e-04 - val_loss: 4.8643e-04\n",
      "Epoch 115/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7263e-04 - val_loss: 4.5660e-04\n",
      "Epoch 116/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6828e-04 - val_loss: 5.9182e-04\n",
      "Epoch 117/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0589e-04 - val_loss: 4.6582e-04\n",
      "Epoch 118/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.7482e-04 - val_loss: 4.9080e-04\n",
      "Epoch 119/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.7254e-04 - val_loss: 5.1560e-04\n",
      "Epoch 120/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.7325e-04 - val_loss: 5.4998e-04\n",
      "Epoch 121/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7292e-04 - val_loss: 4.8441e-04\n",
      "Epoch 122/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6848e-04 - val_loss: 6.2237e-04\n",
      "Epoch 123/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.7541e-04 - val_loss: 5.0245e-04\n",
      "Epoch 124/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.7298e-04 - val_loss: 4.6908e-04\n",
      "Epoch 125/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.7161e-04 - val_loss: 5.0322e-04\n",
      "Epoch 126/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6840e-04 - val_loss: 4.6997e-04\n",
      "Epoch 127/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.5990e-04 - val_loss: 4.9853e-04\n",
      "Epoch 128/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.6749e-04 - val_loss: 5.0721e-04\n",
      "Epoch 129/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7250e-04 - val_loss: 5.7788e-04\n",
      "Epoch 130/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6811e-04 - val_loss: 5.2695e-04\n",
      "Epoch 131/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6594e-04 - val_loss: 4.9153e-04\n",
      "Epoch 132/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.6486e-04 - val_loss: 5.3677e-04\n",
      "Epoch 133/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6159e-04 - val_loss: 7.6508e-04\n",
      "Epoch 134/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7437e-04 - val_loss: 4.9697e-04\n",
      "Epoch 135/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6933e-04 - val_loss: 4.6457e-04\n",
      "Epoch 136/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6489e-04 - val_loss: 5.4613e-04\n",
      "Epoch 137/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6602e-04 - val_loss: 5.8013e-04\n",
      "Epoch 138/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6247e-04 - val_loss: 5.0836e-04\n",
      "Epoch 139/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.6038e-04 - val_loss: 5.2352e-04\n",
      "Epoch 140/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6866e-04 - val_loss: 5.0528e-04\n",
      "Epoch 141/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8425e-04 - val_loss: 4.7261e-04\n",
      "Epoch 142/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6707e-04 - val_loss: 4.4466e-04\n",
      "Epoch 143/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6352e-04 - val_loss: 5.0452e-04\n",
      "Epoch 144/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6617e-04 - val_loss: 5.2771e-04\n",
      "Epoch 145/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6011e-04 - val_loss: 5.3042e-04\n",
      "Epoch 146/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.1002e-04 - val_loss: 4.8627e-04\n",
      "Epoch 147/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6233e-04 - val_loss: 4.9078e-04\n",
      "Epoch 148/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6165e-04 - val_loss: 5.9640e-04\n",
      "Epoch 149/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6463e-04 - val_loss: 4.7358e-04\n",
      "Epoch 150/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6404e-04 - val_loss: 6.4244e-04\n",
      "Epoch 151/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 2.6310e-04 - val_loss: 5.0221e-04\n",
      "Epoch 152/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 2.6343e-04 - val_loss: 5.1308e-04\n",
      "Epoch 153/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5804e-04 - val_loss: 5.0013e-04\n",
      "Epoch 154/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7945e-04 - val_loss: 4.6582e-04\n",
      "Epoch 155/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.5972e-04 - val_loss: 5.5019e-04\n",
      "Epoch 156/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.7635e-04 - val_loss: 4.6490e-04\n",
      "Epoch 157/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7132e-04 - val_loss: 5.2399e-04\n",
      "Epoch 158/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.5793e-04 - val_loss: 5.1730e-04\n",
      "Epoch 159/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5731e-04 - val_loss: 4.5844e-04\n",
      "Epoch 160/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.5978e-04 - val_loss: 4.8693e-04\n",
      "Epoch 161/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6458e-04 - val_loss: 5.2996e-04\n",
      "Epoch 162/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6780e-04 - val_loss: 6.0312e-04\n",
      "Epoch 163/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6400e-04 - val_loss: 4.9904e-04\n",
      "Epoch 164/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6115e-04 - val_loss: 5.0239e-04\n",
      "Epoch 165/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.5613e-04 - val_loss: 5.2860e-04\n",
      "Epoch 166/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.5407e-04 - val_loss: 5.5378e-04\n",
      "Epoch 167/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6871e-04 - val_loss: 5.1399e-04\n",
      "Epoch 168/2000\n",
      "45/45 [==============================] - 7s 147ms/step - loss: 2.5312e-04 - val_loss: 5.1757e-04\n",
      "Epoch 169/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.5653e-04 - val_loss: 4.8051e-04\n",
      "Epoch 170/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.5432e-04 - val_loss: 5.0917e-04\n",
      "Epoch 171/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.5358e-04 - val_loss: 5.3947e-04\n",
      "Epoch 172/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6200e-04 - val_loss: 5.2700e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_128_layer_call_fn, lstm_cell_128_layer_call_and_return_conditional_losses, lstm_cell_129_layer_call_fn, lstm_cell_129_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 9s 156ms/step - loss: 0.0209 - val_loss: 0.0036\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 5.9409e-04 - val_loss: 4.4843e-04\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.5667e-04 - val_loss: 4.8887e-04\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 3.2639e-04 - val_loss: 4.6987e-04\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1887e-04 - val_loss: 4.8500e-04\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.2022e-04 - val_loss: 4.8527e-04\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.1144e-04 - val_loss: 6.4068e-04\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.1521e-04 - val_loss: 5.1670e-04\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0685e-04 - val_loss: 5.5493e-04\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0647e-04 - val_loss: 5.5998e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9867e-04 - val_loss: 5.5547e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0319e-04 - val_loss: 5.3058e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0466e-04 - val_loss: 5.4562e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9696e-04 - val_loss: 5.8709e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9446e-04 - val_loss: 6.1684e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9864e-04 - val_loss: 5.7701e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9102e-04 - val_loss: 5.8487e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9015e-04 - val_loss: 6.2323e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9094e-04 - val_loss: 6.0379e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8945e-04 - val_loss: 6.0593e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9168e-04 - val_loss: 6.2094e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8824e-04 - val_loss: 6.3120e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9128e-04 - val_loss: 6.1952e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8600e-04 - val_loss: 6.4661e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8861e-04 - val_loss: 6.4736e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8714e-04 - val_loss: 7.0737e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.8539e-04 - val_loss: 7.0724e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9892e-04 - val_loss: 6.1971e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8564e-04 - val_loss: 7.0706e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9653e-04 - val_loss: 7.8620e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8988e-04 - val_loss: 6.8599e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8211e-04 - val_loss: 6.6131e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_130_layer_call_fn, lstm_cell_130_layer_call_and_return_conditional_losses, lstm_cell_131_layer_call_fn, lstm_cell_131_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 9s 156ms/step - loss: 0.0358 - val_loss: 0.0200\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 0.0015 - val_loss: 0.0104\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 9.8816e-04 - val_loss: 0.0095\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 8.2634e-04 - val_loss: 0.0080\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 7.0204e-04 - val_loss: 0.0067\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 5.8717e-04 - val_loss: 0.0057\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 7s 152ms/step - loss: 5.0102e-04 - val_loss: 0.0063\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 4.6337e-04 - val_loss: 0.0044\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 4.3427e-04 - val_loss: 0.0035\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 4.1427e-04 - val_loss: 0.0037\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.9164e-04 - val_loss: 0.0027\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 3.9726e-04 - val_loss: 0.0023\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 4.1915e-04 - val_loss: 0.0029\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.7145e-04 - val_loss: 0.0029\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.5526e-04 - val_loss: 0.0028\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.5087e-04 - val_loss: 0.0019\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.4726e-04 - val_loss: 0.0011\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.4642e-04 - val_loss: 0.0014\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.3561e-04 - val_loss: 0.0017\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.2512e-04 - val_loss: 0.0015\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 7s 144ms/step - loss: 3.2244e-04 - val_loss: 0.0018\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2679e-04 - val_loss: 0.0018\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 3.3310e-04 - val_loss: 8.0573e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1867e-04 - val_loss: 0.0016\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.1969e-04 - val_loss: 0.0011\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0875e-04 - val_loss: 0.0011\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.2365e-04 - val_loss: 8.1302e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1810e-04 - val_loss: 0.0011\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0884e-04 - val_loss: 8.7752e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1217e-04 - val_loss: 0.0010\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.1776e-04 - val_loss: 0.0012\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.1126e-04 - val_loss: 6.7571e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9688e-04 - val_loss: 8.7429e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.2241e-04 - val_loss: 0.0011\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9955e-04 - val_loss: 6.8690e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0330e-04 - val_loss: 6.2425e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9595e-04 - val_loss: 6.0221e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9946e-04 - val_loss: 6.9464e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9592e-04 - val_loss: 5.3528e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9525e-04 - val_loss: 6.2461e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9916e-04 - val_loss: 5.1323e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9432e-04 - val_loss: 6.6344e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9831e-04 - val_loss: 6.8119e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9014e-04 - val_loss: 6.0404e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9713e-04 - val_loss: 5.4960e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0956e-04 - val_loss: 5.1221e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 7s 144ms/step - loss: 2.9523e-04 - val_loss: 5.0830e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0526e-04 - val_loss: 6.8496e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0467e-04 - val_loss: 5.3845e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1124e-04 - val_loss: 5.0287e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9897e-04 - val_loss: 6.6458e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8655e-04 - val_loss: 5.2718e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8900e-04 - val_loss: 6.2235e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8823e-04 - val_loss: 6.1399e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8280e-04 - val_loss: 6.7704e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0459e-04 - val_loss: 5.4949e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9916e-04 - val_loss: 4.7838e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0734e-04 - val_loss: 5.9387e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8695e-04 - val_loss: 7.7640e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8712e-04 - val_loss: 5.0795e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9570e-04 - val_loss: 6.7623e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8339e-04 - val_loss: 9.1446e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0608e-04 - val_loss: 5.1369e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8606e-04 - val_loss: 5.1490e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 2.8551e-04 - val_loss: 5.7427e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9111e-04 - val_loss: 7.4179e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9213e-04 - val_loss: 6.9078e-04\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8540e-04 - val_loss: 6.3198e-04\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9763e-04 - val_loss: 5.9668e-04\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8562e-04 - val_loss: 5.3039e-04\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8341e-04 - val_loss: 6.7527e-04\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0466e-04 - val_loss: 5.1221e-04\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.7890e-04 - val_loss: 5.1659e-04\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7830e-04 - val_loss: 5.0922e-04\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7900e-04 - val_loss: 5.3939e-04\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8520e-04 - val_loss: 4.6590e-04\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9155e-04 - val_loss: 5.1409e-04\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8570e-04 - val_loss: 4.7048e-04\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.7989e-04 - val_loss: 5.6349e-04\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8448e-04 - val_loss: 7.3725e-04\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8304e-04 - val_loss: 5.0034e-04\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8015e-04 - val_loss: 7.0501e-04\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8675e-04 - val_loss: 4.7193e-04\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.7677e-04 - val_loss: 6.3236e-04\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.2304e-04 - val_loss: 4.5197e-04\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8289e-04 - val_loss: 5.0296e-04\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8027e-04 - val_loss: 5.7236e-04\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8555e-04 - val_loss: 7.4232e-04\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8335e-04 - val_loss: 6.0003e-04\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7840e-04 - val_loss: 5.5008e-04\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7577e-04 - val_loss: 8.4965e-04\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8309e-04 - val_loss: 5.5954e-04\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7680e-04 - val_loss: 6.4439e-04\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7525e-04 - val_loss: 6.7170e-04\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.7322e-04 - val_loss: 6.7787e-04\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9832e-04 - val_loss: 7.5565e-04\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8701e-04 - val_loss: 4.9945e-04\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 3.0005e-04 - val_loss: 7.2680e-04\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8335e-04 - val_loss: 5.1990e-04\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 2.7446e-04 - val_loss: 5.4013e-04\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7668e-04 - val_loss: 5.8208e-04\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7620e-04 - val_loss: 5.7385e-04\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6949e-04 - val_loss: 5.8188e-04\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9339e-04 - val_loss: 4.8702e-04\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7789e-04 - val_loss: 7.6273e-04\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9437e-04 - val_loss: 5.7205e-04\n",
      "Epoch 107/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7109e-04 - val_loss: 5.4528e-04\n",
      "Epoch 108/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6677e-04 - val_loss: 5.3555e-04\n",
      "Epoch 109/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7498e-04 - val_loss: 6.7254e-04\n",
      "Epoch 110/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 2.6744e-04 - val_loss: 5.6409e-04\n",
      "Epoch 111/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7335e-04 - val_loss: 5.3082e-04\n",
      "Epoch 112/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9546e-04 - val_loss: 5.4800e-04\n",
      "Epoch 113/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6654e-04 - val_loss: 5.6536e-04\n",
      "Epoch 114/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6816e-04 - val_loss: 5.4062e-04\n",
      "Epoch 115/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8238e-04 - val_loss: 6.5451e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_132_layer_call_fn, lstm_cell_132_layer_call_and_return_conditional_losses, lstm_cell_133_layer_call_fn, lstm_cell_133_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 9s 155ms/step - loss: 0.0065 - val_loss: 0.0014\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 7.5937e-04 - val_loss: 0.0042\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 4.4252e-04 - val_loss: 0.0031\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.8120e-04 - val_loss: 0.0054\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.6557e-04 - val_loss: 0.0040\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.4575e-04 - val_loss: 0.0044\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.3431e-04 - val_loss: 0.0033\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.3339e-04 - val_loss: 0.0031\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.2646e-04 - val_loss: 0.0028\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1900e-04 - val_loss: 0.0023\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.2156e-04 - val_loss: 0.0027\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1549e-04 - val_loss: 0.0021\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0850e-04 - val_loss: 0.0012\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.3072e-04 - val_loss: 0.0021\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1108e-04 - val_loss: 9.9830e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.3133e-04 - val_loss: 0.0022\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.1993e-04 - val_loss: 0.0015\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9889e-04 - val_loss: 8.2018e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0467e-04 - val_loss: 0.0010\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9706e-04 - val_loss: 0.0010\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 7s 147ms/step - loss: 2.9042e-04 - val_loss: 0.0011\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0870e-04 - val_loss: 0.0011\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8985e-04 - val_loss: 8.5779e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9432e-04 - val_loss: 7.6670e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9353e-04 - val_loss: 9.6928e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9174e-04 - val_loss: 6.1611e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9191e-04 - val_loss: 7.1584e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8139e-04 - val_loss: 6.0909e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.8581e-04 - val_loss: 0.0010\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8757e-04 - val_loss: 7.2411e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9134e-04 - val_loss: 0.0010\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8725e-04 - val_loss: 5.6606e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8407e-04 - val_loss: 5.6608e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8734e-04 - val_loss: 9.4263e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9151e-04 - val_loss: 4.8352e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8153e-04 - val_loss: 8.8327e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8492e-04 - val_loss: 4.8108e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9204e-04 - val_loss: 8.0476e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8120e-04 - val_loss: 5.4602e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8089e-04 - val_loss: 5.2323e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7813e-04 - val_loss: 5.6512e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8303e-04 - val_loss: 5.2546e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7665e-04 - val_loss: 5.4504e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7636e-04 - val_loss: 5.9167e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8373e-04 - val_loss: 5.6873e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7301e-04 - val_loss: 5.7875e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9192e-04 - val_loss: 6.2276e-04\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7550e-04 - val_loss: 6.3393e-04\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8040e-04 - val_loss: 6.3099e-04\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7158e-04 - val_loss: 5.9602e-04\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7772e-04 - val_loss: 5.9963e-04\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6733e-04 - val_loss: 6.0243e-04\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7091e-04 - val_loss: 6.1311e-04\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6854e-04 - val_loss: 6.0115e-04\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7109e-04 - val_loss: 6.0385e-04\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6933e-04 - val_loss: 5.8966e-04\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7573e-04 - val_loss: 6.2243e-04\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7060e-04 - val_loss: 6.2782e-04\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6743e-04 - val_loss: 6.0407e-04\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6921e-04 - val_loss: 6.9484e-04\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.8083e-04 - val_loss: 5.8901e-04\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.6303e-04 - val_loss: 5.8811e-04\n",
      "Epoch 63/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.6754e-04 - val_loss: 6.3005e-04\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.7883e-04 - val_loss: 6.3600e-04\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6464e-04 - val_loss: 6.1955e-04\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.6189e-04 - val_loss: 6.8815e-04\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 2.8968e-04 - val_loss: 6.4391e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_134_layer_call_fn, lstm_cell_134_layer_call_and_return_conditional_losses, lstm_cell_135_layer_call_fn, lstm_cell_135_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 10s 158ms/step - loss: 0.0132 - val_loss: 0.0017\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 8.2933e-04 - val_loss: 0.0014\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 7s 147ms/step - loss: 5.0941e-04 - val_loss: 6.6358e-04\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 4.1049e-04 - val_loss: 4.6990e-04\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.8326e-04 - val_loss: 5.5476e-04\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 4.0576e-04 - val_loss: 6.2697e-04\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.5261e-04 - val_loss: 5.5783e-04\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.5449e-04 - val_loss: 3.9053e-04\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 7s 147ms/step - loss: 3.5966e-04 - val_loss: 5.1542e-04\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.5804e-04 - val_loss: 6.4880e-04\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.2910e-04 - val_loss: 4.2338e-04\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.2546e-04 - val_loss: 6.6151e-04\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.4296e-04 - val_loss: 4.9865e-04\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.1556e-04 - val_loss: 4.2731e-04\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.2286e-04 - val_loss: 6.2816e-04\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.2359e-04 - val_loss: 4.9289e-04\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.2737e-04 - val_loss: 3.6555e-04\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0942e-04 - val_loss: 4.9925e-04\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.1728e-04 - val_loss: 3.6946e-04\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.1313e-04 - val_loss: 5.5081e-04\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.1644e-04 - val_loss: 4.6563e-04\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0660e-04 - val_loss: 3.8154e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.0492e-04 - val_loss: 4.3400e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.0107e-04 - val_loss: 3.6921e-04\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.1267e-04 - val_loss: 3.7238e-04\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.1205e-04 - val_loss: 4.3411e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.0471e-04 - val_loss: 3.6578e-04\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 6s 133ms/step - loss: 3.2533e-04 - val_loss: 5.0137e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0153e-04 - val_loss: 5.7178e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 7s 148ms/step - loss: 2.9662e-04 - val_loss: 4.7300e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.9700e-04 - val_loss: 4.4078e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.9285e-04 - val_loss: 8.3293e-04\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.0487e-04 - val_loss: 4.6206e-04\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.9403e-04 - val_loss: 6.6681e-04\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.9840e-04 - val_loss: 4.5150e-04\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.9386e-04 - val_loss: 4.0245e-04\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 3.1373e-04 - val_loss: 4.3303e-04\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 7s 147ms/step - loss: 2.8828e-04 - val_loss: 4.9424e-04\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 7s 147ms/step - loss: 2.8954e-04 - val_loss: 4.5887e-04\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 7s 147ms/step - loss: 2.8760e-04 - val_loss: 6.4784e-04\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 7s 147ms/step - loss: 2.9021e-04 - val_loss: 4.3917e-04\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.8577e-04 - val_loss: 4.3274e-04\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.8538e-04 - val_loss: 6.1398e-04\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.8721e-04 - val_loss: 4.0232e-04\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.9378e-04 - val_loss: 7.1854e-04\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.8777e-04 - val_loss: 7.5435e-04\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 7s 146ms/step - loss: 2.8852e-04 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_136_layer_call_fn, lstm_cell_136_layer_call_and_return_conditional_losses, lstm_cell_137_layer_call_fn, lstm_cell_137_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "45/45 [==============================] - 10s 159ms/step - loss: 0.0213 - val_loss: 0.0026\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 6.3740e-04 - val_loss: 6.7212e-04\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 5.0291e-04 - val_loss: 9.9304e-04\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 4.4155e-04 - val_loss: 8.1866e-04\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.8326e-04 - val_loss: 7.7306e-04\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 6s 143ms/step - loss: 3.6553e-04 - val_loss: 9.6025e-04\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.4372e-04 - val_loss: 9.3865e-04\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.3887e-04 - val_loss: 9.4324e-04\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.2594e-04 - val_loss: 9.8875e-04\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1839e-04 - val_loss: 0.0012\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.5424e-04 - val_loss: 0.0011\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1984e-04 - val_loss: 0.0010\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.1157e-04 - val_loss: 0.0011\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 6s 145ms/step - loss: 3.0430e-04 - val_loss: 0.0011\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.1789e-04 - val_loss: 0.0011\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.2099e-04 - val_loss: 0.0010\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0270e-04 - val_loss: 0.0010\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0020e-04 - val_loss: 0.0011\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0271e-04 - val_loss: 0.0011\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0215e-04 - val_loss: 0.0010\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0003e-04 - val_loss: 9.5622e-04\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0013e-04 - val_loss: 9.9511e-04\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0148e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.4135e-04 - val_loss: 0.0010\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9823e-04 - val_loss: 9.9321e-04\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9733e-04 - val_loss: 0.0011\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 3.0142e-04 - val_loss: 9.9294e-04\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9739e-04 - val_loss: 8.9786e-04\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9335e-04 - val_loss: 9.4320e-04\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 2.9872e-04 - val_loss: 9.1160e-04\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 2.9823e-04 - val_loss: 0.0011\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 3.0495e-04 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_138_layer_call_fn, lstm_cell_138_layer_call_and_return_conditional_losses, lstm_cell_139_layer_call_fn, lstm_cell_139_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_9\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_memory = 400\n",
    "\n",
    "trainInputX, trainInputY = sf.prepareData(trainX, trainY, lstm_memory)\n",
    "testInputX, testInputY = sf.prepareData(testX, testY, lstm_memory)\n",
    "print(trainInputX.shape)\n",
    "print(trainInputY.shape)\n",
    "print(testInputX.shape)\n",
    "print(testInputY.shape)\n",
    "\n",
    "#validacao tamanho apos tratamentos\n",
    "print(len(trainX))\n",
    "print(len(trainInputX))\n",
    "\n",
    "print(len(trainY))\n",
    "print(len(trainInputY))\n",
    "\n",
    "trainInputX = trainInputX [:,:,0:14]\n",
    "testInputX = testInputX [:,:,0:14]\n",
    "print(trainInputX.shape)\n",
    "\n",
    "trained_models_lstm_400 = []\n",
    "trained_models_lstm_400_history = []\n",
    "\n",
    "for i in range(0,10):\n",
    "\n",
    "    #giving it reproducibility\n",
    "    seed = (i+1000)\n",
    "\n",
    "    os.environ['PYTHONHASHseed']=str(seed)\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    batch_size = 256\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "    \n",
    "    trained_models_lstm_400.append(kr.Sequential())\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_400[i].add(kr.layers.LSTM(14,return_sequences = True))\n",
    "    trained_models_lstm_400[i].add(kr.layers.LSTM(8))\n",
    "    # lstm_model.add(kr.layers.Simplelstm(5,input_shape=(trainInputX.shape[1],trainInputX.shape[2])))\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_400[i].add(kr.layers.Dense(1))\n",
    "    trained_models_lstm_400[i].compile(loss='mean_squared_error',optimizer='adam')\n",
    "    \n",
    "    trained_models_lstm_400_history.append(trained_models_lstm_400[i].fit(trainInputX, trainInputY, epochs=2000, batch_size=batch_size, verbose = 1, validation_data=(testInputX,testInputY),  callbacks=[callback]))\n",
    "    \n",
    "    trained_models_lstm_400[i].save('C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_400_batch_256_earlystop_valloss_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c06f007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10890, 800, 14)\n",
      "(10890,)\n",
      "(2123, 800, 14)\n",
      "(2123,)\n",
      "11690\n",
      "10890\n",
      "11690\n",
      "10890\n",
      "(10890, 800, 14)\n",
      "Epoch 1/2000\n",
      "43/43 [==============================] - 15s 300ms/step - loss: 0.0505 - val_loss: 0.0029\n",
      "Epoch 2/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 3/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 8.0492e-04 - val_loss: 0.0025\n",
      "Epoch 4/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 6.0391e-04 - val_loss: 0.0034\n",
      "Epoch 5/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 5.2872e-04 - val_loss: 0.0036\n",
      "Epoch 6/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 4.8343e-04 - val_loss: 0.0034\n",
      "Epoch 7/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 4.4935e-04 - val_loss: 0.0035\n",
      "Epoch 8/2000\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 4.1843e-04 - val_loss: 0.0032\n",
      "Epoch 9/2000\n",
      "43/43 [==============================] - 12s 282ms/step - loss: 3.9700e-04 - val_loss: 0.0035\n",
      "Epoch 10/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.8141e-04 - val_loss: 0.0026\n",
      "Epoch 11/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.7000e-04 - val_loss: 0.0028\n",
      "Epoch 12/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.5422e-04 - val_loss: 0.0023\n",
      "Epoch 13/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.5349e-04 - val_loss: 0.0022\n",
      "Epoch 14/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.4663e-04 - val_loss: 0.0018\n",
      "Epoch 15/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.4184e-04 - val_loss: 0.0017\n",
      "Epoch 16/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.3952e-04 - val_loss: 0.0017\n",
      "Epoch 17/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.3314e-04 - val_loss: 0.0015\n",
      "Epoch 18/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.3121e-04 - val_loss: 0.0013\n",
      "Epoch 19/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.3390e-04 - val_loss: 0.0017\n",
      "Epoch 20/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.3043e-04 - val_loss: 0.0016\n",
      "Epoch 21/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.2912e-04 - val_loss: 0.0011\n",
      "Epoch 22/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.3241e-04 - val_loss: 7.9470e-04\n",
      "Epoch 23/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.3553e-04 - val_loss: 0.0010\n",
      "Epoch 24/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.2287e-04 - val_loss: 9.2798e-04\n",
      "Epoch 25/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.2905e-04 - val_loss: 0.0014\n",
      "Epoch 26/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.3505e-04 - val_loss: 0.0011\n",
      "Epoch 27/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.2413e-04 - val_loss: 7.7734e-04\n",
      "Epoch 28/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.2337e-04 - val_loss: 0.0010\n",
      "Epoch 29/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 3.1779e-04 - val_loss: 8.9187e-04\n",
      "Epoch 30/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.2602e-04 - val_loss: 9.8779e-04\n",
      "Epoch 31/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1736e-04 - val_loss: 8.7798e-04\n",
      "Epoch 32/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1763e-04 - val_loss: 9.4591e-04\n",
      "Epoch 33/2000\n",
      "43/43 [==============================] - 13s 291ms/step - loss: 3.1829e-04 - val_loss: 7.0771e-04\n",
      "Epoch 34/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.1449e-04 - val_loss: 8.9497e-04\n",
      "Epoch 35/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.1699e-04 - val_loss: 8.3447e-04\n",
      "Epoch 36/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.1619e-04 - val_loss: 0.0011\n",
      "Epoch 37/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1727e-04 - val_loss: 6.7396e-04\n",
      "Epoch 38/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.1087e-04 - val_loss: 6.1941e-04\n",
      "Epoch 39/2000\n",
      "43/43 [==============================] - 12s 276ms/step - loss: 3.1319e-04 - val_loss: 7.5406e-04\n",
      "Epoch 40/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.1861e-04 - val_loss: 6.2327e-04\n",
      "Epoch 41/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.0913e-04 - val_loss: 4.7628e-04\n",
      "Epoch 42/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1081e-04 - val_loss: 6.1009e-04\n",
      "Epoch 43/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.3025e-04 - val_loss: 8.2615e-04\n",
      "Epoch 44/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0894e-04 - val_loss: 7.2145e-04\n",
      "Epoch 45/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0881e-04 - val_loss: 5.6976e-04\n",
      "Epoch 46/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.1888e-04 - val_loss: 4.5196e-04\n",
      "Epoch 47/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0680e-04 - val_loss: 5.3304e-04\n",
      "Epoch 48/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1291e-04 - val_loss: 4.5568e-04\n",
      "Epoch 49/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0968e-04 - val_loss: 8.2497e-04\n",
      "Epoch 50/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1543e-04 - val_loss: 5.1340e-04\n",
      "Epoch 51/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.2583e-04 - val_loss: 4.1017e-04\n",
      "Epoch 52/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1159e-04 - val_loss: 4.1667e-04\n",
      "Epoch 53/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.0874e-04 - val_loss: 4.2495e-04\n",
      "Epoch 54/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.1468e-04 - val_loss: 7.4896e-04\n",
      "Epoch 55/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1606e-04 - val_loss: 9.2784e-04\n",
      "Epoch 56/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0486e-04 - val_loss: 6.6027e-04\n",
      "Epoch 57/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.0542e-04 - val_loss: 5.0854e-04\n",
      "Epoch 58/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0255e-04 - val_loss: 5.2941e-04\n",
      "Epoch 59/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.0442e-04 - val_loss: 4.8088e-04\n",
      "Epoch 60/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0610e-04 - val_loss: 5.1588e-04\n",
      "Epoch 61/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.0417e-04 - val_loss: 5.5886e-04\n",
      "Epoch 62/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1510e-04 - val_loss: 4.2104e-04\n",
      "Epoch 63/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.0508e-04 - val_loss: 4.3500e-04\n",
      "Epoch 64/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1464e-04 - val_loss: 4.2491e-04\n",
      "Epoch 65/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.0608e-04 - val_loss: 7.2720e-04\n",
      "Epoch 66/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0925e-04 - val_loss: 5.7915e-04\n",
      "Epoch 67/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.0303e-04 - val_loss: 4.9671e-04\n",
      "Epoch 68/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.2005e-04 - val_loss: 6.3335e-04\n",
      "Epoch 69/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.2837e-04 - val_loss: 3.6636e-04\n",
      "Epoch 70/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.9789e-04 - val_loss: 6.4967e-04\n",
      "Epoch 71/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.9838e-04 - val_loss: 5.7306e-04\n",
      "Epoch 72/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.9698e-04 - val_loss: 5.0964e-04\n",
      "Epoch 73/2000\n",
      "43/43 [==============================] - 13s 291ms/step - loss: 2.9766e-04 - val_loss: 5.0697e-04\n",
      "Epoch 74/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1854e-04 - val_loss: 5.0377e-04\n",
      "Epoch 75/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.9261e-04 - val_loss: 5.2219e-04\n",
      "Epoch 76/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0280e-04 - val_loss: 6.5491e-04\n",
      "Epoch 77/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.9663e-04 - val_loss: 4.6175e-04\n",
      "Epoch 78/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.9996e-04 - val_loss: 4.7513e-04\n",
      "Epoch 79/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0490e-04 - val_loss: 3.8652e-04\n",
      "Epoch 80/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.9147e-04 - val_loss: 7.3548e-04\n",
      "Epoch 81/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.9790e-04 - val_loss: 4.7953e-04\n",
      "Epoch 82/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.0176e-04 - val_loss: 7.7246e-04\n",
      "Epoch 83/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0003e-04 - val_loss: 3.9028e-04\n",
      "Epoch 84/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.0396e-04 - val_loss: 4.3998e-04\n",
      "Epoch 85/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0605e-04 - val_loss: 5.1999e-04\n",
      "Epoch 86/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.9137e-04 - val_loss: 4.9577e-04\n",
      "Epoch 87/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0172e-04 - val_loss: 4.5686e-04\n",
      "Epoch 88/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.0561e-04 - val_loss: 3.8752e-04\n",
      "Epoch 89/2000\n",
      "43/43 [==============================] - 13s 291ms/step - loss: 3.1324e-04 - val_loss: 5.4005e-04\n",
      "Epoch 90/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.9421e-04 - val_loss: 5.7237e-04\n",
      "Epoch 91/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.9318e-04 - val_loss: 4.2048e-04\n",
      "Epoch 92/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.9252e-04 - val_loss: 4.0064e-04\n",
      "Epoch 93/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.9037e-04 - val_loss: 3.8562e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_140_layer_call_fn, lstm_cell_140_layer_call_and_return_conditional_losses, lstm_cell_141_layer_call_fn, lstm_cell_141_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_800_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_800_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "43/43 [==============================] - 16s 306ms/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 2/2000\n",
      "43/43 [==============================] - 13s 306ms/step - loss: 8.2263e-04 - val_loss: 0.0021\n",
      "Epoch 3/2000\n",
      "43/43 [==============================] - 13s 308ms/step - loss: 4.7462e-04 - val_loss: 0.0018\n",
      "Epoch 4/2000\n",
      "43/43 [==============================] - 13s 310ms/step - loss: 4.0900e-04 - val_loss: 0.0015\n",
      "Epoch 5/2000\n",
      "43/43 [==============================] - 13s 309ms/step - loss: 3.8197e-04 - val_loss: 0.0017\n",
      "Epoch 6/2000\n",
      "43/43 [==============================] - 13s 301ms/step - loss: 3.6348e-04 - val_loss: 0.0017\n",
      "Epoch 7/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 3.4759e-04 - val_loss: 0.0011\n",
      "Epoch 8/2000\n",
      "43/43 [==============================] - 13s 310ms/step - loss: 3.4734e-04 - val_loss: 8.4056e-04\n",
      "Epoch 9/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 3.4893e-04 - val_loss: 9.1509e-04\n",
      "Epoch 10/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.4009e-04 - val_loss: 0.0012\n",
      "Epoch 11/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.3714e-04 - val_loss: 0.0013\n",
      "Epoch 12/2000\n",
      "43/43 [==============================] - 13s 293ms/step - loss: 3.2382e-04 - val_loss: 8.4618e-04\n",
      "Epoch 13/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.2506e-04 - val_loss: 9.6433e-04\n",
      "Epoch 14/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.4018e-04 - val_loss: 9.7277e-04\n",
      "Epoch 15/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.2424e-04 - val_loss: 0.0012\n",
      "Epoch 16/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1361e-04 - val_loss: 0.0013\n",
      "Epoch 17/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1470e-04 - val_loss: 9.9389e-04\n",
      "Epoch 18/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.1570e-04 - val_loss: 0.0010\n",
      "Epoch 19/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.2400e-04 - val_loss: 8.1617e-04\n",
      "Epoch 20/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.1550e-04 - val_loss: 7.9635e-04\n",
      "Epoch 21/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.0657e-04 - val_loss: 9.9623e-04\n",
      "Epoch 22/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1402e-04 - val_loss: 0.0012\n",
      "Epoch 23/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 3.0931e-04 - val_loss: 7.3989e-04\n",
      "Epoch 24/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.0730e-04 - val_loss: 7.6671e-04\n",
      "Epoch 25/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1268e-04 - val_loss: 0.0011\n",
      "Epoch 26/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.0283e-04 - val_loss: 8.8107e-04\n",
      "Epoch 27/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.0109e-04 - val_loss: 7.9973e-04\n",
      "Epoch 28/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.0702e-04 - val_loss: 9.2285e-04\n",
      "Epoch 29/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.0408e-04 - val_loss: 7.2822e-04\n",
      "Epoch 30/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.9857e-04 - val_loss: 6.7112e-04\n",
      "Epoch 31/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.3338e-04 - val_loss: 6.9497e-04\n",
      "Epoch 32/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 3.0700e-04 - val_loss: 8.2199e-04\n",
      "Epoch 33/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.9096e-04 - val_loss: 7.2927e-04\n",
      "Epoch 34/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.9766e-04 - val_loss: 8.4923e-04\n",
      "Epoch 35/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.9568e-04 - val_loss: 8.2869e-04\n",
      "Epoch 36/2000\n",
      "43/43 [==============================] - 13s 292ms/step - loss: 2.9106e-04 - val_loss: 7.4082e-04\n",
      "Epoch 37/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 3.0445e-04 - val_loss: 8.6898e-04\n",
      "Epoch 38/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 3.0251e-04 - val_loss: 8.8524e-04\n",
      "Epoch 39/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.9547e-04 - val_loss: 0.0011\n",
      "Epoch 40/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.9526e-04 - val_loss: 7.2380e-04\n",
      "Epoch 41/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.9749e-04 - val_loss: 8.9270e-04\n",
      "Epoch 42/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.8931e-04 - val_loss: 8.2479e-04\n",
      "Epoch 43/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.9239e-04 - val_loss: 8.5704e-04\n",
      "Epoch 44/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.8086e-04 - val_loss: 7.0650e-04\n",
      "Epoch 45/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.8412e-04 - val_loss: 6.5624e-04\n",
      "Epoch 46/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.8403e-04 - val_loss: 6.5675e-04\n",
      "Epoch 47/2000\n",
      "43/43 [==============================] - 12s 272ms/step - loss: 2.8648e-04 - val_loss: 8.1109e-04\n",
      "Epoch 48/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.8396e-04 - val_loss: 6.7797e-04\n",
      "Epoch 49/2000\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 2.8239e-04 - val_loss: 6.8657e-04\n",
      "Epoch 50/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.7993e-04 - val_loss: 6.4640e-04\n",
      "Epoch 51/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.8918e-04 - val_loss: 0.0011\n",
      "Epoch 52/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.8499e-04 - val_loss: 8.8559e-04\n",
      "Epoch 53/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.7641e-04 - val_loss: 6.8122e-04\n",
      "Epoch 54/2000\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 3.1148e-04 - val_loss: 0.0011\n",
      "Epoch 55/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 3.1390e-04 - val_loss: 9.2926e-04\n",
      "Epoch 56/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.8245e-04 - val_loss: 8.4734e-04\n",
      "Epoch 57/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.7542e-04 - val_loss: 6.9828e-04\n",
      "Epoch 58/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.8003e-04 - val_loss: 7.6006e-04\n",
      "Epoch 59/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.7990e-04 - val_loss: 7.9269e-04\n",
      "Epoch 60/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.7813e-04 - val_loss: 0.0010\n",
      "Epoch 61/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.8472e-04 - val_loss: 6.4830e-04\n",
      "Epoch 62/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.7284e-04 - val_loss: 6.6748e-04\n",
      "Epoch 63/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.7840e-04 - val_loss: 6.3229e-04\n",
      "Epoch 64/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.8571e-04 - val_loss: 8.9787e-04\n",
      "Epoch 65/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.8020e-04 - val_loss: 7.4721e-04\n",
      "Epoch 66/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.7292e-04 - val_loss: 7.5366e-04\n",
      "Epoch 67/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.7184e-04 - val_loss: 8.2465e-04\n",
      "Epoch 68/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6944e-04 - val_loss: 6.8258e-04\n",
      "Epoch 69/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.7073e-04 - val_loss: 6.5807e-04\n",
      "Epoch 70/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6711e-04 - val_loss: 6.1216e-04\n",
      "Epoch 71/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.8310e-04 - val_loss: 8.5122e-04\n",
      "Epoch 72/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.7344e-04 - val_loss: 6.8339e-04\n",
      "Epoch 73/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.7517e-04 - val_loss: 6.9599e-04\n",
      "Epoch 74/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.8877e-04 - val_loss: 7.8090e-04\n",
      "Epoch 75/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.9750e-04 - val_loss: 7.4024e-04\n",
      "Epoch 76/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.7035e-04 - val_loss: 7.6644e-04\n",
      "Epoch 77/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.6704e-04 - val_loss: 6.6497e-04\n",
      "Epoch 78/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6691e-04 - val_loss: 7.8076e-04\n",
      "Epoch 79/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6570e-04 - val_loss: 7.4871e-04\n",
      "Epoch 80/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6885e-04 - val_loss: 9.2295e-04\n",
      "Epoch 81/2000\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 2.7173e-04 - val_loss: 7.1974e-04\n",
      "Epoch 82/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.9658e-04 - val_loss: 7.7199e-04\n",
      "Epoch 83/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.6953e-04 - val_loss: 9.0480e-04\n",
      "Epoch 84/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.7725e-04 - val_loss: 8.3922e-04\n",
      "Epoch 85/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.7907e-04 - val_loss: 7.5675e-04\n",
      "Epoch 86/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6276e-04 - val_loss: 7.0627e-04\n",
      "Epoch 87/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.6548e-04 - val_loss: 7.8248e-04\n",
      "Epoch 88/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.6680e-04 - val_loss: 6.0145e-04\n",
      "Epoch 89/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.7773e-04 - val_loss: 7.7480e-04\n",
      "Epoch 90/2000\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 2.6258e-04 - val_loss: 7.5058e-04\n",
      "Epoch 91/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5846e-04 - val_loss: 8.6347e-04\n",
      "Epoch 92/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.6432e-04 - val_loss: 6.9920e-04\n",
      "Epoch 93/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6491e-04 - val_loss: 6.7496e-04\n",
      "Epoch 94/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6607e-04 - val_loss: 9.1153e-04\n",
      "Epoch 95/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.6429e-04 - val_loss: 8.6430e-04\n",
      "Epoch 96/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.5684e-04 - val_loss: 6.5192e-04\n",
      "Epoch 97/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.5893e-04 - val_loss: 6.2616e-04\n",
      "Epoch 98/2000\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 2.6649e-04 - val_loss: 6.4467e-04\n",
      "Epoch 99/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6527e-04 - val_loss: 7.1196e-04\n",
      "Epoch 100/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6553e-04 - val_loss: 6.9275e-04\n",
      "Epoch 101/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.6275e-04 - val_loss: 6.6074e-04\n",
      "Epoch 102/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6415e-04 - val_loss: 6.0989e-04\n",
      "Epoch 103/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.6612e-04 - val_loss: 6.1568e-04\n",
      "Epoch 104/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.6077e-04 - val_loss: 6.4649e-04\n",
      "Epoch 105/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.6271e-04 - val_loss: 6.8823e-04\n",
      "Epoch 106/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.5982e-04 - val_loss: 8.8126e-04\n",
      "Epoch 107/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5718e-04 - val_loss: 8.1300e-04\n",
      "Epoch 108/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6433e-04 - val_loss: 6.8552e-04\n",
      "Epoch 109/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.6542e-04 - val_loss: 6.6327e-04\n",
      "Epoch 110/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5997e-04 - val_loss: 6.0988e-04\n",
      "Epoch 111/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6725e-04 - val_loss: 6.8814e-04\n",
      "Epoch 112/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5368e-04 - val_loss: 5.6656e-04\n",
      "Epoch 113/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5944e-04 - val_loss: 5.6413e-04\n",
      "Epoch 114/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6305e-04 - val_loss: 7.1589e-04\n",
      "Epoch 115/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5703e-04 - val_loss: 6.2603e-04\n",
      "Epoch 116/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.5642e-04 - val_loss: 6.7365e-04\n",
      "Epoch 117/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.5668e-04 - val_loss: 9.0933e-04\n",
      "Epoch 118/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.6875e-04 - val_loss: 5.6298e-04\n",
      "Epoch 119/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6240e-04 - val_loss: 5.3210e-04\n",
      "Epoch 120/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.7476e-04 - val_loss: 6.0970e-04\n",
      "Epoch 121/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.6365e-04 - val_loss: 6.0899e-04\n",
      "Epoch 122/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5473e-04 - val_loss: 6.1409e-04\n",
      "Epoch 123/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.5236e-04 - val_loss: 5.9996e-04\n",
      "Epoch 124/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5758e-04 - val_loss: 9.1703e-04\n",
      "Epoch 125/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5300e-04 - val_loss: 7.7863e-04\n",
      "Epoch 126/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.5484e-04 - val_loss: 6.0056e-04\n",
      "Epoch 127/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.6027e-04 - val_loss: 6.9957e-04\n",
      "Epoch 128/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.5906e-04 - val_loss: 5.9922e-04\n",
      "Epoch 129/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5282e-04 - val_loss: 6.2154e-04\n",
      "Epoch 130/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5127e-04 - val_loss: 6.1468e-04\n",
      "Epoch 131/2000\n",
      "43/43 [==============================] - 13s 292ms/step - loss: 2.6837e-04 - val_loss: 9.2325e-04\n",
      "Epoch 132/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5618e-04 - val_loss: 5.5289e-04\n",
      "Epoch 133/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.6650e-04 - val_loss: 5.6578e-04\n",
      "Epoch 134/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.5749e-04 - val_loss: 5.6149e-04\n",
      "Epoch 135/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.5448e-04 - val_loss: 5.9970e-04\n",
      "Epoch 136/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.5198e-04 - val_loss: 5.9700e-04\n",
      "Epoch 137/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5262e-04 - val_loss: 6.8180e-04\n",
      "Epoch 138/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.4865e-04 - val_loss: 6.0393e-04\n",
      "Epoch 139/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5727e-04 - val_loss: 5.2116e-04\n",
      "Epoch 140/2000\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 2.5569e-04 - val_loss: 6.2530e-04\n",
      "Epoch 141/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5204e-04 - val_loss: 5.7391e-04\n",
      "Epoch 142/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.4235e-04 - val_loss: 5.0902e-04\n",
      "Epoch 143/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5320e-04 - val_loss: 5.9906e-04\n",
      "Epoch 144/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.5792e-04 - val_loss: 5.4580e-04\n",
      "Epoch 145/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.5895e-04 - val_loss: 5.7951e-04\n",
      "Epoch 146/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.4687e-04 - val_loss: 5.0949e-04\n",
      "Epoch 147/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.4815e-04 - val_loss: 5.4956e-04\n",
      "Epoch 148/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.4437e-04 - val_loss: 5.7922e-04\n",
      "Epoch 149/2000\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 2.4273e-04 - val_loss: 4.5896e-04\n",
      "Epoch 150/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.5547e-04 - val_loss: 5.3833e-04\n",
      "Epoch 151/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.4577e-04 - val_loss: 4.6593e-04\n",
      "Epoch 152/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.6818e-04 - val_loss: 5.5663e-04\n",
      "Epoch 153/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.4180e-04 - val_loss: 5.5146e-04\n",
      "Epoch 154/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.4054e-04 - val_loss: 5.3999e-04\n",
      "Epoch 155/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.4236e-04 - val_loss: 4.7664e-04\n",
      "Epoch 156/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.3822e-04 - val_loss: 6.2523e-04\n",
      "Epoch 157/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.3979e-04 - val_loss: 5.4756e-04\n",
      "Epoch 158/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.4096e-04 - val_loss: 4.8106e-04\n",
      "Epoch 159/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.3778e-04 - val_loss: 4.2682e-04\n",
      "Epoch 160/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.4069e-04 - val_loss: 4.3180e-04\n",
      "Epoch 161/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.3330e-04 - val_loss: 4.5895e-04\n",
      "Epoch 162/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.4141e-04 - val_loss: 4.0317e-04\n",
      "Epoch 163/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.3970e-04 - val_loss: 4.0878e-04\n",
      "Epoch 164/2000\n",
      "43/43 [==============================] - 12s 269ms/step - loss: 2.2713e-04 - val_loss: 4.5459e-04\n",
      "Epoch 165/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.2258e-04 - val_loss: 5.4802e-04\n",
      "Epoch 166/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.3150e-04 - val_loss: 6.4001e-04\n",
      "Epoch 167/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.3968e-04 - val_loss: 4.5156e-04\n",
      "Epoch 168/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.3677e-04 - val_loss: 4.0773e-04\n",
      "Epoch 169/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.2564e-04 - val_loss: 5.1204e-04\n",
      "Epoch 170/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.2003e-04 - val_loss: 5.3441e-04\n",
      "Epoch 171/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.2039e-04 - val_loss: 6.0590e-04\n",
      "Epoch 172/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.1961e-04 - val_loss: 5.5373e-04\n",
      "Epoch 173/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.2205e-04 - val_loss: 4.1375e-04\n",
      "Epoch 174/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.3079e-04 - val_loss: 6.5570e-04\n",
      "Epoch 175/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.3355e-04 - val_loss: 4.3227e-04\n",
      "Epoch 176/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.1935e-04 - val_loss: 4.3110e-04\n",
      "Epoch 177/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.2149e-04 - val_loss: 5.0558e-04\n",
      "Epoch 178/2000\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 2.0862e-04 - val_loss: 4.3942e-04\n",
      "Epoch 179/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.1372e-04 - val_loss: 6.0904e-04\n",
      "Epoch 180/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.1303e-04 - val_loss: 7.6743e-04\n",
      "Epoch 181/2000\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 2.0945e-04 - val_loss: 4.5501e-04\n",
      "Epoch 182/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.0450e-04 - val_loss: 5.0766e-04\n",
      "Epoch 183/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 1.9954e-04 - val_loss: 6.1762e-04\n",
      "Epoch 184/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.0563e-04 - val_loss: 5.8991e-04\n",
      "Epoch 185/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 1.9666e-04 - val_loss: 4.4509e-04\n",
      "Epoch 186/2000\n",
      "43/43 [==============================] - 12s 287ms/step - loss: 2.0986e-04 - val_loss: 6.5821e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_142_layer_call_fn, lstm_cell_142_layer_call_and_return_conditional_losses, lstm_cell_143_layer_call_fn, lstm_cell_143_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_800_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_800_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "43/43 [==============================] - 15s 299ms/step - loss: 0.0416 - val_loss: 0.0110\n",
      "Epoch 2/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 3/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 4/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 8.1249e-04 - val_loss: 0.0018\n",
      "Epoch 5/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 6.2284e-04 - val_loss: 0.0015\n",
      "Epoch 6/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 5.2398e-04 - val_loss: 0.0015\n",
      "Epoch 7/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 4.6274e-04 - val_loss: 0.0012\n",
      "Epoch 8/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 4.2820e-04 - val_loss: 0.0011\n",
      "Epoch 9/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 4.0145e-04 - val_loss: 9.6386e-04\n",
      "Epoch 10/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.8429e-04 - val_loss: 9.7798e-04\n",
      "Epoch 11/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.7438e-04 - val_loss: 8.3425e-04\n",
      "Epoch 12/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.5838e-04 - val_loss: 7.4195e-04\n",
      "Epoch 13/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.5231e-04 - val_loss: 6.9058e-04\n",
      "Epoch 14/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.4809e-04 - val_loss: 7.0173e-04\n",
      "Epoch 15/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.4780e-04 - val_loss: 6.1021e-04\n",
      "Epoch 16/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.3342e-04 - val_loss: 6.3362e-04\n",
      "Epoch 17/2000\n",
      "43/43 [==============================] - 13s 292ms/step - loss: 3.3042e-04 - val_loss: 6.5376e-04\n",
      "Epoch 18/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.3234e-04 - val_loss: 7.8015e-04\n",
      "Epoch 19/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.3195e-04 - val_loss: 7.0388e-04\n",
      "Epoch 20/2000\n",
      "43/43 [==============================] - 13s 291ms/step - loss: 3.3048e-04 - val_loss: 6.1767e-04\n",
      "Epoch 21/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.2386e-04 - val_loss: 5.5374e-04\n",
      "Epoch 22/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1930e-04 - val_loss: 7.2997e-04\n",
      "Epoch 23/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1653e-04 - val_loss: 8.1917e-04\n",
      "Epoch 24/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.1500e-04 - val_loss: 9.1686e-04\n",
      "Epoch 25/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1690e-04 - val_loss: 6.3631e-04\n",
      "Epoch 26/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1429e-04 - val_loss: 8.7918e-04\n",
      "Epoch 27/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1192e-04 - val_loss: 7.0236e-04\n",
      "Epoch 28/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1347e-04 - val_loss: 8.0299e-04\n",
      "Epoch 29/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.0760e-04 - val_loss: 9.3007e-04\n",
      "Epoch 30/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1531e-04 - val_loss: 5.4395e-04\n",
      "Epoch 31/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1158e-04 - val_loss: 8.5743e-04\n",
      "Epoch 32/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.1273e-04 - val_loss: 0.0011\n",
      "Epoch 33/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.2136e-04 - val_loss: 7.4633e-04\n",
      "Epoch 34/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0716e-04 - val_loss: 9.6535e-04\n",
      "Epoch 35/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.1614e-04 - val_loss: 5.9172e-04\n",
      "Epoch 36/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1468e-04 - val_loss: 9.7489e-04\n",
      "Epoch 37/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1065e-04 - val_loss: 7.2092e-04\n",
      "Epoch 38/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0763e-04 - val_loss: 6.0864e-04\n",
      "Epoch 39/2000\n",
      "43/43 [==============================] - 13s 291ms/step - loss: 3.0345e-04 - val_loss: 8.5327e-04\n",
      "Epoch 40/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0856e-04 - val_loss: 8.0313e-04\n",
      "Epoch 41/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.2640e-04 - val_loss: 7.5536e-04\n",
      "Epoch 42/2000\n",
      "43/43 [==============================] - 12s 279ms/step - loss: 3.0199e-04 - val_loss: 5.3799e-04\n",
      "Epoch 43/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1365e-04 - val_loss: 6.9331e-04\n",
      "Epoch 44/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.0435e-04 - val_loss: 7.5949e-04\n",
      "Epoch 45/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0418e-04 - val_loss: 4.7349e-04\n",
      "Epoch 46/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.0830e-04 - val_loss: 6.3616e-04\n",
      "Epoch 47/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1314e-04 - val_loss: 6.2626e-04\n",
      "Epoch 48/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0086e-04 - val_loss: 9.7775e-04\n",
      "Epoch 49/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1835e-04 - val_loss: 4.1448e-04\n",
      "Epoch 50/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0831e-04 - val_loss: 7.8635e-04\n",
      "Epoch 51/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.0410e-04 - val_loss: 5.3315e-04\n",
      "Epoch 52/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.9792e-04 - val_loss: 5.4824e-04\n",
      "Epoch 53/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.9550e-04 - val_loss: 6.1372e-04\n",
      "Epoch 54/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.9666e-04 - val_loss: 6.8868e-04\n",
      "Epoch 55/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.9887e-04 - val_loss: 4.7457e-04\n",
      "Epoch 56/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.0043e-04 - val_loss: 5.9076e-04\n",
      "Epoch 57/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 3.0175e-04 - val_loss: 5.7801e-04\n",
      "Epoch 58/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.9848e-04 - val_loss: 4.4613e-04\n",
      "Epoch 59/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1227e-04 - val_loss: 4.2031e-04\n",
      "Epoch 60/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.9572e-04 - val_loss: 7.6750e-04\n",
      "Epoch 61/2000\n",
      "43/43 [==============================] - 13s 292ms/step - loss: 2.9888e-04 - val_loss: 7.3571e-04\n",
      "Epoch 62/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.9410e-04 - val_loss: 5.4415e-04\n",
      "Epoch 63/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.9919e-04 - val_loss: 4.9037e-04\n",
      "Epoch 64/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0716e-04 - val_loss: 4.2003e-04\n",
      "Epoch 65/2000\n",
      "43/43 [==============================] - 13s 291ms/step - loss: 3.1750e-04 - val_loss: 5.2069e-04\n",
      "Epoch 66/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.1043e-04 - val_loss: 3.6735e-04\n",
      "Epoch 67/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.0403e-04 - val_loss: 8.0438e-04\n",
      "Epoch 68/2000\n",
      "43/43 [==============================] - 13s 291ms/step - loss: 3.2242e-04 - val_loss: 5.1993e-04\n",
      "Epoch 69/2000\n",
      "43/43 [==============================] - 13s 291ms/step - loss: 2.9180e-04 - val_loss: 5.9678e-04\n",
      "Epoch 70/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.9844e-04 - val_loss: 3.5857e-04\n",
      "Epoch 71/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.9569e-04 - val_loss: 6.1520e-04\n",
      "Epoch 72/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.9381e-04 - val_loss: 5.3650e-04\n",
      "Epoch 73/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.8585e-04 - val_loss: 5.4693e-04\n",
      "Epoch 74/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.9420e-04 - val_loss: 4.4907e-04\n",
      "Epoch 75/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 3.1319e-04 - val_loss: 4.3444e-04\n",
      "Epoch 76/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.8634e-04 - val_loss: 4.8553e-04\n",
      "Epoch 77/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.8578e-04 - val_loss: 6.7485e-04\n",
      "Epoch 78/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 3.0906e-04 - val_loss: 6.7321e-04\n",
      "Epoch 79/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.9118e-04 - val_loss: 8.3024e-04\n",
      "Epoch 80/2000\n",
      "43/43 [==============================] - 13s 291ms/step - loss: 2.8967e-04 - val_loss: 5.3547e-04\n",
      "Epoch 81/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.8425e-04 - val_loss: 6.7585e-04\n",
      "Epoch 82/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.8711e-04 - val_loss: 6.8187e-04\n",
      "Epoch 83/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.8882e-04 - val_loss: 3.7040e-04\n",
      "Epoch 84/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.8429e-04 - val_loss: 4.5976e-04\n",
      "Epoch 85/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.8940e-04 - val_loss: 3.6161e-04\n",
      "Epoch 86/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.9129e-04 - val_loss: 4.1850e-04\n",
      "Epoch 87/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.8776e-04 - val_loss: 6.7450e-04\n",
      "Epoch 88/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.7992e-04 - val_loss: 6.6029e-04\n",
      "Epoch 89/2000\n",
      "43/43 [==============================] - 12s 291ms/step - loss: 2.8813e-04 - val_loss: 6.3759e-04\n",
      "Epoch 90/2000\n",
      "43/43 [==============================] - 13s 291ms/step - loss: 2.8750e-04 - val_loss: 4.0422e-04\n",
      "Epoch 91/2000\n",
      "43/43 [==============================] - 12s 290ms/step - loss: 2.7953e-04 - val_loss: 8.2673e-04\n",
      "Epoch 92/2000\n",
      "43/43 [==============================] - 13s 291ms/step - loss: 3.0385e-04 - val_loss: 4.3170e-04\n",
      "Epoch 93/2000\n",
      "43/43 [==============================] - 12s 279ms/step - loss: 2.9067e-04 - val_loss: 6.4265e-04\n",
      "Epoch 94/2000\n",
      "43/43 [==============================] - 12s 289ms/step - loss: 2.8559e-04 - val_loss: 6.2573e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_144_layer_call_fn, lstm_cell_144_layer_call_and_return_conditional_losses, lstm_cell_145_layer_call_fn, lstm_cell_145_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_800_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_800_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "43/43 [==============================] - 16s 305ms/step - loss: 0.0570 - val_loss: 0.0110\n",
      "Epoch 2/2000\n",
      "43/43 [==============================] - 13s 293ms/step - loss: 0.0025 - val_loss: 0.0217\n",
      "Epoch 3/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 0.0014 - val_loss: 0.0213\n",
      "Epoch 4/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 0.0011 - val_loss: 0.0199\n",
      "Epoch 5/2000\n",
      "43/43 [==============================] - 13s 293ms/step - loss: 8.7302e-04 - val_loss: 0.0160\n",
      "Epoch 6/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 7.0665e-04 - val_loss: 0.0159\n",
      "Epoch 7/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 5.9339e-04 - val_loss: 0.0129\n",
      "Epoch 8/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 5.2480e-04 - val_loss: 0.0112\n",
      "Epoch 9/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 4.8133e-04 - val_loss: 0.0094\n",
      "Epoch 10/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 4.4437e-04 - val_loss: 0.0087\n",
      "Epoch 11/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 4.2695e-04 - val_loss: 0.0061\n",
      "Epoch 12/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 4.0280e-04 - val_loss: 0.0049\n",
      "Epoch 13/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 3.8269e-04 - val_loss: 0.0049\n",
      "Epoch 14/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.7010e-04 - val_loss: 0.0049\n",
      "Epoch 15/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.6082e-04 - val_loss: 0.0036\n",
      "Epoch 16/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 3.4605e-04 - val_loss: 0.0035\n",
      "Epoch 17/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.4287e-04 - val_loss: 0.0028\n",
      "Epoch 18/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 3.4595e-04 - val_loss: 0.0023\n",
      "Epoch 19/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.2717e-04 - val_loss: 0.0034\n",
      "Epoch 20/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 3.2824e-04 - val_loss: 0.0020\n",
      "Epoch 21/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 3.1945e-04 - val_loss: 0.0021\n",
      "Epoch 22/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.2334e-04 - val_loss: 0.0022\n",
      "Epoch 23/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.1418e-04 - val_loss: 0.0017\n",
      "Epoch 24/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.2135e-04 - val_loss: 0.0026\n",
      "Epoch 25/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 3.1311e-04 - val_loss: 0.0024\n",
      "Epoch 26/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 3.0779e-04 - val_loss: 0.0017\n",
      "Epoch 27/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.0097e-04 - val_loss: 0.0019\n",
      "Epoch 28/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.9885e-04 - val_loss: 0.0017\n",
      "Epoch 29/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.0313e-04 - val_loss: 0.0014\n",
      "Epoch 30/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.0205e-04 - val_loss: 0.0014\n",
      "Epoch 31/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9882e-04 - val_loss: 0.0018\n",
      "Epoch 32/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9985e-04 - val_loss: 0.0016\n",
      "Epoch 33/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.9637e-04 - val_loss: 0.0016\n",
      "Epoch 34/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 3.0348e-04 - val_loss: 0.0011\n",
      "Epoch 35/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.9546e-04 - val_loss: 0.0012\n",
      "Epoch 36/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.1066e-04 - val_loss: 0.0016\n",
      "Epoch 37/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9700e-04 - val_loss: 0.0012\n",
      "Epoch 38/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9316e-04 - val_loss: 0.0014\n",
      "Epoch 39/2000\n",
      "43/43 [==============================] - 13s 293ms/step - loss: 2.9453e-04 - val_loss: 0.0011\n",
      "Epoch 40/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.9894e-04 - val_loss: 9.4891e-04\n",
      "Epoch 41/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9095e-04 - val_loss: 9.6518e-04\n",
      "Epoch 42/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9110e-04 - val_loss: 0.0012\n",
      "Epoch 43/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.9559e-04 - val_loss: 0.0011\n",
      "Epoch 44/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.9666e-04 - val_loss: 7.5235e-04\n",
      "Epoch 45/2000\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 2.9413e-04 - val_loss: 8.0862e-04\n",
      "Epoch 46/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.9031e-04 - val_loss: 7.0082e-04\n",
      "Epoch 47/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.0789e-04 - val_loss: 0.0014\n",
      "Epoch 48/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9690e-04 - val_loss: 0.0014\n",
      "Epoch 49/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9380e-04 - val_loss: 8.7305e-04\n",
      "Epoch 50/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8489e-04 - val_loss: 0.0010\n",
      "Epoch 51/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 3.0512e-04 - val_loss: 8.7383e-04\n",
      "Epoch 52/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 3.1090e-04 - val_loss: 7.0754e-04\n",
      "Epoch 53/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.8962e-04 - val_loss: 0.0010\n",
      "Epoch 54/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8391e-04 - val_loss: 0.0011\n",
      "Epoch 55/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.9409e-04 - val_loss: 8.9088e-04\n",
      "Epoch 56/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9075e-04 - val_loss: 7.9572e-04\n",
      "Epoch 57/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9601e-04 - val_loss: 9.1815e-04\n",
      "Epoch 58/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8803e-04 - val_loss: 8.1669e-04\n",
      "Epoch 59/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.9133e-04 - val_loss: 8.4415e-04\n",
      "Epoch 60/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 2.8131e-04 - val_loss: 7.8497e-04\n",
      "Epoch 61/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8674e-04 - val_loss: 0.0010\n",
      "Epoch 62/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 2.8302e-04 - val_loss: 8.9068e-04\n",
      "Epoch 63/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8830e-04 - val_loss: 5.7882e-04\n",
      "Epoch 64/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9969e-04 - val_loss: 0.0012\n",
      "Epoch 65/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8412e-04 - val_loss: 8.9274e-04\n",
      "Epoch 66/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 2.8744e-04 - val_loss: 0.0012\n",
      "Epoch 67/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8587e-04 - val_loss: 8.8978e-04\n",
      "Epoch 68/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8356e-04 - val_loss: 0.0012\n",
      "Epoch 69/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8062e-04 - val_loss: 6.7128e-04\n",
      "Epoch 70/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8474e-04 - val_loss: 6.8371e-04\n",
      "Epoch 71/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 3.1290e-04 - val_loss: 0.0014\n",
      "Epoch 72/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 3.0128e-04 - val_loss: 8.7285e-04\n",
      "Epoch 73/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.9096e-04 - val_loss: 6.9828e-04\n",
      "Epoch 74/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8124e-04 - val_loss: 9.1330e-04\n",
      "Epoch 75/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.7867e-04 - val_loss: 8.7821e-04\n",
      "Epoch 76/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8635e-04 - val_loss: 8.4548e-04\n",
      "Epoch 77/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8145e-04 - val_loss: 7.2298e-04\n",
      "Epoch 78/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8192e-04 - val_loss: 8.3253e-04\n",
      "Epoch 79/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8454e-04 - val_loss: 7.3155e-04\n",
      "Epoch 80/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.7814e-04 - val_loss: 6.0793e-04\n",
      "Epoch 81/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8225e-04 - val_loss: 0.0011\n",
      "Epoch 82/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.8781e-04 - val_loss: 5.5853e-04\n",
      "Epoch 83/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8446e-04 - val_loss: 7.3298e-04\n",
      "Epoch 84/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8302e-04 - val_loss: 7.0404e-04\n",
      "Epoch 85/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.7897e-04 - val_loss: 0.0010\n",
      "Epoch 86/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7589e-04 - val_loss: 6.0427e-04\n",
      "Epoch 87/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7899e-04 - val_loss: 9.3043e-04\n",
      "Epoch 88/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7623e-04 - val_loss: 6.9270e-04\n",
      "Epoch 89/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7565e-04 - val_loss: 7.3586e-04\n",
      "Epoch 90/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8107e-04 - val_loss: 7.2256e-04\n",
      "Epoch 91/2000\n",
      "43/43 [==============================] - 13s 293ms/step - loss: 2.8426e-04 - val_loss: 7.3839e-04\n",
      "Epoch 92/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8220e-04 - val_loss: 9.2961e-04\n",
      "Epoch 93/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 2.7592e-04 - val_loss: 5.5162e-04\n",
      "Epoch 94/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8377e-04 - val_loss: 7.2576e-04\n",
      "Epoch 95/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7688e-04 - val_loss: 5.8351e-04\n",
      "Epoch 96/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8525e-04 - val_loss: 5.0770e-04\n",
      "Epoch 97/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.9379e-04 - val_loss: 6.6525e-04\n",
      "Epoch 98/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8385e-04 - val_loss: 7.5695e-04\n",
      "Epoch 99/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7765e-04 - val_loss: 6.1662e-04\n",
      "Epoch 100/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.8482e-04 - val_loss: 5.2975e-04\n",
      "Epoch 101/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8895e-04 - val_loss: 0.0011\n",
      "Epoch 102/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.7537e-04 - val_loss: 8.2791e-04\n",
      "Epoch 103/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8349e-04 - val_loss: 7.7397e-04\n",
      "Epoch 104/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8711e-04 - val_loss: 4.9204e-04\n",
      "Epoch 105/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.8578e-04 - val_loss: 6.6245e-04\n",
      "Epoch 106/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.7738e-04 - val_loss: 9.2263e-04\n",
      "Epoch 107/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7511e-04 - val_loss: 8.4303e-04\n",
      "Epoch 108/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.7795e-04 - val_loss: 5.5763e-04\n",
      "Epoch 109/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.8314e-04 - val_loss: 8.3615e-04\n",
      "Epoch 110/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.7230e-04 - val_loss: 5.5914e-04\n",
      "Epoch 111/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.6612e-04 - val_loss: 6.9010e-04\n",
      "Epoch 112/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.7087e-04 - val_loss: 6.4637e-04\n",
      "Epoch 113/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7545e-04 - val_loss: 7.3050e-04\n",
      "Epoch 114/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7665e-04 - val_loss: 0.0010\n",
      "Epoch 115/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.8305e-04 - val_loss: 5.3897e-04\n",
      "Epoch 116/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7501e-04 - val_loss: 5.5325e-04\n",
      "Epoch 117/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.7726e-04 - val_loss: 7.3545e-04\n",
      "Epoch 118/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7093e-04 - val_loss: 8.1063e-04\n",
      "Epoch 119/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.7800e-04 - val_loss: 5.2385e-04\n",
      "Epoch 120/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.7200e-04 - val_loss: 8.0073e-04\n",
      "Epoch 121/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.6488e-04 - val_loss: 5.5894e-04\n",
      "Epoch 122/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.6649e-04 - val_loss: 7.0478e-04\n",
      "Epoch 123/2000\n",
      "43/43 [==============================] - 13s 295ms/step - loss: 2.6432e-04 - val_loss: 6.7947e-04\n",
      "Epoch 124/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.6905e-04 - val_loss: 5.2457e-04\n",
      "Epoch 125/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.7011e-04 - val_loss: 6.5956e-04\n",
      "Epoch 126/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.6801e-04 - val_loss: 0.0011\n",
      "Epoch 127/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 2.7779e-04 - val_loss: 8.6048e-04\n",
      "Epoch 128/2000\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 2.6238e-04 - val_loss: 6.4554e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_146_layer_call_fn, lstm_cell_146_layer_call_and_return_conditional_losses, lstm_cell_147_layer_call_fn, lstm_cell_147_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_800_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_800_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "43/43 [==============================] - 16s 310ms/step - loss: 0.0504 - val_loss: 0.0303\n",
      "Epoch 2/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 0.0021 - val_loss: 0.0154\n",
      "Epoch 3/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 0.0011 - val_loss: 0.0115\n",
      "Epoch 4/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 8.3213e-04 - val_loss: 0.0081\n",
      "Epoch 5/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 6.7955e-04 - val_loss: 0.0054\n",
      "Epoch 6/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 5.6456e-04 - val_loss: 0.0031\n",
      "Epoch 7/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 4.8635e-04 - val_loss: 0.0021\n",
      "Epoch 8/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 4.2777e-04 - val_loss: 0.0013\n",
      "Epoch 9/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 3.9126e-04 - val_loss: 0.0014\n",
      "Epoch 10/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.7105e-04 - val_loss: 0.0012\n",
      "Epoch 11/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 3.4988e-04 - val_loss: 9.7564e-04\n",
      "Epoch 12/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.4492e-04 - val_loss: 9.0915e-04\n",
      "Epoch 13/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.4151e-04 - val_loss: 8.6580e-04\n",
      "Epoch 14/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.3283e-04 - val_loss: 8.3111e-04\n",
      "Epoch 15/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 3.3361e-04 - val_loss: 8.2173e-04\n",
      "Epoch 16/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.2886e-04 - val_loss: 8.0071e-04\n",
      "Epoch 17/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.2318e-04 - val_loss: 7.7970e-04\n",
      "Epoch 18/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 3.2813e-04 - val_loss: 7.3465e-04\n",
      "Epoch 19/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.2035e-04 - val_loss: 7.3719e-04\n",
      "Epoch 20/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 3.2643e-04 - val_loss: 8.5368e-04\n",
      "Epoch 21/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.2808e-04 - val_loss: 7.0786e-04\n",
      "Epoch 22/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.2782e-04 - val_loss: 6.8502e-04\n",
      "Epoch 23/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.1776e-04 - val_loss: 7.8556e-04\n",
      "Epoch 24/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.2909e-04 - val_loss: 7.6695e-04\n",
      "Epoch 25/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.1732e-04 - val_loss: 6.7447e-04\n",
      "Epoch 26/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.1742e-04 - val_loss: 6.8949e-04\n",
      "Epoch 27/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.1027e-04 - val_loss: 6.8939e-04\n",
      "Epoch 28/2000\n",
      "43/43 [==============================] - 13s 296ms/step - loss: 3.1763e-04 - val_loss: 6.3350e-04\n",
      "Epoch 29/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.1479e-04 - val_loss: 6.1978e-04\n",
      "Epoch 30/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.1094e-04 - val_loss: 6.3469e-04\n",
      "Epoch 31/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.0766e-04 - val_loss: 7.5485e-04\n",
      "Epoch 32/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.1568e-04 - val_loss: 5.8359e-04\n",
      "Epoch 33/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.0733e-04 - val_loss: 6.0021e-04\n",
      "Epoch 34/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.1078e-04 - val_loss: 6.3723e-04\n",
      "Epoch 35/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 3.0667e-04 - val_loss: 6.4832e-04\n",
      "Epoch 36/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 3.0414e-04 - val_loss: 6.0000e-04\n",
      "Epoch 37/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.0286e-04 - val_loss: 6.7830e-04\n",
      "Epoch 38/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.0684e-04 - val_loss: 5.7940e-04\n",
      "Epoch 39/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.0561e-04 - val_loss: 5.7039e-04\n",
      "Epoch 40/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 3.0961e-04 - val_loss: 6.3580e-04\n",
      "Epoch 41/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 3.0357e-04 - val_loss: 5.8076e-04\n",
      "Epoch 42/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.9919e-04 - val_loss: 6.4691e-04\n",
      "Epoch 43/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 2.9770e-04 - val_loss: 6.3366e-04\n",
      "Epoch 44/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 2.9772e-04 - val_loss: 7.8210e-04\n",
      "Epoch 45/2000\n",
      "43/43 [==============================] - 13s 301ms/step - loss: 3.0419e-04 - val_loss: 5.5940e-04\n",
      "Epoch 46/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.9876e-04 - val_loss: 6.6323e-04\n",
      "Epoch 47/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 2.9554e-04 - val_loss: 6.5627e-04\n",
      "Epoch 48/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 2.9794e-04 - val_loss: 5.5913e-04\n",
      "Epoch 49/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 3.2563e-04 - val_loss: 7.0843e-04\n",
      "Epoch 50/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 3.0404e-04 - val_loss: 6.0343e-04\n",
      "Epoch 51/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 3.0121e-04 - val_loss: 6.1868e-04\n",
      "Epoch 52/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 2.9221e-04 - val_loss: 5.5031e-04\n",
      "Epoch 53/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 2.9734e-04 - val_loss: 5.9858e-04\n",
      "Epoch 54/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.9644e-04 - val_loss: 6.0223e-04\n",
      "Epoch 55/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.9876e-04 - val_loss: 6.2331e-04\n",
      "Epoch 56/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 3.0174e-04 - val_loss: 5.6964e-04\n",
      "Epoch 57/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 2.9415e-04 - val_loss: 5.9060e-04\n",
      "Epoch 58/2000\n",
      "43/43 [==============================] - 13s 301ms/step - loss: 2.9533e-04 - val_loss: 5.7102e-04\n",
      "Epoch 59/2000\n",
      "43/43 [==============================] - 13s 301ms/step - loss: 3.1473e-04 - val_loss: 5.4849e-04\n",
      "Epoch 60/2000\n",
      "43/43 [==============================] - 13s 302ms/step - loss: 3.1299e-04 - val_loss: 5.8529e-04\n",
      "Epoch 61/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 2.9951e-04 - val_loss: 5.6943e-04\n",
      "Epoch 62/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 2.8942e-04 - val_loss: 6.2752e-04\n",
      "Epoch 63/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 2.9307e-04 - val_loss: 5.3305e-04\n",
      "Epoch 64/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.9272e-04 - val_loss: 5.9327e-04\n",
      "Epoch 65/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 2.9886e-04 - val_loss: 6.1045e-04\n",
      "Epoch 66/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.9348e-04 - val_loss: 5.5061e-04\n",
      "Epoch 67/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 2.9360e-04 - val_loss: 6.7522e-04\n",
      "Epoch 68/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.8899e-04 - val_loss: 6.2900e-04\n",
      "Epoch 69/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 3.0152e-04 - val_loss: 5.5852e-04\n",
      "Epoch 70/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 2.8788e-04 - val_loss: 5.3891e-04\n",
      "Epoch 71/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 2.9848e-04 - val_loss: 5.7441e-04\n",
      "Epoch 72/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 3.0769e-04 - val_loss: 5.8862e-04\n",
      "Epoch 73/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.9409e-04 - val_loss: 7.0867e-04\n",
      "Epoch 74/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 2.8839e-04 - val_loss: 6.2833e-04\n",
      "Epoch 75/2000\n",
      "43/43 [==============================] - 13s 298ms/step - loss: 2.8999e-04 - val_loss: 6.3370e-04\n",
      "Epoch 76/2000\n",
      "43/43 [==============================] - 13s 297ms/step - loss: 2.9375e-04 - val_loss: 5.4334e-04\n",
      "Epoch 77/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 2.9178e-04 - val_loss: 5.3415e-04\n",
      "Epoch 78/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 2.8394e-04 - val_loss: 5.3834e-04\n",
      "Epoch 79/2000\n",
      "43/43 [==============================] - 13s 301ms/step - loss: 2.8612e-04 - val_loss: 5.4708e-04\n",
      "Epoch 80/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.9603e-04 - val_loss: 6.1196e-04\n",
      "Epoch 81/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.9795e-04 - val_loss: 5.5102e-04\n",
      "Epoch 82/2000\n",
      "43/43 [==============================] - 13s 302ms/step - loss: 2.8842e-04 - val_loss: 6.3221e-04\n",
      "Epoch 83/2000\n",
      "43/43 [==============================] - 13s 302ms/step - loss: 2.9982e-04 - val_loss: 5.8346e-04\n",
      "Epoch 84/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.9554e-04 - val_loss: 6.9312e-04\n",
      "Epoch 85/2000\n",
      "43/43 [==============================] - 13s 299ms/step - loss: 2.8216e-04 - val_loss: 5.7845e-04\n",
      "Epoch 86/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.8069e-04 - val_loss: 6.0883e-04\n",
      "Epoch 87/2000\n",
      "43/43 [==============================] - 13s 300ms/step - loss: 2.8323e-04 - val_loss: 6.2557e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_148_layer_call_fn, lstm_cell_148_layer_call_and_return_conditional_losses, lstm_cell_149_layer_call_fn, lstm_cell_149_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_800_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_800_batch_256_earlystop_valloss_4\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_memory = 800\n",
    "\n",
    "trainInputX, trainInputY = sf.prepareData(trainX, trainY, lstm_memory)\n",
    "testInputX, testInputY = sf.prepareData(testX, testY, lstm_memory)\n",
    "print(trainInputX.shape)\n",
    "print(trainInputY.shape)\n",
    "print(testInputX.shape)\n",
    "print(testInputY.shape)\n",
    "\n",
    "#validacao tamanho apos tratamentos\n",
    "print(len(trainX))\n",
    "print(len(trainInputX))\n",
    "\n",
    "print(len(trainY))\n",
    "print(len(trainInputY))\n",
    "\n",
    "trainInputX = trainInputX [:,:,0:14]\n",
    "testInputX = testInputX [:,:,0:14]\n",
    "print(trainInputX.shape)\n",
    "\n",
    "trained_models_lstm_800 = []\n",
    "trained_models_lstm_800_history = []\n",
    "\n",
    "for i in range(0,5):\n",
    "\n",
    "    #giving it reproducibility\n",
    "    seed = (i+1000)\n",
    "\n",
    "    os.environ['PYTHONHASHseed']=str(seed)\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    batch_size = 256\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=24)\n",
    "    \n",
    "    trained_models_lstm_800.append(kr.Sequential())\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_800[i].add(kr.layers.LSTM(14,return_sequences = True))\n",
    "    trained_models_lstm_800[i].add(kr.layers.LSTM(8))\n",
    "    # lstm_model.add(kr.layers.Simplelstm(5,input_shape=(trainInputX.shape[1],trainInputX.shape[2])))\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_800[i].add(kr.layers.Dense(1))\n",
    "    trained_models_lstm_800[i].compile(loss='mean_squared_error',optimizer='adam')\n",
    "    \n",
    "    trained_models_lstm_800_history.append(trained_models_lstm_800[i].fit(trainInputX, trainInputY, epochs=2000, batch_size=batch_size, verbose = 1, validation_data=(testInputX,testInputY),  callbacks=[callback]))\n",
    "    \n",
    "    trained_models_lstm_800[i].save('C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_800_batch_256_earlystop_valloss_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c202e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10690, 1000, 14)\n",
      "(10690,)\n",
      "(1923, 1000, 14)\n",
      "(1923,)\n",
      "11690\n",
      "10690\n",
      "11690\n",
      "10690\n",
      "(10690, 1000, 14)\n",
      "Epoch 1/2000\n",
      "42/42 [==============================] - 22s 387ms/step - loss: 0.0540 - val_loss: 0.0035\n",
      "Epoch 2/2000\n",
      "42/42 [==============================] - 16s 377ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 3/2000\n",
      "42/42 [==============================] - 16s 377ms/step - loss: 8.4357e-04 - val_loss: 0.0026\n",
      "Epoch 4/2000\n",
      "42/42 [==============================] - 16s 376ms/step - loss: 6.2885e-04 - val_loss: 0.0032\n",
      "Epoch 5/2000\n",
      "42/42 [==============================] - 16s 376ms/step - loss: 5.4645e-04 - val_loss: 0.0035\n",
      "Epoch 6/2000\n",
      "42/42 [==============================] - 15s 364ms/step - loss: 5.0031e-04 - val_loss: 0.0036\n",
      "Epoch 7/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 4.6256e-04 - val_loss: 0.0036\n",
      "Epoch 8/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 4.3312e-04 - val_loss: 0.0034\n",
      "Epoch 9/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 4.1013e-04 - val_loss: 0.0036\n",
      "Epoch 10/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.9549e-04 - val_loss: 0.0028\n",
      "Epoch 11/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.7866e-04 - val_loss: 0.0025\n",
      "Epoch 12/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.6817e-04 - val_loss: 0.0026\n",
      "Epoch 13/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.5654e-04 - val_loss: 0.0024\n",
      "Epoch 14/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.5441e-04 - val_loss: 0.0019\n",
      "Epoch 15/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.4644e-04 - val_loss: 0.0018\n",
      "Epoch 16/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.4531e-04 - val_loss: 0.0014\n",
      "Epoch 17/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.4180e-04 - val_loss: 0.0012\n",
      "Epoch 18/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.4885e-04 - val_loss: 0.0014\n",
      "Epoch 19/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.3913e-04 - val_loss: 0.0017\n",
      "Epoch 20/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.4047e-04 - val_loss: 0.0014\n",
      "Epoch 21/2000\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 3.3691e-04 - val_loss: 9.1170e-04\n",
      "Epoch 22/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.4777e-04 - val_loss: 0.0012\n",
      "Epoch 23/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.3464e-04 - val_loss: 8.8239e-04\n",
      "Epoch 24/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2913e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.3484e-04 - val_loss: 0.0011\n",
      "Epoch 26/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.3748e-04 - val_loss: 8.8326e-04\n",
      "Epoch 27/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.2806e-04 - val_loss: 0.0011\n",
      "Epoch 28/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.2998e-04 - val_loss: 8.6771e-04\n",
      "Epoch 29/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.4359e-04 - val_loss: 5.8984e-04\n",
      "Epoch 30/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2414e-04 - val_loss: 8.6549e-04\n",
      "Epoch 31/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.2753e-04 - val_loss: 0.0010\n",
      "Epoch 32/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.2961e-04 - val_loss: 6.8364e-04\n",
      "Epoch 33/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.3810e-04 - val_loss: 6.8984e-04\n",
      "Epoch 34/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2176e-04 - val_loss: 0.0010\n",
      "Epoch 35/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.3235e-04 - val_loss: 5.4882e-04\n",
      "Epoch 36/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2249e-04 - val_loss: 5.8397e-04\n",
      "Epoch 37/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.2547e-04 - val_loss: 9.2116e-04\n",
      "Epoch 38/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.1913e-04 - val_loss: 5.9857e-04\n",
      "Epoch 39/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2597e-04 - val_loss: 0.0010\n",
      "Epoch 40/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1806e-04 - val_loss: 6.0319e-04\n",
      "Epoch 41/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.1686e-04 - val_loss: 6.4947e-04\n",
      "Epoch 42/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1955e-04 - val_loss: 0.0012\n",
      "Epoch 43/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.2399e-04 - val_loss: 9.7279e-04\n",
      "Epoch 44/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.1722e-04 - val_loss: 9.0506e-04\n",
      "Epoch 45/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.1434e-04 - val_loss: 6.9052e-04\n",
      "Epoch 46/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1186e-04 - val_loss: 8.7726e-04\n",
      "Epoch 47/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.1750e-04 - val_loss: 4.8975e-04\n",
      "Epoch 48/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1258e-04 - val_loss: 7.0270e-04\n",
      "Epoch 49/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2010e-04 - val_loss: 7.8058e-04\n",
      "Epoch 50/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1134e-04 - val_loss: 5.1438e-04\n",
      "Epoch 51/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1527e-04 - val_loss: 4.0548e-04\n",
      "Epoch 52/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1935e-04 - val_loss: 7.3352e-04\n",
      "Epoch 53/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.1552e-04 - val_loss: 4.4837e-04\n",
      "Epoch 54/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.1601e-04 - val_loss: 4.9874e-04\n",
      "Epoch 55/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2608e-04 - val_loss: 6.8189e-04\n",
      "Epoch 56/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0945e-04 - val_loss: 5.9325e-04\n",
      "Epoch 57/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0681e-04 - val_loss: 4.6956e-04\n",
      "Epoch 58/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0775e-04 - val_loss: 7.2280e-04\n",
      "Epoch 59/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0836e-04 - val_loss: 6.9531e-04\n",
      "Epoch 60/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0844e-04 - val_loss: 7.5325e-04\n",
      "Epoch 61/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1180e-04 - val_loss: 4.4344e-04\n",
      "Epoch 62/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.4855e-04 - val_loss: 3.8249e-04\n",
      "Epoch 63/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1769e-04 - val_loss: 7.4760e-04\n",
      "Epoch 64/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.1219e-04 - val_loss: 8.7435e-04\n",
      "Epoch 65/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0761e-04 - val_loss: 9.4179e-04\n",
      "Epoch 66/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1748e-04 - val_loss: 7.4641e-04\n",
      "Epoch 67/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0561e-04 - val_loss: 5.9236e-04\n",
      "Epoch 68/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1292e-04 - val_loss: 7.3230e-04\n",
      "Epoch 69/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2084e-04 - val_loss: 5.3554e-04\n",
      "Epoch 70/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.0300e-04 - val_loss: 7.8040e-04\n",
      "Epoch 71/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1092e-04 - val_loss: 7.4216e-04\n",
      "Epoch 72/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2442e-04 - val_loss: 6.3064e-04\n",
      "Epoch 73/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.1321e-04 - val_loss: 6.9173e-04\n",
      "Epoch 74/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0521e-04 - val_loss: 5.0907e-04\n",
      "Epoch 75/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0348e-04 - val_loss: 6.8975e-04\n",
      "Epoch 76/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1357e-04 - val_loss: 5.7064e-04\n",
      "Epoch 77/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0176e-04 - val_loss: 5.4529e-04\n",
      "Epoch 78/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0101e-04 - val_loss: 5.8269e-04\n",
      "Epoch 79/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0286e-04 - val_loss: 4.7377e-04\n",
      "Epoch 80/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.9867e-04 - val_loss: 6.4315e-04\n",
      "Epoch 81/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0748e-04 - val_loss: 0.0010\n",
      "Epoch 82/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0062e-04 - val_loss: 5.7356e-04\n",
      "Epoch 83/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0108e-04 - val_loss: 3.5636e-04\n",
      "Epoch 84/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0611e-04 - val_loss: 6.3420e-04\n",
      "Epoch 85/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0734e-04 - val_loss: 6.1544e-04\n",
      "Epoch 86/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0815e-04 - val_loss: 4.5876e-04\n",
      "Epoch 87/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0436e-04 - val_loss: 5.2840e-04\n",
      "Epoch 88/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9631e-04 - val_loss: 6.0743e-04\n",
      "Epoch 89/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.0097e-04 - val_loss: 5.5886e-04\n",
      "Epoch 90/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9355e-04 - val_loss: 6.1213e-04\n",
      "Epoch 91/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0017e-04 - val_loss: 3.7555e-04\n",
      "Epoch 92/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9838e-04 - val_loss: 5.3721e-04\n",
      "Epoch 93/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.1967e-04 - val_loss: 3.5830e-04\n",
      "Epoch 94/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0628e-04 - val_loss: 4.2788e-04\n",
      "Epoch 95/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0771e-04 - val_loss: 4.7400e-04\n",
      "Epoch 96/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0726e-04 - val_loss: 5.9861e-04\n",
      "Epoch 97/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9655e-04 - val_loss: 4.2359e-04\n",
      "Epoch 98/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 2.9755e-04 - val_loss: 9.2158e-04\n",
      "Epoch 99/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9722e-04 - val_loss: 5.0861e-04\n",
      "Epoch 100/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9894e-04 - val_loss: 6.1488e-04\n",
      "Epoch 101/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9056e-04 - val_loss: 4.1747e-04\n",
      "Epoch 102/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9542e-04 - val_loss: 5.9464e-04\n",
      "Epoch 103/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9466e-04 - val_loss: 4.4400e-04\n",
      "Epoch 104/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0170e-04 - val_loss: 5.4507e-04\n",
      "Epoch 105/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9184e-04 - val_loss: 6.1790e-04\n",
      "Epoch 106/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.9469e-04 - val_loss: 8.2339e-04\n",
      "Epoch 107/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1799e-04 - val_loss: 4.0997e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_150_layer_call_fn, lstm_cell_150_layer_call_and_return_conditional_losses, lstm_cell_151_layer_call_fn, lstm_cell_151_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_1000_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_1000_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "42/42 [==============================] - 15s 322ms/step - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 2/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 8.7377e-04 - val_loss: 0.0022\n",
      "Epoch 3/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 4.9057e-04 - val_loss: 0.0015\n",
      "Epoch 4/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 4.4058e-04 - val_loss: 0.0018\n",
      "Epoch 5/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.8661e-04 - val_loss: 0.0018\n",
      "Epoch 6/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.6913e-04 - val_loss: 0.0012\n",
      "Epoch 7/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.6002e-04 - val_loss: 0.0017\n",
      "Epoch 8/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.6256e-04 - val_loss: 8.3160e-04\n",
      "Epoch 9/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.5815e-04 - val_loss: 0.0015\n",
      "Epoch 10/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.3683e-04 - val_loss: 0.0014\n",
      "Epoch 11/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.3826e-04 - val_loss: 0.0015\n",
      "Epoch 12/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.3317e-04 - val_loss: 0.0012\n",
      "Epoch 13/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.3345e-04 - val_loss: 0.0011\n",
      "Epoch 14/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.3296e-04 - val_loss: 0.0019\n",
      "Epoch 15/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.2753e-04 - val_loss: 0.0012\n",
      "Epoch 16/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.2559e-04 - val_loss: 9.4515e-04\n",
      "Epoch 17/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.2120e-04 - val_loss: 0.0014\n",
      "Epoch 18/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1797e-04 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2790e-04 - val_loss: 7.3794e-04\n",
      "Epoch 20/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.3138e-04 - val_loss: 9.7532e-04\n",
      "Epoch 21/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1527e-04 - val_loss: 0.0012\n",
      "Epoch 22/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.1335e-04 - val_loss: 8.4895e-04\n",
      "Epoch 23/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.4003e-04 - val_loss: 7.2884e-04\n",
      "Epoch 24/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.1192e-04 - val_loss: 0.0011\n",
      "Epoch 25/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0843e-04 - val_loss: 8.5810e-04\n",
      "Epoch 26/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0369e-04 - val_loss: 7.6838e-04\n",
      "Epoch 27/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1097e-04 - val_loss: 0.0011\n",
      "Epoch 28/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.0262e-04 - val_loss: 9.6690e-04\n",
      "Epoch 29/2000\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 3.0012e-04 - val_loss: 9.0039e-04\n",
      "Epoch 30/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2006e-04 - val_loss: 7.8171e-04\n",
      "Epoch 31/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0198e-04 - val_loss: 8.9913e-04\n",
      "Epoch 32/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1300e-04 - val_loss: 8.3170e-04\n",
      "Epoch 33/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.0784e-04 - val_loss: 8.6517e-04\n",
      "Epoch 34/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.9653e-04 - val_loss: 9.2987e-04\n",
      "Epoch 35/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0071e-04 - val_loss: 0.0012\n",
      "Epoch 36/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0868e-04 - val_loss: 7.4898e-04\n",
      "Epoch 37/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 2.9901e-04 - val_loss: 7.1343e-04\n",
      "Epoch 38/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0176e-04 - val_loss: 0.0011\n",
      "Epoch 39/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9654e-04 - val_loss: 0.0011\n",
      "Epoch 40/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9484e-04 - val_loss: 7.1291e-04\n",
      "Epoch 41/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 2.9332e-04 - val_loss: 8.7810e-04\n",
      "Epoch 42/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.8852e-04 - val_loss: 8.8910e-04\n",
      "Epoch 43/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9432e-04 - val_loss: 8.1705e-04\n",
      "Epoch 44/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9350e-04 - val_loss: 8.0071e-04\n",
      "Epoch 45/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0883e-04 - val_loss: 6.4447e-04\n",
      "Epoch 46/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0209e-04 - val_loss: 0.0010\n",
      "Epoch 47/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.8438e-04 - val_loss: 9.8617e-04\n",
      "Epoch 48/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.8816e-04 - val_loss: 7.0918e-04\n",
      "Epoch 49/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 2.8548e-04 - val_loss: 7.0767e-04\n",
      "Epoch 50/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.8653e-04 - val_loss: 7.9287e-04\n",
      "Epoch 51/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.7990e-04 - val_loss: 7.6119e-04\n",
      "Epoch 52/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.8055e-04 - val_loss: 8.8107e-04\n",
      "Epoch 53/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 2.8713e-04 - val_loss: 7.8624e-04\n",
      "Epoch 54/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.0163e-04 - val_loss: 8.7622e-04\n",
      "Epoch 55/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0336e-04 - val_loss: 8.5201e-04\n",
      "Epoch 56/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.9284e-04 - val_loss: 8.6803e-04\n",
      "Epoch 57/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.8102e-04 - val_loss: 7.4472e-04\n",
      "Epoch 58/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.8088e-04 - val_loss: 9.0629e-04\n",
      "Epoch 59/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 2.8204e-04 - val_loss: 7.3724e-04\n",
      "Epoch 60/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.7638e-04 - val_loss: 7.2427e-04\n",
      "Epoch 61/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.8194e-04 - val_loss: 7.5375e-04\n",
      "Epoch 62/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.8472e-04 - val_loss: 7.8043e-04\n",
      "Epoch 63/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.7802e-04 - val_loss: 7.2974e-04\n",
      "Epoch 64/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.8395e-04 - val_loss: 6.9120e-04\n",
      "Epoch 65/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.8388e-04 - val_loss: 7.6650e-04\n",
      "Epoch 66/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.7566e-04 - val_loss: 6.9993e-04\n",
      "Epoch 67/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.8504e-04 - val_loss: 8.7017e-04\n",
      "Epoch 68/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.7225e-04 - val_loss: 8.7730e-04\n",
      "Epoch 69/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9097e-04 - val_loss: 9.4768e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_152_layer_call_fn, lstm_cell_152_layer_call_and_return_conditional_losses, lstm_cell_153_layer_call_fn, lstm_cell_153_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_1000_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_1000_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "42/42 [==============================] - 15s 319ms/step - loss: 0.0433 - val_loss: 0.0116\n",
      "Epoch 2/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 3/2000\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 4/2000\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 8.6400e-04 - val_loss: 0.0021\n",
      "Epoch 5/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 6.6375e-04 - val_loss: 0.0016\n",
      "Epoch 6/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 5.5321e-04 - val_loss: 0.0015\n",
      "Epoch 7/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 4.8933e-04 - val_loss: 0.0015\n",
      "Epoch 8/2000\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 4.4392e-04 - val_loss: 0.0013\n",
      "Epoch 9/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 4.1995e-04 - val_loss: 0.0011\n",
      "Epoch 10/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.9742e-04 - val_loss: 9.7695e-04\n",
      "Epoch 11/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.8147e-04 - val_loss: 9.1841e-04\n",
      "Epoch 12/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.8180e-04 - val_loss: 8.4432e-04\n",
      "Epoch 13/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.6681e-04 - val_loss: 8.2915e-04\n",
      "Epoch 14/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.6188e-04 - val_loss: 8.2610e-04\n",
      "Epoch 15/2000\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 3.4842e-04 - val_loss: 7.1120e-04\n",
      "Epoch 16/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.4207e-04 - val_loss: 7.1230e-04\n",
      "Epoch 17/2000\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 3.3785e-04 - val_loss: 8.0044e-04\n",
      "Epoch 18/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.3743e-04 - val_loss: 6.8963e-04\n",
      "Epoch 19/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.3144e-04 - val_loss: 8.5730e-04\n",
      "Epoch 20/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.3501e-04 - val_loss: 8.5081e-04\n",
      "Epoch 21/2000\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 3.2789e-04 - val_loss: 7.0979e-04\n",
      "Epoch 22/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.3280e-04 - val_loss: 0.0011\n",
      "Epoch 23/2000\n",
      "42/42 [==============================] - 13s 308ms/step - loss: 3.2432e-04 - val_loss: 7.6103e-04\n",
      "Epoch 24/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.2362e-04 - val_loss: 0.0012\n",
      "Epoch 25/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.2326e-04 - val_loss: 8.6588e-04\n",
      "Epoch 26/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.1932e-04 - val_loss: 9.2834e-04\n",
      "Epoch 27/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2212e-04 - val_loss: 0.0012\n",
      "Epoch 28/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2179e-04 - val_loss: 0.0011\n",
      "Epoch 29/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2405e-04 - val_loss: 0.0012\n",
      "Epoch 30/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1590e-04 - val_loss: 6.6556e-04\n",
      "Epoch 31/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1515e-04 - val_loss: 6.8652e-04\n",
      "Epoch 32/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.1592e-04 - val_loss: 9.1024e-04\n",
      "Epoch 33/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.1723e-04 - val_loss: 8.9341e-04\n",
      "Epoch 34/2000\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 3.1988e-04 - val_loss: 7.7187e-04\n",
      "Epoch 35/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1604e-04 - val_loss: 0.0010\n",
      "Epoch 36/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.2035e-04 - val_loss: 8.5070e-04\n",
      "Epoch 37/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.1148e-04 - val_loss: 8.9584e-04\n",
      "Epoch 38/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0878e-04 - val_loss: 0.0010\n",
      "Epoch 39/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.2128e-04 - val_loss: 5.6645e-04\n",
      "Epoch 40/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.2089e-04 - val_loss: 9.0587e-04\n",
      "Epoch 41/2000\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 3.1508e-04 - val_loss: 7.3778e-04\n",
      "Epoch 42/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.1267e-04 - val_loss: 7.2053e-04\n",
      "Epoch 43/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.0977e-04 - val_loss: 7.8688e-04\n",
      "Epoch 44/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.1380e-04 - val_loss: 7.7929e-04\n",
      "Epoch 45/2000\n",
      "42/42 [==============================] - 13s 309ms/step - loss: 3.1324e-04 - val_loss: 0.0012\n",
      "Epoch 46/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.1630e-04 - val_loss: 7.7802e-04\n",
      "Epoch 47/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.1028e-04 - val_loss: 6.6261e-04\n",
      "Epoch 48/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0928e-04 - val_loss: 7.6134e-04\n",
      "Epoch 49/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0467e-04 - val_loss: 5.9581e-04\n",
      "Epoch 50/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0887e-04 - val_loss: 6.9680e-04\n",
      "Epoch 51/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0470e-04 - val_loss: 6.8253e-04\n",
      "Epoch 52/2000\n",
      "42/42 [==============================] - 13s 310ms/step - loss: 3.1121e-04 - val_loss: 7.7505e-04\n",
      "Epoch 53/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.0941e-04 - val_loss: 5.7514e-04\n",
      "Epoch 54/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.1089e-04 - val_loss: 7.6378e-04\n",
      "Epoch 55/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 3.1255e-04 - val_loss: 5.7839e-04\n",
      "Epoch 56/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0787e-04 - val_loss: 4.9263e-04\n",
      "Epoch 57/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0927e-04 - val_loss: 6.3094e-04\n",
      "Epoch 58/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.9865e-04 - val_loss: 6.3836e-04\n",
      "Epoch 59/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0595e-04 - val_loss: 5.3160e-04\n",
      "Epoch 60/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0870e-04 - val_loss: 7.9654e-04\n",
      "Epoch 61/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0346e-04 - val_loss: 5.4844e-04\n",
      "Epoch 62/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0972e-04 - val_loss: 6.1245e-04\n",
      "Epoch 63/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9763e-04 - val_loss: 6.1385e-04\n",
      "Epoch 64/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0749e-04 - val_loss: 6.7580e-04\n",
      "Epoch 65/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.2403e-04 - val_loss: 3.8952e-04\n",
      "Epoch 66/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.0359e-04 - val_loss: 5.1287e-04\n",
      "Epoch 67/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9578e-04 - val_loss: 6.5902e-04\n",
      "Epoch 68/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9749e-04 - val_loss: 5.6501e-04\n",
      "Epoch 69/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.9605e-04 - val_loss: 4.4492e-04\n",
      "Epoch 70/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9820e-04 - val_loss: 4.9423e-04\n",
      "Epoch 71/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.9974e-04 - val_loss: 4.2071e-04\n",
      "Epoch 72/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.1195e-04 - val_loss: 4.4868e-04\n",
      "Epoch 73/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.1362e-04 - val_loss: 3.9801e-04\n",
      "Epoch 74/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.2603e-04 - val_loss: 4.9234e-04\n",
      "Epoch 75/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0222e-04 - val_loss: 5.9082e-04\n",
      "Epoch 76/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.9396e-04 - val_loss: 4.9299e-04\n",
      "Epoch 77/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.1876e-04 - val_loss: 6.1551e-04\n",
      "Epoch 78/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.0028e-04 - val_loss: 5.3909e-04\n",
      "Epoch 79/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9880e-04 - val_loss: 4.3189e-04\n",
      "Epoch 80/2000\n",
      "42/42 [==============================] - 13s 315ms/step - loss: 2.9457e-04 - val_loss: 4.3009e-04\n",
      "Epoch 81/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9857e-04 - val_loss: 5.2630e-04\n",
      "Epoch 82/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9484e-04 - val_loss: 5.4795e-04\n",
      "Epoch 83/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.0567e-04 - val_loss: 7.8505e-04\n",
      "Epoch 84/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.1057e-04 - val_loss: 5.8912e-04\n",
      "Epoch 85/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.9348e-04 - val_loss: 4.6106e-04\n",
      "Epoch 86/2000\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.8943e-04 - val_loss: 4.7779e-04\n",
      "Epoch 87/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.8517e-04 - val_loss: 5.3045e-04\n",
      "Epoch 88/2000\n",
      "42/42 [==============================] - 13s 315ms/step - loss: 2.8969e-04 - val_loss: 7.7968e-04\n",
      "Epoch 89/2000\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 3.0297e-04 - val_loss: 7.2783e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_154_layer_call_fn, lstm_cell_154_layer_call_and_return_conditional_losses, lstm_cell_155_layer_call_fn, lstm_cell_155_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_1000_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_1000_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "42/42 [==============================] - 15s 321ms/step - loss: 0.0601 - val_loss: 0.0094\n",
      "Epoch 2/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 0.0027 - val_loss: 0.0229\n",
      "Epoch 3/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 0.0014 - val_loss: 0.0217\n",
      "Epoch 4/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 0.0011 - val_loss: 0.0226\n",
      "Epoch 5/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 9.0984e-04 - val_loss: 0.0179\n",
      "Epoch 6/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 7.4289e-04 - val_loss: 0.0155\n",
      "Epoch 7/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 6.2778e-04 - val_loss: 0.0139\n",
      "Epoch 8/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 5.4528e-04 - val_loss: 0.0121\n",
      "Epoch 9/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 4.9330e-04 - val_loss: 0.0094\n",
      "Epoch 10/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 4.7427e-04 - val_loss: 0.0084\n",
      "Epoch 11/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 4.4319e-04 - val_loss: 0.0084\n",
      "Epoch 12/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 4.1388e-04 - val_loss: 0.0068\n",
      "Epoch 13/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.9520e-04 - val_loss: 0.0062\n",
      "Epoch 14/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.8390e-04 - val_loss: 0.0056\n",
      "Epoch 15/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.7953e-04 - val_loss: 0.0044\n",
      "Epoch 16/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.5460e-04 - val_loss: 0.0040\n",
      "Epoch 17/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.4907e-04 - val_loss: 0.0031\n",
      "Epoch 18/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.5016e-04 - val_loss: 0.0034\n",
      "Epoch 19/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.4409e-04 - val_loss: 0.0024\n",
      "Epoch 20/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.3132e-04 - val_loss: 0.0029\n",
      "Epoch 21/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.3095e-04 - val_loss: 0.0022\n",
      "Epoch 22/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.1939e-04 - val_loss: 0.0023\n",
      "Epoch 23/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.1755e-04 - val_loss: 0.0021\n",
      "Epoch 24/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.1765e-04 - val_loss: 0.0022\n",
      "Epoch 25/2000\n",
      "42/42 [==============================] - 13s 315ms/step - loss: 3.1568e-04 - val_loss: 0.0018\n",
      "Epoch 26/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.1183e-04 - val_loss: 0.0016\n",
      "Epoch 27/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0864e-04 - val_loss: 0.0017\n",
      "Epoch 28/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0744e-04 - val_loss: 0.0015\n",
      "Epoch 29/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.1098e-04 - val_loss: 0.0018\n",
      "Epoch 30/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.2436e-04 - val_loss: 0.0015\n",
      "Epoch 31/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.1550e-04 - val_loss: 0.0013\n",
      "Epoch 32/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0516e-04 - val_loss: 0.0010\n",
      "Epoch 33/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0647e-04 - val_loss: 0.0014\n",
      "Epoch 34/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.0264e-04 - val_loss: 0.0011\n",
      "Epoch 35/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.1907e-04 - val_loss: 0.0014\n",
      "Epoch 36/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0407e-04 - val_loss: 0.0012\n",
      "Epoch 37/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0566e-04 - val_loss: 0.0010\n",
      "Epoch 38/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9683e-04 - val_loss: 0.0014\n",
      "Epoch 39/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0064e-04 - val_loss: 0.0011\n",
      "Epoch 40/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0573e-04 - val_loss: 0.0011\n",
      "Epoch 41/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0444e-04 - val_loss: 0.0012\n",
      "Epoch 42/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9958e-04 - val_loss: 0.0012\n",
      "Epoch 43/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0380e-04 - val_loss: 9.8010e-04\n",
      "Epoch 44/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0575e-04 - val_loss: 0.0013\n",
      "Epoch 45/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9647e-04 - val_loss: 8.6862e-04\n",
      "Epoch 46/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0067e-04 - val_loss: 0.0012\n",
      "Epoch 47/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.0216e-04 - val_loss: 0.0010\n",
      "Epoch 48/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.9600e-04 - val_loss: 0.0011\n",
      "Epoch 49/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.9159e-04 - val_loss: 8.0377e-04\n",
      "Epoch 50/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9270e-04 - val_loss: 0.0013\n",
      "Epoch 51/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.9471e-04 - val_loss: 8.2026e-04\n",
      "Epoch 52/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.9461e-04 - val_loss: 0.0010\n",
      "Epoch 53/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9642e-04 - val_loss: 0.0010\n",
      "Epoch 54/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.9587e-04 - val_loss: 0.0010\n",
      "Epoch 55/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9247e-04 - val_loss: 9.4827e-04\n",
      "Epoch 56/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9117e-04 - val_loss: 0.0013\n",
      "Epoch 57/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.0171e-04 - val_loss: 7.8523e-04\n",
      "Epoch 58/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.9508e-04 - val_loss: 8.4394e-04\n",
      "Epoch 59/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.9571e-04 - val_loss: 0.0012\n",
      "Epoch 60/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.9448e-04 - val_loss: 8.6099e-04\n",
      "Epoch 61/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9280e-04 - val_loss: 0.0010\n",
      "Epoch 62/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.8615e-04 - val_loss: 6.6957e-04\n",
      "Epoch 63/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9221e-04 - val_loss: 6.7565e-04\n",
      "Epoch 64/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0551e-04 - val_loss: 9.0839e-04\n",
      "Epoch 65/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0494e-04 - val_loss: 9.5560e-04\n",
      "Epoch 66/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.8818e-04 - val_loss: 0.0011\n",
      "Epoch 67/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0078e-04 - val_loss: 8.1328e-04\n",
      "Epoch 68/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9548e-04 - val_loss: 7.1735e-04\n",
      "Epoch 69/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9529e-04 - val_loss: 8.9871e-04\n",
      "Epoch 70/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9448e-04 - val_loss: 0.0012\n",
      "Epoch 71/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 3.0302e-04 - val_loss: 0.0012\n",
      "Epoch 72/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.1498e-04 - val_loss: 0.0013\n",
      "Epoch 73/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 3.0321e-04 - val_loss: 0.0013\n",
      "Epoch 74/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.8430e-04 - val_loss: 8.7193e-04\n",
      "Epoch 75/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.8836e-04 - val_loss: 0.0011\n",
      "Epoch 76/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.9338e-04 - val_loss: 8.5353e-04\n",
      "Epoch 77/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.8516e-04 - val_loss: 7.8706e-04\n",
      "Epoch 78/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.9697e-04 - val_loss: 9.9803e-04\n",
      "Epoch 79/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9713e-04 - val_loss: 0.0011\n",
      "Epoch 80/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9742e-04 - val_loss: 7.4974e-04\n",
      "Epoch 81/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.8560e-04 - val_loss: 0.0011\n",
      "Epoch 82/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.8608e-04 - val_loss: 0.0011\n",
      "Epoch 83/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.8927e-04 - val_loss: 9.8581e-04\n",
      "Epoch 84/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.8422e-04 - val_loss: 8.8151e-04\n",
      "Epoch 85/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.8645e-04 - val_loss: 8.2756e-04\n",
      "Epoch 86/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 3.0855e-04 - val_loss: 5.5617e-04\n",
      "Epoch 87/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.8794e-04 - val_loss: 0.0010\n",
      "Epoch 88/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.8477e-04 - val_loss: 7.3997e-04\n",
      "Epoch 89/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.8280e-04 - val_loss: 8.4404e-04\n",
      "Epoch 90/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.7765e-04 - val_loss: 8.5163e-04\n",
      "Epoch 91/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.8426e-04 - val_loss: 9.3661e-04\n",
      "Epoch 92/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.8416e-04 - val_loss: 6.8767e-04\n",
      "Epoch 93/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.9505e-04 - val_loss: 7.6398e-04\n",
      "Epoch 94/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9258e-04 - val_loss: 6.4982e-04\n",
      "Epoch 95/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9076e-04 - val_loss: 0.0010\n",
      "Epoch 96/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.8146e-04 - val_loss: 7.9010e-04\n",
      "Epoch 97/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.8327e-04 - val_loss: 6.8120e-04\n",
      "Epoch 98/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.8494e-04 - val_loss: 7.3115e-04\n",
      "Epoch 99/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.8320e-04 - val_loss: 7.7011e-04\n",
      "Epoch 100/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9692e-04 - val_loss: 7.3336e-04\n",
      "Epoch 101/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.8677e-04 - val_loss: 7.5312e-04\n",
      "Epoch 102/2000\n",
      "42/42 [==============================] - 13s 312ms/step - loss: 2.7612e-04 - val_loss: 7.0856e-04\n",
      "Epoch 103/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.8240e-04 - val_loss: 8.0257e-04\n",
      "Epoch 104/2000\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 2.8463e-04 - val_loss: 0.0010\n",
      "Epoch 105/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.9127e-04 - val_loss: 7.2052e-04\n",
      "Epoch 106/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.8063e-04 - val_loss: 8.1161e-04\n",
      "Epoch 107/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.7702e-04 - val_loss: 6.2822e-04\n",
      "Epoch 108/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.8086e-04 - val_loss: 6.8878e-04\n",
      "Epoch 109/2000\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 2.9160e-04 - val_loss: 6.9258e-04\n",
      "Epoch 110/2000\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.7575e-04 - val_loss: 6.1989e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_156_layer_call_fn, lstm_cell_156_layer_call_and_return_conditional_losses, lstm_cell_157_layer_call_fn, lstm_cell_157_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_1000_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_1000_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "42/42 [==============================] - 16s 329ms/step - loss: 0.0528 - val_loss: 0.0298\n",
      "Epoch 2/2000\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0022 - val_loss: 0.0176\n",
      "Epoch 3/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 0.0012 - val_loss: 0.0126\n",
      "Epoch 4/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 8.6875e-04 - val_loss: 0.0082\n",
      "Epoch 5/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 6.9953e-04 - val_loss: 0.0058\n",
      "Epoch 6/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 5.8455e-04 - val_loss: 0.0037\n",
      "Epoch 7/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 4.9956e-04 - val_loss: 0.0020\n",
      "Epoch 8/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 4.3902e-04 - val_loss: 0.0018\n",
      "Epoch 9/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.9635e-04 - val_loss: 0.0014\n",
      "Epoch 10/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.7326e-04 - val_loss: 0.0011\n",
      "Epoch 11/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.5996e-04 - val_loss: 0.0011\n",
      "Epoch 12/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 3.5048e-04 - val_loss: 0.0012\n",
      "Epoch 13/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.5243e-04 - val_loss: 0.0010\n",
      "Epoch 14/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.4794e-04 - val_loss: 9.4584e-04\n",
      "Epoch 15/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.3663e-04 - val_loss: 9.3131e-04\n",
      "Epoch 16/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.3576e-04 - val_loss: 9.4497e-04\n",
      "Epoch 17/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.3371e-04 - val_loss: 8.6812e-04\n",
      "Epoch 18/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.3997e-04 - val_loss: 8.3630e-04\n",
      "Epoch 19/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.2919e-04 - val_loss: 8.1219e-04\n",
      "Epoch 20/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.3721e-04 - val_loss: 8.1061e-04\n",
      "Epoch 21/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 3.2589e-04 - val_loss: 8.0222e-04\n",
      "Epoch 22/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.3061e-04 - val_loss: 7.7248e-04\n",
      "Epoch 23/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 3.2799e-04 - val_loss: 7.6809e-04\n",
      "Epoch 24/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.2659e-04 - val_loss: 7.2742e-04\n",
      "Epoch 25/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.2211e-04 - val_loss: 7.4129e-04\n",
      "Epoch 26/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.2015e-04 - val_loss: 7.9793e-04\n",
      "Epoch 27/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.2146e-04 - val_loss: 7.1777e-04\n",
      "Epoch 28/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 3.1451e-04 - val_loss: 7.1612e-04\n",
      "Epoch 29/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.1541e-04 - val_loss: 7.3234e-04\n",
      "Epoch 30/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.1850e-04 - val_loss: 6.6361e-04\n",
      "Epoch 31/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.1547e-04 - val_loss: 8.0329e-04\n",
      "Epoch 32/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.1651e-04 - val_loss: 7.2781e-04\n",
      "Epoch 33/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.1299e-04 - val_loss: 6.4396e-04\n",
      "Epoch 34/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.1308e-04 - val_loss: 7.3119e-04\n",
      "Epoch 35/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.1675e-04 - val_loss: 6.9729e-04\n",
      "Epoch 36/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.1018e-04 - val_loss: 7.4077e-04\n",
      "Epoch 37/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.1064e-04 - val_loss: 7.0567e-04\n",
      "Epoch 38/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0908e-04 - val_loss: 9.3719e-04\n",
      "Epoch 39/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.1744e-04 - val_loss: 6.7687e-04\n",
      "Epoch 40/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.1237e-04 - val_loss: 7.4367e-04\n",
      "Epoch 41/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.1053e-04 - val_loss: 6.0467e-04\n",
      "Epoch 42/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.0690e-04 - val_loss: 7.3719e-04\n",
      "Epoch 43/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.1165e-04 - val_loss: 6.3389e-04\n",
      "Epoch 44/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0976e-04 - val_loss: 8.2553e-04\n",
      "Epoch 45/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.1883e-04 - val_loss: 8.0806e-04\n",
      "Epoch 46/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.1772e-04 - val_loss: 6.9490e-04\n",
      "Epoch 47/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0866e-04 - val_loss: 6.0914e-04\n",
      "Epoch 48/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0780e-04 - val_loss: 6.4988e-04\n",
      "Epoch 49/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.0338e-04 - val_loss: 8.1546e-04\n",
      "Epoch 50/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 2.9856e-04 - val_loss: 7.5638e-04\n",
      "Epoch 51/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0526e-04 - val_loss: 6.2811e-04\n",
      "Epoch 52/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0626e-04 - val_loss: 7.7776e-04\n",
      "Epoch 53/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.0653e-04 - val_loss: 6.9995e-04\n",
      "Epoch 54/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0059e-04 - val_loss: 7.1073e-04\n",
      "Epoch 55/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9795e-04 - val_loss: 7.2036e-04\n",
      "Epoch 56/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0266e-04 - val_loss: 8.6567e-04\n",
      "Epoch 57/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.0123e-04 - val_loss: 7.3463e-04\n",
      "Epoch 58/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.0804e-04 - val_loss: 6.0011e-04\n",
      "Epoch 59/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9924e-04 - val_loss: 5.7908e-04\n",
      "Epoch 60/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0709e-04 - val_loss: 7.3537e-04\n",
      "Epoch 61/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9686e-04 - val_loss: 7.1955e-04\n",
      "Epoch 62/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.0127e-04 - val_loss: 5.9236e-04\n",
      "Epoch 63/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.0176e-04 - val_loss: 6.0517e-04\n",
      "Epoch 64/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.1199e-04 - val_loss: 6.2603e-04\n",
      "Epoch 65/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0194e-04 - val_loss: 6.4924e-04\n",
      "Epoch 66/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9870e-04 - val_loss: 6.2153e-04\n",
      "Epoch 67/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.1059e-04 - val_loss: 6.3360e-04\n",
      "Epoch 68/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0452e-04 - val_loss: 5.9457e-04\n",
      "Epoch 69/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9472e-04 - val_loss: 6.1876e-04\n",
      "Epoch 70/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9596e-04 - val_loss: 6.2077e-04\n",
      "Epoch 71/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9130e-04 - val_loss: 6.2347e-04\n",
      "Epoch 72/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 2.9269e-04 - val_loss: 6.0670e-04\n",
      "Epoch 73/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.0354e-04 - val_loss: 6.1595e-04\n",
      "Epoch 74/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 2.9649e-04 - val_loss: 6.0604e-04\n",
      "Epoch 75/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9472e-04 - val_loss: 7.7288e-04\n",
      "Epoch 76/2000\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 2.9152e-04 - val_loss: 6.5495e-04\n",
      "Epoch 77/2000\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 2.9499e-04 - val_loss: 6.4187e-04\n",
      "Epoch 78/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.0666e-04 - val_loss: 7.2508e-04\n",
      "Epoch 79/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9641e-04 - val_loss: 6.2999e-04\n",
      "Epoch 80/2000\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 3.0506e-04 - val_loss: 5.8595e-04\n",
      "Epoch 81/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 2.9799e-04 - val_loss: 6.7985e-04\n",
      "Epoch 82/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 3.0228e-04 - val_loss: 6.5051e-04\n",
      "Epoch 83/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 3.0066e-04 - val_loss: 5.7265e-04\n",
      "Epoch 84/2000\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 2.9219e-04 - val_loss: 6.5373e-04\n",
      "Epoch 85/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9833e-04 - val_loss: 6.0305e-04\n",
      "Epoch 86/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 3.1285e-04 - val_loss: 7.8287e-04\n",
      "Epoch 87/2000\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 2.9187e-04 - val_loss: 6.3328e-04\n",
      "Epoch 88/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9508e-04 - val_loss: 6.9046e-04\n",
      "Epoch 89/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 2.8905e-04 - val_loss: 5.6580e-04\n",
      "Epoch 90/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 2.9369e-04 - val_loss: 5.8074e-04\n",
      "Epoch 91/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9599e-04 - val_loss: 6.2054e-04\n",
      "Epoch 92/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8984e-04 - val_loss: 6.1966e-04\n",
      "Epoch 93/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8895e-04 - val_loss: 6.2995e-04\n",
      "Epoch 94/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 2.9921e-04 - val_loss: 7.0597e-04\n",
      "Epoch 95/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8968e-04 - val_loss: 5.8315e-04\n",
      "Epoch 96/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 3.0007e-04 - val_loss: 6.1971e-04\n",
      "Epoch 97/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9782e-04 - val_loss: 6.7670e-04\n",
      "Epoch 98/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 2.8356e-04 - val_loss: 6.2260e-04\n",
      "Epoch 99/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 2.8989e-04 - val_loss: 5.9871e-04\n",
      "Epoch 100/2000\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 2.8435e-04 - val_loss: 5.8852e-04\n",
      "Epoch 101/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8484e-04 - val_loss: 5.7492e-04\n",
      "Epoch 102/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8993e-04 - val_loss: 5.9046e-04\n",
      "Epoch 103/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 2.8758e-04 - val_loss: 5.8649e-04\n",
      "Epoch 104/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8650e-04 - val_loss: 5.6709e-04\n",
      "Epoch 105/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8851e-04 - val_loss: 5.6205e-04\n",
      "Epoch 106/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 2.7898e-04 - val_loss: 6.2686e-04\n",
      "Epoch 107/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8512e-04 - val_loss: 6.5185e-04\n",
      "Epoch 108/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9558e-04 - val_loss: 6.6480e-04\n",
      "Epoch 109/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9313e-04 - val_loss: 5.6546e-04\n",
      "Epoch 110/2000\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 2.8880e-04 - val_loss: 5.2902e-04\n",
      "Epoch 111/2000\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 2.8526e-04 - val_loss: 5.9459e-04\n",
      "Epoch 112/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8572e-04 - val_loss: 7.7324e-04\n",
      "Epoch 113/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 2.9867e-04 - val_loss: 7.4967e-04\n",
      "Epoch 114/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8901e-04 - val_loss: 5.6718e-04\n",
      "Epoch 115/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8100e-04 - val_loss: 5.6072e-04\n",
      "Epoch 116/2000\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 2.7816e-04 - val_loss: 5.6961e-04\n",
      "Epoch 117/2000\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 2.8464e-04 - val_loss: 5.8130e-04\n",
      "Epoch 118/2000\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 2.8236e-04 - val_loss: 6.9420e-04\n",
      "Epoch 119/2000\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 3.0313e-04 - val_loss: 6.5724e-04\n",
      "Epoch 120/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8053e-04 - val_loss: 5.5004e-04\n",
      "Epoch 121/2000\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 2.7949e-04 - val_loss: 5.7196e-04\n",
      "Epoch 122/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 2.8056e-04 - val_loss: 5.5634e-04\n",
      "Epoch 123/2000\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 2.8613e-04 - val_loss: 5.7193e-04\n",
      "Epoch 124/2000\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 2.8701e-04 - val_loss: 5.6058e-04\n",
      "Epoch 125/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9607e-04 - val_loss: 5.5896e-04\n",
      "Epoch 126/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.7836e-04 - val_loss: 5.6764e-04\n",
      "Epoch 127/2000\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 2.8841e-04 - val_loss: 6.6940e-04\n",
      "Epoch 128/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 2.8580e-04 - val_loss: 5.5620e-04\n",
      "Epoch 129/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 2.7385e-04 - val_loss: 5.6960e-04\n",
      "Epoch 130/2000\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 2.7960e-04 - val_loss: 5.3801e-04\n",
      "Epoch 131/2000\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 2.9104e-04 - val_loss: 6.4646e-04\n",
      "Epoch 132/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9345e-04 - val_loss: 6.2043e-04\n",
      "Epoch 133/2000\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.9090e-04 - val_loss: 6.0178e-04\n",
      "Epoch 134/2000\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 2.7401e-04 - val_loss: 5.9800e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_158_layer_call_fn, lstm_cell_158_layer_call_and_return_conditional_losses, lstm_cell_159_layer_call_fn, lstm_cell_159_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_1000_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_1000_batch_256_earlystop_valloss_4\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_memory = 1000\n",
    "\n",
    "trainInputX, trainInputY = sf.prepareData(trainX, trainY, lstm_memory)\n",
    "testInputX, testInputY = sf.prepareData(testX, testY, lstm_memory)\n",
    "print(trainInputX.shape)\n",
    "print(trainInputY.shape)\n",
    "print(testInputX.shape)\n",
    "print(testInputY.shape)\n",
    "\n",
    "#validacao tamanho apos tratamentos\n",
    "print(len(trainX))\n",
    "print(len(trainInputX))\n",
    "\n",
    "print(len(trainY))\n",
    "print(len(trainInputY))\n",
    "\n",
    "trainInputX = trainInputX [:,:,0:14]\n",
    "testInputX = testInputX [:,:,0:14]\n",
    "print(trainInputX.shape)\n",
    "\n",
    "trained_models_lstm_1000 = []\n",
    "trained_models_lstm_1000_history = []\n",
    "\n",
    "for i in range(0,5):\n",
    "\n",
    "    #giving it reproducibility\n",
    "    seed = (i+1000)\n",
    "\n",
    "    os.environ['PYTHONHASHseed']=str(seed)\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    batch_size = 256\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=24)\n",
    "    \n",
    "    trained_models_lstm_1000.append(kr.Sequential())\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_1000[i].add(kr.layers.LSTM(14,return_sequences = True))\n",
    "    trained_models_lstm_1000[i].add(kr.layers.LSTM(8))\n",
    "    # lstm_model.add(kr.layers.Simplelstm(5,input_shape=(trainInputX.shape[1],trainInputX.shape[2])))\n",
    "    # lstm_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_lstm_1000[i].add(kr.layers.Dense(1))\n",
    "    trained_models_lstm_1000[i].compile(loss='mean_squared_error',optimizer='adam')\n",
    "    \n",
    "    trained_models_lstm_1000_history.append(trained_models_lstm_1000[i].fit(trainInputX, trainInputY, epochs=2000, batch_size=batch_size, verbose = 1, validation_data=(testInputX,testInputY),  callbacks=[callback]))\n",
    "    \n",
    "    trained_models_lstm_1000[i].save('C:/Users/guilh/PythonCodes/Models/LSTM_predicting10ahead_param_14_ts_1000_batch_256_earlystop_valloss_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3128d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
