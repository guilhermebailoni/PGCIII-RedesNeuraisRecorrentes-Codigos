{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0333e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as kr\n",
    "\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "import supportFunctions as sf\n",
    "\n",
    "import inspect\n",
    "lines = inspect.getsource(sf.highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f60e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função utilizada para normalizar os dados de treino e validação\n",
    "def normalize_data(train, test):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    train_scaled = scaler.transform(train)\n",
    "    test_scaled = scaler.transform(test)\n",
    "    \n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "#função utilizada para desnormalizar os dados, no formato de entrada\n",
    "def denormalize_data(scaler,data):\n",
    "    result = scaler.inverse_transform(data)\n",
    "    return result\n",
    "\n",
    "#função utilizada para desnomalizar o valor predito\n",
    "def denormalize_prediction(scaler, dataX, dataY):\n",
    "    formatted_data = np.array(dataX)\n",
    "    formatted_data[:,3] = np.array(dataY)\n",
    "    \n",
    "    return denormalize_data(scaler,formatted_data)[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f62a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.12.0\n",
      "Keras Version: 2.12.0\n",
      "\n",
      "Python 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas 1.5.2\n",
      "Scikit-Learn 1.2.1\n",
      "WARNING:tensorflow:From C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_19148\\3882079960.py:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n",
    "# tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c84100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantos passos para trás os indicadores técnicos vão olhar\n",
    "ti_memory = 10\n",
    "\n",
    "#lendo os dados que serão utilizados para treinamento e validação\n",
    "ge1day = pd.read_csv('Data\\GE.csv')\n",
    "#removendo a coluna que indica a data\n",
    "ge1day = ge1day.drop(['Date'], axis = 1)\n",
    "\n",
    "df = ge1day\n",
    "#reseting the index\n",
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ca2794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\PythonCodes\\supportFunctions.py:263: RuntimeWarning: divide by zero encountered in divide\n",
      "  rs = ag_vector/al_vector #numpy arrays so therefore can use element wise division\n",
      "C:\\Users\\guilh\\PythonCodes\\supportFunctions.py:263: RuntimeWarning: invalid value encountered in divide\n",
      "  rs = ag_vector/al_vector #numpy arrays so therefore can use element wise division\n"
     ]
    }
   ],
   "source": [
    "#adicionando os parametros de indicadores tecnicos ao dataframe\n",
    "df[\"\"\"highest_{}\"\"\".format(ti_memory)] = sf.highest(df.Close,ti_memory)\n",
    "df[\"\"\"lowest_{}\"\"\".format(ti_memory)] = sf.lowest(df.Close,ti_memory)\n",
    "df[\"\"\"wma_{}\"\"\".format(ti_memory)] = sf.wma(df.Close,ti_memory)\n",
    "df[\"\"\"ema_{}\"\"\".format(ti_memory)] = sf.ema(df.Close,ti_memory)\n",
    "df[\"\"\"hma_{}\"\"\".format(ti_memory)] = sf.hma(df.Close,ti_memory)\n",
    "df[\"\"\"macd_12_26\"\"\"] = sf.macd(df.Close,12,26)\n",
    "df[\"\"\"rsi_{}\"\"\".format(ti_memory)] = sf.rsi(df.Close,ti_memory)\n",
    "df[\"\"\"dpo_{}\"\"\".format(ti_memory)] = sf.dpo(df.Close,ti_memory)\n",
    "\n",
    "#parametros nao utilizados:\n",
    "# df[\"\"\"sma_{}\"\"\".format(ti_memory)] = sf.sma(df.Close,ti_memory)\n",
    "# df[\"\"\"so_k_5\"\"\"] = sf.so_k(df.Close)\n",
    "# df[\"\"\"so_d_3\"\"\"] = sf.so_d(df.Close)\n",
    "# df[\"\"\"obv\"\"\".format(ti_memory)] = sf.obv(df.Close,df.Volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c08296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>highest_10</th>\n",
       "      <th>lowest_10</th>\n",
       "      <th>wma_10</th>\n",
       "      <th>ema_10</th>\n",
       "      <th>hma_10</th>\n",
       "      <th>macd_12_26</th>\n",
       "      <th>rsi_10</th>\n",
       "      <th>dpo_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.751202</td>\n",
       "      <td>0.763722</td>\n",
       "      <td>0.743690</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>2156500</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.744942</td>\n",
       "      <td>0.744942</td>\n",
       "      <td>0.738682</td>\n",
       "      <td>0.741186</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>1477600</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.741186</td>\n",
       "      <td>0.743690</td>\n",
       "      <td>0.744942</td>\n",
       "      <td>0.745359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.744942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741186</td>\n",
       "      <td>0.747446</td>\n",
       "      <td>0.726162</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>1837000</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.738056</td>\n",
       "      <td>0.740769</td>\n",
       "      <td>0.741708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.740769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.733674</td>\n",
       "      <td>0.701122</td>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>2725600</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.728290</td>\n",
       "      <td>0.733987</td>\n",
       "      <td>0.734112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.733987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.691106</td>\n",
       "      <td>0.712390</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>3095000</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.712390</td>\n",
       "      <td>0.722990</td>\n",
       "      <td>0.729667</td>\n",
       "      <td>0.727268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.729667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14658</th>\n",
       "      <td>7.630000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>7.510000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>123180900</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.062182</td>\n",
       "      <td>7.424700</td>\n",
       "      <td>7.239323</td>\n",
       "      <td>-1.116727</td>\n",
       "      <td>50.108961</td>\n",
       "      <td>-0.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14659</th>\n",
       "      <td>7.680000</td>\n",
       "      <td>7.870000</td>\n",
       "      <td>7.540000</td>\n",
       "      <td>7.620000</td>\n",
       "      <td>7.620000</td>\n",
       "      <td>93299000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.175091</td>\n",
       "      <td>7.460209</td>\n",
       "      <td>7.697586</td>\n",
       "      <td>-1.029444</td>\n",
       "      <td>40.027642</td>\n",
       "      <td>-0.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14660</th>\n",
       "      <td>7.540000</td>\n",
       "      <td>7.940000</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>7.890000</td>\n",
       "      <td>7.890000</td>\n",
       "      <td>86850200</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.341273</td>\n",
       "      <td>7.538353</td>\n",
       "      <td>8.019525</td>\n",
       "      <td>-0.927790</td>\n",
       "      <td>41.907705</td>\n",
       "      <td>-0.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14661</th>\n",
       "      <td>7.870000</td>\n",
       "      <td>8.180000</td>\n",
       "      <td>7.820000</td>\n",
       "      <td>7.940000</td>\n",
       "      <td>7.940000</td>\n",
       "      <td>121149900</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.494182</td>\n",
       "      <td>7.611380</td>\n",
       "      <td>8.165303</td>\n",
       "      <td>-0.833585</td>\n",
       "      <td>32.316173</td>\n",
       "      <td>-1.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14662</th>\n",
       "      <td>7.520000</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.040000</td>\n",
       "      <td>7.040000</td>\n",
       "      <td>99330200</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.467818</td>\n",
       "      <td>7.507492</td>\n",
       "      <td>7.971818</td>\n",
       "      <td>-0.822072</td>\n",
       "      <td>45.132949</td>\n",
       "      <td>-0.219000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14663 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open      High       Low     Close  Adj Close     Volume  \\\n",
       "0      0.751202  0.763722  0.743690  0.748698   0.001782    2156500   \n",
       "1      0.744942  0.744942  0.738682  0.741186   0.001764    1477600   \n",
       "2      0.741186  0.747446  0.726162  0.732422   0.001743    1837000   \n",
       "3      0.732422  0.733674  0.701122  0.713642   0.001698    2725600   \n",
       "4      0.713642  0.713642  0.691106  0.712390   0.001695    3095000   \n",
       "...         ...       ...       ...       ...        ...        ...   \n",
       "14658  7.630000  8.300000  7.510000  8.120000   8.120000  123180900   \n",
       "14659  7.680000  7.870000  7.540000  7.620000   7.620000   93299000   \n",
       "14660  7.540000  7.940000  7.350000  7.890000   7.890000   86850200   \n",
       "14661  7.870000  8.180000  7.820000  7.940000   7.940000  121149900   \n",
       "14662  7.520000  7.550000  7.000000  7.040000   7.040000   99330200   \n",
       "\n",
       "       highest_10  lowest_10    wma_10    ema_10    hma_10  macd_12_26  \\\n",
       "0        0.748698   0.748698  0.748698  0.748698  0.748698    0.000000   \n",
       "1        0.748698   0.741186  0.743690  0.744942  0.745359    0.000000   \n",
       "2        0.748698   0.732422  0.738056  0.740769  0.741708    0.000000   \n",
       "3        0.748698   0.713642  0.728290  0.733987  0.734112    0.000000   \n",
       "4        0.748698   0.712390  0.722990  0.729667  0.727268    0.000000   \n",
       "...           ...        ...       ...       ...       ...         ...   \n",
       "14658    8.120000   6.110000  7.062182  7.424700  7.239323   -1.116727   \n",
       "14659    8.120000   6.110000  7.175091  7.460209  7.697586   -1.029444   \n",
       "14660    8.120000   6.110000  7.341273  7.538353  8.019525   -0.927790   \n",
       "14661    8.120000   6.110000  7.494182  7.611380  8.165303   -0.833585   \n",
       "14662    8.120000   6.110000  7.467818  7.507492  7.971818   -0.822072   \n",
       "\n",
       "           rsi_10    dpo_10  \n",
       "0             NaN  0.000000  \n",
       "1      100.000000 -0.744942  \n",
       "2      100.000000 -0.740769  \n",
       "3      100.000000 -0.733987  \n",
       "4      100.000000 -0.729667  \n",
       "...           ...       ...  \n",
       "14658   50.108961 -0.399000  \n",
       "14659   40.027642 -0.496000  \n",
       "14660   41.907705 -0.579000  \n",
       "14661   32.316173 -1.075000  \n",
       "14662   45.132949 -0.219000  \n",
       "\n",
       "[14663 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7c3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jogando alguns dados fora para termos todas variaveis incializadas\n",
    "inicialization_steps = 30\n",
    "prediction_ahead = 10\n",
    "\n",
    "dataValues = df.values\n",
    "\n",
    "trainSize = int(len(dataValues)*0.8)\n",
    "testSize = len(dataValues) - trainSize\n",
    "\n",
    "train = df.head(trainSize)\n",
    "# train,minDataTrain,minMaxDataTrain = sf.normalizaTrain(train)\n",
    "test = df.tail(testSize)\n",
    "# test = sf.normalizaTest(test, minDataTrain, minMaxDataTrain)\n",
    "\n",
    "scaler, train_normalized, test_normalized = normalize_data(train, test)\n",
    "\n",
    "#deixando um valor de fora, para podermos prever o próximo valor quando for o último:\n",
    "trainX = train_normalized[inicialization_steps:(len(train)-prediction_ahead)]\n",
    "testX = test_normalized[0:(len(test)-prediction_ahead)]\n",
    "\n",
    "#normalizando as entradas\n",
    "# scalerX, trainX, testX = normalize_data(trainX, testX)\n",
    "\n",
    "#pegando apenas o valor que queremos prever\n",
    "trainY = train_normalized[(inicialization_steps+prediction_ahead):len(train),3]\n",
    "testY = test_normalized[prediction_ahead:len(test),3]\n",
    "\n",
    "#calculando a diferenca percentual do preco de fechamento entre um dia e outro\n",
    "# trainY = (train.values[(inicialization_steps+1):len(train),3]/trainX[:,3])-1\n",
    "# testY = (test.values[1:len(test),3]/testX[:,3])-1\n",
    "\n",
    "\n",
    "# scalerY, trainY, testY = normalize_data(trainY, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd9aebb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 14)\n",
      "(11690,)\n",
      "(2923, 14)\n",
      "(2923,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4aa933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if it makes sense\n",
    "# print(trainInputX[:10,(rnn_memory-1),3])\n",
    "# print(trainInputY[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4958670c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 14)\n",
      "(11690,)\n",
      "(2923, 14)\n",
      "(2923,)\n",
      "11690\n",
      "11690\n",
      "11690\n",
      "11690\n",
      "(11690, 14)\n",
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 4.5928e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.6183e-04 - val_loss: 5.7068e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3253e-04 - val_loss: 4.0737e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2045e-04 - val_loss: 8.7500e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 927us/step - loss: 3.3208e-04 - val_loss: 4.5363e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.0565e-04 - val_loss: 5.2538e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3383e-04 - val_loss: 5.3038e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1593e-04 - val_loss: 3.7877e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4313e-04 - val_loss: 0.0012\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3850e-04 - val_loss: 5.4442e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1647e-04 - val_loss: 5.0247e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 2.9984e-04 - val_loss: 5.6913e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0680e-04 - val_loss: 4.6205e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 962us/step - loss: 3.2218e-04 - val_loss: 4.6981e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 902us/step - loss: 3.2023e-04 - val_loss: 6.4410e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.2133e-04 - val_loss: 6.6396e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2219e-04 - val_loss: 4.3131e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 3.1135e-04 - val_loss: 5.1679e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0102e-04 - val_loss: 3.9546e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0541e-04 - val_loss: 3.8291e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0911e-04 - val_loss: 3.8550e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.8598e-04 - val_loss: 4.3388e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0652e-04 - val_loss: 5.0739e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0842e-04 - val_loss: 5.0108e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0970e-04 - val_loss: 3.9381e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9202e-04 - val_loss: 4.3045e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.9587e-04 - val_loss: 4.9767e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8121e-04 - val_loss: 4.3770e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 2.8819e-04 - val_loss: 4.7271e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 3.0468e-04 - val_loss: 4.4881e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 2.8837e-04 - val_loss: 3.9631e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.7838e-04 - val_loss: 4.3296e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0129 - val_loss: 0.0038\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 4.2704e-04 - val_loss: 0.0018\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.5197e-04 - val_loss: 4.9478e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3792e-04 - val_loss: 4.7442e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2038e-04 - val_loss: 3.8759e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1741e-04 - val_loss: 4.1078e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0462e-04 - val_loss: 3.7123e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1344e-04 - val_loss: 3.9568e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1096e-04 - val_loss: 4.9834e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.2959e-04 - val_loss: 4.3076e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 3.1259e-04 - val_loss: 4.0209e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1861e-04 - val_loss: 4.5696e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2062e-04 - val_loss: 4.1567e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1322e-04 - val_loss: 6.1139e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1734e-04 - val_loss: 3.9732e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0872e-04 - val_loss: 3.6836e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3094e-04 - val_loss: 4.1308e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1750e-04 - val_loss: 4.9668e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3247e-04 - val_loss: 4.7926e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 761us/step - loss: 3.4115e-04 - val_loss: 5.5668e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 3.0526e-04 - val_loss: 8.1922e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9777e-04 - val_loss: 4.1709e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3968e-04 - val_loss: 4.0812e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0404e-04 - val_loss: 6.0852e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.0001e-04 - val_loss: 4.4582e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3485e-04 - val_loss: 4.6299e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0822e-04 - val_loss: 5.3431e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1586e-04 - val_loss: 3.8172e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1181e-04 - val_loss: 6.6451e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1650e-04 - val_loss: 4.0960e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8907e-04 - val_loss: 6.2245e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1993e-04 - val_loss: 4.3006e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0544e-04 - val_loss: 4.0684e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8835e-04 - val_loss: 5.6203e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0307e-04 - val_loss: 4.6795e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1998e-04 - val_loss: 5.6069e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9219e-04 - val_loss: 4.6369e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0684e-04 - val_loss: 4.7262e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8559e-04 - val_loss: 3.7671e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3438e-04 - val_loss: 4.0538e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.8221e-04 - val_loss: 6.4833e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 3.1570e-04 - val_loss: 4.9389e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 3.3509e-04 - val_loss: 4.0195e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 3.2685e-04 - val_loss: 4.1188e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 3.0673e-04 - val_loss: 4.5285e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1860e-04 - val_loss: 4.1299e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.0164e-04 - val_loss: 3.8591e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1202e-04 - val_loss: 5.9562e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2691e-04 - val_loss: 6.4323e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0932e-04 - val_loss: 5.7994e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0471e-04 - val_loss: 4.7578e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1001e-04 - val_loss: 4.1258e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1845e-04 - val_loss: 4.0088e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1741e-04 - val_loss: 3.7334e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 3.1075e-04 - val_loss: 3.8390e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2434e-04 - val_loss: 4.4970e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0723e-04 - val_loss: 3.8611e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 3.0672e-04 - val_loss: 4.1385e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1827e-04 - val_loss: 3.9948e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9465e-04 - val_loss: 3.9407e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 2.8675e-04 - val_loss: 3.7030e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9058e-04 - val_loss: 3.6386e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9603e-04 - val_loss: 7.6682e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1001e-04 - val_loss: 3.8954e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0014e-04 - val_loss: 4.1861e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1228e-04 - val_loss: 4.8731e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9158e-04 - val_loss: 3.7575e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8818e-04 - val_loss: 4.6799e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9795e-04 - val_loss: 6.5779e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0808e-04 - val_loss: 5.6570e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0070e-04 - val_loss: 4.1476e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0931e-04 - val_loss: 4.1044e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8681e-04 - val_loss: 3.8621e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8924e-04 - val_loss: 3.7170e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9665e-04 - val_loss: 6.5534e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9568e-04 - val_loss: 5.7985e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0925e-04 - val_loss: 4.2083e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8885e-04 - val_loss: 4.7265e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0600e-04 - val_loss: 5.0037e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8669e-04 - val_loss: 4.0144e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0877e-04 - val_loss: 5.5013e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 2.8236e-04 - val_loss: 3.9944e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 3.0406e-04 - val_loss: 4.0826e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.9153e-04 - val_loss: 3.8245e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.8507e-04 - val_loss: 4.3701e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8773e-04 - val_loss: 3.7505e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 8.3492e-04 - val_loss: 8.4659e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0657e-04 - val_loss: 0.0015\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4116e-04 - val_loss: 3.7361e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3427e-04 - val_loss: 6.5217e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.2464e-04 - val_loss: 4.0716e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1762e-04 - val_loss: 5.7641e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0275e-04 - val_loss: 5.0347e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.9315e-04 - val_loss: 4.8167e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0167e-04 - val_loss: 4.1678e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0997e-04 - val_loss: 5.0154e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9656e-04 - val_loss: 5.3060e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9697e-04 - val_loss: 4.0073e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9981e-04 - val_loss: 3.8304e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1380e-04 - val_loss: 4.0190e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 3.0212e-04 - val_loss: 3.6975e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9006e-04 - val_loss: 3.8362e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8759e-04 - val_loss: 3.7288e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9128e-04 - val_loss: 4.3310e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9905e-04 - val_loss: 6.7115e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2655e-04 - val_loss: 4.4121e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3243e-04 - val_loss: 3.8796e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8967e-04 - val_loss: 5.7601e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8644e-04 - val_loss: 3.8347e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8796e-04 - val_loss: 5.0485e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0374e-04 - val_loss: 4.1021e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9954e-04 - val_loss: 6.1639e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0903e-04 - val_loss: 4.7137e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 3.0468e-04 - val_loss: 4.5205e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9941e-04 - val_loss: 3.8704e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0115e-04 - val_loss: 3.9574e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1027e-04 - val_loss: 4.1089e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9542e-04 - val_loss: 4.1359e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0528e-04 - val_loss: 4.5469e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8667e-04 - val_loss: 4.0014e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.9333e-04 - val_loss: 3.7000e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8201e-04 - val_loss: 3.7757e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8930e-04 - val_loss: 4.7441e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8530e-04 - val_loss: 3.8375e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.7576e-04 - val_loss: 5.0789e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 8.2385e-04 - val_loss: 6.6150e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3873e-04 - val_loss: 7.2930e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.3321e-04 - val_loss: 4.6395e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.8141e-04 - val_loss: 5.4836e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.1084e-04 - val_loss: 6.0388e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 800us/step - loss: 3.5324e-04 - val_loss: 3.6682e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9378e-04 - val_loss: 3.8090e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2395e-04 - val_loss: 3.8376e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.3555e-04 - val_loss: 3.7926e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 3.0971e-04 - val_loss: 4.9996e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 3.1959e-04 - val_loss: 4.2284e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 874us/step - loss: 3.0446e-04 - val_loss: 4.3040e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 902us/step - loss: 2.9233e-04 - val_loss: 3.7625e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 3.0589e-04 - val_loss: 4.0286e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 2.8438e-04 - val_loss: 4.9424e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 3.1597e-04 - val_loss: 4.2511e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 3.3518e-04 - val_loss: 3.6801e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 3.1275e-04 - val_loss: 7.1363e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 2.9894e-04 - val_loss: 5.9299e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.4347e-04 - val_loss: 0.0013\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 3.0014e-04 - val_loss: 4.0294e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 2.9079e-04 - val_loss: 4.0737e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 2.9448e-04 - val_loss: 3.7041e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.0289e-04 - val_loss: 3.8709e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 2.9217e-04 - val_loss: 4.3445e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 3.1226e-04 - val_loss: 4.0341e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 3.0927e-04 - val_loss: 4.7383e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 2.9240e-04 - val_loss: 3.8946e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 2.9438e-04 - val_loss: 4.4616e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.1329e-04 - val_loss: 4.6056e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 5.7643e-04 - val_loss: 4.1544e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.5841e-04 - val_loss: 3.6146e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4939e-04 - val_loss: 4.2318e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3240e-04 - val_loss: 4.0149e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4513e-04 - val_loss: 6.0945e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2342e-04 - val_loss: 7.7048e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.4598e-04 - val_loss: 3.9787e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2131e-04 - val_loss: 3.7047e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3224e-04 - val_loss: 3.7198e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2822e-04 - val_loss: 4.8136e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 3.1891e-04 - val_loss: 3.8546e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2852e-04 - val_loss: 4.4370e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 724us/step - loss: 3.3787e-04 - val_loss: 5.8870e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2260e-04 - val_loss: 3.9448e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 3.0108e-04 - val_loss: 3.6416e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 2.9828e-04 - val_loss: 3.8563e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9997e-04 - val_loss: 4.8290e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 3.1565e-04 - val_loss: 4.3810e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.4660e-04 - val_loss: 3.8549e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 3.1657e-04 - val_loss: 3.9390e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 3.1359e-04 - val_loss: 3.8962e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.2559e-04 - val_loss: 6.2474e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3203e-04 - val_loss: 3.9926e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1154e-04 - val_loss: 4.1518e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0278e-04 - val_loss: 4.2418e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1861e-04 - val_loss: 3.6236e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.5263e-04 - val_loss: 4.5968e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2598e-04 - val_loss: 5.2019e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 3.6232e-04 - val_loss: 5.6521e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3872e-04 - val_loss: 3.9819e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3324e-04 - val_loss: 4.3453e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1081e-04 - val_loss: 4.2888e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2078e-04 - val_loss: 4.1790e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3951e-04 - val_loss: 4.4016e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2146e-04 - val_loss: 5.6734e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3454e-04 - val_loss: 3.9929e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1484e-04 - val_loss: 4.1503e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2060e-04 - val_loss: 3.9890e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0714e-04 - val_loss: 4.2815e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0184e-04 - val_loss: 5.7699e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1987e-04 - val_loss: 4.4529e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0727e-04 - val_loss: 4.5168e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2916e-04 - val_loss: 4.0425e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1484e-04 - val_loss: 4.3671e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9107e-04 - val_loss: 4.0694e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 3.1646e-04 - val_loss: 3.7790e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0445e-04 - val_loss: 3.8928e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1892e-04 - val_loss: 3.7350e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0857e-04 - val_loss: 4.6342e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0559e-04 - val_loss: 4.1286e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2070e-04 - val_loss: 7.3557e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0203e-04 - val_loss: 4.5470e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9478e-04 - val_loss: 4.9019e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1206e-04 - val_loss: 3.8438e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9787e-04 - val_loss: 4.8062e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8847e-04 - val_loss: 4.4750e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.3563e-04 - val_loss: 4.2229e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1650e-04 - val_loss: 3.8854e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9795e-04 - val_loss: 4.5756e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8775e-04 - val_loss: 7.9251e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 2.9900e-04 - val_loss: 4.8677e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8508e-04 - val_loss: 4.0223e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0408e-04 - val_loss: 4.3459e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.3091e-04 - val_loss: 4.0467e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9477e-04 - val_loss: 4.0863e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2012e-04 - val_loss: 4.0219e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9586e-04 - val_loss: 3.8609e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9279e-04 - val_loss: 4.0722e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7842e-04 - val_loss: 4.3977e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8290e-04 - val_loss: 4.8533e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.8584e-04 - val_loss: 4.0192e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0685e-04 - val_loss: 3.6368e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0218e-04 - val_loss: 4.1770e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8952e-04 - val_loss: 3.7121e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8836e-04 - val_loss: 3.8628e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1782e-04 - val_loss: 3.7530e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.0280e-04 - val_loss: 4.2104e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1408e-04 - val_loss: 3.9608e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9459e-04 - val_loss: 4.4406e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7975e-04 - val_loss: 6.6869e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0261e-04 - val_loss: 5.2345e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8990e-04 - val_loss: 4.6502e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.7468e-04 - val_loss: 6.3113e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8208e-04 - val_loss: 3.9447e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1123e-04 - val_loss: 3.9863e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0993e-04 - val_loss: 3.8123e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9925e-04 - val_loss: 7.3038e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8406e-04 - val_loss: 3.9021e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8427e-04 - val_loss: 4.0595e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9991e-04 - val_loss: 4.9486e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7952e-04 - val_loss: 4.6420e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9282e-04 - val_loss: 3.7924e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 2.7849e-04 - val_loss: 4.2311e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.7926e-04 - val_loss: 3.8254e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 2.8416e-04 - val_loss: 3.7471e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8254e-04 - val_loss: 4.2754e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 6.3105e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0645e-04 - val_loss: 3.7404e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9576e-04 - val_loss: 3.7771e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0473e-04 - val_loss: 3.6979e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9577e-04 - val_loss: 3.7231e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9946e-04 - val_loss: 3.8667e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1833e-04 - val_loss: 6.8944e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2619e-04 - val_loss: 3.5599e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2314e-04 - val_loss: 5.3804e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1095e-04 - val_loss: 3.7666e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1729e-04 - val_loss: 4.4020e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9220e-04 - val_loss: 4.2666e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3026e-04 - val_loss: 4.3573e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2272e-04 - val_loss: 3.8116e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0264e-04 - val_loss: 4.0177e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9924e-04 - val_loss: 3.8211e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0742e-04 - val_loss: 4.8598e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0581e-04 - val_loss: 4.5599e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0130e-04 - val_loss: 4.1962e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0237e-04 - val_loss: 3.8223e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2385e-04 - val_loss: 4.2194e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1229e-04 - val_loss: 4.2815e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1283e-04 - val_loss: 3.6573e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9719e-04 - val_loss: 4.3202e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1908e-04 - val_loss: 3.6500e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0169e-04 - val_loss: 4.1162e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0701e-04 - val_loss: 4.5664e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0837e-04 - val_loss: 3.7416e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0190e-04 - val_loss: 3.7717e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9297e-04 - val_loss: 4.0354e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1630e-04 - val_loss: 5.4236e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0678e-04 - val_loss: 5.0103e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9623e-04 - val_loss: 6.5132e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8474e-04 - val_loss: 4.3830e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9972e-04 - val_loss: 4.5272e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9746e-04 - val_loss: 4.3957e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.1170e-04 - val_loss: 4.2389e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0871e-04 - val_loss: 4.2346e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2197e-04 - val_loss: 5.8701e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4572e-04 - val_loss: 5.0434e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9736e-04 - val_loss: 6.5075e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9037e-04 - val_loss: 4.0645e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.5002e-04 - val_loss: 4.0707e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0133e-04 - val_loss: 5.0610e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0187e-04 - val_loss: 4.0047e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4989e-04 - val_loss: 4.5088e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0020e-04 - val_loss: 4.4895e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2080e-04 - val_loss: 5.2813e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 2.9600e-04 - val_loss: 4.1895e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2189e-04 - val_loss: 4.3399e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 3.0288e-04 - val_loss: 4.0494e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1742e-04 - val_loss: 3.9764e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9186e-04 - val_loss: 4.0767e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9349e-04 - val_loss: 4.3604e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 3.1076e-04 - val_loss: 4.0506e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0195e-04 - val_loss: 3.8814e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9878e-04 - val_loss: 4.3113e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1520e-04 - val_loss: 4.3839e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3330e-04 - val_loss: 7.3845e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8645e-04 - val_loss: 4.1116e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8074e-04 - val_loss: 4.3051e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2292e-04 - val_loss: 3.7509e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0691e-04 - val_loss: 5.2507e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0906e-04 - val_loss: 4.1065e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.9370e-04 - val_loss: 4.1821e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0791e-04 - val_loss: 4.0668e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9120e-04 - val_loss: 3.8363e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.9179e-04 - val_loss: 4.0735e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1340e-04 - val_loss: 4.1540e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3118e-04 - val_loss: 4.0354e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8887e-04 - val_loss: 4.4644e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.0023e-04 - val_loss: 4.5787e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9934e-04 - val_loss: 4.7075e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.9283e-04 - val_loss: 3.7626e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2690e-04 - val_loss: 7.4226e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0266e-04 - val_loss: 7.1684e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1431e-04 - val_loss: 3.9556e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9900e-04 - val_loss: 3.7731e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8875e-04 - val_loss: 4.2822e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9303e-04 - val_loss: 4.5886e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8565e-04 - val_loss: 4.9634e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9418e-04 - val_loss: 3.9402e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0594e-04 - val_loss: 4.1036e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9445e-04 - val_loss: 4.0509e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3676e-04 - val_loss: 5.1493e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8752e-04 - val_loss: 4.1814e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 3.5958e-04 - val_loss: 5.1288e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3411e-04 - val_loss: 5.6653e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.6569e-04 - val_loss: 4.2962e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4033e-04 - val_loss: 4.4014e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2857e-04 - val_loss: 4.2093e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.4554e-04 - val_loss: 4.8388e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.4483e-04 - val_loss: 4.6987e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3551e-04 - val_loss: 4.0689e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4914e-04 - val_loss: 4.0716e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1563e-04 - val_loss: 7.7768e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1110e-04 - val_loss: 4.3665e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0273e-04 - val_loss: 5.3132e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2322e-04 - val_loss: 4.3840e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0900e-04 - val_loss: 4.9913e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9854e-04 - val_loss: 4.4281e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0963e-04 - val_loss: 4.1319e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9672e-04 - val_loss: 4.3911e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1756e-04 - val_loss: 4.2261e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 3.1067e-04 - val_loss: 8.6000e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0596e-04 - val_loss: 3.8681e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0495e-04 - val_loss: 4.0632e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9976e-04 - val_loss: 9.0931e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3236e-04 - val_loss: 4.3154e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0022e-04 - val_loss: 5.7071e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2437e-04 - val_loss: 6.1057e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9745e-04 - val_loss: 3.8574e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.0435e-04 - val_loss: 4.5525e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9004e-04 - val_loss: 3.8383e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1743e-04 - val_loss: 4.7429e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9178e-04 - val_loss: 3.9660e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9814e-04 - val_loss: 4.8751e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0202e-04 - val_loss: 4.7348e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0368e-04 - val_loss: 5.7372e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1110e-04 - val_loss: 3.9993e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8762e-04 - val_loss: 3.8584e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8815e-04 - val_loss: 6.6252e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 2.7863e-04 - val_loss: 4.3399e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 729us/step - loss: 3.1931e-04 - val_loss: 4.1602e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0829e-04 - val_loss: 3.9406e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1445e-04 - val_loss: 5.0407e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8064e-04 - val_loss: 4.2783e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.7829e-04 - val_loss: 4.4676e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9574e-04 - val_loss: 4.3899e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8950e-04 - val_loss: 4.5649e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1004e-04 - val_loss: 4.2645e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9018e-04 - val_loss: 4.0289e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8979e-04 - val_loss: 5.5464e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9261e-04 - val_loss: 3.8488e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8354e-04 - val_loss: 5.2934e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9670e-04 - val_loss: 4.0961e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.7844e-04 - val_loss: 4.9803e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8544e-04 - val_loss: 4.8815e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0031 - val_loss: 0.0087\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.4425e-04 - val_loss: 0.0034\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.9857e-04 - val_loss: 7.4978e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.6004e-04 - val_loss: 3.8984e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4509e-04 - val_loss: 4.4417e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.5120e-04 - val_loss: 4.3517e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4690e-04 - val_loss: 4.1624e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1520e-04 - val_loss: 4.3095e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2981e-04 - val_loss: 4.4088e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0338e-04 - val_loss: 4.2405e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4263e-04 - val_loss: 4.7020e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0017e-04 - val_loss: 6.3116e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4315e-04 - val_loss: 5.2500e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4605e-04 - val_loss: 7.5759e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3362e-04 - val_loss: 6.0742e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1539e-04 - val_loss: 3.8604e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0201e-04 - val_loss: 4.0033e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9006e-04 - val_loss: 7.7990e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0687e-04 - val_loss: 3.8258e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 3.0821e-04 - val_loss: 3.8702e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3636e-04 - val_loss: 4.0461e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0524e-04 - val_loss: 3.9398e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9998e-04 - val_loss: 4.6546e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1792e-04 - val_loss: 3.9171e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9817e-04 - val_loss: 3.7993e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9436e-04 - val_loss: 4.6056e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4837e-04 - val_loss: 4.0554e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9987e-04 - val_loss: 4.8091e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9735e-04 - val_loss: 5.8878e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1346e-04 - val_loss: 3.9784e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0024e-04 - val_loss: 6.4689e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0667e-04 - val_loss: 3.8772e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8899e-04 - val_loss: 5.0726e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2057e-04 - val_loss: 4.2074e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0013e-04 - val_loss: 3.7186e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9581e-04 - val_loss: 4.8698e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1752e-04 - val_loss: 4.9452e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9621e-04 - val_loss: 5.4421e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2649e-04 - val_loss: 4.7326e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9330e-04 - val_loss: 3.9051e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9857e-04 - val_loss: 5.7994e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0937e-04 - val_loss: 4.0621e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9897e-04 - val_loss: 4.7738e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8846e-04 - val_loss: 4.8252e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9839e-04 - val_loss: 3.8520e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 2.9185e-04 - val_loss: 3.8138e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8642e-04 - val_loss: 3.8777e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 745us/step - loss: 2.9605e-04 - val_loss: 3.8228e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9266e-04 - val_loss: 3.9631e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8929e-04 - val_loss: 4.2007e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8217e-04 - val_loss: 3.9448e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2624e-04 - val_loss: 3.9226e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9448e-04 - val_loss: 5.1031e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8926e-04 - val_loss: 4.1267e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0033e-04 - val_loss: 3.6094e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 738us/step - loss: 2.9457e-04 - val_loss: 3.7103e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8378e-04 - val_loss: 4.1504e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 2.8768e-04 - val_loss: 4.0446e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8596e-04 - val_loss: 4.0223e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8900e-04 - val_loss: 4.0876e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9975e-04 - val_loss: 3.9514e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8166e-04 - val_loss: 3.7651e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8973e-04 - val_loss: 3.9562e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9878e-04 - val_loss: 3.7832e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7857e-04 - val_loss: 4.1804e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8784e-04 - val_loss: 3.7056e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9696e-04 - val_loss: 3.8357e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8813e-04 - val_loss: 4.1915e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9165e-04 - val_loss: 3.7859e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.8975e-04 - val_loss: 3.7837e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9444e-04 - val_loss: 4.0444e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0577e-04 - val_loss: 3.9208e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8354e-04 - val_loss: 5.0115e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8552e-04 - val_loss: 5.8512e-04\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8205e-04 - val_loss: 3.8959e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9380e-04 - val_loss: 3.6931e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0216e-04 - val_loss: 4.4967e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8578e-04 - val_loss: 4.1110e-04\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0523e-04 - val_loss: 6.3056e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0042 - val_loss: 8.2176e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.7949e-04 - val_loss: 0.0012\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4800e-04 - val_loss: 4.2477e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3969e-04 - val_loss: 3.9645e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4854e-04 - val_loss: 8.2525e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.7394e-04 - val_loss: 8.2367e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.8142e-04 - val_loss: 5.8287e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.8711e-04 - val_loss: 3.7551e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.5657e-04 - val_loss: 3.9291e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.5927e-04 - val_loss: 7.4001e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.7391e-04 - val_loss: 4.6907e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2798e-04 - val_loss: 7.1025e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.8759e-04 - val_loss: 3.7837e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2819e-04 - val_loss: 5.5930e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1639e-04 - val_loss: 3.8913e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2392e-04 - val_loss: 3.6205e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1719e-04 - val_loss: 3.9697e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2680e-04 - val_loss: 6.7263e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2624e-04 - val_loss: 3.7325e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2091e-04 - val_loss: 5.3510e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2097e-04 - val_loss: 8.0919e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4288e-04 - val_loss: 3.8563e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2854e-04 - val_loss: 4.7652e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2776e-04 - val_loss: 4.0213e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0634e-04 - val_loss: 4.1844e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0788e-04 - val_loss: 4.1662e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0000e-04 - val_loss: 4.4815e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9454e-04 - val_loss: 3.7185e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.5254e-04 - val_loss: 5.2746e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0839e-04 - val_loss: 4.4188e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0447e-04 - val_loss: 4.1298e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.2197e-04 - val_loss: 3.8756e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9834e-04 - val_loss: 4.2079e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 3.0432e-04 - val_loss: 3.9172e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2104e-04 - val_loss: 3.7963e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 3.0849e-04 - val_loss: 4.6468e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1101e-04 - val_loss: 3.9406e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1805e-04 - val_loss: 7.0361e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 760us/step - loss: 3.1014e-04 - val_loss: 4.2065e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 861us/step - loss: 3.2032e-04 - val_loss: 3.7011e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_11\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3915e-04 - val_loss: 0.0011\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.5302e-04 - val_loss: 6.7262e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2655e-04 - val_loss: 4.5231e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3476e-04 - val_loss: 4.3955e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1878e-04 - val_loss: 4.4373e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3013e-04 - val_loss: 3.7593e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.3972e-04 - val_loss: 3.8108e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2707e-04 - val_loss: 5.1521e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.4540e-04 - val_loss: 5.9006e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2152e-04 - val_loss: 3.8684e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2887e-04 - val_loss: 3.7909e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2472e-04 - val_loss: 4.4326e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1691e-04 - val_loss: 3.9202e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4356e-04 - val_loss: 3.9115e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2804e-04 - val_loss: 4.4358e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0953e-04 - val_loss: 3.8833e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3180e-04 - val_loss: 4.7327e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4977e-04 - val_loss: 3.7747e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0874e-04 - val_loss: 4.1026e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2007e-04 - val_loss: 4.2599e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.5067e-04 - val_loss: 4.5137e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.6320e-04 - val_loss: 4.2184e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2641e-04 - val_loss: 5.2023e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2341e-04 - val_loss: 4.3313e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0755e-04 - val_loss: 4.3832e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1670e-04 - val_loss: 3.7930e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2159e-04 - val_loss: 4.7751e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0123e-04 - val_loss: 4.0942e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2591e-04 - val_loss: 4.4029e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1607e-04 - val_loss: 4.4408e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_12\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3747e-04 - val_loss: 0.0013\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.5457e-04 - val_loss: 0.0011\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.6682e-04 - val_loss: 4.9201e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.1646e-04 - val_loss: 5.6642e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4708e-04 - val_loss: 4.2574e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4655e-04 - val_loss: 3.8330e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.5399e-04 - val_loss: 4.8531e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.3338e-04 - val_loss: 4.1707e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.3361e-04 - val_loss: 4.3044e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1275e-04 - val_loss: 7.3508e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.5566e-04 - val_loss: 3.8901e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1250e-04 - val_loss: 6.5252e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3064e-04 - val_loss: 5.1959e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2240e-04 - val_loss: 4.0901e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2772e-04 - val_loss: 4.3335e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.3757e-04 - val_loss: 4.7900e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0339e-04 - val_loss: 4.0805e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.5974e-04 - val_loss: 7.0901e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.3431e-04 - val_loss: 7.1549e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0892e-04 - val_loss: 3.9827e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1518e-04 - val_loss: 6.9364e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0923e-04 - val_loss: 5.8416e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 3.1165e-04 - val_loss: 4.5718e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1104e-04 - val_loss: 3.9376e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0585e-04 - val_loss: 3.9552e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9224e-04 - val_loss: 8.0937e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 3.1547e-04 - val_loss: 6.6372e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4216e-04 - val_loss: 4.5980e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.2685e-04 - val_loss: 3.7791e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 2.9745e-04 - val_loss: 4.2954e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1647e-04 - val_loss: 3.8641e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 2.9123e-04 - val_loss: 4.3009e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0295e-04 - val_loss: 4.2176e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.1130e-04 - val_loss: 4.1721e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2209e-04 - val_loss: 5.3245e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0330e-04 - val_loss: 5.9177e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1323e-04 - val_loss: 3.8690e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0044e-04 - val_loss: 4.0670e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0222e-04 - val_loss: 4.9971e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9490e-04 - val_loss: 4.6062e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2881e-04 - val_loss: 8.6479e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 2.8529e-04 - val_loss: 4.1527e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0925e-04 - val_loss: 4.2497e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0402e-04 - val_loss: 5.4291e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 3.0891e-04 - val_loss: 5.8394e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.3062e-04 - val_loss: 4.4275e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.7867e-04 - val_loss: 4.0504e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.9770e-04 - val_loss: 8.7840e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.0142e-04 - val_loss: 3.7718e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1542e-04 - val_loss: 3.9338e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.8693e-04 - val_loss: 5.2442e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1484e-04 - val_loss: 3.9737e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9192e-04 - val_loss: 5.7907e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8771e-04 - val_loss: 3.9902e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8490e-04 - val_loss: 3.6810e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 3.0468e-04 - val_loss: 5.6298e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9005e-04 - val_loss: 4.2329e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 2.8307e-04 - val_loss: 3.8347e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.8714e-04 - val_loss: 4.0951e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9692e-04 - val_loss: 5.1354e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.7480e-04 - val_loss: 4.8792e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8801e-04 - val_loss: 6.1797e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9551e-04 - val_loss: 4.2596e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9601e-04 - val_loss: 3.9141e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.8912e-04 - val_loss: 3.9301e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1064e-04 - val_loss: 4.2201e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9696e-04 - val_loss: 3.8541e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8581e-04 - val_loss: 3.7570e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.7865e-04 - val_loss: 3.7360e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.7922e-04 - val_loss: 4.0042e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9113e-04 - val_loss: 4.0295e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9115e-04 - val_loss: 5.2352e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8907e-04 - val_loss: 4.5151e-04\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.7408e-04 - val_loss: 3.8953e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9346e-04 - val_loss: 3.8324e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9040e-04 - val_loss: 3.9423e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8671e-04 - val_loss: 4.0237e-04\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8135e-04 - val_loss: 4.9232e-04\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8457e-04 - val_loss: 3.9358e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_13\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_13\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 9.8014e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0962e-04 - val_loss: 8.5832e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1062e-04 - val_loss: 4.2667e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2023e-04 - val_loss: 4.2281e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1425e-04 - val_loss: 4.5063e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0927e-04 - val_loss: 5.0196e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3222e-04 - val_loss: 5.7527e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1806e-04 - val_loss: 4.2096e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0306e-04 - val_loss: 4.1165e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1311e-04 - val_loss: 3.9832e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1142e-04 - val_loss: 5.4983e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2536e-04 - val_loss: 4.0780e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1469e-04 - val_loss: 5.1048e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0278e-04 - val_loss: 5.3098e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9971e-04 - val_loss: 4.3553e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2932e-04 - val_loss: 4.3278e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9223e-04 - val_loss: 3.8280e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 3.0577e-04 - val_loss: 4.0100e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8570e-04 - val_loss: 4.0255e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9720e-04 - val_loss: 4.5461e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1125e-04 - val_loss: 6.6817e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1416e-04 - val_loss: 5.4713e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 880us/step - loss: 3.0327e-04 - val_loss: 3.8517e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 3.0473e-04 - val_loss: 5.2193e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 3.2274e-04 - val_loss: 6.2408e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0666e-04 - val_loss: 4.5432e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0597e-04 - val_loss: 3.8506e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9644e-04 - val_loss: 4.8692e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0383e-04 - val_loss: 3.7794e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9517e-04 - val_loss: 3.6706e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9308e-04 - val_loss: 3.8193e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8944e-04 - val_loss: 5.1965e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 3.0090e-04 - val_loss: 4.8856e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0062e-04 - val_loss: 4.5251e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.5379e-04 - val_loss: 3.6464e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.8324e-04 - val_loss: 4.0814e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 2.9512e-04 - val_loss: 3.9654e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7757e-04 - val_loss: 4.0210e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8425e-04 - val_loss: 4.5452e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8379e-04 - val_loss: 4.1588e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0272e-04 - val_loss: 5.0869e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9258e-04 - val_loss: 3.7234e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 3.1228e-04 - val_loss: 3.9915e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0337e-04 - val_loss: 3.7628e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9227e-04 - val_loss: 4.0506e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8041e-04 - val_loss: 3.9506e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8787e-04 - val_loss: 3.8521e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.7697e-04 - val_loss: 3.8990e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8938e-04 - val_loss: 4.5196e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9247e-04 - val_loss: 4.4159e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0487e-04 - val_loss: 6.0283e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9220e-04 - val_loss: 3.9329e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9005e-04 - val_loss: 3.9192e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9955e-04 - val_loss: 3.9931e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0537e-04 - val_loss: 3.8335e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7558e-04 - val_loss: 4.6235e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9360e-04 - val_loss: 4.3051e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8520e-04 - val_loss: 4.0896e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0679e-04 - val_loss: 5.3790e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_14\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_14\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0095 - val_loss: 0.0012\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.2189e-04 - val_loss: 5.4030e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0344e-04 - val_loss: 4.0865e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9440e-04 - val_loss: 4.1707e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9487e-04 - val_loss: 4.1760e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9520e-04 - val_loss: 3.7962e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9624e-04 - val_loss: 3.7498e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0667e-04 - val_loss: 5.4439e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2841e-04 - val_loss: 4.1302e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0017e-04 - val_loss: 3.9416e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9697e-04 - val_loss: 4.0135e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9675e-04 - val_loss: 3.9489e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9639e-04 - val_loss: 4.2621e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9732e-04 - val_loss: 4.2150e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1061e-04 - val_loss: 4.7585e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0328e-04 - val_loss: 3.6229e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0779e-04 - val_loss: 3.8121e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0159e-04 - val_loss: 4.2702e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2454e-04 - val_loss: 0.0010\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3446e-04 - val_loss: 3.6943e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0970e-04 - val_loss: 4.0232e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8760e-04 - val_loss: 4.8585e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1374e-04 - val_loss: 3.7254e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.0616e-04 - val_loss: 4.0707e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9519e-04 - val_loss: 3.8645e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2616e-04 - val_loss: 4.4923e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2703e-04 - val_loss: 3.6105e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0817e-04 - val_loss: 4.1183e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9117e-04 - val_loss: 4.4108e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.2558e-04 - val_loss: 3.6705e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0181e-04 - val_loss: 3.8141e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2769e-04 - val_loss: 4.3438e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 729us/step - loss: 2.9225e-04 - val_loss: 3.8784e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9884e-04 - val_loss: 6.9137e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 3.0080e-04 - val_loss: 4.6192e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 2.8768e-04 - val_loss: 4.1989e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9704e-04 - val_loss: 4.5291e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 869us/step - loss: 3.3952e-04 - val_loss: 8.0322e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9525e-04 - val_loss: 4.2371e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0294e-04 - val_loss: 4.1441e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0381e-04 - val_loss: 3.8296e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1808e-04 - val_loss: 4.8250e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 2.8002e-04 - val_loss: 4.3990e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0677e-04 - val_loss: 3.5538e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 2.7862e-04 - val_loss: 4.0023e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9215e-04 - val_loss: 3.8501e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9815e-04 - val_loss: 3.7031e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.9736e-04 - val_loss: 6.4157e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9169e-04 - val_loss: 4.5388e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1127e-04 - val_loss: 3.6993e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9795e-04 - val_loss: 4.2843e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9990e-04 - val_loss: 5.3352e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0576e-04 - val_loss: 4.2559e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8212e-04 - val_loss: 3.6029e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 2.8333e-04 - val_loss: 3.6848e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8759e-04 - val_loss: 4.4786e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8188e-04 - val_loss: 6.2944e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8767e-04 - val_loss: 3.8034e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9537e-04 - val_loss: 4.3400e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9767e-04 - val_loss: 3.9461e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9679e-04 - val_loss: 3.9589e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8858e-04 - val_loss: 3.6853e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0101e-04 - val_loss: 4.2925e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9275e-04 - val_loss: 4.0512e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8675e-04 - val_loss: 4.3076e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8080e-04 - val_loss: 4.4016e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8865e-04 - val_loss: 3.7830e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0962e-04 - val_loss: 4.6605e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_15\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_15\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0048 - val_loss: 9.1882e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0120e-04 - val_loss: 5.6363e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0213e-04 - val_loss: 4.1462e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9847e-04 - val_loss: 4.4252e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0978e-04 - val_loss: 4.1461e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0448e-04 - val_loss: 4.1252e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1208e-04 - val_loss: 3.9306e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0631e-04 - val_loss: 5.7616e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1355e-04 - val_loss: 7.4959e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1609e-04 - val_loss: 4.1886e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1660e-04 - val_loss: 4.0815e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 3.0126e-04 - val_loss: 3.9865e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.3123e-04 - val_loss: 3.7788e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1019e-04 - val_loss: 4.6118e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.2800e-04 - val_loss: 3.9201e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0653e-04 - val_loss: 3.7613e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.0711e-04 - val_loss: 7.3763e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1801e-04 - val_loss: 4.1142e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1835e-04 - val_loss: 0.0011\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0987e-04 - val_loss: 3.9938e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1758e-04 - val_loss: 4.0474e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 2.9181e-04 - val_loss: 3.7918e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4647e-04 - val_loss: 7.1650e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.0393e-04 - val_loss: 4.1136e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2788e-04 - val_loss: 3.8577e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 2.9427e-04 - val_loss: 4.0788e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9481e-04 - val_loss: 3.7380e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9084e-04 - val_loss: 3.8568e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9280e-04 - val_loss: 4.2000e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8863e-04 - val_loss: 3.9410e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8212e-04 - val_loss: 4.0553e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.0179e-04 - val_loss: 3.9876e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0022e-04 - val_loss: 4.6689e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9342e-04 - val_loss: 4.1049e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.0435e-04 - val_loss: 3.8714e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8349e-04 - val_loss: 3.7996e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8208e-04 - val_loss: 3.8841e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0635e-04 - val_loss: 4.8500e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.7283e-04 - val_loss: 4.7833e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8384e-04 - val_loss: 5.0447e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 2.9989e-04 - val_loss: 4.2987e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8597e-04 - val_loss: 4.4605e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 3.0622e-04 - val_loss: 3.6941e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8594e-04 - val_loss: 3.7994e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 2.8402e-04 - val_loss: 5.5431e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8900e-04 - val_loss: 4.6481e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8873e-04 - val_loss: 3.6940e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8370e-04 - val_loss: 3.6645e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0051e-04 - val_loss: 3.8294e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8278e-04 - val_loss: 3.7353e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9097e-04 - val_loss: 5.1240e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9008e-04 - val_loss: 3.8705e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.8613e-04 - val_loss: 3.8409e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 732us/step - loss: 3.0427e-04 - val_loss: 3.5598e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8983e-04 - val_loss: 3.7399e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8415e-04 - val_loss: 3.7032e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8419e-04 - val_loss: 3.7920e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 2.8335e-04 - val_loss: 4.4313e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8795e-04 - val_loss: 3.7778e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0308e-04 - val_loss: 3.6670e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 2.9003e-04 - val_loss: 3.9850e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8951e-04 - val_loss: 3.9273e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8631e-04 - val_loss: 3.7579e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.7942e-04 - val_loss: 3.8172e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8448e-04 - val_loss: 3.8901e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8272e-04 - val_loss: 4.0628e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8318e-04 - val_loss: 3.9222e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.6890e-04 - val_loss: 4.1922e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.7751e-04 - val_loss: 5.2335e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8288e-04 - val_loss: 3.9752e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9082e-04 - val_loss: 3.7811e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7810e-04 - val_loss: 4.2073e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7757e-04 - val_loss: 3.9424e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8235e-04 - val_loss: 5.3932e-04\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8014e-04 - val_loss: 3.7295e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 757us/step - loss: 2.8013e-04 - val_loss: 4.3076e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 2.8683e-04 - val_loss: 4.4313e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 2.7244e-04 - val_loss: 4.9573e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1151e-04 - val_loss: 0.0010\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3104e-04 - val_loss: 5.0076e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1647e-04 - val_loss: 5.0822e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 852us/step - loss: 3.1308e-04 - val_loss: 4.1697e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 3.3573e-04 - val_loss: 4.1804e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.2591e-04 - val_loss: 6.9374e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.2856e-04 - val_loss: 8.7853e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.0579e-04 - val_loss: 4.1602e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.2321e-04 - val_loss: 3.8203e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3100e-04 - val_loss: 5.1239e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4433e-04 - val_loss: 5.3023e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1488e-04 - val_loss: 4.2470e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2257e-04 - val_loss: 4.5790e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1409e-04 - val_loss: 9.4322e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3234e-04 - val_loss: 7.0183e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2689e-04 - val_loss: 5.9595e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1488e-04 - val_loss: 7.8404e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.2004e-04 - val_loss: 4.0308e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0348e-04 - val_loss: 7.2940e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 3.3613e-04 - val_loss: 3.8052e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.2793e-04 - val_loss: 4.5876e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1479e-04 - val_loss: 3.7266e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0527e-04 - val_loss: 4.0758e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 3.0196e-04 - val_loss: 4.1230e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0696e-04 - val_loss: 4.1065e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0026e-04 - val_loss: 4.7698e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1023e-04 - val_loss: 3.6793e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2203e-04 - val_loss: 5.9911e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9159e-04 - val_loss: 7.1295e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 3.4362e-04 - val_loss: 5.4804e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9900e-04 - val_loss: 4.4558e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4208e-04 - val_loss: 9.4496e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 3.1234e-04 - val_loss: 4.9780e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0265e-04 - val_loss: 3.7901e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 2.9845e-04 - val_loss: 3.9279e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9874e-04 - val_loss: 3.9112e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1947e-04 - val_loss: 5.4240e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9762e-04 - val_loss: 4.2682e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2017e-04 - val_loss: 3.7571e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.0688e-04 - val_loss: 3.9400e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.9018e-04 - val_loss: 4.1935e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 2.9983e-04 - val_loss: 5.4084e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.9701e-04 - val_loss: 4.0078e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0467e-04 - val_loss: 3.8458e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8313e-04 - val_loss: 3.9256e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 3.0820e-04 - val_loss: 3.7650e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8706e-04 - val_loss: 3.9204e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9407e-04 - val_loss: 4.7139e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0289e-04 - val_loss: 5.9334e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 3.0407e-04 - val_loss: 3.6718e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8408e-04 - val_loss: 4.3413e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0189e-04 - val_loss: 4.1936e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1563e-04 - val_loss: 4.6051e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9880e-04 - val_loss: 6.1557e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 2.8335e-04 - val_loss: 4.4305e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.7726e-04 - val_loss: 4.2520e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9941e-04 - val_loss: 3.9433e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8244e-04 - val_loss: 3.7836e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9246e-04 - val_loss: 4.4404e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9015e-04 - val_loss: 3.8297e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 2.8628e-04 - val_loss: 4.0244e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 2.8399e-04 - val_loss: 3.6280e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9280e-04 - val_loss: 4.0869e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9340e-04 - val_loss: 5.0651e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8842e-04 - val_loss: 3.9085e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9447e-04 - val_loss: 3.9629e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9763e-04 - val_loss: 3.8070e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 2.9142e-04 - val_loss: 4.7626e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.9196e-04 - val_loss: 4.1827e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8021e-04 - val_loss: 3.7375e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9403e-04 - val_loss: 3.7096e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.9036e-04 - val_loss: 4.3347e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8393e-04 - val_loss: 3.7339e-04\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 907us/step - loss: 2.8702e-04 - val_loss: 3.7379e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.7916e-04 - val_loss: 4.6258e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.7828e-04 - val_loss: 3.7768e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8722e-04 - val_loss: 4.3157e-04\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 2.8342e-04 - val_loss: 4.0567e-04\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 918us/step - loss: 2.7874e-04 - val_loss: 4.8257e-04\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9044e-04 - val_loss: 5.1131e-04\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8693e-04 - val_loss: 3.7627e-04\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.0799e-04 - val_loss: 4.8076e-04\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.7358e-04 - val_loss: 5.3624e-04\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 2.8228e-04 - val_loss: 3.8332e-04\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.8044e-04 - val_loss: 4.4357e-04\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.7694e-04 - val_loss: 3.9168e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_17\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_17\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 852us/step - loss: 3.7233e-04 - val_loss: 5.2978e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2535e-04 - val_loss: 4.6922e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0840e-04 - val_loss: 4.1715e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 783us/step - loss: 2.9901e-04 - val_loss: 4.0873e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 818us/step - loss: 3.1981e-04 - val_loss: 4.0563e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 2.9666e-04 - val_loss: 3.9940e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0322e-04 - val_loss: 3.9337e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2123e-04 - val_loss: 3.9381e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.3007e-04 - val_loss: 4.8388e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 2.9221e-04 - val_loss: 4.4139e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 3.3766e-04 - val_loss: 3.8946e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 935us/step - loss: 3.0309e-04 - val_loss: 4.2032e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 3.1260e-04 - val_loss: 5.3276e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 852us/step - loss: 2.9248e-04 - val_loss: 4.0044e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 2.9539e-04 - val_loss: 3.8898e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 3.0526e-04 - val_loss: 3.7798e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 3.2010e-04 - val_loss: 6.3324e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 3.0141e-04 - val_loss: 5.0344e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 3.2174e-04 - val_loss: 3.7254e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 2.8830e-04 - val_loss: 5.1350e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 3.5959e-04 - val_loss: 3.9084e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.0420e-04 - val_loss: 3.6993e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 3.1884e-04 - val_loss: 3.8378e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.0220e-04 - val_loss: 3.7609e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 2.9829e-04 - val_loss: 3.9058e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 3.0399e-04 - val_loss: 4.0726e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 3.1512e-04 - val_loss: 4.4452e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 2.9816e-04 - val_loss: 4.4069e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 2.9948e-04 - val_loss: 5.1551e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.1644e-04 - val_loss: 4.6326e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 3.0980e-04 - val_loss: 3.9001e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 2.9308e-04 - val_loss: 4.3788e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 3.0286e-04 - val_loss: 6.3667e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.0531e-04 - val_loss: 5.1683e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 3.1072e-04 - val_loss: 3.8931e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 2.9309e-04 - val_loss: 3.9478e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1035e-04 - val_loss: 4.8641e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9618e-04 - val_loss: 3.8925e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0441e-04 - val_loss: 4.3357e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9710e-04 - val_loss: 4.6054e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0269e-04 - val_loss: 4.6658e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1368e-04 - val_loss: 4.2716e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1059e-04 - val_loss: 3.8465e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8366e-04 - val_loss: 4.1913e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9475e-04 - val_loss: 4.9024e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8689e-04 - val_loss: 4.0858e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_18\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_18\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0017 - val_loss: 4.0673e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.6638e-04 - val_loss: 4.0978e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.7198e-04 - val_loss: 9.2204e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.8704e-04 - val_loss: 4.5758e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 750us/step - loss: 3.7246e-04 - val_loss: 6.0789e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4173e-04 - val_loss: 3.7290e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.5115e-04 - val_loss: 6.6034e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2995e-04 - val_loss: 4.0140e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.6617e-04 - val_loss: 4.1182e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.5269e-04 - val_loss: 3.9643e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1836e-04 - val_loss: 5.1983e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2390e-04 - val_loss: 4.6163e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 3.2726e-04 - val_loss: 5.6771e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2898e-04 - val_loss: 3.8754e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3607e-04 - val_loss: 4.5801e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2075e-04 - val_loss: 3.8590e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2420e-04 - val_loss: 3.9615e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0962e-04 - val_loss: 3.7907e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0069e-04 - val_loss: 4.4465e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 789us/step - loss: 3.2215e-04 - val_loss: 6.0244e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 768us/step - loss: 3.0793e-04 - val_loss: 4.2462e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9536e-04 - val_loss: 3.7751e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.3061e-04 - val_loss: 7.5298e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1957e-04 - val_loss: 5.9715e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9097e-04 - val_loss: 4.7835e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.1957e-04 - val_loss: 5.2718e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1231e-04 - val_loss: 5.8332e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.1836e-04 - val_loss: 4.0838e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9488e-04 - val_loss: 3.7885e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1231e-04 - val_loss: 9.9098e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0129 - val_loss: 0.0023\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2647e-04 - val_loss: 0.0016\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1165e-04 - val_loss: 0.0012\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9798e-04 - val_loss: 7.5392e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9658e-04 - val_loss: 4.5799e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9396e-04 - val_loss: 5.0893e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9489e-04 - val_loss: 3.9199e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9615e-04 - val_loss: 3.6659e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9306e-04 - val_loss: 3.8444e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0103e-04 - val_loss: 8.1816e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0799e-04 - val_loss: 3.8375e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0124e-04 - val_loss: 3.6983e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2642e-04 - val_loss: 3.6744e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0496e-04 - val_loss: 6.8290e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1882e-04 - val_loss: 3.7728e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1201e-04 - val_loss: 3.7020e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1163e-04 - val_loss: 3.8898e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0796e-04 - val_loss: 3.7632e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0574e-04 - val_loss: 4.5438e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1171e-04 - val_loss: 5.2507e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1990e-04 - val_loss: 4.0182e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0755e-04 - val_loss: 4.3835e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0527e-04 - val_loss: 9.1900e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 3.2579e-04 - val_loss: 5.0217e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1384e-04 - val_loss: 4.1261e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1820e-04 - val_loss: 3.9960e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1897e-04 - val_loss: 4.2938e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1858e-04 - val_loss: 4.0268e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1224e-04 - val_loss: 5.2153e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0470e-04 - val_loss: 5.3275e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9559e-04 - val_loss: 6.4470e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2462e-04 - val_loss: 3.7247e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_20\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_20\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4416e-04 - val_loss: 0.0021\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1892e-04 - val_loss: 6.5552e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9945e-04 - val_loss: 7.5354e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0980e-04 - val_loss: 7.3078e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9597e-04 - val_loss: 5.1864e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1405e-04 - val_loss: 4.1566e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2979e-04 - val_loss: 4.5413e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 744us/step - loss: 3.0912e-04 - val_loss: 0.0011\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.7306e-04 - val_loss: 0.0013\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2271e-04 - val_loss: 4.6355e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 3.1447e-04 - val_loss: 4.0943e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9724e-04 - val_loss: 4.8131e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2904e-04 - val_loss: 4.1596e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0015e-04 - val_loss: 3.9616e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2587e-04 - val_loss: 3.9873e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.0065e-04 - val_loss: 3.7911e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1342e-04 - val_loss: 4.0300e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0093e-04 - val_loss: 7.0843e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2620e-04 - val_loss: 5.5149e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1087e-04 - val_loss: 4.1396e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1397e-04 - val_loss: 6.1283e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.9376e-04 - val_loss: 5.7767e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9601e-04 - val_loss: 4.5370e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0305e-04 - val_loss: 5.8678e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 3.0081e-04 - val_loss: 4.8302e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9729e-04 - val_loss: 7.3708e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1170e-04 - val_loss: 5.7296e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9241e-04 - val_loss: 6.8596e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9594e-04 - val_loss: 3.8635e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0171e-04 - val_loss: 4.0272e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9867e-04 - val_loss: 8.4552e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8631e-04 - val_loss: 3.8604e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0836e-04 - val_loss: 4.8562e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0700e-04 - val_loss: 4.1709e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8155e-04 - val_loss: 4.2216e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9432e-04 - val_loss: 4.1633e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2815e-04 - val_loss: 5.5790e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9438e-04 - val_loss: 4.5253e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0226e-04 - val_loss: 3.9358e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8935e-04 - val_loss: 4.0830e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0019 - val_loss: 7.5992e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1124e-04 - val_loss: 3.7596e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0940e-04 - val_loss: 4.0238e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1095e-04 - val_loss: 3.9393e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1308e-04 - val_loss: 3.7005e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0710e-04 - val_loss: 3.7065e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2479e-04 - val_loss: 4.0298e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3401e-04 - val_loss: 3.7144e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2949e-04 - val_loss: 4.0689e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1378e-04 - val_loss: 3.5834e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1006e-04 - val_loss: 3.6168e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0807e-04 - val_loss: 4.4558e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8583e-04 - val_loss: 6.1260e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1082e-04 - val_loss: 3.9428e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3028e-04 - val_loss: 4.1368e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0494e-04 - val_loss: 6.6476e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0908e-04 - val_loss: 3.7878e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1830e-04 - val_loss: 3.9481e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0509e-04 - val_loss: 4.0256e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1094e-04 - val_loss: 3.8641e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0228e-04 - val_loss: 3.8355e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0593e-04 - val_loss: 4.3958e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0450e-04 - val_loss: 4.6125e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1860e-04 - val_loss: 3.6111e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0809e-04 - val_loss: 3.7604e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0824e-04 - val_loss: 3.7991e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0892e-04 - val_loss: 3.9418e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1180e-04 - val_loss: 3.6201e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0154e-04 - val_loss: 3.6844e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2302e-04 - val_loss: 6.9057e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3252e-04 - val_loss: 3.6370e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9760e-04 - val_loss: 4.1203e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9696e-04 - val_loss: 3.8550e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9786e-04 - val_loss: 4.6705e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_22\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_22\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0029 - val_loss: 6.0073e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1407e-04 - val_loss: 4.2088e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1095e-04 - val_loss: 3.6107e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0601e-04 - val_loss: 3.7017e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0960e-04 - val_loss: 6.1917e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.5048e-04 - val_loss: 3.6129e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 3.3427e-04 - val_loss: 3.8264e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 3.0758e-04 - val_loss: 4.8207e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 3.2052e-04 - val_loss: 6.2302e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 3.2604e-04 - val_loss: 5.6232e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 813us/step - loss: 3.6542e-04 - val_loss: 6.5893e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3812e-04 - val_loss: 3.8354e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.4393e-04 - val_loss: 3.7983e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2640e-04 - val_loss: 4.5612e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.9710e-04 - val_loss: 3.9201e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.9069e-04 - val_loss: 4.2289e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0829e-04 - val_loss: 3.7504e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.2786e-04 - val_loss: 0.0013\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 3.2135e-04 - val_loss: 5.1525e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3191e-04 - val_loss: 4.3415e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1330e-04 - val_loss: 4.6682e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9879e-04 - val_loss: 4.5249e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2300e-04 - val_loss: 4.0841e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9136e-04 - val_loss: 5.2826e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0088e-04 - val_loss: 6.6032e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9132e-04 - val_loss: 5.3096e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2263e-04 - val_loss: 3.8097e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_23\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_23\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0083 - val_loss: 0.0010\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9529e-04 - val_loss: 5.9195e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9064e-04 - val_loss: 6.0352e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9585e-04 - val_loss: 5.5009e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9887e-04 - val_loss: 3.8150e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9822e-04 - val_loss: 4.0087e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0418e-04 - val_loss: 4.4697e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2162e-04 - val_loss: 5.6099e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1443e-04 - val_loss: 3.7749e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9976e-04 - val_loss: 5.7891e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1167e-04 - val_loss: 4.2856e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0266e-04 - val_loss: 3.9377e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2429e-04 - val_loss: 4.2769e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1317e-04 - val_loss: 3.7726e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9707e-04 - val_loss: 5.6976e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9479e-04 - val_loss: 3.9115e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0798e-04 - val_loss: 5.0059e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2767e-04 - val_loss: 4.7373e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0228e-04 - val_loss: 3.8477e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0926e-04 - val_loss: 4.2970e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9668e-04 - val_loss: 4.6849e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0833e-04 - val_loss: 3.8529e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9440e-04 - val_loss: 5.1824e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.1597e-04 - val_loss: 4.1058e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0827e-04 - val_loss: 5.6488e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1364e-04 - val_loss: 4.2371e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0071e-04 - val_loss: 4.9500e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0490e-04 - val_loss: 3.8018e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1056e-04 - val_loss: 5.0613e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2060e-04 - val_loss: 3.8958e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.1244e-04 - val_loss: 3.8416e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1396e-04 - val_loss: 3.9662e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0632e-04 - val_loss: 5.6737e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0951e-04 - val_loss: 4.9723e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0464e-04 - val_loss: 3.6776e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9737e-04 - val_loss: 4.9763e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0373e-04 - val_loss: 3.9433e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 3.1203e-04 - val_loss: 5.5031e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9492e-04 - val_loss: 5.2843e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8623e-04 - val_loss: 3.7853e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9391e-04 - val_loss: 3.7994e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3703e-04 - val_loss: 3.7710e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9241e-04 - val_loss: 6.7251e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 3.4734e-04 - val_loss: 4.1866e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1699e-04 - val_loss: 7.5953e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0927e-04 - val_loss: 4.4196e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9930e-04 - val_loss: 6.4959e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0393e-04 - val_loss: 4.2037e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1734e-04 - val_loss: 9.7071e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0448e-04 - val_loss: 6.1160e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0743e-04 - val_loss: 4.1379e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0670e-04 - val_loss: 4.3315e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9114e-04 - val_loss: 3.7276e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7902e-04 - val_loss: 7.5327e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 2.8652e-04 - val_loss: 4.3457e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8761e-04 - val_loss: 4.0536e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9612e-04 - val_loss: 3.5941e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.8303e-04 - val_loss: 3.9700e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 3.0647e-04 - val_loss: 4.0746e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9442e-04 - val_loss: 6.7087e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9491e-04 - val_loss: 5.1798e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9436e-04 - val_loss: 5.8654e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0543e-04 - val_loss: 4.1888e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8241e-04 - val_loss: 4.9789e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.9066e-04 - val_loss: 3.7528e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8578e-04 - val_loss: 4.0161e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9721e-04 - val_loss: 4.2380e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8689e-04 - val_loss: 3.9315e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 3.0598e-04 - val_loss: 3.7519e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.8792e-04 - val_loss: 4.2679e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8818e-04 - val_loss: 3.6810e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8930e-04 - val_loss: 4.2703e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9361e-04 - val_loss: 4.1124e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8122e-04 - val_loss: 4.5454e-04\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8019e-04 - val_loss: 3.8614e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8734e-04 - val_loss: 4.1867e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9193e-04 - val_loss: 3.7491e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8252e-04 - val_loss: 4.2423e-04\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8765e-04 - val_loss: 3.8996e-04\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8215e-04 - val_loss: 3.9244e-04\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9405e-04 - val_loss: 3.9608e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_24\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_24\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3305e-04 - val_loss: 8.8559e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.6201e-04 - val_loss: 5.6207e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4691e-04 - val_loss: 5.7159e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1913e-04 - val_loss: 6.7278e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.5492e-04 - val_loss: 5.4274e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.4835e-04 - val_loss: 4.1888e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3299e-04 - val_loss: 3.6116e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3305e-04 - val_loss: 4.2569e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2329e-04 - val_loss: 5.5473e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2395e-04 - val_loss: 3.9819e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0109e-04 - val_loss: 4.9330e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 2.9348e-04 - val_loss: 4.2079e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0066e-04 - val_loss: 5.2015e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1256e-04 - val_loss: 4.0773e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9380e-04 - val_loss: 3.7153e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2707e-04 - val_loss: 6.0592e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.1235e-04 - val_loss: 5.3733e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2397e-04 - val_loss: 4.1920e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9244e-04 - val_loss: 4.9102e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1048e-04 - val_loss: 3.7993e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9785e-04 - val_loss: 4.1644e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9981e-04 - val_loss: 3.8661e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 2.7808e-04 - val_loss: 3.7166e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 962us/step - loss: 3.1424e-04 - val_loss: 3.7536e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 859us/step - loss: 3.0028e-04 - val_loss: 3.9926e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 834us/step - loss: 2.9085e-04 - val_loss: 4.0078e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 3.0436e-04 - val_loss: 3.8104e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 3.0736e-04 - val_loss: 4.0493e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 852us/step - loss: 3.1952e-04 - val_loss: 6.0134e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 874us/step - loss: 2.9843e-04 - val_loss: 4.1101e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 2.9313e-04 - val_loss: 4.0163e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0041 - val_loss: 5.5178e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.9572e-04 - val_loss: 4.7161e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0136e-04 - val_loss: 4.5172e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0309e-04 - val_loss: 4.0971e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1601e-04 - val_loss: 3.9677e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1895e-04 - val_loss: 4.3248e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3199e-04 - val_loss: 4.3634e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 774us/step - loss: 3.3106e-04 - val_loss: 3.9646e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3981e-04 - val_loss: 4.3051e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4357e-04 - val_loss: 4.2971e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.5078e-04 - val_loss: 5.2036e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1801e-04 - val_loss: 6.4549e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1876e-04 - val_loss: 4.4337e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1939e-04 - val_loss: 8.5610e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1594e-04 - val_loss: 3.7458e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1796e-04 - val_loss: 3.7664e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1168e-04 - val_loss: 4.4613e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.1139e-04 - val_loss: 3.8618e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1691e-04 - val_loss: 3.8753e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1068e-04 - val_loss: 4.2045e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9495e-04 - val_loss: 3.8889e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.1092e-04 - val_loss: 4.0896e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1202e-04 - val_loss: 4.2551e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0715e-04 - val_loss: 5.2863e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0046e-04 - val_loss: 5.3924e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1096e-04 - val_loss: 6.7802e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0457e-04 - val_loss: 4.1802e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9358e-04 - val_loss: 4.1119e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0382e-04 - val_loss: 4.9474e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.9945e-04 - val_loss: 3.7831e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1759e-04 - val_loss: 3.7658e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3824e-04 - val_loss: 4.4681e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9506e-04 - val_loss: 4.3701e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0459e-04 - val_loss: 3.8932e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8773e-04 - val_loss: 3.9449e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0688e-04 - val_loss: 3.8645e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8966e-04 - val_loss: 5.7775e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0217e-04 - val_loss: 4.9589e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0071e-04 - val_loss: 4.0692e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_26\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_26\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.6913e-04 - val_loss: 0.0014\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4713e-04 - val_loss: 5.7593e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.0845e-04 - val_loss: 3.8523e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4805e-04 - val_loss: 3.7572e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.6017e-04 - val_loss: 9.9010e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4739e-04 - val_loss: 6.2829e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2789e-04 - val_loss: 3.6629e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4169e-04 - val_loss: 6.0759e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4037e-04 - val_loss: 4.8187e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.6833e-04 - val_loss: 6.0014e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.4144e-04 - val_loss: 5.0200e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 757us/step - loss: 3.4387e-04 - val_loss: 7.6360e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1076e-04 - val_loss: 5.4009e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 798us/step - loss: 3.0368e-04 - val_loss: 7.1862e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 3.2697e-04 - val_loss: 4.0039e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.0832e-04 - val_loss: 3.8158e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0966e-04 - val_loss: 3.6818e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 2.7681e-04 - val_loss: 4.3669e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.1022e-04 - val_loss: 5.4872e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.2148e-04 - val_loss: 5.7008e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 3.1748e-04 - val_loss: 4.4031e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3404e-04 - val_loss: 4.8950e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0180e-04 - val_loss: 4.0585e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1080e-04 - val_loss: 4.5875e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 754us/step - loss: 3.0647e-04 - val_loss: 4.0001e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 3.0985e-04 - val_loss: 4.0355e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 2.9727e-04 - val_loss: 4.2604e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1338e-04 - val_loss: 3.8885e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8447e-04 - val_loss: 3.7824e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9245e-04 - val_loss: 4.0214e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0485e-04 - val_loss: 4.1775e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_27\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_27\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0037 - val_loss: 9.2557e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.3499e-04 - val_loss: 4.9621e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.3471e-04 - val_loss: 4.4146e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2163e-04 - val_loss: 3.9427e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2106e-04 - val_loss: 3.7430e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1231e-04 - val_loss: 4.6755e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3868e-04 - val_loss: 5.2649e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1645e-04 - val_loss: 4.0346e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4601e-04 - val_loss: 3.7096e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3685e-04 - val_loss: 7.1110e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3486e-04 - val_loss: 3.8692e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.6198e-04 - val_loss: 5.3364e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0838e-04 - val_loss: 5.9929e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.3746e-04 - val_loss: 3.9065e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0342e-04 - val_loss: 3.8643e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9647e-04 - val_loss: 3.6319e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.5843e-04 - val_loss: 4.8476e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.1705e-04 - val_loss: 7.8613e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3558e-04 - val_loss: 6.5668e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0509e-04 - val_loss: 5.3777e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9768e-04 - val_loss: 4.5168e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0940e-04 - val_loss: 3.7076e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2389e-04 - val_loss: 3.8255e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8656e-04 - val_loss: 4.8586e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1163e-04 - val_loss: 4.7201e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9871e-04 - val_loss: 3.9070e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1405e-04 - val_loss: 4.5809e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0802e-04 - val_loss: 5.2212e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9530e-04 - val_loss: 4.4067e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2459e-04 - val_loss: 4.8370e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9920e-04 - val_loss: 3.7102e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2165e-04 - val_loss: 4.0046e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9629e-04 - val_loss: 3.9872e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2093e-04 - val_loss: 4.0726e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1503e-04 - val_loss: 4.0236e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9995e-04 - val_loss: 4.7722e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0457e-04 - val_loss: 3.6575e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 3.2916e-04 - val_loss: 3.9100e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2364e-04 - val_loss: 4.0162e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1783e-04 - val_loss: 3.9416e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_28\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_28\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0025 - val_loss: 8.0047e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 3.1572e-04 - val_loss: 4.8359e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.9883e-04 - val_loss: 3.9377e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0536e-04 - val_loss: 3.7728e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.1816e-04 - val_loss: 4.3410e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1806e-04 - val_loss: 3.8184e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1795e-04 - val_loss: 3.8472e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9456e-04 - val_loss: 4.1745e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9243e-04 - val_loss: 4.6404e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2041e-04 - val_loss: 4.6009e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0989e-04 - val_loss: 3.9458e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 3.1457e-04 - val_loss: 3.7688e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 3.3627e-04 - val_loss: 4.4148e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0617e-04 - val_loss: 3.9665e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 3.2713e-04 - val_loss: 4.6521e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9888e-04 - val_loss: 5.0308e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1752e-04 - val_loss: 4.1960e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8684e-04 - val_loss: 3.7230e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0032e-04 - val_loss: 3.6870e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9114e-04 - val_loss: 3.7529e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3243e-04 - val_loss: 5.0098e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9794e-04 - val_loss: 3.6604e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3011e-04 - val_loss: 5.9906e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2633e-04 - val_loss: 3.8537e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0030e-04 - val_loss: 4.0957e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9159e-04 - val_loss: 3.8072e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9888e-04 - val_loss: 3.9170e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9865e-04 - val_loss: 4.7611e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0436e-04 - val_loss: 3.9422e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2229e-04 - val_loss: 6.7198e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3974e-04 - val_loss: 3.9389e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1210e-04 - val_loss: 3.6785e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0413e-04 - val_loss: 3.8229e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9424e-04 - val_loss: 4.3322e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9305e-04 - val_loss: 4.4993e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0002e-04 - val_loss: 3.7604e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8793e-04 - val_loss: 3.9070e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0893e-04 - val_loss: 3.8825e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7704e-04 - val_loss: 4.7481e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9059e-04 - val_loss: 3.6716e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0476e-04 - val_loss: 5.1086e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9724e-04 - val_loss: 5.1145e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8635e-04 - val_loss: 5.4400e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8499e-04 - val_loss: 3.7286e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8597e-04 - val_loss: 3.9178e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.8405e-04 - val_loss: 3.6582e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8113e-04 - val_loss: 3.7655e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8760e-04 - val_loss: 3.5622e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9001e-04 - val_loss: 3.6750e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1269e-04 - val_loss: 5.2502e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0890e-04 - val_loss: 3.6306e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8161e-04 - val_loss: 3.6766e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7626e-04 - val_loss: 3.6129e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9746e-04 - val_loss: 4.6366e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0969e-04 - val_loss: 3.6514e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9020e-04 - val_loss: 3.9341e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8579e-04 - val_loss: 4.1931e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8109e-04 - val_loss: 3.7283e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8484e-04 - val_loss: 5.4693e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9627e-04 - val_loss: 3.8591e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9041e-04 - val_loss: 3.7189e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9407e-04 - val_loss: 3.6926e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7625e-04 - val_loss: 3.9800e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7868e-04 - val_loss: 4.2498e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8456e-04 - val_loss: 3.7736e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8739e-04 - val_loss: 3.8047e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8180e-04 - val_loss: 3.9262e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.7480e-04 - val_loss: 3.7483e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8453e-04 - val_loss: 4.0326e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8537e-04 - val_loss: 4.0296e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8527e-04 - val_loss: 3.7251e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.7560e-04 - val_loss: 3.9535e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_29\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_29\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0016 - val_loss: 6.9769e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3363e-04 - val_loss: 4.2376e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1715e-04 - val_loss: 3.8773e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2964e-04 - val_loss: 3.7433e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.4079e-04 - val_loss: 3.8862e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.2172e-04 - val_loss: 7.1362e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1768e-04 - val_loss: 0.0011\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.3179e-04 - val_loss: 3.8409e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0993e-04 - val_loss: 8.6264e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0166e-04 - val_loss: 5.6909e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 3.0777e-04 - val_loss: 3.7304e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0950e-04 - val_loss: 5.2526e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2119e-04 - val_loss: 6.1625e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0331e-04 - val_loss: 4.7329e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2950e-04 - val_loss: 4.0069e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1684e-04 - val_loss: 3.7912e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 778us/step - loss: 3.1635e-04 - val_loss: 8.8695e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9281e-04 - val_loss: 5.1285e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1301e-04 - val_loss: 3.7985e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8511e-04 - val_loss: 4.5441e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9518e-04 - val_loss: 4.1827e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9405e-04 - val_loss: 4.1132e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0994e-04 - val_loss: 4.2531e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9243e-04 - val_loss: 5.0439e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.8894e-04 - val_loss: 3.9840e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9997e-04 - val_loss: 4.5369e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9090e-04 - val_loss: 4.3785e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1436e-04 - val_loss: 3.5680e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9452e-04 - val_loss: 4.6290e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2396e-04 - val_loss: 4.6827e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2220e-04 - val_loss: 3.7226e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.7879e-04 - val_loss: 5.3640e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1564e-04 - val_loss: 5.0280e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9647e-04 - val_loss: 3.8843e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9018e-04 - val_loss: 3.5906e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1585e-04 - val_loss: 3.6431e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8461e-04 - val_loss: 3.8343e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9545e-04 - val_loss: 6.3371e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1872e-04 - val_loss: 3.8496e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.8524e-04 - val_loss: 3.8634e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9168e-04 - val_loss: 5.5266e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0560e-04 - val_loss: 4.0113e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9314e-04 - val_loss: 5.7859e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9686e-04 - val_loss: 4.0808e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8518e-04 - val_loss: 3.7018e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1249e-04 - val_loss: 4.3508e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9080e-04 - val_loss: 3.8373e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9672e-04 - val_loss: 4.2019e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8016e-04 - val_loss: 3.8378e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8264e-04 - val_loss: 4.2309e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8962e-04 - val_loss: 3.7971e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1354e-04 - val_loss: 3.7088e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_30\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_30\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.8766e-04 - val_loss: 0.0018\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3413e-04 - val_loss: 4.4748e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2400e-04 - val_loss: 6.1992e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0404e-04 - val_loss: 4.2492e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1393e-04 - val_loss: 7.4467e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1516e-04 - val_loss: 4.1251e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1666e-04 - val_loss: 4.0888e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3028e-04 - val_loss: 4.0361e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.5804e-04 - val_loss: 4.0182e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1003e-04 - val_loss: 4.9704e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.0535e-04 - val_loss: 4.1003e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1183e-04 - val_loss: 4.2730e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 2.9732e-04 - val_loss: 6.6193e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0230e-04 - val_loss: 5.6532e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1830e-04 - val_loss: 4.0569e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1459e-04 - val_loss: 4.1732e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1974e-04 - val_loss: 4.5422e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1155e-04 - val_loss: 3.9652e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0326e-04 - val_loss: 6.8789e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0643e-04 - val_loss: 4.9715e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2731e-04 - val_loss: 6.3328e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1371e-04 - val_loss: 5.7893e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2520e-04 - val_loss: 6.4766e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0087e-04 - val_loss: 4.2145e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0316e-04 - val_loss: 4.7315e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1514e-04 - val_loss: 4.1553e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9158e-04 - val_loss: 4.5764e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9593e-04 - val_loss: 4.0917e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1472e-04 - val_loss: 4.3105e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0573e-04 - val_loss: 4.2539e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9746e-04 - val_loss: 4.3922e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1663e-04 - val_loss: 4.9710e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1131e-04 - val_loss: 6.6343e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9130e-04 - val_loss: 3.9779e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9326e-04 - val_loss: 3.7063e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2622e-04 - val_loss: 4.1503e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0321e-04 - val_loss: 4.4573e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1082e-04 - val_loss: 6.1459e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0119e-04 - val_loss: 6.2989e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9857e-04 - val_loss: 4.0975e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1382e-04 - val_loss: 3.7303e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9448e-04 - val_loss: 4.2407e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9146e-04 - val_loss: 4.3366e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9413e-04 - val_loss: 4.6069e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.8568e-04 - val_loss: 4.7347e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.1285e-04 - val_loss: 5.1093e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9236e-04 - val_loss: 3.9035e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9199e-04 - val_loss: 3.8200e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9818e-04 - val_loss: 5.0155e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0737e-04 - val_loss: 4.8384e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0018e-04 - val_loss: 5.7372e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.7628e-04 - val_loss: 3.8422e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9863e-04 - val_loss: 3.7593e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8272e-04 - val_loss: 4.2576e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 874us/step - loss: 3.0382e-04 - val_loss: 3.7790e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9328e-04 - val_loss: 3.9290e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9990e-04 - val_loss: 4.1497e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9267e-04 - val_loss: 4.5557e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.7561e-04 - val_loss: 4.4876e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_31\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_31\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0112 - val_loss: 0.0021\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.3339e-04 - val_loss: 8.5037e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9249e-04 - val_loss: 5.5099e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8363e-04 - val_loss: 4.5790e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9372e-04 - val_loss: 4.3153e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9071e-04 - val_loss: 7.9231e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9367e-04 - val_loss: 4.3831e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 2.8967e-04 - val_loss: 3.7304e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 2.8840e-04 - val_loss: 4.1882e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8608e-04 - val_loss: 4.0243e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8683e-04 - val_loss: 4.0888e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1193e-04 - val_loss: 4.9477e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9363e-04 - val_loss: 4.1542e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0474e-04 - val_loss: 3.9957e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8987e-04 - val_loss: 4.4767e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9635e-04 - val_loss: 4.1869e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9350e-04 - val_loss: 4.7029e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 769us/step - loss: 3.4658e-04 - val_loss: 4.1903e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9923e-04 - val_loss: 5.5346e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 2.9588e-04 - val_loss: 3.9439e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 3.0028e-04 - val_loss: 5.1093e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8630e-04 - val_loss: 3.6894e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9892e-04 - val_loss: 3.8933e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0611e-04 - val_loss: 4.0476e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1605e-04 - val_loss: 5.0931e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0323e-04 - val_loss: 3.8362e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3470e-04 - val_loss: 4.4561e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9824e-04 - val_loss: 3.8081e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0627e-04 - val_loss: 3.8116e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0529e-04 - val_loss: 4.4945e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1337e-04 - val_loss: 4.1327e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9695e-04 - val_loss: 3.9668e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0368e-04 - val_loss: 5.3806e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0496e-04 - val_loss: 3.8074e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4046e-04 - val_loss: 4.7106e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1654e-04 - val_loss: 5.6764e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8956e-04 - val_loss: 3.8667e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9010e-04 - val_loss: 3.6670e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0500e-04 - val_loss: 4.1001e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8089e-04 - val_loss: 4.5314e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9414e-04 - val_loss: 3.9954e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2673e-04 - val_loss: 3.9484e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8524e-04 - val_loss: 3.9630e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0292e-04 - val_loss: 4.5408e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0822e-04 - val_loss: 4.1431e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9919e-04 - val_loss: 3.8699e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0675e-04 - val_loss: 4.4543e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.7760e-04 - val_loss: 4.9297e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9655e-04 - val_loss: 3.9340e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9081e-04 - val_loss: 4.1011e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9124e-04 - val_loss: 4.7232e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0001e-04 - val_loss: 5.4263e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8744e-04 - val_loss: 5.4519e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9866e-04 - val_loss: 3.9199e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9923e-04 - val_loss: 4.1889e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0442e-04 - val_loss: 4.1126e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 907us/step - loss: 3.1277e-04 - val_loss: 5.0693e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8890e-04 - val_loss: 3.7024e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0910e-04 - val_loss: 3.8059e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8440e-04 - val_loss: 3.9948e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9588e-04 - val_loss: 4.4078e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8652e-04 - val_loss: 4.0831e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_32\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0074 - val_loss: 5.3387e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2170e-04 - val_loss: 4.6911e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1928e-04 - val_loss: 4.4061e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.2597e-04 - val_loss: 4.2191e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2983e-04 - val_loss: 4.5067e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1339e-04 - val_loss: 4.2158e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2754e-04 - val_loss: 4.2625e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1202e-04 - val_loss: 4.0404e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1937e-04 - val_loss: 4.5491e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2100e-04 - val_loss: 5.1381e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2893e-04 - val_loss: 3.9076e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1383e-04 - val_loss: 3.8558e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1659e-04 - val_loss: 3.9690e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0869e-04 - val_loss: 5.4029e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2247e-04 - val_loss: 4.1826e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.1925e-04 - val_loss: 3.8254e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1179e-04 - val_loss: 4.5393e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0330e-04 - val_loss: 5.8171e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.1698e-04 - val_loss: 3.7660e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.3558e-04 - val_loss: 3.6949e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 3.4046e-04 - val_loss: 7.5774e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.1236e-04 - val_loss: 4.4761e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1811e-04 - val_loss: 3.7462e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0761e-04 - val_loss: 3.7386e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9637e-04 - val_loss: 4.1689e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3953e-04 - val_loss: 5.4854e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.3962e-04 - val_loss: 3.7914e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1047e-04 - val_loss: 6.4062e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1734e-04 - val_loss: 6.4471e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2530e-04 - val_loss: 4.4838e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3907e-04 - val_loss: 3.7626e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2502e-04 - val_loss: 4.0989e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 2.9241e-04 - val_loss: 3.8621e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.9326e-04 - val_loss: 3.7799e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1548e-04 - val_loss: 3.9182e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1345e-04 - val_loss: 4.1493e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0775e-04 - val_loss: 4.2012e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0182e-04 - val_loss: 4.1021e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0043e-04 - val_loss: 4.1739e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1785e-04 - val_loss: 4.4973e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9194e-04 - val_loss: 5.3225e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2339e-04 - val_loss: 6.0961e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8959e-04 - val_loss: 3.6264e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0154e-04 - val_loss: 6.5393e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9500e-04 - val_loss: 3.5960e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9734e-04 - val_loss: 4.1351e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8356e-04 - val_loss: 3.9311e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9310e-04 - val_loss: 3.7320e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9204e-04 - val_loss: 3.7708e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8370e-04 - val_loss: 4.2030e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8877e-04 - val_loss: 3.6403e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0914e-04 - val_loss: 4.7857e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9442e-04 - val_loss: 4.0234e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9259e-04 - val_loss: 3.8589e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9154e-04 - val_loss: 5.3982e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0971e-04 - val_loss: 7.7041e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8746e-04 - val_loss: 6.0041e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.8888e-04 - val_loss: 3.9956e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 2.8087e-04 - val_loss: 3.5947e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.7650e-04 - val_loss: 5.4139e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 3.0836e-04 - val_loss: 4.5826e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 2.9724e-04 - val_loss: 3.9269e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8524e-04 - val_loss: 4.2997e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 2.9067e-04 - val_loss: 3.7729e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8245e-04 - val_loss: 4.0637e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9401e-04 - val_loss: 4.3397e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8175e-04 - val_loss: 3.7707e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0061e-04 - val_loss: 4.7984e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0838e-04 - val_loss: 4.7356e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0136e-04 - val_loss: 3.7780e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.7789e-04 - val_loss: 3.7998e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8897e-04 - val_loss: 4.2862e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8938e-04 - val_loss: 5.2997e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9404e-04 - val_loss: 4.0841e-04\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0695e-04 - val_loss: 4.2220e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8413e-04 - val_loss: 4.8299e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9546e-04 - val_loss: 3.9708e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8969e-04 - val_loss: 3.8233e-04\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0585e-04 - val_loss: 4.5816e-04\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9282e-04 - val_loss: 4.5408e-04\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9403e-04 - val_loss: 5.7694e-04\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8344e-04 - val_loss: 5.8151e-04\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.7374e-04 - val_loss: 3.8287e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_33\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_33\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 7.0955e-04 - val_loss: 4.8659e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.4077e-04 - val_loss: 6.2700e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.5570e-04 - val_loss: 4.4543e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1782e-04 - val_loss: 3.7050e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0276e-04 - val_loss: 6.2496e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1344e-04 - val_loss: 6.5062e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1727e-04 - val_loss: 6.9725e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2110e-04 - val_loss: 3.9941e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1788e-04 - val_loss: 5.1789e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4245e-04 - val_loss: 6.6454e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 3.1412e-04 - val_loss: 5.0067e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1619e-04 - val_loss: 4.9270e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9985e-04 - val_loss: 3.6873e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0192e-04 - val_loss: 3.6473e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0844e-04 - val_loss: 3.6865e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9000e-04 - val_loss: 3.8510e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0922e-04 - val_loss: 3.8120e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9117e-04 - val_loss: 3.9337e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2181e-04 - val_loss: 3.8328e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.2665e-04 - val_loss: 4.2672e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8288e-04 - val_loss: 4.0227e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3349e-04 - val_loss: 4.8780e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9387e-04 - val_loss: 3.7648e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0193e-04 - val_loss: 3.8728e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 2.9678e-04 - val_loss: 4.2912e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1837e-04 - val_loss: 3.6635e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.5438e-04 - val_loss: 4.2643e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9875e-04 - val_loss: 5.5061e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9707e-04 - val_loss: 4.2429e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.0559e-04 - val_loss: 4.9455e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.9766e-04 - val_loss: 3.8369e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9495e-04 - val_loss: 3.9650e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9245e-04 - val_loss: 7.0796e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8996e-04 - val_loss: 4.6708e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8697e-04 - val_loss: 4.6240e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1162e-04 - val_loss: 3.7829e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8416e-04 - val_loss: 3.8694e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0164e-04 - val_loss: 4.6416e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_34\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_34\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0013\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0787e-04 - val_loss: 8.9999e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8623e-04 - val_loss: 8.4232e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8085e-04 - val_loss: 4.7623e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8262e-04 - val_loss: 5.2609e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.9618e-04 - val_loss: 4.4773e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2629e-04 - val_loss: 4.2784e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3331e-04 - val_loss: 4.4960e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9574e-04 - val_loss: 4.2208e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0720e-04 - val_loss: 3.9381e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1296e-04 - val_loss: 4.3364e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0379e-04 - val_loss: 3.9175e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1738e-04 - val_loss: 4.7759e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3018e-04 - val_loss: 4.0230e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9716e-04 - val_loss: 3.9122e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1229e-04 - val_loss: 4.3194e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.0090e-04 - val_loss: 4.1459e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2362e-04 - val_loss: 4.8363e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0139e-04 - val_loss: 3.9681e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1345e-04 - val_loss: 3.9371e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9508e-04 - val_loss: 4.1647e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2636e-04 - val_loss: 5.5956e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 3.1825e-04 - val_loss: 5.6234e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 3.2836e-04 - val_loss: 4.0070e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.5829e-04 - val_loss: 4.1300e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9361e-04 - val_loss: 3.6857e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0341e-04 - val_loss: 4.4808e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9618e-04 - val_loss: 4.0071e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 3.0673e-04 - val_loss: 4.3341e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0574e-04 - val_loss: 5.3183e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0299e-04 - val_loss: 5.4681e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2180e-04 - val_loss: 3.7742e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0573e-04 - val_loss: 4.0875e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0574e-04 - val_loss: 3.7609e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 2.8442e-04 - val_loss: 5.3002e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9300e-04 - val_loss: 3.9245e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1624e-04 - val_loss: 3.9873e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8931e-04 - val_loss: 3.8122e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9656e-04 - val_loss: 6.4590e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1726e-04 - val_loss: 3.9188e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9003e-04 - val_loss: 4.6526e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9630e-04 - val_loss: 3.8984e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.9180e-04 - val_loss: 5.1281e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1141e-04 - val_loss: 3.7035e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8864e-04 - val_loss: 3.6986e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0836e-04 - val_loss: 4.1636e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8581e-04 - val_loss: 3.9074e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8577e-04 - val_loss: 5.0228e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 3.0233e-04 - val_loss: 4.5942e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9679e-04 - val_loss: 4.5376e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_35\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_35\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0058 - val_loss: 0.0011\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 769us/step - loss: 2.9008e-04 - val_loss: 4.3897e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8395e-04 - val_loss: 3.7479e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8955e-04 - val_loss: 3.8014e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8734e-04 - val_loss: 6.0641e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9668e-04 - val_loss: 3.7311e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2125e-04 - val_loss: 3.7734e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3990e-04 - val_loss: 4.9904e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3698e-04 - val_loss: 5.3825e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0528e-04 - val_loss: 3.8801e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9370e-04 - val_loss: 3.9121e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1485e-04 - val_loss: 6.0831e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1246e-04 - val_loss: 3.9813e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0001e-04 - val_loss: 3.8833e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8747e-04 - val_loss: 5.4654e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9108e-04 - val_loss: 3.7776e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8889e-04 - val_loss: 4.5355e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9611e-04 - val_loss: 4.7469e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0060e-04 - val_loss: 5.0854e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3719e-04 - val_loss: 6.2351e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0857e-04 - val_loss: 4.2072e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8932e-04 - val_loss: 4.5840e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3796e-04 - val_loss: 4.8367e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0646e-04 - val_loss: 4.8988e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0310e-04 - val_loss: 3.9944e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7927e-04 - val_loss: 3.6313e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9778e-04 - val_loss: 3.9102e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0000e-04 - val_loss: 3.8516e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1353e-04 - val_loss: 4.1858e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9289e-04 - val_loss: 3.7720e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0777e-04 - val_loss: 5.3432e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0560e-04 - val_loss: 4.3810e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0050e-04 - val_loss: 3.7285e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9697e-04 - val_loss: 4.0681e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0000e-04 - val_loss: 4.7585e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9345e-04 - val_loss: 3.9177e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1025e-04 - val_loss: 4.2077e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 3.2040e-04 - val_loss: 3.9124e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8645e-04 - val_loss: 4.1650e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.0017e-04 - val_loss: 4.0350e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0555e-04 - val_loss: 6.7548e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2653e-04 - val_loss: 5.0929e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9320e-04 - val_loss: 4.9345e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9836e-04 - val_loss: 4.5564e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9770e-04 - val_loss: 3.7196e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8472e-04 - val_loss: 4.1390e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1398e-04 - val_loss: 3.7337e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9751e-04 - val_loss: 6.4766e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9555e-04 - val_loss: 3.7304e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0354e-04 - val_loss: 4.1258e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_36\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_36\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2977e-04 - val_loss: 9.3029e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 757us/step - loss: 3.0875e-04 - val_loss: 4.4138e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0618e-04 - val_loss: 4.0672e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0410e-04 - val_loss: 5.8300e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.6854e-04 - val_loss: 3.7671e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1656e-04 - val_loss: 4.5138e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.5092e-04 - val_loss: 5.1602e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4032e-04 - val_loss: 3.8225e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2721e-04 - val_loss: 4.8818e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2265e-04 - val_loss: 4.3127e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 3.1939e-04 - val_loss: 3.7842e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0513e-04 - val_loss: 4.2141e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 3.1190e-04 - val_loss: 4.1805e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9915e-04 - val_loss: 6.9290e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.0148e-04 - val_loss: 4.2693e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.1258e-04 - val_loss: 3.9975e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9671e-04 - val_loss: 6.4715e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.8253e-04 - val_loss: 3.6087e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0757e-04 - val_loss: 3.7156e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0152e-04 - val_loss: 4.0724e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 3.0308e-04 - val_loss: 4.2882e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 2.9951e-04 - val_loss: 3.9320e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 2.9833e-04 - val_loss: 3.9930e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9992e-04 - val_loss: 8.5462e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9906e-04 - val_loss: 5.1827e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 769us/step - loss: 3.1720e-04 - val_loss: 4.2553e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1191e-04 - val_loss: 3.9156e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0737e-04 - val_loss: 4.0460e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 769us/step - loss: 2.9576e-04 - val_loss: 3.8481e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8692e-04 - val_loss: 3.8257e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.9455e-04 - val_loss: 3.8789e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9638e-04 - val_loss: 4.1816e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.9894e-04 - val_loss: 8.1477e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0330e-04 - val_loss: 3.8954e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8879e-04 - val_loss: 3.8152e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9443e-04 - val_loss: 6.6396e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8907e-04 - val_loss: 5.7597e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0799e-04 - val_loss: 3.8353e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9991e-04 - val_loss: 5.8832e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0327e-04 - val_loss: 3.8818e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0108e-04 - val_loss: 3.8791e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.8962e-04 - val_loss: 4.6350e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_37\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_37\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0147 - val_loss: 0.0052\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.7423e-04 - val_loss: 0.0034\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3617e-04 - val_loss: 0.0021\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1183e-04 - val_loss: 0.0012\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0601e-04 - val_loss: 0.0010\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8335e-04 - val_loss: 4.8643e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2058e-04 - val_loss: 4.3662e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9750e-04 - val_loss: 5.5884e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9076e-04 - val_loss: 3.9565e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1556e-04 - val_loss: 0.0012\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1860e-04 - val_loss: 4.2368e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1158e-04 - val_loss: 4.4152e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4119e-04 - val_loss: 4.0082e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0360e-04 - val_loss: 3.9788e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1707e-04 - val_loss: 5.2001e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 3.4365e-04 - val_loss: 3.9056e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2046e-04 - val_loss: 4.0682e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9934e-04 - val_loss: 4.3765e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1131e-04 - val_loss: 3.7459e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2464e-04 - val_loss: 4.4388e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1170e-04 - val_loss: 4.3477e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0891e-04 - val_loss: 4.2786e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0199e-04 - val_loss: 4.2535e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1233e-04 - val_loss: 4.5126e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1432e-04 - val_loss: 4.0191e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1460e-04 - val_loss: 5.2068e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1232e-04 - val_loss: 4.4289e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3576e-04 - val_loss: 4.2079e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0985e-04 - val_loss: 4.4318e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2116e-04 - val_loss: 4.7428e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1979e-04 - val_loss: 3.8082e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2433e-04 - val_loss: 4.3701e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9935e-04 - val_loss: 3.8235e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9641e-04 - val_loss: 6.7687e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0652e-04 - val_loss: 4.6913e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0115e-04 - val_loss: 4.4505e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1791e-04 - val_loss: 5.3603e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 729us/step - loss: 2.9014e-04 - val_loss: 7.2898e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8943e-04 - val_loss: 4.1413e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9235e-04 - val_loss: 4.0747e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0577e-04 - val_loss: 4.4849e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8492e-04 - val_loss: 5.3947e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9298e-04 - val_loss: 4.0003e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_38\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_38\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1988e-04 - val_loss: 9.3938e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9144e-04 - val_loss: 7.4092e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8044e-04 - val_loss: 4.0776e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9814e-04 - val_loss: 6.4376e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9557e-04 - val_loss: 4.9332e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8497e-04 - val_loss: 3.9885e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1242e-04 - val_loss: 4.2519e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0445e-04 - val_loss: 4.1623e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8771e-04 - val_loss: 6.7008e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 806us/step - loss: 2.9351e-04 - val_loss: 4.3487e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9747e-04 - val_loss: 3.9542e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.0285e-04 - val_loss: 6.6519e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.0206e-04 - val_loss: 3.7346e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9390e-04 - val_loss: 4.1745e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9138e-04 - val_loss: 4.8980e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 994us/step - loss: 2.8391e-04 - val_loss: 3.8334e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 896us/step - loss: 2.9678e-04 - val_loss: 4.9581e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0904e-04 - val_loss: 6.1412e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0701e-04 - val_loss: 4.8130e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1538e-04 - val_loss: 3.8992e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 3.0681e-04 - val_loss: 4.7697e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0349e-04 - val_loss: 4.1747e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0197e-04 - val_loss: 3.7903e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8884e-04 - val_loss: 4.7153e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0397e-04 - val_loss: 3.7604e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.8766e-04 - val_loss: 3.9213e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.9379e-04 - val_loss: 4.9269e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8015e-04 - val_loss: 3.8693e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8937e-04 - val_loss: 3.9405e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0444e-04 - val_loss: 4.4667e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2121e-04 - val_loss: 3.7343e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0143e-04 - val_loss: 5.1300e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 880us/step - loss: 2.8349e-04 - val_loss: 5.1065e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 924us/step - loss: 2.9210e-04 - val_loss: 3.8830e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0195e-04 - val_loss: 4.0799e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 2.7507e-04 - val_loss: 4.3653e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 913us/step - loss: 3.0341e-04 - val_loss: 3.8967e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8726e-04 - val_loss: 5.3421e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1916e-04 - val_loss: 4.0798e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8750e-04 - val_loss: 5.4010e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9783e-04 - val_loss: 3.8447e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9647e-04 - val_loss: 4.7521e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8529e-04 - val_loss: 4.6619e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9451e-04 - val_loss: 3.9227e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0862e-04 - val_loss: 4.7189e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7789e-04 - val_loss: 3.9234e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9684e-04 - val_loss: 4.5117e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9662e-04 - val_loss: 4.0360e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.7547e-04 - val_loss: 3.9613e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.7960e-04 - val_loss: 3.8069e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0270e-04 - val_loss: 4.5076e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9155e-04 - val_loss: 4.3738e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0685e-04 - val_loss: 3.8456e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.7460e-04 - val_loss: 3.7942e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 2.8373e-04 - val_loss: 3.9791e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_39\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_39\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0093 - val_loss: 0.0012\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.8049e-04 - val_loss: 4.6513e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4018e-04 - val_loss: 6.1374e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.5529e-04 - val_loss: 5.4558e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2414e-04 - val_loss: 5.5901e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1454e-04 - val_loss: 3.7542e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3051e-04 - val_loss: 4.6763e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3319e-04 - val_loss: 7.7547e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 4.0739e-04 - val_loss: 4.4933e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4138e-04 - val_loss: 3.8473e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 3.0783e-04 - val_loss: 4.4021e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1046e-04 - val_loss: 8.0999e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 3.5397e-04 - val_loss: 3.7497e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.2170e-04 - val_loss: 3.6457e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.1346e-04 - val_loss: 3.9074e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 3.1573e-04 - val_loss: 3.9311e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9042e-04 - val_loss: 4.7181e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9937e-04 - val_loss: 7.2554e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2588e-04 - val_loss: 3.9202e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1733e-04 - val_loss: 3.7197e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 754us/step - loss: 2.8832e-04 - val_loss: 4.0976e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9319e-04 - val_loss: 3.8831e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1757e-04 - val_loss: 4.0559e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3011e-04 - val_loss: 8.4596e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0415e-04 - val_loss: 3.9193e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9537e-04 - val_loss: 4.0462e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9668e-04 - val_loss: 4.8396e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1060e-04 - val_loss: 3.7244e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2716e-04 - val_loss: 4.4955e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8618e-04 - val_loss: 5.4538e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0984e-04 - val_loss: 3.8340e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1533e-04 - val_loss: 3.8332e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3570e-04 - val_loss: 4.1027e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0317e-04 - val_loss: 4.0147e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8517e-04 - val_loss: 4.7060e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3204e-04 - val_loss: 9.4296e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1172e-04 - val_loss: 4.2350e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3686e-04 - val_loss: 4.1936e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_40\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_40\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0079 - val_loss: 0.0025\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4279e-04 - val_loss: 6.6383e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1567e-04 - val_loss: 4.0851e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0023e-04 - val_loss: 3.6527e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1975e-04 - val_loss: 4.1216e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2490e-04 - val_loss: 4.0468e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3760e-04 - val_loss: 4.1607e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0667e-04 - val_loss: 7.7236e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4172e-04 - val_loss: 4.6809e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2730e-04 - val_loss: 7.1192e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0917e-04 - val_loss: 3.7955e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2608e-04 - val_loss: 0.0011\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9805e-04 - val_loss: 5.0364e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2452e-04 - val_loss: 4.1564e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.6579e-04 - val_loss: 3.6836e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2918e-04 - val_loss: 3.7169e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.5686e-04 - val_loss: 4.0630e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2222e-04 - val_loss: 6.4846e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1004e-04 - val_loss: 3.7397e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1456e-04 - val_loss: 6.0197e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0316e-04 - val_loss: 4.0799e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2576e-04 - val_loss: 7.1710e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3216e-04 - val_loss: 0.0012\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4369e-04 - val_loss: 5.0561e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3691e-04 - val_loss: 4.1496e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1348e-04 - val_loss: 3.7034e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.9764e-04 - val_loss: 3.7803e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1698e-04 - val_loss: 4.2847e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_41\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_41\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0055 - val_loss: 5.4364e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 3.6723e-04 - val_loss: 5.3670e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 828us/step - loss: 3.6843e-04 - val_loss: 4.1138e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.3921e-04 - val_loss: 7.0116e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.4576e-04 - val_loss: 5.4157e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.0092e-04 - val_loss: 0.0011\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 757us/step - loss: 4.2249e-04 - val_loss: 5.2386e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.6208e-04 - val_loss: 4.2422e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4710e-04 - val_loss: 3.8991e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.7227e-04 - val_loss: 4.3300e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.6279e-04 - val_loss: 4.2978e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.7341e-04 - val_loss: 3.7698e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1882e-04 - val_loss: 3.6714e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.7703e-04 - val_loss: 0.0011\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.7495e-04 - val_loss: 3.9333e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0123e-04 - val_loss: 7.0232e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.3589e-04 - val_loss: 4.4092e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 874us/step - loss: 3.3313e-04 - val_loss: 4.4241e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2698e-04 - val_loss: 7.9520e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 3.2555e-04 - val_loss: 3.6964e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.3758e-04 - val_loss: 4.1543e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 2.9925e-04 - val_loss: 4.2917e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1839e-04 - val_loss: 4.2120e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1029e-04 - val_loss: 4.8793e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 2.9660e-04 - val_loss: 4.7791e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1236e-04 - val_loss: 4.1437e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 3.1135e-04 - val_loss: 3.6532e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.6983e-04 - val_loss: 6.0480e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2599e-04 - val_loss: 3.8585e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0897e-04 - val_loss: 4.3968e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2314e-04 - val_loss: 6.8257e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3002e-04 - val_loss: 3.9189e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8789e-04 - val_loss: 7.1666e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0379e-04 - val_loss: 3.9883e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9177e-04 - val_loss: 4.0870e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9778e-04 - val_loss: 6.1304e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9481e-04 - val_loss: 3.9517e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9958e-04 - val_loss: 4.4393e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0805e-04 - val_loss: 3.9753e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0546e-04 - val_loss: 4.0005e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0825e-04 - val_loss: 3.7857e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9613e-04 - val_loss: 4.1694e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0070e-04 - val_loss: 4.3214e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1523e-04 - val_loss: 4.0796e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0511e-04 - val_loss: 4.3411e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0927e-04 - val_loss: 3.6872e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0133e-04 - val_loss: 3.8767e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.8592e-04 - val_loss: 4.0355e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0379e-04 - val_loss: 4.6135e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9931e-04 - val_loss: 3.9689e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0310e-04 - val_loss: 3.9285e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_42\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_42\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0127 - val_loss: 0.0012\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.1169e-04 - val_loss: 7.5354e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0940e-04 - val_loss: 5.4862e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9743e-04 - val_loss: 6.2363e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2186e-04 - val_loss: 4.0286e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0943e-04 - val_loss: 3.6418e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4745e-04 - val_loss: 6.4506e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2373e-04 - val_loss: 0.0011\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 769us/step - loss: 3.2822e-04 - val_loss: 4.0746e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3595e-04 - val_loss: 3.8120e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.3772e-04 - val_loss: 5.9310e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3289e-04 - val_loss: 4.3620e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1768e-04 - val_loss: 4.7269e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3152e-04 - val_loss: 3.9280e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1570e-04 - val_loss: 4.6815e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2596e-04 - val_loss: 4.9706e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4844e-04 - val_loss: 3.8738e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.5431e-04 - val_loss: 6.8484e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0867e-04 - val_loss: 4.0005e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.8680e-04 - val_loss: 3.6379e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2741e-04 - val_loss: 3.9305e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0624e-04 - val_loss: 3.8282e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2499e-04 - val_loss: 8.4970e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.4069e-04 - val_loss: 3.7072e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1515e-04 - val_loss: 4.0857e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2010e-04 - val_loss: 3.6990e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0769e-04 - val_loss: 4.2031e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.6769e-04 - val_loss: 4.2537e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0663e-04 - val_loss: 4.0127e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1481e-04 - val_loss: 4.2557e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2490e-04 - val_loss: 3.6721e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0308e-04 - val_loss: 3.9459e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1677e-04 - val_loss: 5.0021e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9261e-04 - val_loss: 4.0319e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2273e-04 - val_loss: 3.6757e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1121e-04 - val_loss: 4.2038e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9386e-04 - val_loss: 4.1710e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1874e-04 - val_loss: 4.9914e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9804e-04 - val_loss: 4.0778e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9627e-04 - val_loss: 3.8350e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9525e-04 - val_loss: 4.8517e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9565e-04 - val_loss: 6.0698e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2529e-04 - val_loss: 4.2882e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1275e-04 - val_loss: 5.0227e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_43\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_43\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0075 - val_loss: 8.8988e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2959e-04 - val_loss: 5.8434e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1911e-04 - val_loss: 4.6664e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1981e-04 - val_loss: 4.1289e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9930e-04 - val_loss: 6.0636e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3426e-04 - val_loss: 5.5856e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2400e-04 - val_loss: 3.9052e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1598e-04 - val_loss: 4.2630e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1649e-04 - val_loss: 4.2171e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1147e-04 - val_loss: 3.8890e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9989e-04 - val_loss: 4.1421e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0519e-04 - val_loss: 4.3100e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0927e-04 - val_loss: 4.3409e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4542e-04 - val_loss: 4.5030e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1879e-04 - val_loss: 4.8422e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0552e-04 - val_loss: 3.6575e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9087e-04 - val_loss: 3.7765e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0545e-04 - val_loss: 4.0432e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1675e-04 - val_loss: 4.5005e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0172e-04 - val_loss: 4.0688e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1488e-04 - val_loss: 5.3853e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2152e-04 - val_loss: 5.0155e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9765e-04 - val_loss: 5.0009e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2938e-04 - val_loss: 4.1327e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0674e-04 - val_loss: 4.5145e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0969e-04 - val_loss: 3.8194e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2355e-04 - val_loss: 5.0589e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 745us/step - loss: 3.0812e-04 - val_loss: 4.0808e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9454e-04 - val_loss: 3.7492e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9875e-04 - val_loss: 4.7265e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3232e-04 - val_loss: 4.2309e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9297e-04 - val_loss: 4.4332e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9333e-04 - val_loss: 4.1001e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9756e-04 - val_loss: 3.9203e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0019e-04 - val_loss: 5.5915e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 3.2327e-04 - val_loss: 8.2541e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0688e-04 - val_loss: 4.0042e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0559e-04 - val_loss: 3.6567e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9772e-04 - val_loss: 4.4338e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 2.9903e-04 - val_loss: 3.6456e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9545e-04 - val_loss: 4.3986e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 3.0579e-04 - val_loss: 4.3898e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8797e-04 - val_loss: 4.0186e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0288e-04 - val_loss: 3.9300e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.8428e-04 - val_loss: 4.3823e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 745us/step - loss: 3.1074e-04 - val_loss: 4.3729e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 2.9642e-04 - val_loss: 5.7057e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0197e-04 - val_loss: 4.1688e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0437e-04 - val_loss: 3.7051e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8281e-04 - val_loss: 4.3897e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.1082e-04 - val_loss: 6.0832e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1215e-04 - val_loss: 3.6904e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0096e-04 - val_loss: 3.7885e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8402e-04 - val_loss: 5.2301e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8806e-04 - val_loss: 3.7950e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 2.7989e-04 - val_loss: 4.2154e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8231e-04 - val_loss: 4.3290e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9503e-04 - val_loss: 4.7792e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9019e-04 - val_loss: 3.8506e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.2786e-04 - val_loss: 4.1897e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9052e-04 - val_loss: 4.0477e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.9096e-04 - val_loss: 4.4819e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8416e-04 - val_loss: 5.4098e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.7773e-04 - val_loss: 4.4740e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_44\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_44\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.9520e-04 - val_loss: 8.5027e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4763e-04 - val_loss: 4.5519e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.3167e-04 - val_loss: 7.3861e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.4165e-04 - val_loss: 4.2542e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4141e-04 - val_loss: 3.9718e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3004e-04 - val_loss: 4.5166e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4013e-04 - val_loss: 4.8013e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.5331e-04 - val_loss: 5.2979e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.6057e-04 - val_loss: 4.5949e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4218e-04 - val_loss: 4.0843e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4642e-04 - val_loss: 4.6136e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0150e-04 - val_loss: 4.3025e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3490e-04 - val_loss: 4.1136e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0228e-04 - val_loss: 3.8162e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0961e-04 - val_loss: 3.9930e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.1594e-04 - val_loss: 5.3597e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.0834e-04 - val_loss: 3.9740e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.1632e-04 - val_loss: 4.9375e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.3846e-04 - val_loss: 4.0138e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0913e-04 - val_loss: 4.3080e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 874us/step - loss: 2.9592e-04 - val_loss: 4.2680e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.9767e-04 - val_loss: 3.8988e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 3.3237e-04 - val_loss: 3.7569e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.9281e-04 - val_loss: 4.0654e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2765e-04 - val_loss: 5.5692e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9764e-04 - val_loss: 3.8295e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9669e-04 - val_loss: 5.5350e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 3.1604e-04 - val_loss: 4.2028e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 2.9940e-04 - val_loss: 4.2505e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.9563e-04 - val_loss: 4.6993e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 2.8003e-04 - val_loss: 4.7988e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 3.0387e-04 - val_loss: 3.8114e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 891us/step - loss: 3.1117e-04 - val_loss: 4.0218e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 3.0068e-04 - val_loss: 4.2943e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 3.0073e-04 - val_loss: 4.6421e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 2.9675e-04 - val_loss: 3.8246e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 3.2931e-04 - val_loss: 3.9401e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 2.9063e-04 - val_loss: 3.9406e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 3.1052e-04 - val_loss: 4.2534e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 2.9334e-04 - val_loss: 3.7694e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 2.8230e-04 - val_loss: 3.9792e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 918us/step - loss: 3.0631e-04 - val_loss: 4.1926e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.0238e-04 - val_loss: 3.9003e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 822us/step - loss: 2.9209e-04 - val_loss: 4.2715e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 813us/step - loss: 2.9056e-04 - val_loss: 4.3027e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.1506e-04 - val_loss: 4.8711e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 818us/step - loss: 2.9237e-04 - val_loss: 3.7852e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_45\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_45\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0102 - val_loss: 0.0011\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.4868e-04 - val_loss: 4.2863e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.5241e-04 - val_loss: 7.3593e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 3.4491e-04 - val_loss: 3.6944e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3174e-04 - val_loss: 4.1922e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.5984e-04 - val_loss: 3.9950e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 3.5176e-04 - val_loss: 3.6218e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.6918e-04 - val_loss: 3.7270e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1459e-04 - val_loss: 5.1206e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1498e-04 - val_loss: 5.2479e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.7835e-04 - val_loss: 9.6572e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.6062e-04 - val_loss: 3.8701e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2332e-04 - val_loss: 3.9907e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.5222e-04 - val_loss: 5.6563e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 3.2562e-04 - val_loss: 4.8963e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.6514e-04 - val_loss: 4.8436e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.4680e-04 - val_loss: 3.8983e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1962e-04 - val_loss: 4.2970e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1365e-04 - val_loss: 4.4262e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1475e-04 - val_loss: 3.6834e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3501e-04 - val_loss: 3.7155e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.6812e-04 - val_loss: 5.6550e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3394e-04 - val_loss: 5.4751e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0199e-04 - val_loss: 4.2642e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1825e-04 - val_loss: 3.9265e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0731e-04 - val_loss: 3.7461e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4598e-04 - val_loss: 3.7423e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1039e-04 - val_loss: 5.3509e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0805e-04 - val_loss: 4.3296e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1321e-04 - val_loss: 6.3461e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9532e-04 - val_loss: 3.8624e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_46\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_46\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0029\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.4909e-04 - val_loss: 0.0015\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.3603e-04 - val_loss: 8.7301e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1486e-04 - val_loss: 8.9657e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1245e-04 - val_loss: 4.3955e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1123e-04 - val_loss: 5.9005e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9309e-04 - val_loss: 4.3446e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 2.9920e-04 - val_loss: 3.8674e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 902us/step - loss: 3.1059e-04 - val_loss: 3.9732e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1229e-04 - val_loss: 6.0471e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4834e-04 - val_loss: 4.7134e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.5359e-04 - val_loss: 4.2251e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1113e-04 - val_loss: 5.0969e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3923e-04 - val_loss: 4.7035e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1636e-04 - val_loss: 4.0703e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9358e-04 - val_loss: 4.5011e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2718e-04 - val_loss: 3.9816e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4190e-04 - val_loss: 4.6278e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0797e-04 - val_loss: 3.7960e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1019e-04 - val_loss: 4.3262e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0190e-04 - val_loss: 8.7477e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1861e-04 - val_loss: 4.2255e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3358e-04 - val_loss: 3.8800e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1791e-04 - val_loss: 4.8694e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9906e-04 - val_loss: 3.8836e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9199e-04 - val_loss: 4.5115e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.4044e-04 - val_loss: 3.6371e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1584e-04 - val_loss: 3.6464e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2423e-04 - val_loss: 3.8984e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 755us/step - loss: 2.9268e-04 - val_loss: 3.7261e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0479e-04 - val_loss: 3.8401e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 3.1536e-04 - val_loss: 3.9145e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9264e-04 - val_loss: 5.1550e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0631e-04 - val_loss: 3.7859e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 757us/step - loss: 3.0049e-04 - val_loss: 3.8967e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0713e-04 - val_loss: 4.4116e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1007e-04 - val_loss: 3.6636e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1040e-04 - val_loss: 4.5648e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1053e-04 - val_loss: 4.1146e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2765e-04 - val_loss: 4.3902e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.9651e-04 - val_loss: 4.0363e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.9572e-04 - val_loss: 5.8477e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0612e-04 - val_loss: 6.3357e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0520e-04 - val_loss: 3.8349e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1085e-04 - val_loss: 3.7378e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0923e-04 - val_loss: 4.3355e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9161e-04 - val_loss: 3.8592e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1379e-04 - val_loss: 4.1272e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8456e-04 - val_loss: 4.0315e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1764e-04 - val_loss: 3.8228e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1494e-04 - val_loss: 4.2278e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_47\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_47\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0029 - val_loss: 5.7325e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1465e-04 - val_loss: 5.2957e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2773e-04 - val_loss: 7.7745e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3449e-04 - val_loss: 6.6149e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3872e-04 - val_loss: 4.1191e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4825e-04 - val_loss: 3.9501e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4351e-04 - val_loss: 9.2342e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1998e-04 - val_loss: 4.5562e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 3.3953e-04 - val_loss: 0.0010\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.0217e-04 - val_loss: 4.3175e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2535e-04 - val_loss: 5.8366e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.8533e-04 - val_loss: 4.2668e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.3358e-04 - val_loss: 4.0524e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4895e-04 - val_loss: 4.2716e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0410e-04 - val_loss: 3.8320e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9830e-04 - val_loss: 4.7535e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1697e-04 - val_loss: 4.4616e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4366e-04 - val_loss: 4.1595e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9672e-04 - val_loss: 3.9517e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.5981e-04 - val_loss: 3.9295e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1189e-04 - val_loss: 3.8602e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1052e-04 - val_loss: 3.8044e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2090e-04 - val_loss: 3.7619e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9961e-04 - val_loss: 5.9096e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3994e-04 - val_loss: 7.9548e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.3905e-04 - val_loss: 4.2262e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.3578e-04 - val_loss: 3.9364e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.3630e-04 - val_loss: 4.8135e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0657e-04 - val_loss: 7.0680e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.0461e-04 - val_loss: 4.0941e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1356e-04 - val_loss: 3.7948e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2130e-04 - val_loss: 3.7375e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1057e-04 - val_loss: 3.8499e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0708e-04 - val_loss: 5.7805e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1584e-04 - val_loss: 3.8833e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9372e-04 - val_loss: 5.3727e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1064e-04 - val_loss: 4.4406e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9578e-04 - val_loss: 4.4224e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9982e-04 - val_loss: 3.8049e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1121e-04 - val_loss: 4.0034e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9463e-04 - val_loss: 4.0468e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0428e-04 - val_loss: 3.9297e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1162e-04 - val_loss: 3.7522e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1481e-04 - val_loss: 4.4698e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9714e-04 - val_loss: 3.8774e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8370e-04 - val_loss: 4.4190e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9556e-04 - val_loss: 3.8870e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9695e-04 - val_loss: 4.2006e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1020e-04 - val_loss: 5.8477e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9385e-04 - val_loss: 4.0492e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1170e-04 - val_loss: 4.4087e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0099e-04 - val_loss: 3.7603e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9246e-04 - val_loss: 4.2500e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9896e-04 - val_loss: 4.3541e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 3.0393e-04 - val_loss: 3.8659e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0481e-04 - val_loss: 4.4367e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_48\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.6397e-04 - val_loss: 0.0010\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2385e-04 - val_loss: 6.4043e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2295e-04 - val_loss: 4.6792e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1003e-04 - val_loss: 4.0128e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1031e-04 - val_loss: 3.8852e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1696e-04 - val_loss: 4.1499e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2197e-04 - val_loss: 5.1461e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.4931e-04 - val_loss: 4.1221e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2507e-04 - val_loss: 5.2810e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 869us/step - loss: 3.2694e-04 - val_loss: 4.0384e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1356e-04 - val_loss: 3.8956e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3656e-04 - val_loss: 4.6722e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1331e-04 - val_loss: 5.1440e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3561e-04 - val_loss: 3.9101e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2204e-04 - val_loss: 4.9262e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.4803e-04 - val_loss: 4.7637e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2796e-04 - val_loss: 5.2104e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3520e-04 - val_loss: 5.4060e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2932e-04 - val_loss: 9.6799e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3208e-04 - val_loss: 3.9761e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0359e-04 - val_loss: 4.2514e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1760e-04 - val_loss: 3.8315e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3011e-04 - val_loss: 3.9291e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1857e-04 - val_loss: 4.7101e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1358e-04 - val_loss: 4.1430e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9561e-04 - val_loss: 3.8875e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2358e-04 - val_loss: 3.8781e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9066e-04 - val_loss: 4.0157e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0988e-04 - val_loss: 4.3607e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1626e-04 - val_loss: 4.0152e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1886e-04 - val_loss: 3.9602e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2575e-04 - val_loss: 4.7368e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1009e-04 - val_loss: 4.5532e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2111e-04 - val_loss: 4.2947e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9027e-04 - val_loss: 5.0424e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1009e-04 - val_loss: 3.9334e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9409e-04 - val_loss: 3.9936e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 2.8877e-04 - val_loss: 3.7961e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9477e-04 - val_loss: 6.1182e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9080e-04 - val_loss: 4.8065e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0923e-04 - val_loss: 7.6948e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0067e-04 - val_loss: 5.2621e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9986e-04 - val_loss: 4.1113e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9352e-04 - val_loss: 4.2341e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0408e-04 - val_loss: 5.3632e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0626e-04 - val_loss: 4.6468e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9179e-04 - val_loss: 4.2084e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0671e-04 - val_loss: 4.0958e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3126e-04 - val_loss: 4.7620e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.1412e-04 - val_loss: 3.7493e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9407e-04 - val_loss: 4.0309e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9980e-04 - val_loss: 4.5930e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8571e-04 - val_loss: 7.7709e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1502e-04 - val_loss: 6.0205e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9080e-04 - val_loss: 4.0387e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8317e-04 - val_loss: 3.7630e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1398e-04 - val_loss: 3.8558e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.8878e-04 - val_loss: 3.7079e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8781e-04 - val_loss: 4.3816e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.7924e-04 - val_loss: 3.9744e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9118e-04 - val_loss: 3.9680e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1372e-04 - val_loss: 3.9132e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 2.9481e-04 - val_loss: 4.0593e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 729us/step - loss: 2.7875e-04 - val_loss: 4.0986e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8265e-04 - val_loss: 4.1054e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0431e-04 - val_loss: 3.7601e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.7963e-04 - val_loss: 4.0810e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9195e-04 - val_loss: 3.9971e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9017e-04 - val_loss: 4.0936e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9303e-04 - val_loss: 3.9688e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9309e-04 - val_loss: 3.9080e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.1428e-04 - val_loss: 3.9217e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0356e-04 - val_loss: 4.1580e-04\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0275e-04 - val_loss: 3.9415e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.7808e-04 - val_loss: 3.8199e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 2.8391e-04 - val_loss: 4.3786e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9424e-04 - val_loss: 3.7981e-04\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0025e-04 - val_loss: 3.8192e-04\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8574e-04 - val_loss: 3.8363e-04\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8420e-04 - val_loss: 3.9472e-04\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9312e-04 - val_loss: 5.8693e-04\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8792e-04 - val_loss: 5.3265e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_49\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_49\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.6558e-04 - val_loss: 0.0016\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4211e-04 - val_loss: 8.7953e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.4974e-04 - val_loss: 0.0014\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 3.6846e-04 - val_loss: 4.8823e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3231e-04 - val_loss: 7.4408e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3942e-04 - val_loss: 5.3108e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.7474e-04 - val_loss: 3.6999e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.5015e-04 - val_loss: 6.0827e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.6835e-04 - val_loss: 3.6106e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.6833e-04 - val_loss: 5.2242e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.6854e-04 - val_loss: 3.7412e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.5195e-04 - val_loss: 3.5981e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4891e-04 - val_loss: 5.2587e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1615e-04 - val_loss: 4.6419e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1415e-04 - val_loss: 3.6351e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2748e-04 - val_loss: 4.8966e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2815e-04 - val_loss: 4.0518e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3315e-04 - val_loss: 3.6337e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.5574e-04 - val_loss: 5.9207e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.1041e-04 - val_loss: 3.9777e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4225e-04 - val_loss: 3.6638e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0730e-04 - val_loss: 3.9158e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1756e-04 - val_loss: 3.8742e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1473e-04 - val_loss: 3.6118e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8725e-04 - val_loss: 3.9493e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9671e-04 - val_loss: 6.5831e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0150e-04 - val_loss: 3.6762e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.3811e-04 - val_loss: 7.2963e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0641e-04 - val_loss: 3.6282e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2449e-04 - val_loss: 3.6605e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2954e-04 - val_loss: 3.6370e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8609e-04 - val_loss: 4.3776e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1089e-04 - val_loss: 3.7621e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0193e-04 - val_loss: 6.0814e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9137e-04 - val_loss: 4.8111e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0885e-04 - val_loss: 4.9304e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 4.1410e-04 - val_loss: 0.0032\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 4.0325e-04 - val_loss: 0.0033\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.6145e-04 - val_loss: 0.0023\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.8813e-04 - val_loss: 0.0010\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.7771e-04 - val_loss: 0.0012\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3428e-04 - val_loss: 4.1576e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.4657e-04 - val_loss: 7.5528e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.7631e-04 - val_loss: 6.4347e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.8370e-04 - val_loss: 4.9587e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.9542e-04 - val_loss: 3.8125e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 3.3749e-04 - val_loss: 3.9235e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.4199e-04 - val_loss: 4.9398e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 3.4475e-04 - val_loss: 4.1188e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4062e-04 - val_loss: 3.9427e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 3.4633e-04 - val_loss: 3.8709e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 3.1074e-04 - val_loss: 4.7918e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3559e-04 - val_loss: 3.9851e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0132e-04 - val_loss: 4.1669e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2417e-04 - val_loss: 5.5873e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9139e-04 - val_loss: 3.6844e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2776e-04 - val_loss: 3.9954e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0973e-04 - val_loss: 3.9466e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3943e-04 - val_loss: 4.1890e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1827e-04 - val_loss: 3.7062e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0704e-04 - val_loss: 3.9097e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0575e-04 - val_loss: 5.5251e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2158e-04 - val_loss: 3.9066e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9685e-04 - val_loss: 4.0708e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0244e-04 - val_loss: 5.9530e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9100e-04 - val_loss: 3.9810e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9673e-04 - val_loss: 4.3746e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2173e-04 - val_loss: 4.3009e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9902e-04 - val_loss: 4.0865e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9787e-04 - val_loss: 4.3995e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3120e-04 - val_loss: 4.1803e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0352e-04 - val_loss: 4.5114e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0357e-04 - val_loss: 3.8163e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9407e-04 - val_loss: 4.8484e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8638e-04 - val_loss: 3.9316e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0109e-04 - val_loss: 5.0610e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0098e-04 - val_loss: 3.7478e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8896e-04 - val_loss: 4.3549e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1707e-04 - val_loss: 5.6428e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9566e-04 - val_loss: 4.0477e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_51\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_51\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 6.0963e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9371e-04 - val_loss: 4.2788e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8935e-04 - val_loss: 5.0234e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2689e-04 - val_loss: 3.6803e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0810e-04 - val_loss: 4.2304e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8031e-04 - val_loss: 3.9487e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8556e-04 - val_loss: 3.9124e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1209e-04 - val_loss: 3.9404e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9804e-04 - val_loss: 3.7447e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0655e-04 - val_loss: 4.5296e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2259e-04 - val_loss: 3.9306e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0424e-04 - val_loss: 4.2348e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.8347e-04 - val_loss: 3.6353e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 2.9557e-04 - val_loss: 4.3694e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.1853e-04 - val_loss: 3.6875e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1909e-04 - val_loss: 3.7311e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0608e-04 - val_loss: 4.3855e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0837e-04 - val_loss: 4.0078e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0330e-04 - val_loss: 4.3079e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 3.0911e-04 - val_loss: 3.7133e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.9243e-04 - val_loss: 4.0432e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0455e-04 - val_loss: 3.9089e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.0408e-04 - val_loss: 4.3465e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9142e-04 - val_loss: 4.6821e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9883e-04 - val_loss: 5.3284e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0360e-04 - val_loss: 4.1576e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0524e-04 - val_loss: 3.9228e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9027e-04 - val_loss: 3.8652e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0109e-04 - val_loss: 4.7027e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0030e-04 - val_loss: 4.4877e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 3.0481e-04 - val_loss: 6.1222e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9998e-04 - val_loss: 4.1946e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0563e-04 - val_loss: 4.8284e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9979e-04 - val_loss: 4.6472e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8506e-04 - val_loss: 4.1794e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.7935e-04 - val_loss: 4.1324e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0749e-04 - val_loss: 4.6472e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_52\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.2781e-04 - val_loss: 0.0011\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9645e-04 - val_loss: 5.7728e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1771e-04 - val_loss: 5.6882e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0499e-04 - val_loss: 4.1943e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0844e-04 - val_loss: 4.6029e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9663e-04 - val_loss: 4.0342e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0202e-04 - val_loss: 6.2291e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1949e-04 - val_loss: 4.2421e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.1842e-04 - val_loss: 4.0134e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.1001e-04 - val_loss: 3.7533e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.0263e-04 - val_loss: 6.1914e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2570e-04 - val_loss: 4.2472e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9793e-04 - val_loss: 3.8573e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 3.3262e-04 - val_loss: 4.1867e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0777e-04 - val_loss: 4.7335e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1671e-04 - val_loss: 3.8452e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1223e-04 - val_loss: 6.3959e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.4771e-04 - val_loss: 4.3580e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0084e-04 - val_loss: 4.9143e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9739e-04 - val_loss: 3.9361e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.8362e-04 - val_loss: 4.2917e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0966e-04 - val_loss: 3.9015e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3938e-04 - val_loss: 3.9239e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2684e-04 - val_loss: 4.1867e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9400e-04 - val_loss: 6.7263e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8941e-04 - val_loss: 4.0078e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9147e-04 - val_loss: 3.8046e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9929e-04 - val_loss: 3.8161e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8415e-04 - val_loss: 4.5468e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2113e-04 - val_loss: 3.7640e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0211e-04 - val_loss: 4.3425e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0179e-04 - val_loss: 4.5151e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8737e-04 - val_loss: 4.4463e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9221e-04 - val_loss: 4.8845e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_53\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_53\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0101 - val_loss: 0.0013\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0374e-04 - val_loss: 8.1820e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0957e-04 - val_loss: 6.0236e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 2.9284e-04 - val_loss: 4.6078e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0705e-04 - val_loss: 6.1914e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2078e-04 - val_loss: 5.2089e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1066e-04 - val_loss: 4.2519e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0736e-04 - val_loss: 8.0877e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3102e-04 - val_loss: 5.5880e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1251e-04 - val_loss: 5.1513e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0118e-04 - val_loss: 4.2448e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2072e-04 - val_loss: 4.0229e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2578e-04 - val_loss: 4.6357e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0094e-04 - val_loss: 4.3491e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0283e-04 - val_loss: 4.8136e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4063e-04 - val_loss: 5.7218e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.5975e-04 - val_loss: 5.4306e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1809e-04 - val_loss: 4.7281e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0338e-04 - val_loss: 4.9747e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0284e-04 - val_loss: 5.7172e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0502e-04 - val_loss: 4.1492e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.3847e-04 - val_loss: 7.3754e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3820e-04 - val_loss: 4.3135e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3797e-04 - val_loss: 4.5504e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2922e-04 - val_loss: 5.8314e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0522e-04 - val_loss: 4.0457e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2958e-04 - val_loss: 4.1050e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1098e-04 - val_loss: 3.7724e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9545e-04 - val_loss: 4.3801e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9898e-04 - val_loss: 5.2783e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1023e-04 - val_loss: 4.4364e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1952e-04 - val_loss: 3.7113e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 2.9934e-04 - val_loss: 5.0787e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9914e-04 - val_loss: 3.9423e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9862e-04 - val_loss: 6.5938e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0507e-04 - val_loss: 4.8500e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0181e-04 - val_loss: 4.3906e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0748e-04 - val_loss: 4.4018e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3528e-04 - val_loss: 3.7949e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8750e-04 - val_loss: 3.9576e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9687e-04 - val_loss: 5.2920e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4247e-04 - val_loss: 4.2802e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0357e-04 - val_loss: 4.4294e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0144e-04 - val_loss: 3.9389e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1120e-04 - val_loss: 4.2872e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8577e-04 - val_loss: 5.1546e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1954e-04 - val_loss: 3.7297e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8281e-04 - val_loss: 4.3020e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 2.9848e-04 - val_loss: 4.5858e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9711e-04 - val_loss: 4.0081e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8940e-04 - val_loss: 3.8217e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8972e-04 - val_loss: 4.0203e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.0182e-04 - val_loss: 3.8815e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.9303e-04 - val_loss: 5.0026e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3500e-04 - val_loss: 3.6814e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9452e-04 - val_loss: 7.6050e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2009e-04 - val_loss: 3.7660e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9222e-04 - val_loss: 4.9482e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9142e-04 - val_loss: 3.9428e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9536e-04 - val_loss: 3.7822e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8852e-04 - val_loss: 3.9060e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9125e-04 - val_loss: 3.8654e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9326e-04 - val_loss: 4.1547e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9251e-04 - val_loss: 4.4242e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9181e-04 - val_loss: 3.8042e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9236e-04 - val_loss: 4.4178e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 2.8219e-04 - val_loss: 4.1244e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1373e-04 - val_loss: 4.4320e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.9445e-04 - val_loss: 3.8209e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8402e-04 - val_loss: 3.8914e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9729e-04 - val_loss: 3.9536e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 3.2158e-04 - val_loss: 5.3622e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9990e-04 - val_loss: 4.3325e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7944e-04 - val_loss: 3.7320e-04\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9828e-04 - val_loss: 4.8838e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9550e-04 - val_loss: 5.0655e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8614e-04 - val_loss: 3.8045e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8936e-04 - val_loss: 3.8692e-04\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8064e-04 - val_loss: 4.3302e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_54\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_54\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0059 - val_loss: 8.7204e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2552e-04 - val_loss: 7.9913e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0525e-04 - val_loss: 4.0765e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0780e-04 - val_loss: 4.4117e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0348e-04 - val_loss: 4.1494e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0851e-04 - val_loss: 5.0224e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.5295e-04 - val_loss: 4.6699e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1128e-04 - val_loss: 7.2641e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2143e-04 - val_loss: 5.1460e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.6432e-04 - val_loss: 4.3262e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0188e-04 - val_loss: 4.6233e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.5579e-04 - val_loss: 6.8597e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.4152e-04 - val_loss: 8.1110e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.2679e-04 - val_loss: 4.0144e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.3459e-04 - val_loss: 4.1963e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.5069e-04 - val_loss: 3.9826e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2650e-04 - val_loss: 5.0113e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0042e-04 - val_loss: 3.8878e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9963e-04 - val_loss: 5.4794e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9604e-04 - val_loss: 5.4768e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.2583e-04 - val_loss: 4.6783e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9439e-04 - val_loss: 5.4252e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0747e-04 - val_loss: 4.3894e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0255e-04 - val_loss: 7.0881e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9067e-04 - val_loss: 3.8371e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8750e-04 - val_loss: 4.2926e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9350e-04 - val_loss: 4.1490e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9931e-04 - val_loss: 4.5115e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1632e-04 - val_loss: 4.6944e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9598e-04 - val_loss: 4.6978e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9828e-04 - val_loss: 4.3133e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1479e-04 - val_loss: 3.9870e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9452e-04 - val_loss: 4.1652e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0008e-04 - val_loss: 8.0949e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9987e-04 - val_loss: 4.8093e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9280e-04 - val_loss: 3.8487e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1169e-04 - val_loss: 5.5741e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2596e-04 - val_loss: 3.8265e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3081e-04 - val_loss: 4.1762e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1424e-04 - val_loss: 5.5396e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9671e-04 - val_loss: 3.8699e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1234e-04 - val_loss: 4.4294e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8979e-04 - val_loss: 3.9009e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1310e-04 - val_loss: 3.9051e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0440e-04 - val_loss: 4.1381e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9542e-04 - val_loss: 7.9027e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1123e-04 - val_loss: 4.1472e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7635e-04 - val_loss: 4.4872e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9531e-04 - val_loss: 5.0029e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9942e-04 - val_loss: 3.9185e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9741e-04 - val_loss: 4.6999e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 2.7940e-04 - val_loss: 3.7658e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9091e-04 - val_loss: 4.3559e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9072e-04 - val_loss: 4.1380e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.7968e-04 - val_loss: 4.3521e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8256e-04 - val_loss: 3.9183e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8277e-04 - val_loss: 4.3510e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.7650e-04 - val_loss: 4.3727e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9492e-04 - val_loss: 3.8408e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8972e-04 - val_loss: 4.4530e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9007e-04 - val_loss: 3.9512e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0625e-04 - val_loss: 4.7508e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8666e-04 - val_loss: 4.0288e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 2.9333e-04 - val_loss: 4.1864e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0279e-04 - val_loss: 4.2266e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.9613e-04 - val_loss: 4.2637e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 835us/step - loss: 2.9147e-04 - val_loss: 4.1672e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 2.9215e-04 - val_loss: 4.0387e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7658e-04 - val_loss: 4.2250e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.7898e-04 - val_loss: 3.9982e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9043e-04 - val_loss: 3.8600e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8668e-04 - val_loss: 4.8017e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9760e-04 - val_loss: 3.6743e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8681e-04 - val_loss: 4.0348e-04\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8667e-04 - val_loss: 4.7712e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.9675e-04 - val_loss: 4.4460e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9503e-04 - val_loss: 3.6702e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8498e-04 - val_loss: 4.1641e-04\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.7065e-04 - val_loss: 3.8430e-04\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7941e-04 - val_loss: 4.3023e-04\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.7805e-04 - val_loss: 3.8449e-04\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7796e-04 - val_loss: 3.8192e-04\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 2.7388e-04 - val_loss: 4.0346e-04\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 2.9121e-04 - val_loss: 3.8810e-04\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7734e-04 - val_loss: 4.3453e-04\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 2.8561e-04 - val_loss: 3.9775e-04\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8721e-04 - val_loss: 5.4013e-04\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 2.7485e-04 - val_loss: 4.0856e-04\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9105e-04 - val_loss: 3.7035e-04\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8209e-04 - val_loss: 5.3279e-04\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.8717e-04 - val_loss: 5.0658e-04\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.8759e-04 - val_loss: 4.0517e-04\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.7593e-04 - val_loss: 4.0183e-04\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.7797e-04 - val_loss: 3.9457e-04\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 2.7786e-04 - val_loss: 6.9963e-04\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8106e-04 - val_loss: 3.8853e-04\n",
      "Epoch 97/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7530e-04 - val_loss: 3.8948e-04\n",
      "Epoch 98/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.6729e-04 - val_loss: 3.8874e-04\n",
      "Epoch 99/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.7855e-04 - val_loss: 3.7847e-04\n",
      "Epoch 100/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.7201e-04 - val_loss: 4.1711e-04\n",
      "Epoch 101/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8028e-04 - val_loss: 5.3851e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_55\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_55\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2364e-04 - val_loss: 6.4968e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9226e-04 - val_loss: 0.0012\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1739e-04 - val_loss: 8.1472e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.5160e-04 - val_loss: 3.7602e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2193e-04 - val_loss: 5.0332e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.3410e-04 - val_loss: 4.5140e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1655e-04 - val_loss: 4.5817e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9705e-04 - val_loss: 4.1136e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4477e-04 - val_loss: 4.1935e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.6181e-04 - val_loss: 5.5224e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0100e-04 - val_loss: 4.4312e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1914e-04 - val_loss: 4.0649e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1272e-04 - val_loss: 4.8150e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2607e-04 - val_loss: 5.7809e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8112e-04 - val_loss: 3.9301e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9311e-04 - val_loss: 5.1189e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0723e-04 - val_loss: 5.6512e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2781e-04 - val_loss: 3.6793e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0299e-04 - val_loss: 4.2403e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0086e-04 - val_loss: 4.4532e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0372e-04 - val_loss: 3.8768e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2851e-04 - val_loss: 3.9505e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 3.0462e-04 - val_loss: 4.2422e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 2.9039e-04 - val_loss: 3.8955e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 2.8752e-04 - val_loss: 4.5264e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.1036e-04 - val_loss: 4.3666e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 2.8899e-04 - val_loss: 5.2196e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 3.0233e-04 - val_loss: 4.0826e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 2.9090e-04 - val_loss: 5.7881e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 3.3577e-04 - val_loss: 5.3613e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 3.2973e-04 - val_loss: 4.2487e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 3.0325e-04 - val_loss: 3.7859e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 3.2029e-04 - val_loss: 3.8318e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 2.8240e-04 - val_loss: 3.8880e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 2.9460e-04 - val_loss: 4.3011e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 3.0539e-04 - val_loss: 3.9843e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 2.9486e-04 - val_loss: 4.1450e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 3.1884e-04 - val_loss: 4.2742e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 800us/step - loss: 2.8572e-04 - val_loss: 3.6711e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 2.8914e-04 - val_loss: 4.2910e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 3.0205e-04 - val_loss: 3.7852e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 795us/step - loss: 2.9321e-04 - val_loss: 4.1523e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 2.9412e-04 - val_loss: 4.0315e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 2.9850e-04 - val_loss: 3.9361e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 2.9114e-04 - val_loss: 4.3339e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.7651e-04 - val_loss: 3.9853e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0555e-04 - val_loss: 3.7515e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.7478e-04 - val_loss: 4.9072e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 2.9373e-04 - val_loss: 3.8077e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 2.9143e-04 - val_loss: 4.5074e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 3.1096e-04 - val_loss: 3.8846e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 804us/step - loss: 3.1566e-04 - val_loss: 4.6888e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 3.0138e-04 - val_loss: 4.0302e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 807us/step - loss: 2.7667e-04 - val_loss: 4.3043e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 796us/step - loss: 2.8231e-04 - val_loss: 3.7300e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 2.9258e-04 - val_loss: 4.0139e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 2.9145e-04 - val_loss: 3.7567e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 2.9102e-04 - val_loss: 4.7217e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 2.8032e-04 - val_loss: 3.7529e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 2.7806e-04 - val_loss: 5.1442e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 2.9620e-04 - val_loss: 4.2408e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 852us/step - loss: 2.8052e-04 - val_loss: 4.6911e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 2.8501e-04 - val_loss: 6.0092e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_56\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_56\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.1734e-04 - val_loss: 0.0013\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2650e-04 - val_loss: 6.3386e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2656e-04 - val_loss: 4.5356e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0247e-04 - val_loss: 4.1575e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3392e-04 - val_loss: 4.2192e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.5298e-04 - val_loss: 4.5716e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.3272e-04 - val_loss: 5.1141e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2338e-04 - val_loss: 4.1567e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4225e-04 - val_loss: 5.8215e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.5557e-04 - val_loss: 4.3666e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0816e-04 - val_loss: 3.9941e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9907e-04 - val_loss: 5.0512e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2407e-04 - val_loss: 4.0705e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2102e-04 - val_loss: 5.0727e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2544e-04 - val_loss: 4.3647e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.4713e-04 - val_loss: 7.7048e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0790e-04 - val_loss: 4.0723e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2699e-04 - val_loss: 3.8971e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3908e-04 - val_loss: 4.2167e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.3497e-04 - val_loss: 4.6677e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0855e-04 - val_loss: 9.8914e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0942e-04 - val_loss: 4.1108e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1209e-04 - val_loss: 3.7900e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0708e-04 - val_loss: 3.7615e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9982e-04 - val_loss: 3.9833e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9899e-04 - val_loss: 4.4192e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1571e-04 - val_loss: 4.2382e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0747e-04 - val_loss: 4.1164e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2741e-04 - val_loss: 3.7139e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.4615e-04 - val_loss: 3.9003e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2429e-04 - val_loss: 4.0685e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9014e-04 - val_loss: 3.7236e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 745us/step - loss: 3.1444e-04 - val_loss: 3.7737e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9395e-04 - val_loss: 4.3266e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.2677e-04 - val_loss: 4.2730e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 734us/step - loss: 2.9283e-04 - val_loss: 4.0872e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.8979e-04 - val_loss: 3.9195e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 3.1182e-04 - val_loss: 3.9802e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 3.2576e-04 - val_loss: 4.0104e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9477e-04 - val_loss: 7.9045e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8945e-04 - val_loss: 4.4593e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 2.9767e-04 - val_loss: 4.7208e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.1143e-04 - val_loss: 3.9232e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0147e-04 - val_loss: 3.7941e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9928e-04 - val_loss: 4.3137e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9920e-04 - val_loss: 4.0945e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9863e-04 - val_loss: 4.2406e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9506e-04 - val_loss: 4.2131e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8881e-04 - val_loss: 4.0989e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8227e-04 - val_loss: 4.9372e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0802e-04 - val_loss: 3.9301e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 2.9079e-04 - val_loss: 4.9293e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 738us/step - loss: 2.9761e-04 - val_loss: 4.9968e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_57\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_57\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 3.0423e-04 - val_loss: 3.6027e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1503e-04 - val_loss: 4.0917e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2442e-04 - val_loss: 6.3652e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1864e-04 - val_loss: 4.1011e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2043e-04 - val_loss: 4.9088e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0209e-04 - val_loss: 4.6634e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.1761e-04 - val_loss: 4.6604e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.2984e-04 - val_loss: 7.8546e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.6138e-04 - val_loss: 3.7874e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9745e-04 - val_loss: 3.7831e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.3913e-04 - val_loss: 6.4386e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0239e-04 - val_loss: 4.6672e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0980e-04 - val_loss: 4.0209e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0926e-04 - val_loss: 4.5165e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9544e-04 - val_loss: 3.9381e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9207e-04 - val_loss: 4.2211e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8670e-04 - val_loss: 6.0106e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0974e-04 - val_loss: 3.9687e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8258e-04 - val_loss: 4.3366e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8868e-04 - val_loss: 4.5490e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0164e-04 - val_loss: 4.0171e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0682e-04 - val_loss: 3.8762e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8859e-04 - val_loss: 3.7793e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0514e-04 - val_loss: 5.9278e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9062e-04 - val_loss: 4.3011e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_58\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_58\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0051 - val_loss: 5.9647e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 2.9229e-04 - val_loss: 4.8231e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9214e-04 - val_loss: 4.1577e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8812e-04 - val_loss: 4.6124e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0271e-04 - val_loss: 4.6915e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0687e-04 - val_loss: 4.2000e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9626e-04 - val_loss: 4.1530e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0490e-04 - val_loss: 4.1391e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9331e-04 - val_loss: 4.5461e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8869e-04 - val_loss: 4.4495e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0186e-04 - val_loss: 6.2606e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9885e-04 - val_loss: 3.9152e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0442e-04 - val_loss: 3.8521e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0431e-04 - val_loss: 4.0354e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.1844e-04 - val_loss: 4.3651e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 3.1999e-04 - val_loss: 5.0628e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9965e-04 - val_loss: 4.1346e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.2831e-04 - val_loss: 4.7057e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.2737e-04 - val_loss: 3.8141e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0766e-04 - val_loss: 3.9455e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0141e-04 - val_loss: 4.2652e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9559e-04 - val_loss: 8.1508e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.0227e-04 - val_loss: 4.0412e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.0072e-04 - val_loss: 3.8380e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.9521e-04 - val_loss: 3.9562e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9135e-04 - val_loss: 6.5434e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0959e-04 - val_loss: 4.6059e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9407e-04 - val_loss: 4.0633e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 767us/step - loss: 3.1418e-04 - val_loss: 5.5292e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0165e-04 - val_loss: 3.8956e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1153e-04 - val_loss: 5.6770e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.9674e-04 - val_loss: 4.5683e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.0773e-04 - val_loss: 3.7864e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 2.9168e-04 - val_loss: 6.1359e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.0786e-04 - val_loss: 3.7948e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.1935e-04 - val_loss: 4.7971e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 2.8925e-04 - val_loss: 3.9176e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8243e-04 - val_loss: 4.2162e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9739e-04 - val_loss: 3.7869e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0006e-04 - val_loss: 4.4236e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.0357e-04 - val_loss: 4.0909e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 757us/step - loss: 3.0719e-04 - val_loss: 5.2670e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0987e-04 - val_loss: 4.7843e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 2.8926e-04 - val_loss: 4.2779e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 3.1211e-04 - val_loss: 3.6949e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9552e-04 - val_loss: 4.6667e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 2.8914e-04 - val_loss: 3.8834e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8574e-04 - val_loss: 5.2787e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8499e-04 - val_loss: 4.6185e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.9547e-04 - val_loss: 3.6938e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8217e-04 - val_loss: 4.8513e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0480e-04 - val_loss: 4.1732e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0264e-04 - val_loss: 4.0524e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8650e-04 - val_loss: 3.8611e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 869us/step - loss: 2.8077e-04 - val_loss: 4.2421e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9471e-04 - val_loss: 4.6567e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0420e-04 - val_loss: 4.1611e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8565e-04 - val_loss: 3.8525e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.8784e-04 - val_loss: 4.3921e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8399e-04 - val_loss: 4.1209e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8288e-04 - val_loss: 4.2917e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8584e-04 - val_loss: 4.7209e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8590e-04 - val_loss: 4.0990e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9616e-04 - val_loss: 4.0254e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.8795e-04 - val_loss: 3.9544e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 2.8685e-04 - val_loss: 4.0329e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.8582e-04 - val_loss: 4.0561e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.7641e-04 - val_loss: 3.9470e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9827e-04 - val_loss: 3.9650e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 2.9217e-04 - val_loss: 3.8658e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 2.9671e-04 - val_loss: 3.8776e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 2.8491e-04 - val_loss: 4.4543e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 2.9299e-04 - val_loss: 4.3406e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.0709e-04 - val_loss: 5.3432e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_59\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_59\\assets\n"
     ]
    }
   ],
   "source": [
    "trainInputX = trainX\n",
    "trainInputY = trainY\n",
    "testInputX = testX\n",
    "testInputY = testY\n",
    "print(trainInputX.shape)\n",
    "print(trainInputY.shape)\n",
    "print(testInputX.shape)\n",
    "print(testInputY.shape)\n",
    "\n",
    "#validacao tamanho apos tratamentos\n",
    "print(len(trainX))\n",
    "print(len(trainInputX))\n",
    "\n",
    "print(len(trainY))\n",
    "print(len(trainInputY))\n",
    "\n",
    "trainInputX = trainInputX [:,0:14]\n",
    "testInputX = testInputX [:,0:14]\n",
    "print(trainInputX.shape)\n",
    "\n",
    "trained_models_MLP = []\n",
    "trained_models_MLP_history = []\n",
    "\n",
    "for i in range(0,60):\n",
    "\n",
    "    #giving it reproducibility\n",
    "    seed = (i+1000)\n",
    "\n",
    "    os.environ['PYTHONHASHseed']=str(seed)\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    batch_size = 64\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=24)\n",
    "    \n",
    "    trained_models_MLP.append(kr.Sequential())\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(14))\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(32))\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(32))\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(32))\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(8))\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(1))\n",
    "    trained_models_MLP[i].compile(loss='mean_squared_error',optimizer='adam')\n",
    "    \n",
    "    trained_models_MLP_history.append(trained_models_MLP[i].fit(trainInputX, trainInputY, epochs=2000, batch_size=batch_size, verbose = 1, validation_data=(testInputX,testInputY), callbacks=[callback]))\n",
    "    \n",
    "    trained_models_MLP[i].save('C:/Users/guilh/PythonCodes/Models/MLP_predicting10ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b413ac58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
