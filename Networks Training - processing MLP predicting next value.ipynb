{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0333e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as kr\n",
    "\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "import supportFunctions as sf\n",
    "\n",
    "import inspect\n",
    "lines = inspect.getsource(sf.highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f60e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função utilizada para normalizar os dados de treino e validação\n",
    "def normalize_data(train, test):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    train_scaled = scaler.transform(train)\n",
    "    test_scaled = scaler.transform(test)\n",
    "    \n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "#função utilizada para desnormalizar os dados, no formato de entrada\n",
    "def denormalize_data(scaler,data):\n",
    "    result = scaler.inverse_transform(data)\n",
    "    return result\n",
    "\n",
    "#função utilizada para desnomalizar o valor predito\n",
    "def denormalize_prediction(scaler, dataX, dataY):\n",
    "    formatted_data = np.array(dataX)\n",
    "    formatted_data[:,3] = np.array(dataY)\n",
    "    \n",
    "    return denormalize_data(scaler,formatted_data)[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f62a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.12.0\n",
      "Keras Version: 2.12.0\n",
      "\n",
      "Python 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas 1.5.2\n",
      "Scikit-Learn 1.2.1\n",
      "WARNING:tensorflow:From C:\\Users\\guilh\\AppData\\Local\\Temp\\ipykernel_16436\\3882079960.py:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n",
    "# tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c84100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantos passos para trás os indicadores técnicos vão olhar\n",
    "ti_memory = 10\n",
    "\n",
    "#lendo os dados que serão utilizados para treinamento e validação\n",
    "ge1day = pd.read_csv('Data\\GE.csv')\n",
    "#removendo a coluna que indica a data\n",
    "ge1day = ge1day.drop(['Date'], axis = 1)\n",
    "\n",
    "df = ge1day\n",
    "#reseting the index\n",
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ca2794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh\\PythonCodes\\supportFunctions.py:263: RuntimeWarning: divide by zero encountered in divide\n",
      "  rs = ag_vector/al_vector #numpy arrays so therefore can use element wise division\n",
      "C:\\Users\\guilh\\PythonCodes\\supportFunctions.py:263: RuntimeWarning: invalid value encountered in divide\n",
      "  rs = ag_vector/al_vector #numpy arrays so therefore can use element wise division\n"
     ]
    }
   ],
   "source": [
    "#adicionando os parametros de indicadores tecnicos ao dataframe\n",
    "df[\"\"\"highest_{}\"\"\".format(ti_memory)] = sf.highest(df.Close,ti_memory)\n",
    "df[\"\"\"lowest_{}\"\"\".format(ti_memory)] = sf.lowest(df.Close,ti_memory)\n",
    "df[\"\"\"wma_{}\"\"\".format(ti_memory)] = sf.wma(df.Close,ti_memory)\n",
    "df[\"\"\"ema_{}\"\"\".format(ti_memory)] = sf.ema(df.Close,ti_memory)\n",
    "df[\"\"\"hma_{}\"\"\".format(ti_memory)] = sf.hma(df.Close,ti_memory)\n",
    "df[\"\"\"macd_12_26\"\"\"] = sf.macd(df.Close,12,26)\n",
    "df[\"\"\"rsi_{}\"\"\".format(ti_memory)] = sf.rsi(df.Close,ti_memory)\n",
    "df[\"\"\"dpo_{}\"\"\".format(ti_memory)] = sf.dpo(df.Close,ti_memory)\n",
    "\n",
    "#parametros nao utilizados:\n",
    "# df[\"\"\"sma_{}\"\"\".format(ti_memory)] = sf.sma(df.Close,ti_memory)\n",
    "# df[\"\"\"so_k_5\"\"\"] = sf.so_k(df.Close)\n",
    "# df[\"\"\"so_d_3\"\"\"] = sf.so_d(df.Close)\n",
    "# df[\"\"\"obv\"\"\".format(ti_memory)] = sf.obv(df.Close,df.Volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c08296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>highest_10</th>\n",
       "      <th>lowest_10</th>\n",
       "      <th>wma_10</th>\n",
       "      <th>ema_10</th>\n",
       "      <th>hma_10</th>\n",
       "      <th>macd_12_26</th>\n",
       "      <th>rsi_10</th>\n",
       "      <th>dpo_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.751202</td>\n",
       "      <td>0.763722</td>\n",
       "      <td>0.743690</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>2156500</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.744942</td>\n",
       "      <td>0.744942</td>\n",
       "      <td>0.738682</td>\n",
       "      <td>0.741186</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>1477600</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.741186</td>\n",
       "      <td>0.743690</td>\n",
       "      <td>0.744942</td>\n",
       "      <td>0.745359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.744942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741186</td>\n",
       "      <td>0.747446</td>\n",
       "      <td>0.726162</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>1837000</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.738056</td>\n",
       "      <td>0.740769</td>\n",
       "      <td>0.741708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.740769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.733674</td>\n",
       "      <td>0.701122</td>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>2725600</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.728290</td>\n",
       "      <td>0.733987</td>\n",
       "      <td>0.734112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.733987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.691106</td>\n",
       "      <td>0.712390</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>3095000</td>\n",
       "      <td>0.748698</td>\n",
       "      <td>0.712390</td>\n",
       "      <td>0.722990</td>\n",
       "      <td>0.729667</td>\n",
       "      <td>0.727268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.729667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14658</th>\n",
       "      <td>7.630000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>7.510000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>123180900</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.062182</td>\n",
       "      <td>7.424700</td>\n",
       "      <td>7.239323</td>\n",
       "      <td>-1.116727</td>\n",
       "      <td>50.108961</td>\n",
       "      <td>-0.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14659</th>\n",
       "      <td>7.680000</td>\n",
       "      <td>7.870000</td>\n",
       "      <td>7.540000</td>\n",
       "      <td>7.620000</td>\n",
       "      <td>7.620000</td>\n",
       "      <td>93299000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.175091</td>\n",
       "      <td>7.460209</td>\n",
       "      <td>7.697586</td>\n",
       "      <td>-1.029444</td>\n",
       "      <td>40.027642</td>\n",
       "      <td>-0.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14660</th>\n",
       "      <td>7.540000</td>\n",
       "      <td>7.940000</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>7.890000</td>\n",
       "      <td>7.890000</td>\n",
       "      <td>86850200</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.341273</td>\n",
       "      <td>7.538353</td>\n",
       "      <td>8.019525</td>\n",
       "      <td>-0.927790</td>\n",
       "      <td>41.907705</td>\n",
       "      <td>-0.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14661</th>\n",
       "      <td>7.870000</td>\n",
       "      <td>8.180000</td>\n",
       "      <td>7.820000</td>\n",
       "      <td>7.940000</td>\n",
       "      <td>7.940000</td>\n",
       "      <td>121149900</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.494182</td>\n",
       "      <td>7.611380</td>\n",
       "      <td>8.165303</td>\n",
       "      <td>-0.833585</td>\n",
       "      <td>32.316173</td>\n",
       "      <td>-1.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14662</th>\n",
       "      <td>7.520000</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.040000</td>\n",
       "      <td>7.040000</td>\n",
       "      <td>99330200</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>7.467818</td>\n",
       "      <td>7.507492</td>\n",
       "      <td>7.971818</td>\n",
       "      <td>-0.822072</td>\n",
       "      <td>45.132949</td>\n",
       "      <td>-0.219000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14663 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open      High       Low     Close  Adj Close     Volume  \\\n",
       "0      0.751202  0.763722  0.743690  0.748698   0.001782    2156500   \n",
       "1      0.744942  0.744942  0.738682  0.741186   0.001764    1477600   \n",
       "2      0.741186  0.747446  0.726162  0.732422   0.001743    1837000   \n",
       "3      0.732422  0.733674  0.701122  0.713642   0.001698    2725600   \n",
       "4      0.713642  0.713642  0.691106  0.712390   0.001695    3095000   \n",
       "...         ...       ...       ...       ...        ...        ...   \n",
       "14658  7.630000  8.300000  7.510000  8.120000   8.120000  123180900   \n",
       "14659  7.680000  7.870000  7.540000  7.620000   7.620000   93299000   \n",
       "14660  7.540000  7.940000  7.350000  7.890000   7.890000   86850200   \n",
       "14661  7.870000  8.180000  7.820000  7.940000   7.940000  121149900   \n",
       "14662  7.520000  7.550000  7.000000  7.040000   7.040000   99330200   \n",
       "\n",
       "       highest_10  lowest_10    wma_10    ema_10    hma_10  macd_12_26  \\\n",
       "0        0.748698   0.748698  0.748698  0.748698  0.748698    0.000000   \n",
       "1        0.748698   0.741186  0.743690  0.744942  0.745359    0.000000   \n",
       "2        0.748698   0.732422  0.738056  0.740769  0.741708    0.000000   \n",
       "3        0.748698   0.713642  0.728290  0.733987  0.734112    0.000000   \n",
       "4        0.748698   0.712390  0.722990  0.729667  0.727268    0.000000   \n",
       "...           ...        ...       ...       ...       ...         ...   \n",
       "14658    8.120000   6.110000  7.062182  7.424700  7.239323   -1.116727   \n",
       "14659    8.120000   6.110000  7.175091  7.460209  7.697586   -1.029444   \n",
       "14660    8.120000   6.110000  7.341273  7.538353  8.019525   -0.927790   \n",
       "14661    8.120000   6.110000  7.494182  7.611380  8.165303   -0.833585   \n",
       "14662    8.120000   6.110000  7.467818  7.507492  7.971818   -0.822072   \n",
       "\n",
       "           rsi_10    dpo_10  \n",
       "0             NaN  0.000000  \n",
       "1      100.000000 -0.744942  \n",
       "2      100.000000 -0.740769  \n",
       "3      100.000000 -0.733987  \n",
       "4      100.000000 -0.729667  \n",
       "...           ...       ...  \n",
       "14658   50.108961 -0.399000  \n",
       "14659   40.027642 -0.496000  \n",
       "14660   41.907705 -0.579000  \n",
       "14661   32.316173 -1.075000  \n",
       "14662   45.132949 -0.219000  \n",
       "\n",
       "[14663 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7c3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jogando alguns dados fora para termos todas variaveis incializadas\n",
    "inicialization_steps = 30\n",
    "prediction_ahead = 1\n",
    "\n",
    "dataValues = df.values\n",
    "\n",
    "trainSize = int(len(dataValues)*0.8)\n",
    "testSize = len(dataValues) - trainSize\n",
    "\n",
    "train = df.head(trainSize)\n",
    "# train,minDataTrain,minMaxDataTrain = sf.normalizaTrain(train)\n",
    "test = df.tail(testSize)\n",
    "# test = sf.normalizaTest(test, minDataTrain, minMaxDataTrain)\n",
    "\n",
    "scaler, train_normalized, test_normalized = normalize_data(train, test)\n",
    "\n",
    "#deixando um valor de fora, para podermos prever o próximo valor quando for o último:\n",
    "trainX = train_normalized[inicialization_steps:(len(train)-prediction_ahead)]\n",
    "testX = test_normalized[0:(len(test)-prediction_ahead)]\n",
    "\n",
    "#normalizando as entradas\n",
    "# scalerX, trainX, testX = normalize_data(trainX, testX)\n",
    "\n",
    "#pegando apenas o valor que queremos prever\n",
    "trainY = train_normalized[(inicialization_steps+prediction_ahead):len(train),3]\n",
    "testY = test_normalized[prediction_ahead:len(test),3]\n",
    "\n",
    "#calculando a diferenca percentual do preco de fechamento entre um dia e outro\n",
    "# trainY = (train.values[(inicialization_steps+1):len(train),3]/trainX[:,3])-1\n",
    "# testY = (test.values[1:len(test),3]/testX[:,3])-1\n",
    "\n",
    "\n",
    "# scalerY, trainY, testY = normalize_data(trainY, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd9aebb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11699, 14)\n",
      "(11699,)\n",
      "(2932, 14)\n",
      "(2932,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4aa933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if it makes sense\n",
    "# print(trainInputX[:10,(rnn_memory-1),3])\n",
    "# print(trainInputY[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4958670c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11699, 14)\n",
      "(11699,)\n",
      "(2932, 14)\n",
      "(2932,)\n",
      "11699\n",
      "11699\n",
      "11699\n",
      "11699\n",
      "(11699, 14)\n",
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 2ms/step - loss: 0.0016 - val_loss: 1.3060e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 9.6410e-05 - val_loss: 7.1057e-05\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.4566e-05 - val_loss: 5.8033e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.5127e-05 - val_loss: 8.9520e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.5438e-05 - val_loss: 1.3132e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.3502e-05 - val_loss: 5.6957e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.4907e-05 - val_loss: 1.4351e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.0258e-05 - val_loss: 1.1987e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 7.5548e-05 - val_loss: 4.7405e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.5325e-05 - val_loss: 6.1491e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5983e-05 - val_loss: 5.7691e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 6.9721e-05 - val_loss: 4.5574e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8902e-05 - val_loss: 7.1973e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.5091e-05 - val_loss: 1.0346e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.4678e-05 - val_loss: 4.7363e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.0335e-05 - val_loss: 5.8417e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.8153e-05 - val_loss: 8.0201e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.0082e-05 - val_loss: 5.1675e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.2248e-05 - val_loss: 7.3638e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.3832e-05 - val_loss: 5.5207e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.9637e-05 - val_loss: 4.6748e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.8173e-05 - val_loss: 6.7870e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.2496e-05 - val_loss: 2.1673e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 5.5444e-05 - val_loss: 5.1478e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.7101e-05 - val_loss: 4.9632e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.3142e-05 - val_loss: 4.7195e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 7.6815e-05 - val_loss: 5.2348e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.6403e-05 - val_loss: 1.5014e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3739e-05 - val_loss: 6.8170e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5288e-05 - val_loss: 7.2063e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0806e-05 - val_loss: 4.9633e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2964e-05 - val_loss: 2.3446e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1797e-05 - val_loss: 4.5193e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.1671e-05 - val_loss: 3.3178e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7725e-05 - val_loss: 4.1776e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9640e-05 - val_loss: 6.6293e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8919e-05 - val_loss: 5.3101e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.6868e-05 - val_loss: 6.7583e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6245e-05 - val_loss: 7.4481e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3775e-05 - val_loss: 4.8328e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2499e-05 - val_loss: 7.6385e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 5.4776e-05 - val_loss: 1.0179e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 6.0260e-05 - val_loss: 4.3368e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 7.1672e-05 - val_loss: 9.7365e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0433e-05 - val_loss: 4.0057e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9356e-05 - val_loss: 4.4458e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 4.2477e-05 - val_loss: 1.3350e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.8671e-05 - val_loss: 8.3025e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.3665e-05 - val_loss: 5.6953e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.8147e-05 - val_loss: 2.1528e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.1420e-05 - val_loss: 4.2534e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.6224e-05 - val_loss: 1.4533e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7137e-05 - val_loss: 8.0760e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 886us/step - loss: 5.1563e-05 - val_loss: 1.0211e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4601e-05 - val_loss: 1.1425e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.1674e-05 - val_loss: 6.2693e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.5136e-05 - val_loss: 9.4871e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 4.7431e-05 - val_loss: 5.1964e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3350e-05 - val_loss: 5.0352e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 4.8153e-05 - val_loss: 4.1812e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9007e-05 - val_loss: 6.4103e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.8950e-05 - val_loss: 4.5911e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7743e-05 - val_loss: 4.8033e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.5703e-05 - val_loss: 4.1885e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9455e-05 - val_loss: 5.0598e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 5.5620e-05 - val_loss: 4.5069e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 4.2306e-05 - val_loss: 6.9192e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.5651e-05 - val_loss: 4.3830e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.5519e-05 - val_loss: 5.9923e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0124 - val_loss: 0.0043\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 1.6778e-04 - val_loss: 9.0531e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 1.1185e-04 - val_loss: 3.2231e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 8.4759e-05 - val_loss: 2.1321e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.2439e-05 - val_loss: 6.7189e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2655e-05 - val_loss: 5.5433e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1872e-05 - val_loss: 5.4676e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 7.0727e-05 - val_loss: 7.0186e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.8293e-05 - val_loss: 5.2153e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8366e-05 - val_loss: 7.2762e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.9282e-05 - val_loss: 5.4014e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8421e-05 - val_loss: 5.1524e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.3652e-05 - val_loss: 5.5864e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.4942e-05 - val_loss: 8.2965e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7019e-05 - val_loss: 4.8504e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.7201e-05 - val_loss: 5.9484e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.3557e-05 - val_loss: 1.1927e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.1232e-05 - val_loss: 6.2642e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7502e-05 - val_loss: 4.8465e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.6229e-05 - val_loss: 7.9297e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.5158e-05 - val_loss: 4.8429e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.6258e-05 - val_loss: 1.7530e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.2789e-05 - val_loss: 4.9240e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.3583e-05 - val_loss: 1.0265e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 7.0529e-05 - val_loss: 4.4815e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 6.4390e-05 - val_loss: 4.5695e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 6.8756e-05 - val_loss: 5.8853e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.3610e-05 - val_loss: 5.5864e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 7.9377e-05 - val_loss: 1.0990e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 6.2367e-05 - val_loss: 5.4787e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 6.1181e-05 - val_loss: 1.3691e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 6.8437e-05 - val_loss: 5.4619e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 5.7716e-05 - val_loss: 5.3075e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 5.6328e-05 - val_loss: 6.2059e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.2125e-05 - val_loss: 7.7264e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0977e-05 - val_loss: 4.7748e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 6.2138e-05 - val_loss: 5.2964e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 5.7750e-05 - val_loss: 4.8723e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.8619e-05 - val_loss: 5.2513e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.9050e-05 - val_loss: 7.8983e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.1694e-05 - val_loss: 1.3953e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.6423e-05 - val_loss: 1.2338e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.4328e-05 - val_loss: 2.5114e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.0867e-05 - val_loss: 5.9054e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0398e-05 - val_loss: 4.6419e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.1239e-05 - val_loss: 4.3670e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5791e-05 - val_loss: 7.9248e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.2869e-05 - val_loss: 8.1715e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9196e-05 - val_loss: 1.0940e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6496e-05 - val_loss: 1.7030e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.4354e-05 - val_loss: 2.1512e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6581e-05 - val_loss: 1.0129e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6744e-05 - val_loss: 4.6966e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.9576e-05 - val_loss: 5.4284e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6387e-05 - val_loss: 4.3114e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0788e-05 - val_loss: 4.4965e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9727e-05 - val_loss: 4.8487e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.8671e-05 - val_loss: 9.2564e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.5720e-05 - val_loss: 5.9216e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.8258e-05 - val_loss: 5.5165e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.1461e-05 - val_loss: 5.6195e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.0936e-05 - val_loss: 7.6713e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.8859e-05 - val_loss: 4.4425e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0753e-05 - val_loss: 4.6291e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.2568e-05 - val_loss: 1.2419e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.1123e-05 - val_loss: 4.5053e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.2548e-05 - val_loss: 4.5442e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.2553e-05 - val_loss: 4.8723e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.6405e-05 - val_loss: 5.4293e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.3681e-05 - val_loss: 5.8288e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 5.5244e-05 - val_loss: 4.0260e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 693us/step - loss: 4.7115e-05 - val_loss: 7.6617e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 6.2870e-05 - val_loss: 9.7556e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 6.2397e-05 - val_loss: 5.6274e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.8356e-05 - val_loss: 6.1484e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.8160e-05 - val_loss: 4.9528e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.6312e-05 - val_loss: 5.8111e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.8792e-05 - val_loss: 5.3400e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.7554e-05 - val_loss: 6.1601e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 5.3226e-05 - val_loss: 9.5400e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.3089e-05 - val_loss: 4.4621e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9420e-05 - val_loss: 4.6695e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 5.4884e-05 - val_loss: 7.7374e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.0404e-05 - val_loss: 4.1374e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7155e-05 - val_loss: 6.3799e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.5508e-05 - val_loss: 4.2792e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5256e-05 - val_loss: 4.6411e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1532e-05 - val_loss: 4.9383e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.7905e-05 - val_loss: 1.3017e-04\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 5.3597e-05 - val_loss: 5.2875e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.7645e-05 - val_loss: 4.9654e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.2867e-05 - val_loss: 5.8677e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.4171e-05 - val_loss: 6.2566e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.2350e-05 - val_loss: 4.4748e-05\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.5937e-05 - val_loss: 4.4803e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 1.2362e-04 - val_loss: 4.7947e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 8.4361e-05 - val_loss: 1.9453e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.6816e-05 - val_loss: 1.0529e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.4664e-05 - val_loss: 1.0557e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.9414e-05 - val_loss: 1.0522e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.2489e-05 - val_loss: 1.1871e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.1711e-05 - val_loss: 1.0187e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 7.5500e-05 - val_loss: 1.4215e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.9347e-05 - val_loss: 6.9504e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.5112e-05 - val_loss: 1.4898e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1771e-05 - val_loss: 6.2346e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.6093e-05 - val_loss: 8.1758e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.2125e-05 - val_loss: 1.0038e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8556e-05 - val_loss: 1.6730e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5636e-05 - val_loss: 8.8128e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.2320e-05 - val_loss: 1.2615e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2225e-05 - val_loss: 4.8141e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.0048e-05 - val_loss: 9.1587e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.3623e-05 - val_loss: 4.4960e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6928e-05 - val_loss: 9.3724e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.0286e-05 - val_loss: 5.0856e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.4796e-05 - val_loss: 1.5271e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.0362e-05 - val_loss: 1.1851e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7019e-05 - val_loss: 5.7149e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0991e-05 - val_loss: 5.8672e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3357e-05 - val_loss: 9.4715e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1031e-05 - val_loss: 9.7878e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.7920e-05 - val_loss: 4.0265e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8085e-05 - val_loss: 8.9079e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 7.2452e-05 - val_loss: 6.1763e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3498e-05 - val_loss: 4.7000e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6722e-05 - val_loss: 7.2836e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4806e-05 - val_loss: 4.0229e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3449e-05 - val_loss: 4.4660e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6916e-05 - val_loss: 1.5650e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7455e-05 - val_loss: 4.4375e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.6729e-05 - val_loss: 4.5833e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.4855e-05 - val_loss: 4.8236e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7768e-05 - val_loss: 1.3093e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.3677e-05 - val_loss: 4.3509e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.8107e-05 - val_loss: 8.2023e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9844e-05 - val_loss: 5.2650e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.6430e-05 - val_loss: 4.3812e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1938e-05 - val_loss: 5.0217e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.8731e-05 - val_loss: 4.6224e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.6820e-05 - val_loss: 6.2415e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.4092e-05 - val_loss: 4.5284e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0003e-05 - val_loss: 4.2388e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3936e-05 - val_loss: 9.7559e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5201e-05 - val_loss: 4.4744e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.5691e-05 - val_loss: 5.5650e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9486e-05 - val_loss: 5.6247e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6611e-05 - val_loss: 2.6870e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.6348e-05 - val_loss: 7.1725e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.6983e-05 - val_loss: 4.2598e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.9307e-05 - val_loss: 4.2192e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.4718e-05 - val_loss: 4.5113e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 6.1572e-04 - val_loss: 3.3954e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 6.4866e-05 - val_loss: 3.9269e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2550e-05 - val_loss: 4.8097e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.1304e-05 - val_loss: 3.1705e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 8.3386e-05 - val_loss: 1.8030e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.0708e-05 - val_loss: 4.5705e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.8024e-05 - val_loss: 8.8988e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3715e-05 - val_loss: 9.5853e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5288e-05 - val_loss: 6.7679e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0983e-05 - val_loss: 7.6726e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.2733e-05 - val_loss: 4.6206e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.6142e-05 - val_loss: 2.5189e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.3293e-05 - val_loss: 4.0960e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7641e-05 - val_loss: 4.7947e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.5323e-05 - val_loss: 1.3043e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.9610e-05 - val_loss: 1.4977e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 8.5647e-05 - val_loss: 4.8647e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0958e-05 - val_loss: 5.1339e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9326e-05 - val_loss: 1.1019e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5511e-05 - val_loss: 6.9765e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1494e-05 - val_loss: 1.3736e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1172e-05 - val_loss: 1.8792e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5226e-05 - val_loss: 4.5255e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8528e-05 - val_loss: 9.1746e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.4940e-05 - val_loss: 4.2619e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.8409e-05 - val_loss: 2.3642e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.1741e-05 - val_loss: 4.3238e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.6229e-05 - val_loss: 6.2503e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4584e-05 - val_loss: 8.9977e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.7469e-05 - val_loss: 4.6531e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9168e-05 - val_loss: 1.2549e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3857e-05 - val_loss: 5.1022e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8890e-05 - val_loss: 4.7991e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1747e-05 - val_loss: 1.0047e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1874e-05 - val_loss: 8.7850e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0791e-05 - val_loss: 6.4643e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9393e-05 - val_loss: 7.0042e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 5.4218e-04 - val_loss: 9.7176e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.3552e-05 - val_loss: 3.5809e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.1666e-05 - val_loss: 5.0439e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 8.8126e-05 - val_loss: 5.5077e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 8.5882e-05 - val_loss: 8.0902e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 6.5572e-05 - val_loss: 1.1135e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.3223e-05 - val_loss: 5.3565e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.1528e-05 - val_loss: 4.5881e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7451e-05 - val_loss: 2.7572e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 7.3957e-05 - val_loss: 4.5221e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.9270e-05 - val_loss: 4.2118e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.3876e-05 - val_loss: 6.2753e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.8126e-05 - val_loss: 5.7151e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2087e-05 - val_loss: 6.5916e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 6.3628e-05 - val_loss: 6.2098e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.7329e-05 - val_loss: 9.4323e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9509e-05 - val_loss: 7.3030e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7944e-05 - val_loss: 5.1700e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7321e-05 - val_loss: 9.8814e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4659e-05 - val_loss: 5.9238e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.7402e-05 - val_loss: 7.1326e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.6667e-05 - val_loss: 7.9968e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 5.5329e-05 - val_loss: 9.9947e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8826e-05 - val_loss: 6.2821e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.5661e-05 - val_loss: 7.1068e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.6568e-05 - val_loss: 6.0034e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 5.2151e-05 - val_loss: 3.9743e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.0700e-05 - val_loss: 4.4662e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8020e-05 - val_loss: 1.8130e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 4.6792e-05 - val_loss: 8.6604e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.0843e-05 - val_loss: 9.2123e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8093e-05 - val_loss: 3.8404e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9172e-05 - val_loss: 4.4660e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.9077e-05 - val_loss: 4.0870e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1939e-05 - val_loss: 5.7700e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1398e-05 - val_loss: 1.1524e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.8274e-05 - val_loss: 6.5554e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.5666e-05 - val_loss: 5.4126e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.0170e-05 - val_loss: 4.7153e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 5.3778e-05 - val_loss: 4.4825e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3704e-05 - val_loss: 1.2899e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.4447e-05 - val_loss: 5.5135e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1526e-05 - val_loss: 4.0682e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5125e-05 - val_loss: 4.2812e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.6631e-05 - val_loss: 8.2643e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.8877e-05 - val_loss: 4.4176e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.9179e-05 - val_loss: 3.8004e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9308e-05 - val_loss: 4.9344e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1227e-05 - val_loss: 4.5771e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9342e-05 - val_loss: 5.7678e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6076e-05 - val_loss: 4.6651e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.8452e-05 - val_loss: 4.0709e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4313e-05 - val_loss: 4.4280e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.4957e-05 - val_loss: 2.6957e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.9982e-05 - val_loss: 1.1262e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9293e-05 - val_loss: 4.2741e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3065e-05 - val_loss: 8.7962e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.5850e-05 - val_loss: 5.8430e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9563e-05 - val_loss: 9.0716e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6765e-05 - val_loss: 4.6304e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.4693e-05 - val_loss: 5.7352e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.3239e-05 - val_loss: 6.4556e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7444e-05 - val_loss: 7.9388e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6911e-05 - val_loss: 4.5725e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.5001e-05 - val_loss: 6.7138e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 5.0930e-05 - val_loss: 4.0996e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.7205e-05 - val_loss: 4.3780e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.3130e-05 - val_loss: 4.8891e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1613e-05 - val_loss: 5.4959e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8270e-05 - val_loss: 4.3944e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 944us/step - loss: 4.3718e-05 - val_loss: 3.8555e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 2.7808e-04 - val_loss: 9.3067e-05\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 7.3611e-05 - val_loss: 8.2139e-05\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 8.2723e-05 - val_loss: 1.0132e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 7.2838e-05 - val_loss: 1.6807e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 8.7087e-05 - val_loss: 7.6959e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.5132e-05 - val_loss: 6.6905e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 9.0250e-05 - val_loss: 9.0162e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 774us/step - loss: 7.9701e-05 - val_loss: 7.1043e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 7.4221e-05 - val_loss: 7.3860e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.8590e-05 - val_loss: 5.5451e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.8959e-05 - val_loss: 4.7032e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 7.4722e-05 - val_loss: 6.0210e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.7888e-05 - val_loss: 5.3962e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.5074e-05 - val_loss: 1.3921e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 7.2618e-05 - val_loss: 4.8312e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 6.7796e-05 - val_loss: 5.2118e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 6.3489e-05 - val_loss: 1.2693e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 6.5049e-05 - val_loss: 9.2526e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.9297e-05 - val_loss: 4.8237e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.8466e-05 - val_loss: 1.2110e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.0525e-05 - val_loss: 4.8769e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2034e-05 - val_loss: 4.4770e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.1081e-05 - val_loss: 5.2087e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.3775e-05 - val_loss: 4.4021e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6232e-05 - val_loss: 4.2526e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1333e-05 - val_loss: 5.1159e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.1776e-05 - val_loss: 6.9112e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.4558e-05 - val_loss: 5.6875e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 5.4104e-05 - val_loss: 5.9950e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6022e-05 - val_loss: 4.5100e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1470e-05 - val_loss: 5.6456e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.5085e-05 - val_loss: 4.3462e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3797e-05 - val_loss: 1.2461e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8747e-05 - val_loss: 1.0911e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4708e-05 - val_loss: 4.3137e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6852e-05 - val_loss: 6.1011e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 6.1377e-05 - val_loss: 4.2871e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 5.5081e-05 - val_loss: 4.3690e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1155e-05 - val_loss: 2.0229e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9762e-05 - val_loss: 6.0047e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.5979e-05 - val_loss: 7.8759e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9601e-05 - val_loss: 4.4431e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.6654e-05 - val_loss: 4.8933e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2774e-05 - val_loss: 6.1771e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.9066e-05 - val_loss: 8.5198e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7801e-05 - val_loss: 4.4443e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 800us/step - loss: 5.4575e-05 - val_loss: 4.2664e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.5409e-05 - val_loss: 5.6121e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.1768e-05 - val_loss: 3.9960e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.6446e-05 - val_loss: 4.7960e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0319e-05 - val_loss: 1.1335e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4109e-05 - val_loss: 7.5958e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.2532e-05 - val_loss: 6.1377e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0536e-05 - val_loss: 5.0869e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2790e-05 - val_loss: 4.1962e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6616e-05 - val_loss: 4.6902e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2717e-05 - val_loss: 7.8337e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9814e-05 - val_loss: 5.3829e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7540e-05 - val_loss: 1.3851e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.8590e-05 - val_loss: 4.2085e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0009e-05 - val_loss: 7.4745e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1669e-05 - val_loss: 4.3648e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7445e-05 - val_loss: 5.0020e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6221e-05 - val_loss: 5.2501e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8407e-05 - val_loss: 4.6408e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.2832e-05 - val_loss: 4.0221e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7419e-05 - val_loss: 5.7561e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2144e-05 - val_loss: 8.1737e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9323e-05 - val_loss: 8.7860e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5955e-05 - val_loss: 5.1134e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3540e-05 - val_loss: 4.7051e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9197e-05 - val_loss: 7.8838e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 723us/step - loss: 4.7049e-05 - val_loss: 5.6227e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 9.4940e-05 - val_loss: 1.2482e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.3957e-05 - val_loss: 8.9539e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.5281e-05 - val_loss: 8.4815e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.0350e-05 - val_loss: 7.6533e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.6711e-05 - val_loss: 5.3589e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1716e-05 - val_loss: 7.2637e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8759e-05 - val_loss: 5.0784e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8149e-05 - val_loss: 8.4255e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 5.4899e-05 - val_loss: 6.8634e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.0648e-05 - val_loss: 6.4816e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 6.8648e-05 - val_loss: 6.7551e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 5.9635e-05 - val_loss: 1.0574e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.5627e-05 - val_loss: 4.1829e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1622e-05 - val_loss: 4.4017e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 5.5836e-05 - val_loss: 1.2602e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.4311e-05 - val_loss: 1.1369e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.7434e-05 - val_loss: 1.1547e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.0338e-05 - val_loss: 4.9683e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2426e-05 - val_loss: 5.7520e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6756e-05 - val_loss: 8.1138e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6602e-05 - val_loss: 1.0191e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1884e-05 - val_loss: 4.3057e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8792e-05 - val_loss: 4.8520e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6189e-05 - val_loss: 4.4646e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.8417e-05 - val_loss: 9.6593e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.4835e-05 - val_loss: 4.5177e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.1987e-05 - val_loss: 1.5699e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.3110e-05 - val_loss: 4.3664e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4207e-05 - val_loss: 4.2482e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0980e-05 - val_loss: 5.4254e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2751e-05 - val_loss: 4.6706e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9089e-05 - val_loss: 4.8138e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.7478e-05 - val_loss: 8.1471e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.9600e-05 - val_loss: 7.4147e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7717e-05 - val_loss: 9.5843e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 6.0778e-05 - val_loss: 4.5153e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.5935e-05 - val_loss: 4.4694e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 3.4503e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3732e-05 - val_loss: 1.7131e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.2090e-05 - val_loss: 4.8841e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1434e-05 - val_loss: 5.9559e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2263e-05 - val_loss: 6.0085e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1821e-05 - val_loss: 4.6663e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4829e-05 - val_loss: 5.1230e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.4838e-05 - val_loss: 6.4556e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5405e-05 - val_loss: 4.3618e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1208e-05 - val_loss: 5.4233e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.6508e-05 - val_loss: 4.1847e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6271e-05 - val_loss: 9.3124e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8404e-05 - val_loss: 5.1251e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.0354e-05 - val_loss: 4.4198e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0508e-05 - val_loss: 5.0972e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.4691e-05 - val_loss: 7.0798e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.3764e-05 - val_loss: 4.1387e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 7.4815e-05 - val_loss: 5.2746e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4743e-05 - val_loss: 5.5380e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3297e-05 - val_loss: 5.5489e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1700e-05 - val_loss: 4.2520e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2214e-05 - val_loss: 8.5617e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7535e-05 - val_loss: 6.6114e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.4922e-05 - val_loss: 5.9688e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0435e-05 - val_loss: 6.2078e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.1179e-05 - val_loss: 7.2519e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8446e-05 - val_loss: 3.9863e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9595e-05 - val_loss: 4.9279e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3868e-05 - val_loss: 4.1244e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.8175e-05 - val_loss: 1.0371e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8556e-05 - val_loss: 4.0914e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5962e-05 - val_loss: 4.1065e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.3281e-05 - val_loss: 1.9618e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1857e-05 - val_loss: 1.7214e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0387e-05 - val_loss: 4.5782e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4265e-05 - val_loss: 4.0602e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6318e-05 - val_loss: 5.1634e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.2094e-05 - val_loss: 3.9890e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3390e-05 - val_loss: 5.9342e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1285e-05 - val_loss: 4.4391e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.5319e-05 - val_loss: 4.2493e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8768e-05 - val_loss: 9.1040e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.2141e-05 - val_loss: 4.3352e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.0355e-05 - val_loss: 6.8265e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6581e-05 - val_loss: 5.2799e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9283e-05 - val_loss: 4.0614e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7365e-05 - val_loss: 6.1703e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8192e-05 - val_loss: 4.3191e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2208e-05 - val_loss: 4.1504e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9228e-05 - val_loss: 4.1218e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3929e-05 - val_loss: 2.3556e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 6.4778e-05 - val_loss: 4.4759e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 5.8946e-05 - val_loss: 8.4645e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 929us/step - loss: 5.4684e-05 - val_loss: 9.9289e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 5.4376e-05 - val_loss: 5.0933e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 5.4467e-05 - val_loss: 1.3268e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 5.4431e-05 - val_loss: 6.7850e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 5.9037e-05 - val_loss: 6.0778e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 5.5833e-05 - val_loss: 1.1485e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 6.8339e-05 - val_loss: 1.3457e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 6.3781e-05 - val_loss: 4.7452e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 6.2644e-05 - val_loss: 7.9063e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 6.0750e-05 - val_loss: 1.5752e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 7.2109e-05 - val_loss: 1.1172e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 6.8926e-05 - val_loss: 1.1943e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 5.9288e-05 - val_loss: 1.0621e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 5.6331e-05 - val_loss: 1.1185e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 5.3951e-05 - val_loss: 9.2643e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 6.5016e-05 - val_loss: 8.8707e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 5.4644e-05 - val_loss: 1.0624e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 5.6469e-05 - val_loss: 4.5640e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 5.0119e-05 - val_loss: 5.1807e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 6.3958e-05 - val_loss: 4.4419e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 6.3899e-05 - val_loss: 5.0909e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 5.3646e-05 - val_loss: 5.3827e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 5.5933e-05 - val_loss: 8.5471e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.3787e-05 - val_loss: 4.7118e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1471e-05 - val_loss: 8.5847e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3394e-05 - val_loss: 9.9015e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 7.4963e-05 - val_loss: 5.1582e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9752e-05 - val_loss: 6.3372e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5115e-05 - val_loss: 4.5252e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1332e-05 - val_loss: 4.7242e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7608e-05 - val_loss: 1.6076e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7908e-05 - val_loss: 5.0465e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3788e-05 - val_loss: 4.8549e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7605e-05 - val_loss: 4.2885e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9589e-05 - val_loss: 7.5889e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2467e-05 - val_loss: 5.4500e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 5.6078e-05 - val_loss: 1.4511e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4871e-05 - val_loss: 8.2775e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 6.3053e-05 - val_loss: 6.4823e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8714e-05 - val_loss: 1.2349e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.7945e-05 - val_loss: 6.1028e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.1083e-05 - val_loss: 5.0453e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8138e-05 - val_loss: 4.8913e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7675e-05 - val_loss: 1.4200e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.0929e-05 - val_loss: 6.3526e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.7293e-05 - val_loss: 8.5258e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2877e-05 - val_loss: 4.3139e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 5.2304e-05 - val_loss: 4.1193e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4930e-05 - val_loss: 5.0175e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1273e-05 - val_loss: 5.2713e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2693e-05 - val_loss: 6.3484e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8578e-05 - val_loss: 4.9811e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.7549e-05 - val_loss: 4.0492e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3610e-05 - val_loss: 5.3527e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3967e-05 - val_loss: 5.9172e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0030e-05 - val_loss: 3.9627e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9284e-05 - val_loss: 4.0310e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3448e-05 - val_loss: 9.0991e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1254e-05 - val_loss: 5.4369e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5903e-05 - val_loss: 6.3760e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8720e-05 - val_loss: 6.6488e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 5.0590e-05 - val_loss: 2.0251e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9140e-05 - val_loss: 8.8585e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9385e-05 - val_loss: 1.1129e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.4173e-05 - val_loss: 9.2196e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6415e-05 - val_loss: 4.9160e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0783e-05 - val_loss: 7.4694e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3582e-05 - val_loss: 6.0092e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4551e-05 - val_loss: 8.0506e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7252e-05 - val_loss: 4.9084e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5423e-05 - val_loss: 4.1861e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5918e-05 - val_loss: 4.3729e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6162e-05 - val_loss: 4.0148e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1497e-05 - val_loss: 8.7973e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5155e-05 - val_loss: 4.4558e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7101e-05 - val_loss: 4.2642e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.0513e-05 - val_loss: 1.3934e-04\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6312e-05 - val_loss: 4.4875e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3506e-05 - val_loss: 3.9675e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3311e-05 - val_loss: 8.6053e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 1.3597e-04 - val_loss: 0.0012\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.2492e-05 - val_loss: 7.8020e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 8.6994e-05 - val_loss: 2.1952e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 1.1467e-04 - val_loss: 3.8418e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.2657e-05 - val_loss: 2.1672e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.3824e-05 - val_loss: 9.1149e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 6.9759e-05 - val_loss: 6.5294e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 9.0229e-05 - val_loss: 6.9539e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.6846e-05 - val_loss: 1.2902e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.3669e-05 - val_loss: 1.2387e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4738e-05 - val_loss: 8.6306e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.2792e-05 - val_loss: 8.7554e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5407e-05 - val_loss: 1.1079e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8240e-05 - val_loss: 5.1793e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6025e-05 - val_loss: 1.1999e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.6091e-05 - val_loss: 5.6445e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 6.5999e-05 - val_loss: 5.8867e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.8562e-05 - val_loss: 5.3108e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.0831e-05 - val_loss: 7.4640e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.6342e-05 - val_loss: 1.4154e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9098e-05 - val_loss: 7.8777e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9103e-05 - val_loss: 2.5816e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7226e-05 - val_loss: 9.3361e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7329e-05 - val_loss: 5.1170e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4463e-05 - val_loss: 7.1466e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.0981e-05 - val_loss: 1.9198e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2703e-05 - val_loss: 4.4584e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.0047e-05 - val_loss: 7.1821e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0805e-05 - val_loss: 6.3818e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0468e-05 - val_loss: 7.6242e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4041e-05 - val_loss: 4.5768e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7224e-05 - val_loss: 8.1441e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.8876e-05 - val_loss: 4.2069e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0130e-05 - val_loss: 7.0589e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.6687e-05 - val_loss: 2.3309e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0919e-05 - val_loss: 5.0303e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2842e-05 - val_loss: 4.7374e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7913e-05 - val_loss: 9.3361e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 743us/step - loss: 5.1186e-05 - val_loss: 5.1541e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 5.1897e-05 - val_loss: 5.4480e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6443e-05 - val_loss: 4.4587e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6036e-05 - val_loss: 5.0790e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3974e-05 - val_loss: 4.7163e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5313e-05 - val_loss: 1.0291e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7070e-05 - val_loss: 5.1494e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3253e-05 - val_loss: 6.5795e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6356e-05 - val_loss: 5.4430e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6796e-05 - val_loss: 5.1511e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.6474e-05 - val_loss: 6.6417e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2922e-05 - val_loss: 7.2666e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 738us/step - loss: 4.4189e-05 - val_loss: 4.4298e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9384e-05 - val_loss: 7.7033e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6428e-05 - val_loss: 5.4691e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.6935e-05 - val_loss: 5.8563e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5725e-05 - val_loss: 5.0140e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2779e-05 - val_loss: 5.5345e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.1458e-05 - val_loss: 3.9476e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1161e-05 - val_loss: 5.0521e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9507e-05 - val_loss: 5.8969e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4452e-05 - val_loss: 9.1284e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0086e-05 - val_loss: 9.6441e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0768e-05 - val_loss: 7.0216e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4297e-05 - val_loss: 5.2820e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2547e-05 - val_loss: 5.3847e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2330e-05 - val_loss: 4.9293e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9837e-05 - val_loss: 4.1851e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4747e-05 - val_loss: 8.5575e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7377e-05 - val_loss: 7.4941e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.2066e-05 - val_loss: 1.2693e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8969e-05 - val_loss: 7.5034e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2909e-05 - val_loss: 1.0890e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5705e-05 - val_loss: 5.7513e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6448e-05 - val_loss: 5.2188e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3943e-05 - val_loss: 5.4273e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 4.3486e-05 - val_loss: 7.1364e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3916e-05 - val_loss: 5.1481e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5726e-05 - val_loss: 4.7353e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8262e-05 - val_loss: 5.8537e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8421e-05 - val_loss: 1.0551e-04\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4862e-05 - val_loss: 4.4912e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1270e-05 - val_loss: 4.5987e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0030 - val_loss: 0.0083\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 1.9201e-04 - val_loss: 0.0029\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 1.2082e-04 - val_loss: 0.0012\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 9.5882e-05 - val_loss: 7.0721e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.9741e-05 - val_loss: 1.6126e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.2024e-05 - val_loss: 6.2895e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.7604e-05 - val_loss: 9.5771e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.3520e-05 - val_loss: 6.2102e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.3506e-05 - val_loss: 1.9393e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.9532e-05 - val_loss: 4.6314e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8680e-05 - val_loss: 5.5716e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2528e-05 - val_loss: 6.8004e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1921e-05 - val_loss: 7.1409e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.5166e-05 - val_loss: 6.5402e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7746e-05 - val_loss: 4.2185e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2758e-05 - val_loss: 9.4746e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.4519e-05 - val_loss: 4.7966e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0977e-05 - val_loss: 6.1341e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6983e-05 - val_loss: 4.2261e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9357e-05 - val_loss: 5.2598e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.3387e-05 - val_loss: 7.7296e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0718e-05 - val_loss: 6.2867e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.9353e-05 - val_loss: 8.2264e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.3713e-05 - val_loss: 5.6696e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.4918e-05 - val_loss: 4.2327e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7188e-05 - val_loss: 1.4507e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 5.4220e-05 - val_loss: 6.6362e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.3634e-05 - val_loss: 4.7311e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8302e-05 - val_loss: 8.1909e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4494e-05 - val_loss: 4.9175e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.3963e-05 - val_loss: 4.2642e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.3346e-05 - val_loss: 1.8720e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2081e-05 - val_loss: 3.9489e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7633e-05 - val_loss: 1.7257e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.3723e-05 - val_loss: 1.0897e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2107e-05 - val_loss: 5.6743e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 6.0742e-05 - val_loss: 6.2046e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6261e-05 - val_loss: 3.1359e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5903e-05 - val_loss: 5.4332e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.0714e-05 - val_loss: 4.4932e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4593e-05 - val_loss: 6.3887e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2848e-05 - val_loss: 3.9242e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9125e-05 - val_loss: 4.0090e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 4.6424e-05 - val_loss: 4.3247e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0333e-05 - val_loss: 6.3518e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 6.5735e-05 - val_loss: 5.6690e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1057e-05 - val_loss: 6.4650e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.9650e-05 - val_loss: 1.3229e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3576e-05 - val_loss: 7.1047e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9942e-05 - val_loss: 8.5268e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8549e-05 - val_loss: 5.0750e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9480e-05 - val_loss: 3.9379e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6019e-05 - val_loss: 4.0710e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3787e-05 - val_loss: 4.2438e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5631e-05 - val_loss: 4.8326e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.5118e-05 - val_loss: 5.3223e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6176e-05 - val_loss: 7.4796e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5958e-05 - val_loss: 4.6029e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8101e-05 - val_loss: 3.9360e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.8083e-05 - val_loss: 5.1770e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7497e-05 - val_loss: 3.9740e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.4697e-05 - val_loss: 6.8736e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.4625e-05 - val_loss: 4.5536e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1342e-05 - val_loss: 5.5182e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5814e-05 - val_loss: 6.1724e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.0602e-05 - val_loss: 3.9580e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 5.4774e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 1.1854e-04 - val_loss: 2.7755e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.5414e-05 - val_loss: 8.9258e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.7982e-05 - val_loss: 7.3312e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.4424e-05 - val_loss: 9.3424e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 9.2296e-05 - val_loss: 2.0358e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.1949e-05 - val_loss: 5.2248e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.3678e-05 - val_loss: 1.5128e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 9.2382e-05 - val_loss: 5.2296e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 1.0285e-04 - val_loss: 2.3021e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 7.9040e-05 - val_loss: 6.1496e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 9.2205e-05 - val_loss: 5.9635e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 1.1850e-04 - val_loss: 2.7435e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 9.6901e-05 - val_loss: 7.2610e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5813e-05 - val_loss: 2.7472e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.5168e-05 - val_loss: 5.0597e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.5689e-05 - val_loss: 4.7641e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.3904e-05 - val_loss: 6.7553e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1937e-05 - val_loss: 4.6175e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.3504e-05 - val_loss: 7.4957e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.4764e-05 - val_loss: 1.7589e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 9.2097e-05 - val_loss: 1.3693e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.5600e-05 - val_loss: 1.3600e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.2785e-05 - val_loss: 4.6377e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.5708e-05 - val_loss: 6.1535e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.4676e-05 - val_loss: 7.4488e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.6664e-05 - val_loss: 1.9281e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 762us/step - loss: 6.4645e-05 - val_loss: 5.6466e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 5.3302e-05 - val_loss: 6.5140e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.8228e-05 - val_loss: 7.0313e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.6602e-05 - val_loss: 7.5298e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.3932e-05 - val_loss: 4.0623e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.8597e-05 - val_loss: 8.8258e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9597e-05 - val_loss: 6.7320e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.6707e-05 - val_loss: 4.4679e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9786e-05 - val_loss: 4.3357e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.3708e-05 - val_loss: 8.9308e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.6958e-05 - val_loss: 4.6289e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1370e-05 - val_loss: 7.0883e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3198e-05 - val_loss: 4.4695e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.7955e-05 - val_loss: 5.4332e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.9383e-05 - val_loss: 4.0874e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.9432e-05 - val_loss: 6.5767e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.1021e-05 - val_loss: 1.4223e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4265e-05 - val_loss: 5.4175e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.5908e-05 - val_loss: 4.7377e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.8672e-05 - val_loss: 4.3819e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8038e-05 - val_loss: 6.4850e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6276e-05 - val_loss: 6.0184e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8017e-05 - val_loss: 1.3668e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.5942e-05 - val_loss: 8.9125e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3294e-05 - val_loss: 4.2323e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.5198e-05 - val_loss: 8.3847e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9885e-05 - val_loss: 5.4280e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2691e-05 - val_loss: 5.7210e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.4604e-05 - val_loss: 4.3506e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.8249e-05 - val_loss: 1.4724e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.4021e-05 - val_loss: 4.5304e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.4768e-05 - val_loss: 6.4530e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1279e-05 - val_loss: 8.2235e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6546e-05 - val_loss: 4.2833e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9125e-05 - val_loss: 4.4650e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.5958e-05 - val_loss: 1.3506e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.7967e-05 - val_loss: 4.3694e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.0242e-05 - val_loss: 6.0051e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0348e-05 - val_loss: 5.9408e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_11\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 1.3682e-04 - val_loss: 4.0493e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 9.2382e-05 - val_loss: 2.0299e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 7.4217e-05 - val_loss: 1.0380e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 7.4282e-05 - val_loss: 1.9721e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.2093e-05 - val_loss: 5.8927e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.6620e-05 - val_loss: 1.1858e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.0560e-05 - val_loss: 1.0210e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.3611e-05 - val_loss: 5.7665e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.7628e-05 - val_loss: 5.8147e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.3585e-05 - val_loss: 1.0062e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 8.4218e-05 - val_loss: 1.5846e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 9.3845e-05 - val_loss: 5.9731e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6717e-05 - val_loss: 5.1347e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.6483e-05 - val_loss: 5.2906e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.9125e-05 - val_loss: 1.3749e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.0033e-05 - val_loss: 5.1913e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.2321e-05 - val_loss: 4.9203e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.9752e-05 - val_loss: 4.8593e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 1.0215e-04 - val_loss: 4.9841e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9393e-05 - val_loss: 7.1803e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.5910e-05 - val_loss: 9.0397e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.5066e-05 - val_loss: 6.2538e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 756us/step - loss: 7.7239e-05 - val_loss: 1.0154e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.4044e-05 - val_loss: 4.8013e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 8.7187e-05 - val_loss: 8.6201e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.2442e-05 - val_loss: 6.0115e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.5035e-05 - val_loss: 4.8912e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2056e-05 - val_loss: 8.9220e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6727e-05 - val_loss: 4.5561e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.0089e-05 - val_loss: 9.8723e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.7828e-05 - val_loss: 5.5157e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.8994e-05 - val_loss: 5.4081e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 744us/step - loss: 6.6878e-05 - val_loss: 5.1845e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.2024e-05 - val_loss: 8.4919e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 869us/step - loss: 5.8325e-05 - val_loss: 5.1559e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0853e-05 - val_loss: 4.7683e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8767e-05 - val_loss: 7.8887e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.9883e-05 - val_loss: 6.1429e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3592e-05 - val_loss: 5.5797e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6723e-05 - val_loss: 4.4054e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.3750e-05 - val_loss: 1.3352e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.4567e-05 - val_loss: 1.4358e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.1893e-05 - val_loss: 1.5812e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7213e-05 - val_loss: 1.9305e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2242e-05 - val_loss: 4.7066e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.8869e-05 - val_loss: 1.2886e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.8825e-05 - val_loss: 4.4587e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1950e-05 - val_loss: 6.6259e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8071e-05 - val_loss: 1.3662e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2133e-05 - val_loss: 1.0384e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5302e-05 - val_loss: 4.4947e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4507e-05 - val_loss: 8.8270e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5488e-05 - val_loss: 5.0730e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1690e-05 - val_loss: 5.2059e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3380e-05 - val_loss: 4.9598e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4645e-05 - val_loss: 5.6040e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2717e-05 - val_loss: 4.1771e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6106e-05 - val_loss: 5.9309e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7518e-05 - val_loss: 1.1822e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0696e-05 - val_loss: 4.6387e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.4317e-05 - val_loss: 6.5110e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1536e-05 - val_loss: 4.7516e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1474e-05 - val_loss: 9.7394e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7585e-05 - val_loss: 4.5093e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1609e-05 - val_loss: 4.9048e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9441e-05 - val_loss: 1.2606e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.9184e-05 - val_loss: 4.4748e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5318e-05 - val_loss: 5.2880e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9786e-05 - val_loss: 7.2850e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0730e-05 - val_loss: 5.1956e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1903e-05 - val_loss: 1.3794e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7051e-05 - val_loss: 4.2869e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 5.0742e-05 - val_loss: 4.1651e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6873e-05 - val_loss: 4.9991e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8406e-05 - val_loss: 4.5228e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7849e-05 - val_loss: 1.0536e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9301e-05 - val_loss: 4.5382e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8189e-05 - val_loss: 5.4744e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8949e-05 - val_loss: 4.4181e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9174e-05 - val_loss: 4.1821e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1012e-05 - val_loss: 1.2175e-04\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7377e-05 - val_loss: 4.3642e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.3281e-05 - val_loss: 4.2584e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7763e-05 - val_loss: 9.6464e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8534e-05 - val_loss: 5.5923e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9465e-05 - val_loss: 3.9061e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1581e-05 - val_loss: 4.8471e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2591e-05 - val_loss: 4.7808e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4241e-05 - val_loss: 7.7285e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.3314e-05 - val_loss: 4.2474e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7409e-05 - val_loss: 3.7925e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5745e-05 - val_loss: 4.5694e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9773e-05 - val_loss: 5.5925e-05\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.8325e-05 - val_loss: 4.3799e-05\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5220e-05 - val_loss: 4.2835e-05\n",
      "Epoch 97/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2569e-05 - val_loss: 1.1392e-04\n",
      "Epoch 98/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.9068e-05 - val_loss: 4.8331e-05\n",
      "Epoch 99/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 4.3301e-05 - val_loss: 3.8605e-05\n",
      "Epoch 100/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 4.1606e-05 - val_loss: 4.3270e-05\n",
      "Epoch 101/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 4.2259e-05 - val_loss: 6.3299e-05\n",
      "Epoch 102/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6180e-05 - val_loss: 5.0157e-05\n",
      "Epoch 103/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.0183e-05 - val_loss: 4.6353e-05\n",
      "Epoch 104/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5486e-05 - val_loss: 4.7391e-05\n",
      "Epoch 105/2000\n",
      "183/183 [==============================] - 0s 873us/step - loss: 4.6372e-05 - val_loss: 9.0882e-05\n",
      "Epoch 106/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.2102e-05 - val_loss: 4.4191e-05\n",
      "Epoch 107/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6270e-05 - val_loss: 4.2410e-05\n",
      "Epoch 108/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.1580e-05 - val_loss: 7.0394e-05\n",
      "Epoch 109/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2660e-05 - val_loss: 4.8539e-05\n",
      "Epoch 110/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3559e-05 - val_loss: 1.3727e-04\n",
      "Epoch 111/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8681e-05 - val_loss: 3.9639e-05\n",
      "Epoch 112/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.1232e-05 - val_loss: 4.9624e-05\n",
      "Epoch 113/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 4.0044e-05 - val_loss: 4.0252e-05\n",
      "Epoch 114/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.1637e-05 - val_loss: 7.2355e-05\n",
      "Epoch 115/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7869e-05 - val_loss: 6.5977e-05\n",
      "Epoch 116/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.3271e-05 - val_loss: 4.2696e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_12\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.9817e-05 - val_loss: 0.0011\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.7650e-05 - val_loss: 2.9407e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.9598e-05 - val_loss: 5.1162e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.6328e-05 - val_loss: 1.4801e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.6103e-05 - val_loss: 6.9029e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.4983e-05 - val_loss: 1.3973e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9850e-05 - val_loss: 5.2134e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 1.0603e-04 - val_loss: 2.3118e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2794e-05 - val_loss: 2.0625e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 9.9043e-05 - val_loss: 8.4985e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.3573e-05 - val_loss: 8.3931e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.5734e-05 - val_loss: 8.6955e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.9774e-05 - val_loss: 6.0720e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.8135e-05 - val_loss: 6.0519e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.0223e-05 - val_loss: 1.7938e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 7.0034e-05 - val_loss: 5.3432e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.7001e-05 - val_loss: 6.4634e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 7.5795e-05 - val_loss: 9.7161e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.4264e-05 - val_loss: 5.4779e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.8070e-05 - val_loss: 4.7483e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.5527e-05 - val_loss: 1.4432e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.6076e-05 - val_loss: 7.3834e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.1573e-05 - val_loss: 1.5696e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.2310e-05 - val_loss: 1.6701e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1842e-05 - val_loss: 4.8553e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.7208e-05 - val_loss: 6.7050e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.8451e-05 - val_loss: 4.7043e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.7146e-05 - val_loss: 1.1207e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8639e-05 - val_loss: 1.1745e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6035e-05 - val_loss: 4.3658e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.4301e-05 - val_loss: 5.2840e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7200e-05 - val_loss: 4.9202e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 7.0208e-05 - val_loss: 4.7804e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5692e-05 - val_loss: 6.2860e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.3128e-05 - val_loss: 5.4700e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9038e-05 - val_loss: 7.8047e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.3153e-05 - val_loss: 1.3221e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1681e-05 - val_loss: 8.6163e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.8141e-05 - val_loss: 8.6646e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9468e-05 - val_loss: 6.3891e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8511e-05 - val_loss: 1.3005e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8399e-05 - val_loss: 1.0532e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3735e-05 - val_loss: 7.0818e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2543e-05 - val_loss: 7.3655e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1885e-05 - val_loss: 8.0598e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.1365e-05 - val_loss: 6.4388e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2537e-05 - val_loss: 9.1016e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.5108e-05 - val_loss: 9.2290e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.2538e-05 - val_loss: 5.3312e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3462e-05 - val_loss: 8.2779e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.1087e-05 - val_loss: 1.2656e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2300e-05 - val_loss: 4.1912e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 5.3172e-05 - val_loss: 4.2113e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2164e-05 - val_loss: 7.5432e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1525e-05 - val_loss: 1.0899e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 5.7046e-05 - val_loss: 5.2534e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8873e-05 - val_loss: 1.0467e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.5244e-05 - val_loss: 4.6836e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3189e-05 - val_loss: 5.5956e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8852e-05 - val_loss: 8.4544e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4460e-05 - val_loss: 5.2304e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 6.1269e-05 - val_loss: 4.0956e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0442e-05 - val_loss: 4.3609e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 5.0829e-05 - val_loss: 6.0165e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8585e-05 - val_loss: 1.4822e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3286e-05 - val_loss: 1.0646e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7777e-05 - val_loss: 4.2378e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7564e-05 - val_loss: 1.4202e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8654e-05 - val_loss: 5.1750e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6832e-05 - val_loss: 8.5069e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1132e-05 - val_loss: 7.1879e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6118e-05 - val_loss: 1.0799e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7234e-05 - val_loss: 5.7799e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6186e-05 - val_loss: 6.6373e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 4.7807e-05 - val_loss: 4.3027e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2612e-05 - val_loss: 4.8123e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0791e-05 - val_loss: 4.2008e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 785us/step - loss: 4.8407e-05 - val_loss: 5.4031e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4094e-05 - val_loss: 4.5815e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0405e-05 - val_loss: 5.0074e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.7556e-05 - val_loss: 6.0155e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1108e-05 - val_loss: 5.1425e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8237e-05 - val_loss: 5.5262e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2934e-05 - val_loss: 6.5264e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 4.5929e-05 - val_loss: 4.3056e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6669e-05 - val_loss: 4.7352e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_13\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_13\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 6.8378e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.3481e-05 - val_loss: 1.2027e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3256e-05 - val_loss: 5.6824e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0386e-05 - val_loss: 7.3093e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.0338e-05 - val_loss: 6.1907e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.2604e-05 - val_loss: 9.3333e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.4281e-05 - val_loss: 1.1264e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.8564e-05 - val_loss: 5.9912e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.4486e-05 - val_loss: 5.0050e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6572e-05 - val_loss: 4.9309e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.9040e-05 - val_loss: 8.1615e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3909e-05 - val_loss: 4.7256e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.8601e-05 - val_loss: 5.4417e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9807e-05 - val_loss: 5.2316e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 7.6784e-05 - val_loss: 6.2230e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.3146e-05 - val_loss: 5.8419e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.6184e-05 - val_loss: 5.3955e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7053e-05 - val_loss: 4.9213e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.5332e-05 - val_loss: 5.1128e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0610e-05 - val_loss: 1.0666e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3772e-05 - val_loss: 4.7661e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0364e-05 - val_loss: 5.7814e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.3421e-05 - val_loss: 7.8889e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3208e-05 - val_loss: 5.5439e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.5120e-05 - val_loss: 9.2181e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3651e-05 - val_loss: 4.9180e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.9712e-05 - val_loss: 7.3020e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7249e-05 - val_loss: 7.8129e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.3750e-05 - val_loss: 4.3533e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6999e-05 - val_loss: 8.1733e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2238e-05 - val_loss: 5.1357e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1985e-05 - val_loss: 4.5396e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.1934e-05 - val_loss: 5.7522e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0583e-05 - val_loss: 1.9380e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4761e-05 - val_loss: 4.3936e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3911e-05 - val_loss: 4.1213e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3107e-05 - val_loss: 6.2736e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5784e-05 - val_loss: 6.3411e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0837e-05 - val_loss: 8.0001e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3089e-05 - val_loss: 4.8949e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 6.2165e-05 - val_loss: 7.5225e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.5436e-05 - val_loss: 5.6187e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2835e-05 - val_loss: 4.4752e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.5114e-05 - val_loss: 1.0276e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7518e-05 - val_loss: 4.4481e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 874us/step - loss: 4.8898e-05 - val_loss: 1.0315e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.1796e-05 - val_loss: 5.3535e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 4.9165e-05 - val_loss: 5.3324e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4263e-05 - val_loss: 6.9065e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1091e-05 - val_loss: 4.9696e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1344e-05 - val_loss: 4.9796e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8613e-05 - val_loss: 4.3983e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.3562e-05 - val_loss: 4.9855e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7518e-05 - val_loss: 8.4136e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5555e-05 - val_loss: 4.3490e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 4.6258e-05 - val_loss: 4.2431e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9465e-05 - val_loss: 4.7451e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0399e-05 - val_loss: 1.2534e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8865e-05 - val_loss: 3.9770e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.8214e-05 - val_loss: 6.7873e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5989e-05 - val_loss: 4.8465e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.6161e-05 - val_loss: 9.7389e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9549e-05 - val_loss: 1.2849e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9199e-05 - val_loss: 4.0909e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7267e-05 - val_loss: 5.2600e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7772e-05 - val_loss: 5.7511e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3905e-05 - val_loss: 6.6478e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5644e-05 - val_loss: 4.7345e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4853e-05 - val_loss: 5.5068e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7877e-05 - val_loss: 5.9521e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2545e-05 - val_loss: 7.8485e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9604e-05 - val_loss: 4.1652e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.1178e-05 - val_loss: 4.9286e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1302e-05 - val_loss: 4.4802e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2483e-05 - val_loss: 5.9623e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7096e-05 - val_loss: 4.6263e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6426e-05 - val_loss: 4.2539e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5846e-05 - val_loss: 5.4012e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.4364e-05 - val_loss: 4.2949e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1971e-05 - val_loss: 4.2576e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8985e-05 - val_loss: 6.7768e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2306e-05 - val_loss: 4.3659e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6931e-05 - val_loss: 5.1301e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_14\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_14\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0089 - val_loss: 0.0011\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 9.6630e-05 - val_loss: 3.3210e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.6130e-05 - val_loss: 1.0637e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.6849e-05 - val_loss: 8.9160e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0971e-05 - val_loss: 1.0555e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6707e-05 - val_loss: 7.3590e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4319e-05 - val_loss: 5.9637e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2345e-05 - val_loss: 5.4004e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2609e-05 - val_loss: 6.3005e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9389e-05 - val_loss: 4.3517e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0816e-05 - val_loss: 8.2341e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0200e-05 - val_loss: 5.4913e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4781e-05 - val_loss: 4.7411e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9016e-05 - val_loss: 1.0797e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8714e-05 - val_loss: 5.8706e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0598e-05 - val_loss: 7.5322e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2621e-05 - val_loss: 4.9316e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8959e-05 - val_loss: 4.8416e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2553e-05 - val_loss: 4.6162e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1991e-05 - val_loss: 9.4865e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9876e-05 - val_loss: 4.8909e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3576e-05 - val_loss: 7.9893e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8367e-05 - val_loss: 4.6411e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3642e-05 - val_loss: 4.0841e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8466e-05 - val_loss: 2.6400e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1739e-05 - val_loss: 1.2827e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2840e-05 - val_loss: 4.1340e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.0060e-05 - val_loss: 7.5349e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0721e-05 - val_loss: 1.0631e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.9769e-05 - val_loss: 5.9836e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2064e-05 - val_loss: 4.4768e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 729us/step - loss: 6.1420e-05 - val_loss: 8.4902e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1262e-05 - val_loss: 9.3226e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 5.7302e-05 - val_loss: 1.0193e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 6.3998e-05 - val_loss: 4.9446e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3385e-05 - val_loss: 4.6822e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 5.8129e-05 - val_loss: 5.8218e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3009e-05 - val_loss: 4.4031e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1642e-05 - val_loss: 3.8943e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4995e-05 - val_loss: 6.8147e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3416e-05 - val_loss: 8.8968e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 5.4604e-05 - val_loss: 9.8252e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4244e-05 - val_loss: 5.0545e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 5.3458e-05 - val_loss: 6.1246e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7968e-05 - val_loss: 5.7531e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3901e-05 - val_loss: 3.9560e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 4.8315e-05 - val_loss: 4.2298e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4812e-05 - val_loss: 5.0230e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0692e-05 - val_loss: 4.7036e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7585e-05 - val_loss: 6.1919e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6795e-05 - val_loss: 4.0723e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.9740e-05 - val_loss: 2.0129e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0376e-05 - val_loss: 3.9421e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 4.4006e-05 - val_loss: 5.8443e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4257e-05 - val_loss: 7.6606e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1597e-05 - val_loss: 4.7474e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.8526e-05 - val_loss: 4.5827e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7984e-05 - val_loss: 9.1827e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6983e-05 - val_loss: 6.3498e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4493e-05 - val_loss: 4.5597e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9756e-05 - val_loss: 5.5805e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2178e-05 - val_loss: 5.8622e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0459e-05 - val_loss: 3.9883e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_15\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_15\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0050 - val_loss: 0.0012\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.1946e-05 - val_loss: 1.2875e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3408e-05 - val_loss: 6.6670e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7402e-05 - val_loss: 5.3167e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8042e-05 - val_loss: 5.7186e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6499e-05 - val_loss: 6.1068e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.0271e-05 - val_loss: 5.6980e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8321e-05 - val_loss: 5.5088e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7753e-05 - val_loss: 9.1727e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5068e-05 - val_loss: 5.3932e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.8999e-05 - val_loss: 5.1351e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1217e-05 - val_loss: 5.0372e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6825e-05 - val_loss: 6.2125e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.4361e-05 - val_loss: 4.7037e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.5615e-05 - val_loss: 4.9856e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2644e-05 - val_loss: 5.4041e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.0729e-05 - val_loss: 4.5415e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0212e-05 - val_loss: 4.3459e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.4106e-05 - val_loss: 4.8515e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8561e-05 - val_loss: 4.5649e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7938e-05 - val_loss: 4.3782e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0200e-05 - val_loss: 4.4692e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.6195e-05 - val_loss: 4.2459e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1439e-05 - val_loss: 6.8850e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.9992e-05 - val_loss: 4.7739e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2781e-05 - val_loss: 5.2143e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.4174e-05 - val_loss: 4.5973e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.8603e-05 - val_loss: 4.2749e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7523e-05 - val_loss: 1.0490e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 5.5878e-05 - val_loss: 5.4893e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.4604e-05 - val_loss: 6.1255e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.4291e-05 - val_loss: 4.7711e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.9435e-05 - val_loss: 1.6765e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6547e-05 - val_loss: 4.2216e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0291e-05 - val_loss: 4.2461e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.4931e-05 - val_loss: 1.1933e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0983e-05 - val_loss: 5.4478e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.5604e-05 - val_loss: 9.3228e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.6493e-05 - val_loss: 5.1482e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8051e-05 - val_loss: 8.7322e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5481e-05 - val_loss: 4.6050e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3555e-05 - val_loss: 1.0630e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1059e-05 - val_loss: 1.3907e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4542e-05 - val_loss: 5.7818e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 4.8687e-05 - val_loss: 4.8920e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3434e-05 - val_loss: 6.0056e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 4.6441e-05 - val_loss: 4.8608e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2126e-05 - val_loss: 7.1700e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 5.0145e-05 - val_loss: 4.7221e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9574e-05 - val_loss: 5.3319e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4468e-05 - val_loss: 4.1174e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1892e-05 - val_loss: 5.6948e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.7738e-05 - val_loss: 4.6888e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5434e-05 - val_loss: 4.2987e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6088e-05 - val_loss: 5.2834e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.0417e-05 - val_loss: 4.8787e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 4.7823e-05 - val_loss: 6.0204e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 732us/step - loss: 4.7460e-05 - val_loss: 4.0460e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.7265e-05 - val_loss: 1.3276e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0763e-05 - val_loss: 6.9576e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9838e-05 - val_loss: 7.5147e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 5.3778e-05 - val_loss: 4.4604e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0211e-05 - val_loss: 8.3813e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9543e-05 - val_loss: 3.8559e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7818e-05 - val_loss: 4.1500e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.3224e-05 - val_loss: 4.7662e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8253e-05 - val_loss: 7.7492e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9980e-05 - val_loss: 8.0645e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.6786e-05 - val_loss: 4.5582e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.4546e-05 - val_loss: 4.4974e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.7943e-05 - val_loss: 6.0326e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5582e-05 - val_loss: 5.5806e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5025e-05 - val_loss: 1.1774e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.7257e-05 - val_loss: 4.9259e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5840e-05 - val_loss: 4.0685e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.2448e-05 - val_loss: 1.3688e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5346e-05 - val_loss: 4.4384e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.4453e-05 - val_loss: 4.1792e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2803e-05 - val_loss: 6.4547e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 768us/step - loss: 4.4600e-05 - val_loss: 5.2875e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.4257e-05 - val_loss: 3.9482e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 4.6118e-05 - val_loss: 5.6003e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.4799e-05 - val_loss: 4.0603e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 4.3683e-05 - val_loss: 4.2237e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 940us/step - loss: 4.8558e-05 - val_loss: 4.9662e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 4.4537e-05 - val_loss: 3.9731e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.6062e-05 - val_loss: 4.3796e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.5131e-05 - val_loss: 8.9507e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0035 - val_loss: 5.0890e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.1511e-05 - val_loss: 2.8994e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.7641e-05 - val_loss: 1.9217e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.0337e-05 - val_loss: 8.0936e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.0644e-05 - val_loss: 8.6499e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.1681e-05 - val_loss: 5.9977e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.7794e-05 - val_loss: 8.4605e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.8872e-05 - val_loss: 1.0904e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 9.5173e-05 - val_loss: 8.9817e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.7248e-05 - val_loss: 1.0866e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.1691e-05 - val_loss: 1.0764e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.8341e-05 - val_loss: 5.4387e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 8.3277e-05 - val_loss: 1.9116e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.9789e-05 - val_loss: 5.0999e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.8605e-05 - val_loss: 7.7759e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.2310e-05 - val_loss: 7.7337e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.7155e-05 - val_loss: 5.6195e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.5580e-05 - val_loss: 4.9717e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.9833e-05 - val_loss: 5.5279e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.4093e-05 - val_loss: 9.1693e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.0184e-05 - val_loss: 1.3466e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.7160e-05 - val_loss: 1.3728e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.0591e-05 - val_loss: 8.8402e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 8.0611e-05 - val_loss: 4.5214e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 762us/step - loss: 5.7584e-05 - val_loss: 5.4498e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4485e-05 - val_loss: 6.4189e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 745us/step - loss: 5.4940e-05 - val_loss: 4.8453e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6753e-05 - val_loss: 5.0503e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.2760e-05 - val_loss: 4.4006e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.8738e-05 - val_loss: 5.0551e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 754us/step - loss: 5.2037e-05 - val_loss: 4.1370e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.9379e-05 - val_loss: 7.8883e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.7071e-05 - val_loss: 4.5016e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3431e-05 - val_loss: 1.8994e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.3369e-05 - val_loss: 2.0456e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 8.1897e-05 - val_loss: 6.6034e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 769us/step - loss: 6.0271e-05 - val_loss: 6.8995e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 776us/step - loss: 5.6805e-05 - val_loss: 4.3873e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5643e-05 - val_loss: 5.8930e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2077e-05 - val_loss: 8.2345e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.0019e-05 - val_loss: 8.9614e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8177e-05 - val_loss: 9.7945e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7248e-05 - val_loss: 1.6507e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9585e-05 - val_loss: 4.8340e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 4.8216e-05 - val_loss: 6.7571e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6418e-05 - val_loss: 1.6465e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 743us/step - loss: 5.8955e-05 - val_loss: 7.7330e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0242e-05 - val_loss: 4.2032e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7535e-05 - val_loss: 1.0512e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.1405e-05 - val_loss: 6.8056e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3443e-05 - val_loss: 4.9626e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4314e-05 - val_loss: 1.0646e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.7921e-05 - val_loss: 3.2183e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6279e-05 - val_loss: 1.2817e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2282e-05 - val_loss: 4.3375e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_17\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_17\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0055 - val_loss: 0.0014\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 1.3804e-04 - val_loss: 3.7539e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.9478e-05 - val_loss: 8.0758e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0754e-05 - val_loss: 1.1295e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 918us/step - loss: 6.2436e-05 - val_loss: 5.4997e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.6630e-05 - val_loss: 7.5036e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2912e-05 - val_loss: 5.2905e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7366e-05 - val_loss: 6.3212e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.7993e-05 - val_loss: 8.1381e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 929us/step - loss: 5.6026e-05 - val_loss: 5.0253e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5297e-05 - val_loss: 4.6448e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4079e-05 - val_loss: 6.9524e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 5.2192e-05 - val_loss: 7.5986e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.8460e-05 - val_loss: 6.3747e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 6.0103e-05 - val_loss: 5.3030e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 7.1218e-05 - val_loss: 4.5470e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 5.9895e-05 - val_loss: 5.5663e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8751e-05 - val_loss: 9.3522e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5565e-05 - val_loss: 5.2527e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3014e-05 - val_loss: 4.8344e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.2691e-05 - val_loss: 7.0781e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 5.6230e-05 - val_loss: 1.5542e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.2839e-05 - val_loss: 1.3216e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1613e-05 - val_loss: 4.5808e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.7715e-05 - val_loss: 5.0927e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 5.0635e-05 - val_loss: 3.0172e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 968us/step - loss: 5.7246e-05 - val_loss: 4.4175e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 5.1322e-05 - val_loss: 5.4072e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.3046e-05 - val_loss: 5.2403e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 766us/step - loss: 6.2276e-05 - val_loss: 5.7767e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 4.7674e-05 - val_loss: 8.5998e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 813us/step - loss: 5.9091e-05 - val_loss: 4.1925e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 5.2817e-05 - val_loss: 4.2588e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.7018e-05 - val_loss: 4.1961e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1046e-05 - val_loss: 4.2092e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.9415e-05 - val_loss: 4.9408e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 5.0288e-05 - val_loss: 4.8388e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 935us/step - loss: 5.3273e-05 - val_loss: 5.2931e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 4.9059e-05 - val_loss: 4.6589e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 852us/step - loss: 5.3905e-05 - val_loss: 1.1202e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 4.7531e-05 - val_loss: 4.4895e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 5.1461e-05 - val_loss: 8.3390e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 5.0138e-05 - val_loss: 4.4054e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 6.4670e-05 - val_loss: 8.8627e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 5.3131e-05 - val_loss: 6.5276e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 6.3163e-05 - val_loss: 3.8873e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 5.0210e-05 - val_loss: 4.1304e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 4.5010e-05 - val_loss: 5.2465e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 5.6560e-05 - val_loss: 1.9507e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 4.8212e-05 - val_loss: 4.2543e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 5.1735e-05 - val_loss: 4.2437e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 4.5345e-05 - val_loss: 4.7901e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 5.4340e-05 - val_loss: 7.2986e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 4.6017e-05 - val_loss: 3.8119e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 4.5967e-05 - val_loss: 1.9825e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 6.3652e-05 - val_loss: 4.0044e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 5.2142e-05 - val_loss: 5.7573e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 4.7804e-05 - val_loss: 7.0717e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 4.7729e-05 - val_loss: 4.1827e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 4.8650e-05 - val_loss: 5.6561e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 4.1707e-05 - val_loss: 9.7861e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 5.0822e-05 - val_loss: 7.5467e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 5.0219e-05 - val_loss: 6.2285e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 8.0169e-05 - val_loss: 5.2630e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3823e-05 - val_loss: 5.6491e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6723e-05 - val_loss: 7.0445e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2432e-05 - val_loss: 5.0805e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.1672e-05 - val_loss: 5.7311e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8829e-05 - val_loss: 1.8495e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6407e-05 - val_loss: 4.0836e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3504e-05 - val_loss: 4.8587e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2687e-05 - val_loss: 5.1821e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7673e-05 - val_loss: 5.3310e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8939e-05 - val_loss: 5.4782e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 4.4061e-05 - val_loss: 1.3954e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.9142e-05 - val_loss: 4.3859e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.2911e-05 - val_loss: 4.7401e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3708e-05 - val_loss: 4.5326e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_18\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_18\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0013 - val_loss: 3.9934e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.4254e-05 - val_loss: 2.0956e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 1.0271e-04 - val_loss: 1.6324e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.7228e-05 - val_loss: 6.7214e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 9.3159e-05 - val_loss: 2.5000e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 1.1005e-04 - val_loss: 5.2370e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.7469e-05 - val_loss: 4.7306e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.6179e-05 - val_loss: 3.5653e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 8.7557e-05 - val_loss: 4.4802e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 7.4488e-05 - val_loss: 4.7360e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.8940e-05 - val_loss: 6.6179e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 1.0142e-04 - val_loss: 2.5052e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.6996e-05 - val_loss: 7.2331e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.9957e-05 - val_loss: 5.1429e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.8067e-05 - val_loss: 9.5248e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 7.0809e-05 - val_loss: 9.8824e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 780us/step - loss: 8.1176e-05 - val_loss: 4.0398e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 7.9374e-05 - val_loss: 1.0057e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 6.0888e-05 - val_loss: 7.3559e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.7365e-05 - val_loss: 5.4462e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3978e-05 - val_loss: 4.1840e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6763e-05 - val_loss: 4.1087e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 6.3107e-05 - val_loss: 6.8224e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.5263e-05 - val_loss: 9.7954e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.9691e-05 - val_loss: 2.2070e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.5985e-05 - val_loss: 4.4655e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1033e-05 - val_loss: 7.8364e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4427e-05 - val_loss: 5.6413e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.1806e-05 - val_loss: 1.4520e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3536e-05 - val_loss: 9.7847e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.4161e-05 - val_loss: 2.0046e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.5606e-05 - val_loss: 7.0503e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6135e-05 - val_loss: 1.3453e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8281e-05 - val_loss: 5.3601e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1090e-05 - val_loss: 5.2870e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8127e-05 - val_loss: 3.9287e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4071e-05 - val_loss: 4.4593e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9833e-05 - val_loss: 3.8097e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9343e-05 - val_loss: 1.4802e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6278e-05 - val_loss: 3.2417e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.8303e-05 - val_loss: 1.7294e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1676e-05 - val_loss: 6.5580e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8204e-05 - val_loss: 4.1607e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9035e-05 - val_loss: 7.9390e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.8660e-05 - val_loss: 8.5771e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6854e-05 - val_loss: 5.9430e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5478e-05 - val_loss: 4.6567e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9178e-05 - val_loss: 1.0313e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6584e-05 - val_loss: 4.5734e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5071e-05 - val_loss: 4.0065e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4228e-05 - val_loss: 4.3267e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3887e-05 - val_loss: 1.8226e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3629e-05 - val_loss: 1.2704e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0480e-05 - val_loss: 4.0957e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0093e-05 - val_loss: 8.1618e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0077e-05 - val_loss: 1.1630e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7787e-05 - val_loss: 8.8045e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.1064e-05 - val_loss: 3.9570e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.4218e-05 - val_loss: 9.2284e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8664e-05 - val_loss: 5.0266e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6353e-05 - val_loss: 3.9476e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.3180e-05 - val_loss: 6.4672e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0116 - val_loss: 0.0018\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 9.7785e-05 - val_loss: 0.0013\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.9753e-05 - val_loss: 6.5809e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.6764e-05 - val_loss: 2.9068e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.0538e-05 - val_loss: 2.9593e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6436e-05 - val_loss: 1.1702e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4967e-05 - val_loss: 1.1642e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3862e-05 - val_loss: 6.7353e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7499e-05 - val_loss: 6.9225e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6095e-05 - val_loss: 1.3237e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7759e-05 - val_loss: 8.9056e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7019e-05 - val_loss: 1.1635e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 739us/step - loss: 6.0488e-05 - val_loss: 8.8722e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8144e-05 - val_loss: 2.3748e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0224e-05 - val_loss: 5.5096e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 5.5769e-05 - val_loss: 5.5357e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6791e-05 - val_loss: 4.8418e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9373e-05 - val_loss: 9.6715e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7120e-05 - val_loss: 5.4449e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3553e-05 - val_loss: 5.7005e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0480e-05 - val_loss: 1.2550e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6719e-05 - val_loss: 7.6749e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.3990e-05 - val_loss: 5.5724e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.7967e-05 - val_loss: 4.3399e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.4259e-05 - val_loss: 8.0987e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 743us/step - loss: 6.1850e-05 - val_loss: 5.8696e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 5.5657e-05 - val_loss: 1.0689e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7127e-05 - val_loss: 7.8868e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 6.1360e-05 - val_loss: 7.8428e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 6.1309e-05 - val_loss: 2.0881e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9912e-05 - val_loss: 4.6259e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4038e-05 - val_loss: 5.4351e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6401e-05 - val_loss: 1.0932e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1754e-05 - val_loss: 5.0406e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0327e-05 - val_loss: 6.4245e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8645e-05 - val_loss: 4.3804e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6174e-05 - val_loss: 4.5026e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8803e-05 - val_loss: 1.3260e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5375e-05 - val_loss: 3.9910e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3361e-05 - val_loss: 4.1220e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6981e-05 - val_loss: 4.4788e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1199e-05 - val_loss: 1.0637e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1474e-05 - val_loss: 4.0736e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6361e-05 - val_loss: 4.4172e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3468e-05 - val_loss: 4.3552e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2960e-05 - val_loss: 8.6755e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9129e-05 - val_loss: 2.7353e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9732e-05 - val_loss: 3.9732e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.6430e-05 - val_loss: 2.0250e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7329e-05 - val_loss: 4.3753e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8989e-05 - val_loss: 4.0601e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2070e-05 - val_loss: 4.2025e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2330e-05 - val_loss: 7.5382e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7439e-05 - val_loss: 8.1043e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4339e-05 - val_loss: 6.5065e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3983e-05 - val_loss: 4.6725e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1624e-05 - val_loss: 4.2681e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2204e-05 - val_loss: 1.2061e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6103e-05 - val_loss: 4.0918e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7522e-05 - val_loss: 4.0933e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9014e-05 - val_loss: 4.1150e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2202e-05 - val_loss: 3.9249e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6603e-05 - val_loss: 4.7417e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3614e-05 - val_loss: 4.3859e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5931e-05 - val_loss: 7.3608e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9215e-05 - val_loss: 3.9472e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7916e-05 - val_loss: 4.4905e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3965e-05 - val_loss: 3.9009e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0341e-05 - val_loss: 7.7762e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0191e-05 - val_loss: 4.5463e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9170e-05 - val_loss: 5.7833e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0231e-05 - val_loss: 4.1686e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.5617e-05 - val_loss: 6.6882e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6177e-05 - val_loss: 4.1061e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8789e-05 - val_loss: 6.1733e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9453e-05 - val_loss: 3.9805e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2327e-05 - val_loss: 6.9453e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2263e-05 - val_loss: 4.2862e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6317e-05 - val_loss: 5.9285e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2170e-05 - val_loss: 5.0572e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9745e-05 - val_loss: 3.8341e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.9506e-05 - val_loss: 5.7576e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6792e-05 - val_loss: 4.4728e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.3519e-05 - val_loss: 7.6853e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5652e-05 - val_loss: 4.4499e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3230e-05 - val_loss: 6.0953e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7347e-05 - val_loss: 8.7233e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.0858e-05 - val_loss: 7.5981e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8655e-05 - val_loss: 5.8041e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.0833e-05 - val_loss: 3.9467e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.2157e-05 - val_loss: 3.8026e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 4.2030e-05 - val_loss: 8.2202e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5704e-05 - val_loss: 4.7848e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6227e-05 - val_loss: 5.6950e-05\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 4.1698e-05 - val_loss: 4.0305e-05\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 757us/step - loss: 4.4819e-05 - val_loss: 3.9214e-05\n",
      "Epoch 97/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1330e-05 - val_loss: 4.0376e-05\n",
      "Epoch 98/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3865e-05 - val_loss: 3.7351e-05\n",
      "Epoch 99/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2324e-05 - val_loss: 4.3106e-05\n",
      "Epoch 100/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6487e-05 - val_loss: 5.1646e-05\n",
      "Epoch 101/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7650e-05 - val_loss: 6.1126e-05\n",
      "Epoch 102/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4043e-05 - val_loss: 4.2196e-05\n",
      "Epoch 103/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 4.2818e-05 - val_loss: 4.1593e-05\n",
      "Epoch 104/2000\n",
      "183/183 [==============================] - 0s 820us/step - loss: 4.5881e-05 - val_loss: 3.6682e-05\n",
      "Epoch 105/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 4.1021e-05 - val_loss: 7.0011e-05\n",
      "Epoch 106/2000\n",
      "183/183 [==============================] - 0s 813us/step - loss: 4.2860e-05 - val_loss: 4.3595e-05\n",
      "Epoch 107/2000\n",
      "183/183 [==============================] - 0s 813us/step - loss: 4.3546e-05 - val_loss: 3.8422e-05\n",
      "Epoch 108/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.3242e-05 - val_loss: 3.9267e-05\n",
      "Epoch 109/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 3.8676e-05 - val_loss: 4.4036e-05\n",
      "Epoch 110/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.1769e-05 - val_loss: 3.7488e-05\n",
      "Epoch 111/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 4.2248e-05 - val_loss: 6.8091e-05\n",
      "Epoch 112/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 4.3672e-05 - val_loss: 3.9297e-05\n",
      "Epoch 113/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4404e-05 - val_loss: 4.0727e-05\n",
      "Epoch 114/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 3.9122e-05 - val_loss: 7.8333e-05\n",
      "Epoch 115/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 4.9210e-05 - val_loss: 3.8100e-05\n",
      "Epoch 116/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.1643e-05 - val_loss: 1.2627e-04\n",
      "Epoch 117/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.3209e-05 - val_loss: 6.7575e-05\n",
      "Epoch 118/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.0316e-05 - val_loss: 3.9682e-05\n",
      "Epoch 119/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.1505e-05 - val_loss: 5.7744e-05\n",
      "Epoch 120/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.0448e-05 - val_loss: 4.6232e-05\n",
      "Epoch 121/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.0556e-05 - val_loss: 5.9934e-05\n",
      "Epoch 122/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.3718e-05 - val_loss: 7.8202e-05\n",
      "Epoch 123/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.4982e-05 - val_loss: 4.0810e-05\n",
      "Epoch 124/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9278e-05 - val_loss: 5.0079e-05\n",
      "Epoch 125/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.1644e-05 - val_loss: 3.7157e-05\n",
      "Epoch 126/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.0545e-05 - val_loss: 3.8961e-05\n",
      "Epoch 127/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.1895e-05 - val_loss: 4.5734e-05\n",
      "Epoch 128/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.5456e-05 - val_loss: 5.9718e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_20\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_20\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 1.0536e-04 - val_loss: 0.0019\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 8.6979e-05 - val_loss: 7.2149e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.5158e-05 - val_loss: 4.5600e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 6.9055e-05 - val_loss: 2.6689e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9131e-05 - val_loss: 1.5631e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.6800e-05 - val_loss: 2.9124e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.9513e-05 - val_loss: 7.7617e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.5255e-05 - val_loss: 1.7412e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.9375e-05 - val_loss: 2.9587e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5844e-05 - val_loss: 1.5924e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.5197e-05 - val_loss: 6.3148e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.3858e-05 - val_loss: 1.4211e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.3169e-05 - val_loss: 1.9210e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3791e-05 - val_loss: 4.8136e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.2016e-05 - val_loss: 5.4607e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.6741e-05 - val_loss: 5.8255e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.6917e-05 - val_loss: 2.0796e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1830e-05 - val_loss: 4.6642e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.1730e-05 - val_loss: 1.8398e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.4165e-05 - val_loss: 4.8492e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8957e-05 - val_loss: 7.2621e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 8.4438e-05 - val_loss: 8.4426e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5778e-05 - val_loss: 1.8550e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7041e-05 - val_loss: 1.2097e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8319e-05 - val_loss: 6.4696e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9166e-05 - val_loss: 2.0075e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.8372e-05 - val_loss: 5.7812e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3035e-05 - val_loss: 7.0177e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.2286e-05 - val_loss: 7.7044e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6351e-05 - val_loss: 5.2517e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2543e-05 - val_loss: 7.3218e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2601e-05 - val_loss: 5.3480e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0741e-05 - val_loss: 6.8031e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 4.5071e-05 - val_loss: 4.3517e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.1448e-05 - val_loss: 1.7247e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.3041e-05 - val_loss: 5.5473e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6714e-05 - val_loss: 7.8507e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1969e-05 - val_loss: 5.5144e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.6802e-05 - val_loss: 1.3167e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 4.9273e-05 - val_loss: 6.1633e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1263e-05 - val_loss: 5.1561e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6787e-05 - val_loss: 6.5465e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0673e-05 - val_loss: 5.1636e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5045e-05 - val_loss: 4.2172e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6854e-05 - val_loss: 5.2314e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0578e-05 - val_loss: 4.7255e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2117e-05 - val_loss: 8.6040e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7195e-05 - val_loss: 1.5761e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4118e-05 - val_loss: 9.6538e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1817e-05 - val_loss: 1.4427e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.6887e-05 - val_loss: 5.5629e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0691e-05 - val_loss: 8.8313e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5088e-05 - val_loss: 7.8473e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4574e-05 - val_loss: 5.0462e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.3364e-05 - val_loss: 4.1412e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3130e-05 - val_loss: 8.6516e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9185e-05 - val_loss: 4.3504e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6405e-05 - val_loss: 5.7768e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7932e-05 - val_loss: 4.5876e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4950e-05 - val_loss: 5.8846e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 4.9108e-05 - val_loss: 4.3221e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3390e-05 - val_loss: 5.2920e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6365e-05 - val_loss: 1.5637e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8084e-05 - val_loss: 1.0698e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 5.1408e-05 - val_loss: 4.8089e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.5855e-05 - val_loss: 5.3025e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.9449e-05 - val_loss: 5.0502e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6850e-05 - val_loss: 4.0537e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5521e-05 - val_loss: 4.0224e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.2514e-05 - val_loss: 7.4828e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8369e-05 - val_loss: 3.8567e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4911e-05 - val_loss: 4.8206e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6180e-05 - val_loss: 3.9866e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5350e-05 - val_loss: 5.8444e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4180e-05 - val_loss: 7.4531e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8001e-05 - val_loss: 4.1469e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.3997e-05 - val_loss: 4.7653e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3304e-05 - val_loss: 3.8921e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8396e-05 - val_loss: 4.5443e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.7935e-05 - val_loss: 5.2494e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5991e-05 - val_loss: 4.0300e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.2569e-05 - val_loss: 1.0640e-04\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.8176e-05 - val_loss: 5.9701e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7461e-05 - val_loss: 5.5544e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.3522e-05 - val_loss: 6.1041e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.1633e-05 - val_loss: 6.0734e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8210e-05 - val_loss: 4.6606e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.8612e-05 - val_loss: 5.8844e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.5955e-05 - val_loss: 4.9809e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.2366e-05 - val_loss: 4.6651e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4927e-05 - val_loss: 6.0221e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6876e-05 - val_loss: 4.6030e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6333e-05 - val_loss: 1.4834e-04\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8839e-05 - val_loss: 5.3918e-05\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0148e-05 - val_loss: 7.4422e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_21\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0017 - val_loss: 7.4459e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.7904e-05 - val_loss: 1.3541e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.0733e-05 - val_loss: 7.6067e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1901e-05 - val_loss: 9.6240e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1626e-05 - val_loss: 5.9282e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 745us/step - loss: 6.0072e-05 - val_loss: 6.2892e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 962us/step - loss: 6.4333e-05 - val_loss: 5.3951e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 853us/step - loss: 6.0024e-05 - val_loss: 6.7697e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 834us/step - loss: 7.8257e-05 - val_loss: 5.9074e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 5.5684e-05 - val_loss: 6.2450e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 7.6875e-05 - val_loss: 5.7565e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 6.5918e-05 - val_loss: 4.6427e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 5.8015e-05 - val_loss: 7.8989e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 6.7359e-05 - val_loss: 1.0976e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 6.1920e-05 - val_loss: 1.0410e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 5.4460e-05 - val_loss: 9.5740e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 5.7185e-05 - val_loss: 1.0327e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 7.5941e-05 - val_loss: 7.2093e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 929us/step - loss: 7.1567e-05 - val_loss: 5.6960e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 5.1397e-05 - val_loss: 8.6333e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2195e-05 - val_loss: 4.6468e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4112e-05 - val_loss: 4.3900e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 6.2260e-05 - val_loss: 5.1538e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.1391e-05 - val_loss: 1.6482e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.6524e-05 - val_loss: 9.7251e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7256e-05 - val_loss: 4.8383e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5701e-05 - val_loss: 7.7718e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.5454e-05 - val_loss: 4.2445e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6826e-05 - val_loss: 9.4979e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3930e-05 - val_loss: 4.7458e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 5.0818e-05 - val_loss: 6.7000e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4092e-05 - val_loss: 8.1587e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3417e-05 - val_loss: 4.8237e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1895e-05 - val_loss: 2.2668e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.8867e-05 - val_loss: 9.3818e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0837e-05 - val_loss: 5.5304e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3371e-05 - val_loss: 4.2907e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1078e-05 - val_loss: 6.7912e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1446e-05 - val_loss: 7.7635e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2955e-05 - val_loss: 1.0953e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.3717e-05 - val_loss: 5.6787e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1724e-05 - val_loss: 5.2524e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9714e-05 - val_loss: 7.0653e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2521e-05 - val_loss: 5.1202e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.2536e-05 - val_loss: 4.6256e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3752e-05 - val_loss: 1.1673e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6670e-05 - val_loss: 1.7972e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3291e-05 - val_loss: 9.0280e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.9478e-05 - val_loss: 7.7871e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8006e-05 - val_loss: 8.6943e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4957e-05 - val_loss: 4.8024e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.9331e-05 - val_loss: 1.6121e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_22\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_22\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 2.8693e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1507e-05 - val_loss: 9.4898e-05\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8907e-05 - val_loss: 7.0461e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.5238e-05 - val_loss: 6.0612e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.9177e-05 - val_loss: 6.5244e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.5069e-05 - val_loss: 6.1035e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7125e-05 - val_loss: 8.3905e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.0061e-05 - val_loss: 6.3355e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8738e-05 - val_loss: 1.2435e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 7.5268e-05 - val_loss: 4.9845e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.9757e-05 - val_loss: 4.6052e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.9454e-05 - val_loss: 1.3833e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.2374e-05 - val_loss: 4.9151e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.9604e-05 - val_loss: 4.4383e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.6566e-05 - val_loss: 4.8906e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 8.3190e-05 - val_loss: 5.2363e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2103e-05 - val_loss: 5.1132e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9853e-05 - val_loss: 6.3169e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2137e-05 - val_loss: 1.6210e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8610e-05 - val_loss: 8.6538e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.7298e-05 - val_loss: 2.8496e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.0188e-05 - val_loss: 5.8632e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 6.4978e-05 - val_loss: 6.4412e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8703e-05 - val_loss: 4.6646e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 798us/step - loss: 6.0431e-05 - val_loss: 1.3032e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 7.6573e-05 - val_loss: 6.4157e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 5.8155e-05 - val_loss: 4.3536e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.7491e-05 - val_loss: 3.4579e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 5.7711e-05 - val_loss: 9.6233e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 6.4322e-05 - val_loss: 8.2997e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 6.2280e-05 - val_loss: 1.3993e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 847us/step - loss: 4.5354e-05 - val_loss: 4.3296e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.5975e-05 - val_loss: 6.6955e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.8785e-05 - val_loss: 1.4857e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1562e-05 - val_loss: 4.4107e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8287e-05 - val_loss: 5.4004e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 4.7552e-05 - val_loss: 1.3931e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 6.3177e-05 - val_loss: 1.2781e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2206e-05 - val_loss: 6.9985e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9138e-05 - val_loss: 4.1604e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0868e-05 - val_loss: 4.0385e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.9831e-05 - val_loss: 7.1952e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 4.9475e-05 - val_loss: 5.6871e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1267e-05 - val_loss: 1.5165e-04\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7997e-05 - val_loss: 1.7194e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7209e-05 - val_loss: 1.3376e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2240e-05 - val_loss: 5.1322e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3847e-05 - val_loss: 4.9107e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8154e-05 - val_loss: 8.1374e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1675e-05 - val_loss: 3.8037e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.7965e-05 - val_loss: 4.2200e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.6177e-05 - val_loss: 4.0354e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 5.0382e-05 - val_loss: 4.5495e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5051e-05 - val_loss: 4.2686e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8048e-05 - val_loss: 4.0043e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7708e-05 - val_loss: 3.7893e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7434e-05 - val_loss: 4.9235e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5811e-05 - val_loss: 4.2216e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7370e-05 - val_loss: 5.5137e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9879e-05 - val_loss: 7.9017e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.2087e-05 - val_loss: 1.0495e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6959e-05 - val_loss: 1.0217e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.0342e-05 - val_loss: 4.5925e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.6585e-05 - val_loss: 8.5228e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.7647e-05 - val_loss: 6.7454e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9382e-05 - val_loss: 7.9013e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4280e-05 - val_loss: 9.7434e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 5.0748e-05 - val_loss: 6.0654e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 4.3911e-05 - val_loss: 4.5381e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1473e-05 - val_loss: 9.9793e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.8327e-05 - val_loss: 6.7559e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6459e-05 - val_loss: 4.6117e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3126e-05 - val_loss: 4.4867e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4359e-05 - val_loss: 7.6866e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9963e-05 - val_loss: 5.2680e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2893e-05 - val_loss: 3.8424e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.8153e-05 - val_loss: 8.5030e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.4110e-05 - val_loss: 9.6987e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6811e-05 - val_loss: 4.0049e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2958e-05 - val_loss: 5.6502e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_23\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_23\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 5.3582e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.5222e-05 - val_loss: 2.5275e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.5810e-05 - val_loss: 8.7856e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0284e-05 - val_loss: 6.2365e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8610e-05 - val_loss: 6.2987e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6368e-05 - val_loss: 5.6660e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8281e-05 - val_loss: 9.7934e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.5299e-05 - val_loss: 5.6152e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0045e-05 - val_loss: 4.9379e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.8594e-05 - val_loss: 7.1429e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 5.6425e-05 - val_loss: 5.0820e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7187e-05 - val_loss: 5.0587e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 6.1506e-05 - val_loss: 1.1558e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.9970e-05 - val_loss: 6.2699e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1008e-05 - val_loss: 7.4776e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9563e-05 - val_loss: 1.9654e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.5648e-05 - val_loss: 4.5436e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7754e-05 - val_loss: 1.0285e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.3522e-05 - val_loss: 4.8753e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 5.9309e-05 - val_loss: 1.3522e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 6.4957e-05 - val_loss: 1.3419e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 7.4518e-05 - val_loss: 1.4693e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 6.4682e-05 - val_loss: 1.2235e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.2801e-05 - val_loss: 1.5609e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2266e-05 - val_loss: 4.2426e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.1462e-05 - val_loss: 4.7727e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5773e-05 - val_loss: 7.0279e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5642e-05 - val_loss: 1.1193e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1100e-05 - val_loss: 6.4918e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3066e-05 - val_loss: 7.2225e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 7.4186e-05 - val_loss: 9.1943e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3987e-05 - val_loss: 6.1522e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6754e-05 - val_loss: 1.6972e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6873e-05 - val_loss: 1.3996e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.9896e-05 - val_loss: 5.1973e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6347e-05 - val_loss: 4.8501e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2104e-05 - val_loss: 1.9276e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.2625e-05 - val_loss: 1.6248e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2661e-05 - val_loss: 4.3661e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9508e-05 - val_loss: 4.4419e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6339e-05 - val_loss: 4.3813e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1246e-05 - val_loss: 4.1639e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.0917e-05 - val_loss: 1.7059e-04\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2864e-05 - val_loss: 4.7374e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.0812e-05 - val_loss: 4.7006e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3183e-05 - val_loss: 2.0576e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5933e-05 - val_loss: 5.9685e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2225e-05 - val_loss: 4.6177e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7818e-05 - val_loss: 4.9712e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9689e-05 - val_loss: 6.5945e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.0387e-05 - val_loss: 4.9112e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8034e-05 - val_loss: 7.4421e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7894e-05 - val_loss: 1.1070e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6845e-05 - val_loss: 4.9513e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.3323e-05 - val_loss: 4.3784e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.3258e-05 - val_loss: 1.4295e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8077e-05 - val_loss: 5.8510e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9061e-05 - val_loss: 3.8855e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4321e-05 - val_loss: 4.1592e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1327e-05 - val_loss: 5.1543e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9412e-05 - val_loss: 4.9629e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6190e-05 - val_loss: 5.3003e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.0251e-05 - val_loss: 6.5246e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7035e-05 - val_loss: 3.7571e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6212e-05 - val_loss: 5.0648e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2084e-05 - val_loss: 4.5050e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3975e-05 - val_loss: 3.9255e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9855e-05 - val_loss: 1.3606e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8349e-05 - val_loss: 1.5359e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6732e-05 - val_loss: 5.3948e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4837e-05 - val_loss: 7.7645e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0158e-05 - val_loss: 8.1468e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8472e-05 - val_loss: 9.0735e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4329e-05 - val_loss: 5.0025e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5159e-05 - val_loss: 4.2045e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.1938e-05 - val_loss: 1.0863e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2670e-05 - val_loss: 4.8572e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6169e-05 - val_loss: 8.4965e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9296e-05 - val_loss: 5.7185e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4891e-05 - val_loss: 4.2411e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 729us/step - loss: 4.7093e-05 - val_loss: 4.5600e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.3832e-05 - val_loss: 5.2332e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.2039e-05 - val_loss: 3.9961e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.1234e-05 - val_loss: 5.0240e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.3145e-05 - val_loss: 7.5141e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7304e-05 - val_loss: 4.7623e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7442e-05 - val_loss: 7.9323e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.4579e-05 - val_loss: 7.8771e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_24\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_24\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 9.6698e-05 - val_loss: 5.5445e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2927e-05 - val_loss: 2.4195e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7582e-05 - val_loss: 5.6022e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.0302e-05 - val_loss: 6.8405e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 6.8240e-05 - val_loss: 6.6272e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.0299e-05 - val_loss: 9.0043e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.5628e-05 - val_loss: 4.3879e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.4750e-05 - val_loss: 1.1798e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6066e-05 - val_loss: 4.1634e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 767us/step - loss: 5.7100e-05 - val_loss: 3.9857e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5535e-05 - val_loss: 7.7509e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5728e-05 - val_loss: 4.7488e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.5896e-05 - val_loss: 4.3345e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8927e-05 - val_loss: 1.8771e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3787e-05 - val_loss: 5.0298e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.4831e-05 - val_loss: 4.2170e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4306e-05 - val_loss: 2.0996e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.4600e-05 - val_loss: 1.4748e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8495e-05 - val_loss: 3.8869e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6291e-05 - val_loss: 4.2893e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9223e-05 - val_loss: 8.4077e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2290e-05 - val_loss: 4.1919e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4604e-05 - val_loss: 7.6330e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3695e-05 - val_loss: 1.0138e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.2044e-05 - val_loss: 4.0271e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3057e-05 - val_loss: 4.3848e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5088e-05 - val_loss: 4.7330e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7343e-05 - val_loss: 4.6722e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0188e-05 - val_loss: 5.6993e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7390e-05 - val_loss: 3.9139e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1497e-05 - val_loss: 8.3208e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.1359e-05 - val_loss: 4.2105e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5574e-05 - val_loss: 1.2803e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 7.2311e-05 - val_loss: 1.1114e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.0385e-05 - val_loss: 8.5631e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5012e-05 - val_loss: 4.6205e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4535e-05 - val_loss: 4.9898e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0948e-05 - val_loss: 6.9023e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4876e-05 - val_loss: 6.2242e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1743e-05 - val_loss: 4.3587e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3698e-05 - val_loss: 5.1642e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5527e-05 - val_loss: 5.8952e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2744e-05 - val_loss: 8.9243e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_25\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_25\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0032 - val_loss: 2.1511e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.4137e-05 - val_loss: 7.2571e-05\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.3028e-05 - val_loss: 7.7835e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.1983e-05 - val_loss: 1.1128e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 734us/step - loss: 5.8286e-05 - val_loss: 5.3151e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.4882e-05 - val_loss: 6.0060e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.2086e-05 - val_loss: 1.1997e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1646e-05 - val_loss: 5.5411e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.4084e-05 - val_loss: 5.9101e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.5184e-05 - val_loss: 4.9660e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6685e-05 - val_loss: 4.7292e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.3603e-05 - val_loss: 9.2222e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.3043e-05 - val_loss: 5.2568e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.8788e-05 - val_loss: 5.3091e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.3467e-05 - val_loss: 7.0433e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 8.0993e-05 - val_loss: 7.2521e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7550e-05 - val_loss: 7.7462e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 6.8991e-05 - val_loss: 5.7646e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 6.7403e-05 - val_loss: 5.4287e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.0024e-05 - val_loss: 4.9583e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.8042e-05 - val_loss: 1.3913e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6213e-05 - val_loss: 9.4917e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2680e-05 - val_loss: 9.9810e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 6.3564e-05 - val_loss: 4.7190e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.4193e-05 - val_loss: 4.1570e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7493e-05 - val_loss: 5.4453e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.2876e-05 - val_loss: 6.4647e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3013e-05 - val_loss: 1.1358e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4059e-05 - val_loss: 5.1524e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.5008e-05 - val_loss: 9.9046e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7940e-05 - val_loss: 6.7468e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8031e-05 - val_loss: 4.5390e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.6216e-05 - val_loss: 4.2221e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.5275e-05 - val_loss: 9.1864e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1632e-05 - val_loss: 4.3609e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7615e-05 - val_loss: 1.3798e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0895e-05 - val_loss: 1.2296e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6790e-05 - val_loss: 1.0515e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4480e-05 - val_loss: 9.7823e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5282e-05 - val_loss: 6.4259e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.8642e-05 - val_loss: 5.4371e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6878e-05 - val_loss: 1.2350e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2719e-05 - val_loss: 5.2128e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2090e-05 - val_loss: 4.3665e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9899e-05 - val_loss: 4.3481e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2664e-05 - val_loss: 7.2416e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5596e-05 - val_loss: 4.9650e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8436e-05 - val_loss: 4.1403e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6215e-05 - val_loss: 3.8945e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 5.2505e-05 - val_loss: 4.0196e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.2504e-05 - val_loss: 4.0441e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9074e-05 - val_loss: 4.2864e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6249e-05 - val_loss: 4.3804e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3908e-05 - val_loss: 4.7632e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6961e-05 - val_loss: 4.7509e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6676e-05 - val_loss: 4.2256e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9334e-05 - val_loss: 5.1045e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3949e-05 - val_loss: 4.3637e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2787e-05 - val_loss: 6.3426e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 4.9894e-05 - val_loss: 5.3523e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5739e-05 - val_loss: 1.2608e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5698e-05 - val_loss: 6.2416e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5961e-05 - val_loss: 4.1789e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4767e-05 - val_loss: 4.7711e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6416e-05 - val_loss: 8.0532e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.7213e-05 - val_loss: 5.8112e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.6437e-05 - val_loss: 1.2393e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.2241e-05 - val_loss: 5.8959e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7395e-05 - val_loss: 2.0698e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5007e-05 - val_loss: 5.0926e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3799e-05 - val_loss: 3.7709e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.4724e-05 - val_loss: 5.2167e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6177e-05 - val_loss: 4.9368e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6621e-05 - val_loss: 5.5130e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5921e-05 - val_loss: 9.3184e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.4638e-05 - val_loss: 6.8488e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3022e-05 - val_loss: 6.6902e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5406e-05 - val_loss: 4.1672e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1780e-05 - val_loss: 4.1398e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9066e-05 - val_loss: 4.1704e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 4.3834e-05 - val_loss: 4.2853e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 4.4837e-05 - val_loss: 4.4920e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7760e-05 - val_loss: 5.8899e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8578e-05 - val_loss: 4.3549e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4047e-05 - val_loss: 5.1687e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1481e-05 - val_loss: 4.0510e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.7612e-05 - val_loss: 6.3668e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.0322e-05 - val_loss: 4.0324e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8293e-05 - val_loss: 5.7906e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6986e-05 - val_loss: 3.9213e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 774us/step - loss: 4.2076e-05 - val_loss: 4.2920e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.0695e-05 - val_loss: 4.9108e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 4.7654e-05 - val_loss: 5.3082e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 4.6716e-05 - val_loss: 1.1061e-04\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5198e-05 - val_loss: 4.8843e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_26\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_26\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 1.1645e-04 - val_loss: 0.0012\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.4435e-05 - val_loss: 2.0149e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.3207e-05 - val_loss: 5.3464e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6121e-05 - val_loss: 5.9823e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5783e-05 - val_loss: 2.5693e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1027e-05 - val_loss: 8.5004e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2443e-05 - val_loss: 4.4832e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.7030e-05 - val_loss: 3.8764e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.0808e-05 - val_loss: 4.1741e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.1279e-05 - val_loss: 5.7069e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1901e-05 - val_loss: 4.4276e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6258e-05 - val_loss: 3.7308e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0141e-05 - val_loss: 4.0174e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 7.1957e-05 - val_loss: 7.7205e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8118e-05 - val_loss: 3.6976e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1483e-05 - val_loss: 4.2993e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4123e-05 - val_loss: 4.3400e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6552e-05 - val_loss: 6.8079e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.3567e-05 - val_loss: 3.0260e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5214e-05 - val_loss: 4.3547e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1010e-05 - val_loss: 4.0877e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.1734e-05 - val_loss: 5.3814e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.3971e-05 - val_loss: 2.1783e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5225e-05 - val_loss: 2.0361e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.0699e-05 - val_loss: 1.2152e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 4.4099e-05 - val_loss: 4.0370e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.6051e-05 - val_loss: 5.2332e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.9027e-05 - val_loss: 6.1452e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5913e-05 - val_loss: 1.8826e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8493e-05 - val_loss: 4.1628e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8563e-05 - val_loss: 3.9550e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1975e-05 - val_loss: 8.6015e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5474e-05 - val_loss: 3.8205e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2207e-05 - val_loss: 5.9584e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0429e-05 - val_loss: 5.7146e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3249e-05 - val_loss: 4.0815e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5373e-05 - val_loss: 4.2048e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2225e-05 - val_loss: 5.6118e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.4334e-05 - val_loss: 6.0785e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_27\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_27\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 6.6189e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.8322e-05 - val_loss: 1.5060e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.3065e-05 - val_loss: 1.7522e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.5327e-05 - val_loss: 5.8225e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1001e-05 - val_loss: 5.4427e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.2997e-05 - val_loss: 7.6927e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.3645e-05 - val_loss: 7.1372e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.7571e-05 - val_loss: 1.0705e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.0200e-05 - val_loss: 5.6138e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.0325e-05 - val_loss: 6.3526e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 7.6036e-05 - val_loss: 6.9283e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 8.0228e-05 - val_loss: 9.9082e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 8.3862e-05 - val_loss: 4.4811e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.4875e-05 - val_loss: 4.5960e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.5908e-05 - val_loss: 4.5753e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0267e-05 - val_loss: 5.0842e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.1744e-05 - val_loss: 6.3829e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5058e-05 - val_loss: 1.3381e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.8875e-05 - val_loss: 4.0481e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.8588e-05 - val_loss: 4.4695e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.1339e-05 - val_loss: 8.2332e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.9728e-05 - val_loss: 7.7378e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4973e-05 - val_loss: 5.5315e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.2891e-05 - val_loss: 1.3724e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.4447e-05 - val_loss: 6.6906e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 8.5725e-05 - val_loss: 4.3468e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2425e-05 - val_loss: 4.2948e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0641e-05 - val_loss: 4.5383e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 6.0038e-05 - val_loss: 4.2676e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4949e-05 - val_loss: 4.9559e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7490e-05 - val_loss: 4.2809e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8585e-05 - val_loss: 4.8498e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3117e-05 - val_loss: 7.5994e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4795e-05 - val_loss: 5.5628e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6249e-05 - val_loss: 5.8370e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1127e-05 - val_loss: 6.1610e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3188e-05 - val_loss: 7.2966e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.0331e-05 - val_loss: 5.4578e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1923e-05 - val_loss: 6.7173e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1885e-05 - val_loss: 4.2431e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6277e-05 - val_loss: 6.9639e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.4161e-05 - val_loss: 1.8047e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1471e-05 - val_loss: 4.4616e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_28\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_28\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0019 - val_loss: 6.2934e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 7.7376e-05 - val_loss: 2.1892e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 6.1016e-05 - val_loss: 5.8458e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6439e-05 - val_loss: 5.8733e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 5.6890e-05 - val_loss: 4.7739e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3358e-05 - val_loss: 5.0314e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.5111e-05 - val_loss: 5.5405e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0778e-05 - val_loss: 6.4301e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.9594e-05 - val_loss: 2.4040e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1832e-05 - val_loss: 4.4299e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9291e-05 - val_loss: 4.4883e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.2781e-05 - val_loss: 4.3305e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9032e-05 - val_loss: 4.0653e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5665e-05 - val_loss: 8.2338e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6460e-05 - val_loss: 5.0962e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6632e-05 - val_loss: 4.4979e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3925e-05 - val_loss: 4.2834e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.5110e-05 - val_loss: 6.4107e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0201e-05 - val_loss: 5.7685e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0799e-05 - val_loss: 4.3030e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.2679e-05 - val_loss: 6.0962e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1503e-05 - val_loss: 4.4472e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9261e-05 - val_loss: 3.9098e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5151e-05 - val_loss: 6.1614e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2879e-05 - val_loss: 5.0947e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1212e-05 - val_loss: 3.9306e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0309e-05 - val_loss: 4.3099e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2981e-05 - val_loss: 7.6329e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.4101e-05 - val_loss: 5.3433e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.4661e-05 - val_loss: 4.5065e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0864e-05 - val_loss: 1.0379e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2206e-05 - val_loss: 4.0538e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.0134e-05 - val_loss: 4.5209e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3942e-05 - val_loss: 8.0289e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7509e-05 - val_loss: 2.7267e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4320e-05 - val_loss: 5.6341e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6643e-05 - val_loss: 7.8845e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9691e-05 - val_loss: 5.1100e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4849e-05 - val_loss: 4.7165e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1077e-05 - val_loss: 5.9271e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7303e-05 - val_loss: 5.0070e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1957e-05 - val_loss: 5.5941e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6222e-05 - val_loss: 3.8289e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 4.4679e-05 - val_loss: 5.2327e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9351e-05 - val_loss: 5.1817e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1112e-05 - val_loss: 4.0950e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2550e-05 - val_loss: 4.2159e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3635e-05 - val_loss: 5.5590e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6512e-05 - val_loss: 4.1664e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1090e-05 - val_loss: 1.0687e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5159e-05 - val_loss: 4.7153e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1825e-05 - val_loss: 4.7254e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 4.4311e-05 - val_loss: 4.2759e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7518e-05 - val_loss: 7.7583e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 743us/step - loss: 4.7241e-05 - val_loss: 4.0353e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2126e-05 - val_loss: 4.1528e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.1117e-05 - val_loss: 5.7367e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 5.5233e-05 - val_loss: 1.0873e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3926e-05 - val_loss: 3.7854e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 743us/step - loss: 4.9111e-05 - val_loss: 3.9548e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4438e-05 - val_loss: 5.4701e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.0723e-05 - val_loss: 3.8054e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 4.3131e-05 - val_loss: 7.2085e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9283e-05 - val_loss: 8.9852e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2825e-05 - val_loss: 6.8005e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8247e-05 - val_loss: 5.9724e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6220e-05 - val_loss: 5.8349e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6375e-05 - val_loss: 6.4040e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6241e-05 - val_loss: 5.2722e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.2068e-05 - val_loss: 3.8764e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.0213e-05 - val_loss: 4.3501e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.3463e-05 - val_loss: 5.6938e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5377e-05 - val_loss: 4.2763e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.4967e-05 - val_loss: 5.8595e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2360e-05 - val_loss: 4.6613e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5774e-05 - val_loss: 1.6344e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8050e-05 - val_loss: 6.1180e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.2349e-05 - val_loss: 3.7540e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5756e-05 - val_loss: 8.0496e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.0985e-05 - val_loss: 4.4458e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.1002e-05 - val_loss: 4.5883e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.1368e-05 - val_loss: 5.7585e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.2459e-05 - val_loss: 4.9183e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6263e-05 - val_loss: 1.6572e-04\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7175e-05 - val_loss: 3.8203e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7102e-05 - val_loss: 8.6829e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 3.9440e-05 - val_loss: 3.9742e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.5687e-05 - val_loss: 3.8459e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6634e-05 - val_loss: 3.8656e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.9999e-05 - val_loss: 4.1350e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.4766e-05 - val_loss: 3.9993e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5002e-05 - val_loss: 8.1157e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.6950e-05 - val_loss: 4.6829e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5706e-05 - val_loss: 4.3198e-05\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.0912e-05 - val_loss: 4.3947e-05\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.8854e-05 - val_loss: 5.0737e-05\n",
      "Epoch 97/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3568e-05 - val_loss: 4.9361e-05\n",
      "Epoch 98/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.8638e-05 - val_loss: 3.7833e-05\n",
      "Epoch 99/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 5.2117e-05 - val_loss: 4.6498e-05\n",
      "Epoch 100/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.4153e-05 - val_loss: 4.1762e-05\n",
      "Epoch 101/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.9501e-05 - val_loss: 4.9704e-05\n",
      "Epoch 102/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4990e-05 - val_loss: 3.8830e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_29\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_29\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 3.4555e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.1249e-05 - val_loss: 2.0892e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.6339e-05 - val_loss: 7.4795e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 7.4730e-05 - val_loss: 7.2794e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3350e-05 - val_loss: 1.9440e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.1063e-05 - val_loss: 1.4304e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.5905e-05 - val_loss: 9.2310e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.9736e-05 - val_loss: 4.9461e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7775e-05 - val_loss: 8.8075e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.9103e-05 - val_loss: 3.6393e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1675e-05 - val_loss: 2.6266e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.3724e-05 - val_loss: 5.1177e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 9.6365e-05 - val_loss: 5.3808e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.8819e-05 - val_loss: 6.7046e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.9006e-05 - val_loss: 4.8458e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0757e-05 - val_loss: 1.4014e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2671e-05 - val_loss: 4.6557e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 734us/step - loss: 6.3499e-05 - val_loss: 7.2684e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0248e-05 - val_loss: 5.3741e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9900e-05 - val_loss: 5.3667e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0588e-05 - val_loss: 4.9495e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.7260e-05 - val_loss: 1.6930e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1065e-05 - val_loss: 4.1236e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6147e-05 - val_loss: 5.9651e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.9870e-05 - val_loss: 7.5920e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0705e-05 - val_loss: 4.5114e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 738us/step - loss: 5.3574e-05 - val_loss: 4.1516e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5282e-05 - val_loss: 4.4549e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3235e-05 - val_loss: 7.3645e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 5.5729e-05 - val_loss: 6.0246e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.9360e-05 - val_loss: 8.4716e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1769e-05 - val_loss: 5.9593e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2379e-05 - val_loss: 9.6947e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3206e-05 - val_loss: 4.2161e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6402e-05 - val_loss: 1.5582e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.2435e-05 - val_loss: 6.0812e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8882e-05 - val_loss: 4.6194e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0457e-05 - val_loss: 4.2769e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1024e-05 - val_loss: 4.3946e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7523e-05 - val_loss: 5.4835e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9894e-05 - val_loss: 5.1095e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3124e-05 - val_loss: 5.5552e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7344e-05 - val_loss: 5.5878e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1581e-05 - val_loss: 4.1860e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6761e-05 - val_loss: 4.5223e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5674e-05 - val_loss: 2.5774e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1861e-05 - val_loss: 6.1080e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_30\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_30\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 1.3784e-04 - val_loss: 9.6005e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 9.1771e-05 - val_loss: 2.6441e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.9397e-05 - val_loss: 1.0494e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.5367e-05 - val_loss: 1.4511e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.0671e-05 - val_loss: 7.3812e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.0970e-05 - val_loss: 6.8350e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.2286e-05 - val_loss: 1.0906e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.6584e-05 - val_loss: 7.4805e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.5854e-05 - val_loss: 6.4661e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 6.6837e-05 - val_loss: 5.6294e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.8193e-05 - val_loss: 1.0403e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.8027e-05 - val_loss: 7.1811e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3627e-05 - val_loss: 1.9730e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.2950e-05 - val_loss: 5.2248e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.3249e-05 - val_loss: 4.9420e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.3867e-05 - val_loss: 8.0198e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.0731e-05 - val_loss: 1.3338e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.5449e-05 - val_loss: 2.0434e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8410e-05 - val_loss: 4.9742e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7512e-05 - val_loss: 6.2163e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6545e-05 - val_loss: 1.5797e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8135e-05 - val_loss: 8.2848e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6727e-05 - val_loss: 5.3716e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2356e-05 - val_loss: 9.6194e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.0058e-05 - val_loss: 8.7563e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 5.3891e-05 - val_loss: 4.4708e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.3689e-05 - val_loss: 6.0029e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.3785e-05 - val_loss: 1.4811e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.9854e-05 - val_loss: 2.2205e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 5.3703e-05 - val_loss: 4.3370e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 760us/step - loss: 5.3345e-05 - val_loss: 6.4570e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0525e-05 - val_loss: 4.8702e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 5.9449e-05 - val_loss: 5.2707e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7660e-05 - val_loss: 6.0783e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8727e-05 - val_loss: 1.3908e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3072e-05 - val_loss: 7.8515e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0198e-05 - val_loss: 4.3382e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8672e-05 - val_loss: 1.0598e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2634e-05 - val_loss: 5.2648e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.5032e-05 - val_loss: 4.4886e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.8227e-05 - val_loss: 4.0267e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9947e-05 - val_loss: 6.3923e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.5858e-05 - val_loss: 5.4832e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.3634e-05 - val_loss: 4.0297e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.9760e-05 - val_loss: 1.0261e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8113e-05 - val_loss: 4.4463e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.5934e-05 - val_loss: 5.8333e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.8039e-05 - val_loss: 6.6707e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2536e-05 - val_loss: 5.2102e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 5.4339e-05 - val_loss: 5.0598e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8498e-05 - val_loss: 5.0543e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2859e-05 - val_loss: 4.2786e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.2361e-05 - val_loss: 5.9238e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 4.7655e-05 - val_loss: 4.3160e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.3225e-05 - val_loss: 7.0586e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8867e-05 - val_loss: 4.7473e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5115e-05 - val_loss: 4.5658e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.4290e-05 - val_loss: 6.0915e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7122e-05 - val_loss: 9.3717e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4265e-05 - val_loss: 1.1949e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 4.3441e-05 - val_loss: 4.5092e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.1103e-05 - val_loss: 5.3453e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6873e-05 - val_loss: 5.0338e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5209e-05 - val_loss: 5.4673e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 4.8942e-05 - val_loss: 7.0557e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_31\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_31\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0104 - val_loss: 0.0013\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 1.0707e-04 - val_loss: 3.2806e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.1576e-05 - val_loss: 6.0701e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.8828e-05 - val_loss: 4.7954e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7769e-05 - val_loss: 5.7761e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6762e-05 - val_loss: 4.8878e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.9601e-05 - val_loss: 4.3762e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.3238e-05 - val_loss: 5.3442e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2671e-05 - val_loss: 4.5413e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.4917e-05 - val_loss: 4.1646e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4450e-05 - val_loss: 4.9154e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5424e-05 - val_loss: 4.1965e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2364e-05 - val_loss: 9.8614e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.6070e-05 - val_loss: 4.3943e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8249e-05 - val_loss: 4.7223e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5712e-05 - val_loss: 4.2725e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3819e-05 - val_loss: 4.4175e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6071e-05 - val_loss: 5.0560e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6003e-05 - val_loss: 4.3556e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7813e-05 - val_loss: 6.9632e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.5291e-05 - val_loss: 5.8267e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.7013e-05 - val_loss: 5.6700e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.5536e-05 - val_loss: 4.3015e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.3479e-05 - val_loss: 8.1699e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 4.8682e-05 - val_loss: 4.0596e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3437e-05 - val_loss: 4.6735e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4642e-05 - val_loss: 2.8475e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.8341e-05 - val_loss: 4.9616e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8594e-05 - val_loss: 5.3848e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3488e-05 - val_loss: 4.7151e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.0166e-05 - val_loss: 5.5813e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.3631e-05 - val_loss: 4.2530e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0379e-05 - val_loss: 3.9349e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9449e-05 - val_loss: 5.3923e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.7724e-05 - val_loss: 4.4607e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1583e-05 - val_loss: 3.7114e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8734e-05 - val_loss: 4.4916e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8225e-05 - val_loss: 8.0401e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.0358e-05 - val_loss: 4.1182e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6316e-05 - val_loss: 4.9564e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9820e-05 - val_loss: 3.9211e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5131e-05 - val_loss: 8.5315e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4130e-05 - val_loss: 3.7012e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6182e-05 - val_loss: 3.9501e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4319e-05 - val_loss: 4.2453e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1997e-05 - val_loss: 5.8929e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 5.7284e-05 - val_loss: 3.8882e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9642e-05 - val_loss: 4.2149e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7871e-05 - val_loss: 8.2208e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 5.0582e-05 - val_loss: 4.8819e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4664e-05 - val_loss: 1.2328e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 745us/step - loss: 4.9096e-05 - val_loss: 1.6052e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.0635e-05 - val_loss: 4.6886e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4244e-05 - val_loss: 4.2334e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8117e-05 - val_loss: 7.4358e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1960e-05 - val_loss: 4.8811e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2054e-05 - val_loss: 6.6967e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8231e-05 - val_loss: 5.0349e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8715e-05 - val_loss: 6.5601e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 789us/step - loss: 4.8525e-05 - val_loss: 9.6037e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.9908e-05 - val_loss: 3.7558e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7405e-05 - val_loss: 1.2312e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7658e-05 - val_loss: 5.2646e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.2966e-05 - val_loss: 6.4101e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4166e-05 - val_loss: 1.5119e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5064e-05 - val_loss: 6.2714e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6718e-05 - val_loss: 5.1022e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_32\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0080 - val_loss: 1.6179e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 922us/step - loss: 1.0338e-04 - val_loss: 1.7392e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 9.9821e-05 - val_loss: 9.6580e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 9.5355e-05 - val_loss: 1.1757e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 9.1200e-05 - val_loss: 8.1716e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 8.4726e-05 - val_loss: 8.2729e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 7.6561e-05 - val_loss: 8.1999e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 7.8504e-05 - val_loss: 2.4109e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.4490e-05 - val_loss: 1.1212e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.4743e-05 - val_loss: 6.3530e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 6.2433e-05 - val_loss: 1.0153e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 6.4052e-05 - val_loss: 5.5693e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 6.1575e-05 - val_loss: 1.3827e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.4193e-05 - val_loss: 4.7005e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.5816e-05 - val_loss: 4.5501e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4564e-05 - val_loss: 2.9572e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 6.8475e-05 - val_loss: 5.4599e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 5.9596e-05 - val_loss: 7.4314e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 990us/step - loss: 7.8528e-05 - val_loss: 4.4999e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 6.2719e-05 - val_loss: 5.3981e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 6.1117e-05 - val_loss: 8.0279e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 962us/step - loss: 5.9457e-05 - val_loss: 4.6165e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.5993e-05 - val_loss: 6.9406e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2554e-05 - val_loss: 9.8559e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.6600e-05 - val_loss: 4.2951e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7136e-05 - val_loss: 5.0647e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6773e-05 - val_loss: 4.5742e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.4059e-05 - val_loss: 1.7075e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.7670e-05 - val_loss: 5.5875e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 8.3143e-05 - val_loss: 9.9154e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5607e-05 - val_loss: 5.0970e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.3487e-05 - val_loss: 4.1273e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.6125e-05 - val_loss: 1.7249e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7698e-05 - val_loss: 7.4906e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.0623e-05 - val_loss: 1.6887e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6358e-05 - val_loss: 4.2035e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1996e-05 - val_loss: 5.3084e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.4632e-05 - val_loss: 4.7790e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5249e-05 - val_loss: 4.9077e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.9894e-05 - val_loss: 5.9646e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3936e-05 - val_loss: 6.9571e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2106e-05 - val_loss: 4.7274e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3428e-05 - val_loss: 4.2520e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4332e-05 - val_loss: 7.6998e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 6.3651e-05 - val_loss: 1.8869e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 4.9081e-05 - val_loss: 5.6987e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0457e-05 - val_loss: 6.5854e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9374e-05 - val_loss: 6.4697e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.1780e-05 - val_loss: 4.2606e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2413e-05 - val_loss: 5.1398e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.5299e-05 - val_loss: 4.9399e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4861e-05 - val_loss: 2.3448e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8748e-05 - val_loss: 5.3948e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.0080e-05 - val_loss: 8.6848e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8709e-05 - val_loss: 4.8398e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 754us/step - loss: 5.2233e-05 - val_loss: 4.2999e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_33\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_33\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 6.0651e-04 - val_loss: 3.8551e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.8236e-05 - val_loss: 7.3078e-05\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3861e-05 - val_loss: 8.5684e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8687e-05 - val_loss: 1.5028e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 754us/step - loss: 8.0758e-05 - val_loss: 5.3664e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.8745e-05 - val_loss: 5.0621e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.7658e-05 - val_loss: 6.5773e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.3398e-05 - val_loss: 1.1958e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.7623e-05 - val_loss: 1.2642e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6796e-05 - val_loss: 4.8195e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9814e-05 - val_loss: 7.2224e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.7007e-05 - val_loss: 6.4571e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3438e-05 - val_loss: 6.6367e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0946e-05 - val_loss: 4.5130e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.2526e-05 - val_loss: 5.3535e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2618e-05 - val_loss: 4.7680e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8094e-05 - val_loss: 5.3251e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.9950e-05 - val_loss: 4.5428e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1064e-05 - val_loss: 4.6884e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1221e-05 - val_loss: 5.0065e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8604e-05 - val_loss: 5.3578e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.8748e-05 - val_loss: 4.9321e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9332e-05 - val_loss: 8.2104e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6069e-05 - val_loss: 4.8056e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4861e-05 - val_loss: 4.2750e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 5.2533e-05 - val_loss: 1.8374e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5055e-05 - val_loss: 4.3011e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6188e-05 - val_loss: 4.8515e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1025e-05 - val_loss: 5.8637e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2508e-05 - val_loss: 6.1205e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.8900e-05 - val_loss: 4.2691e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 7.9539e-05 - val_loss: 7.6092e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1179e-05 - val_loss: 4.9479e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2659e-05 - val_loss: 7.5363e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8617e-05 - val_loss: 4.4779e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5554e-05 - val_loss: 4.8774e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.4410e-05 - val_loss: 6.2721e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.9451e-05 - val_loss: 4.3936e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2189e-05 - val_loss: 7.4545e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6179e-05 - val_loss: 4.0558e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5918e-05 - val_loss: 5.0719e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1874e-05 - val_loss: 3.9364e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5873e-05 - val_loss: 4.1213e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7998e-05 - val_loss: 6.0104e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8775e-05 - val_loss: 4.2698e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.3424e-05 - val_loss: 6.5794e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1107e-05 - val_loss: 1.6769e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0491e-05 - val_loss: 1.5569e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3276e-05 - val_loss: 5.9030e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7921e-05 - val_loss: 3.9588e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2507e-05 - val_loss: 4.9015e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0717e-05 - val_loss: 1.7751e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.1160e-05 - val_loss: 1.4181e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1983e-05 - val_loss: 4.1948e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4965e-05 - val_loss: 1.0475e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0127e-05 - val_loss: 5.6296e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 4.4686e-05 - val_loss: 5.7816e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6559e-05 - val_loss: 5.0070e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7991e-05 - val_loss: 3.9084e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3104e-05 - val_loss: 4.4028e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8064e-05 - val_loss: 4.9906e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0894e-05 - val_loss: 3.8997e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.7996e-05 - val_loss: 4.2764e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 4.8019e-05 - val_loss: 3.9112e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3259e-05 - val_loss: 1.1302e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.4494e-05 - val_loss: 5.9116e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8561e-05 - val_loss: 5.3922e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6652e-05 - val_loss: 1.1639e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3677e-05 - val_loss: 7.0454e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.6993e-05 - val_loss: 5.6999e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4593e-05 - val_loss: 4.3302e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 815us/step - loss: 4.5709e-05 - val_loss: 3.9846e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 5.7790e-05 - val_loss: 7.2849e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.0814e-05 - val_loss: 3.9540e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4568e-05 - val_loss: 8.3224e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3591e-05 - val_loss: 5.4594e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 4.6814e-05 - val_loss: 4.2436e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4497e-05 - val_loss: 4.4703e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.1466e-05 - val_loss: 5.8942e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8674e-05 - val_loss: 5.7257e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2099e-05 - val_loss: 9.9287e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4355e-05 - val_loss: 6.8176e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4944e-05 - val_loss: 5.9517e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7692e-05 - val_loss: 7.7432e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4742e-05 - val_loss: 4.0835e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9658e-05 - val_loss: 6.6919e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_34\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_34\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0078 - val_loss: 0.0011\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 9.1723e-05 - val_loss: 5.2246e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.6258e-05 - val_loss: 2.7705e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8104e-05 - val_loss: 1.4159e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6957e-05 - val_loss: 6.2102e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7752e-05 - val_loss: 4.4907e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6646e-05 - val_loss: 4.3746e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9426e-05 - val_loss: 5.0202e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8489e-05 - val_loss: 4.3125e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1399e-05 - val_loss: 4.1914e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2697e-05 - val_loss: 4.3960e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9411e-05 - val_loss: 4.2045e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9412e-05 - val_loss: 4.4784e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9525e-05 - val_loss: 4.1136e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4908e-05 - val_loss: 7.9781e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0813e-05 - val_loss: 4.7023e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4574e-05 - val_loss: 5.0454e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9663e-05 - val_loss: 5.0848e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8438e-05 - val_loss: 5.3962e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.9888e-05 - val_loss: 4.9856e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6706e-05 - val_loss: 7.7884e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.4656e-05 - val_loss: 4.6218e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1679e-05 - val_loss: 6.0233e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8245e-05 - val_loss: 4.3325e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7151e-05 - val_loss: 4.0714e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7529e-05 - val_loss: 8.2197e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.7432e-05 - val_loss: 5.4540e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1142e-05 - val_loss: 5.2459e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4616e-05 - val_loss: 5.9800e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1797e-05 - val_loss: 5.4743e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.1738e-05 - val_loss: 9.1988e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 729us/step - loss: 5.8428e-05 - val_loss: 3.9906e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 721us/step - loss: 5.4327e-05 - val_loss: 1.2966e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 717us/step - loss: 6.6374e-05 - val_loss: 5.0841e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.5805e-05 - val_loss: 1.4004e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0373e-05 - val_loss: 7.8534e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9541e-05 - val_loss: 4.3705e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1151e-05 - val_loss: 9.4586e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4546e-05 - val_loss: 5.9787e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0090e-05 - val_loss: 4.4998e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5462e-05 - val_loss: 4.9011e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8028e-05 - val_loss: 6.3079e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5264e-05 - val_loss: 5.1652e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 6.0846e-05 - val_loss: 5.2647e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2819e-05 - val_loss: 5.5047e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7986e-05 - val_loss: 5.8045e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.0150e-05 - val_loss: 6.0467e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 4.9290e-05 - val_loss: 5.4385e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7081e-05 - val_loss: 1.3078e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1774e-05 - val_loss: 9.6253e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6982e-05 - val_loss: 4.9782e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4188e-05 - val_loss: 6.6483e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6194e-05 - val_loss: 6.6824e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 6.3621e-05 - val_loss: 5.6598e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9008e-05 - val_loss: 1.5769e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9020e-05 - val_loss: 5.9111e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_35\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_35\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0065 - val_loss: 7.5855e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.5160e-05 - val_loss: 1.8424e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0380e-05 - val_loss: 1.4412e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9430e-05 - val_loss: 8.0445e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0452e-05 - val_loss: 6.0688e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7130e-05 - val_loss: 4.9830e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7649e-05 - val_loss: 6.1548e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2980e-05 - val_loss: 6.5413e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7830e-05 - val_loss: 4.7059e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9852e-05 - val_loss: 9.1508e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0668e-05 - val_loss: 4.5430e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2916e-05 - val_loss: 6.5360e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8624e-05 - val_loss: 6.8527e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.1962e-05 - val_loss: 5.2104e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.1088e-05 - val_loss: 1.1843e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3415e-05 - val_loss: 1.0630e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7318e-05 - val_loss: 5.3295e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 5.0902e-05 - val_loss: 4.6211e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8773e-05 - val_loss: 8.8259e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.9124e-05 - val_loss: 5.9413e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2625e-05 - val_loss: 4.4695e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.6046e-05 - val_loss: 1.3319e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 6.4108e-05 - val_loss: 3.2247e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6329e-05 - val_loss: 1.2842e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3977e-05 - val_loss: 8.5769e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5672e-05 - val_loss: 4.0579e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6256e-05 - val_loss: 4.8329e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9564e-05 - val_loss: 1.7610e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1306e-05 - val_loss: 5.5342e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9241e-05 - val_loss: 6.4677e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.3682e-05 - val_loss: 4.4530e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0982e-05 - val_loss: 4.9354e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3544e-05 - val_loss: 1.8776e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1246e-05 - val_loss: 5.4300e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5893e-05 - val_loss: 5.7567e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.9811e-05 - val_loss: 7.2331e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7463e-05 - val_loss: 7.6761e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4782e-05 - val_loss: 8.1414e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6112e-05 - val_loss: 6.4599e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6379e-05 - val_loss: 1.1211e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.1966e-05 - val_loss: 8.2486e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0402e-05 - val_loss: 6.9147e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6407e-05 - val_loss: 4.9326e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0437e-05 - val_loss: 4.6612e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5028e-05 - val_loss: 4.3761e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1365e-05 - val_loss: 4.8424e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1710e-05 - val_loss: 4.1652e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2587e-05 - val_loss: 5.4954e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8066e-05 - val_loss: 6.4258e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 4.6291e-05 - val_loss: 4.4431e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_36\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_36\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.0910e-05 - val_loss: 2.8851e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 6.5834e-05 - val_loss: 9.9814e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.6867e-05 - val_loss: 7.9872e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 6.0412e-05 - val_loss: 6.3144e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3157e-05 - val_loss: 5.1152e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0917e-05 - val_loss: 8.7662e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.8939e-05 - val_loss: 5.4442e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 6.2471e-05 - val_loss: 5.1752e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 6.3117e-05 - val_loss: 6.3703e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7514e-05 - val_loss: 4.3024e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.3558e-05 - val_loss: 1.0620e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6851e-05 - val_loss: 4.5539e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7976e-05 - val_loss: 4.7010e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.8592e-05 - val_loss: 4.5312e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8211e-05 - val_loss: 4.3132e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5762e-05 - val_loss: 4.5731e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.3122e-05 - val_loss: 4.4595e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.8929e-05 - val_loss: 5.1519e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8725e-05 - val_loss: 8.1117e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1130e-05 - val_loss: 1.0752e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5520e-05 - val_loss: 4.5382e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8466e-05 - val_loss: 7.2119e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.6002e-05 - val_loss: 4.3258e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.9861e-05 - val_loss: 4.5392e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2737e-05 - val_loss: 4.2638e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2075e-05 - val_loss: 9.7663e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0634e-05 - val_loss: 5.4410e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.2992e-05 - val_loss: 9.5332e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 809us/step - loss: 5.0703e-05 - val_loss: 5.4773e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.8254e-05 - val_loss: 4.3584e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 5.7273e-05 - val_loss: 8.9661e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 4.9814e-05 - val_loss: 4.1327e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2071e-05 - val_loss: 4.7490e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5197e-05 - val_loss: 1.3082e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1025e-05 - val_loss: 4.1976e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.5369e-05 - val_loss: 8.7044e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2209e-05 - val_loss: 1.1344e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3637e-05 - val_loss: 4.5335e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7117e-05 - val_loss: 1.2477e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.7154e-05 - val_loss: 4.8085e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1118e-05 - val_loss: 6.7572e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4986e-05 - val_loss: 4.0519e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6485e-05 - val_loss: 9.4993e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5882e-05 - val_loss: 4.3327e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9015e-05 - val_loss: 5.2674e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3800e-05 - val_loss: 6.5910e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3673e-05 - val_loss: 4.8510e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6564e-05 - val_loss: 6.4604e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8511e-05 - val_loss: 1.2431e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2976e-05 - val_loss: 4.0480e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7739e-05 - val_loss: 4.1630e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.8383e-05 - val_loss: 4.6000e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.3166e-05 - val_loss: 4.2431e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.6675e-05 - val_loss: 1.0104e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5888e-05 - val_loss: 5.9696e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9015e-05 - val_loss: 7.7317e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4707e-05 - val_loss: 4.7015e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 5.0750e-05 - val_loss: 4.0393e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.3682e-05 - val_loss: 8.2862e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 4.9413e-05 - val_loss: 4.1725e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.2506e-05 - val_loss: 1.0631e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0038e-05 - val_loss: 9.2064e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.8262e-05 - val_loss: 5.8351e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 4.4880e-05 - val_loss: 4.5471e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 4.6471e-05 - val_loss: 1.4779e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.3516e-05 - val_loss: 1.0012e-04\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.6257e-05 - val_loss: 7.2921e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 5.6326e-05 - val_loss: 1.8770e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 5.0977e-05 - val_loss: 7.8785e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 858us/step - loss: 4.2904e-05 - val_loss: 5.5286e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 4.3987e-05 - val_loss: 4.1684e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 4.7345e-05 - val_loss: 5.8154e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 4.8857e-05 - val_loss: 4.2047e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 4.4530e-05 - val_loss: 4.2923e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 4.4819e-05 - val_loss: 4.5508e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 4.9546e-05 - val_loss: 1.0091e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 4.5834e-05 - val_loss: 4.0585e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 4.4248e-05 - val_loss: 4.2582e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 852us/step - loss: 4.4128e-05 - val_loss: 4.7433e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 4.3662e-05 - val_loss: 5.6098e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 806us/step - loss: 4.4409e-05 - val_loss: 3.8940e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 4.1720e-05 - val_loss: 3.7409e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 5.0716e-05 - val_loss: 5.6542e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 796us/step - loss: 4.2263e-05 - val_loss: 4.0976e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 4.5630e-05 - val_loss: 3.8551e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.4015e-05 - val_loss: 9.0743e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 4.4108e-05 - val_loss: 3.8867e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 801us/step - loss: 4.3754e-05 - val_loss: 4.7033e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 4.3539e-05 - val_loss: 5.6771e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.6275e-05 - val_loss: 6.6886e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 4.2200e-05 - val_loss: 7.5279e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9155e-05 - val_loss: 2.2868e-04\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.5981e-05 - val_loss: 3.8656e-05\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2578e-05 - val_loss: 3.7727e-05\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5311e-05 - val_loss: 6.9544e-05\n",
      "Epoch 97/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.0060e-05 - val_loss: 4.1798e-05\n",
      "Epoch 98/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 4.4120e-05 - val_loss: 9.2013e-05\n",
      "Epoch 99/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5430e-05 - val_loss: 4.7233e-05\n",
      "Epoch 100/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.2300e-05 - val_loss: 4.1156e-05\n",
      "Epoch 101/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 4.3102e-05 - val_loss: 4.7342e-05\n",
      "Epoch 102/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9285e-05 - val_loss: 4.0741e-05\n",
      "Epoch 103/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.4174e-05 - val_loss: 3.8913e-05\n",
      "Epoch 104/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.0068e-05 - val_loss: 4.0035e-05\n",
      "Epoch 105/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4671e-05 - val_loss: 4.2774e-05\n",
      "Epoch 106/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7269e-05 - val_loss: 5.2648e-05\n",
      "Epoch 107/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5447e-05 - val_loss: 7.5474e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_37\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_37\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0132 - val_loss: 0.0040\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 1.5169e-04 - val_loss: 0.0027\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 1.1254e-04 - val_loss: 0.0020\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.5551e-05 - val_loss: 6.5533e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.9323e-05 - val_loss: 3.2794e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0160e-05 - val_loss: 1.2635e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2653e-05 - val_loss: 6.6999e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1801e-05 - val_loss: 7.3453e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5675e-05 - val_loss: 5.1265e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9806e-05 - val_loss: 4.9993e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.9878e-05 - val_loss: 1.0293e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.6667e-05 - val_loss: 6.0923e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.3385e-05 - val_loss: 7.3721e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5682e-05 - val_loss: 7.4400e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1340e-05 - val_loss: 1.2539e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2988e-05 - val_loss: 7.2199e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.7685e-05 - val_loss: 6.7216e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.3073e-05 - val_loss: 1.1792e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.5286e-05 - val_loss: 1.0872e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.7082e-05 - val_loss: 1.4084e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.4278e-05 - val_loss: 7.1029e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 9.2987e-05 - val_loss: 3.5655e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6279e-05 - val_loss: 8.3240e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.3829e-05 - val_loss: 1.4786e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9041e-05 - val_loss: 5.8674e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 5.8782e-05 - val_loss: 5.9889e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 907us/step - loss: 6.1384e-05 - val_loss: 6.8183e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.8035e-05 - val_loss: 5.2756e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5641e-05 - val_loss: 5.6606e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.0340e-05 - val_loss: 9.0571e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0749e-05 - val_loss: 6.0277e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8847e-05 - val_loss: 6.2748e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2813e-05 - val_loss: 6.0005e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9685e-05 - val_loss: 1.0280e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_38\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_38\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0041 - val_loss: 9.0539e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.6516e-05 - val_loss: 6.8705e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2189e-05 - val_loss: 3.8495e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4121e-05 - val_loss: 2.0792e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 745us/step - loss: 5.0514e-05 - val_loss: 1.7221e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 4.8273e-05 - val_loss: 5.2318e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6442e-05 - val_loss: 7.3951e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 4.7864e-05 - val_loss: 7.1016e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5672e-05 - val_loss: 7.3284e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8509e-05 - val_loss: 8.2820e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.8518e-05 - val_loss: 6.7584e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3312e-05 - val_loss: 4.6562e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3239e-05 - val_loss: 6.9065e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7632e-05 - val_loss: 6.5825e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7860e-05 - val_loss: 4.4024e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2830e-05 - val_loss: 4.6360e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.5570e-05 - val_loss: 4.7546e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4389e-05 - val_loss: 1.2298e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9868e-05 - val_loss: 5.1675e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.3878e-05 - val_loss: 9.5867e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0470e-05 - val_loss: 6.2332e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6621e-05 - val_loss: 4.7158e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.9409e-05 - val_loss: 4.7333e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.0788e-05 - val_loss: 5.5566e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9266e-05 - val_loss: 5.8136e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3574e-05 - val_loss: 1.3256e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2260e-05 - val_loss: 2.5896e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3356e-05 - val_loss: 4.1334e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.3950e-05 - val_loss: 6.2492e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1980e-05 - val_loss: 4.3606e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1096e-05 - val_loss: 5.0770e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.0474e-05 - val_loss: 4.5486e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1008e-05 - val_loss: 4.9108e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4955e-05 - val_loss: 4.3774e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.7465e-05 - val_loss: 4.9029e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2357e-05 - val_loss: 5.1599e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2838e-05 - val_loss: 1.5177e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7943e-05 - val_loss: 5.1697e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0130e-05 - val_loss: 6.6555e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9913e-05 - val_loss: 5.1506e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9657e-05 - val_loss: 6.1671e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0682e-05 - val_loss: 4.4118e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0317e-05 - val_loss: 4.0689e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.9693e-05 - val_loss: 4.2127e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 6.6186e-05 - val_loss: 1.5656e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.7829e-05 - val_loss: 5.5357e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2765e-05 - val_loss: 4.5843e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1463e-05 - val_loss: 1.4024e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.8428e-05 - val_loss: 5.3106e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7207e-05 - val_loss: 8.4437e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3490e-05 - val_loss: 1.3055e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4194e-05 - val_loss: 5.7716e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0678e-05 - val_loss: 5.5138e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0643e-05 - val_loss: 4.2787e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.8443e-05 - val_loss: 4.4766e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1622e-05 - val_loss: 5.1375e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7306e-05 - val_loss: 6.6554e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.6719e-05 - val_loss: 4.2024e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7111e-05 - val_loss: 5.6679e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.9764e-05 - val_loss: 4.8682e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8826e-05 - val_loss: 4.9827e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.5745e-05 - val_loss: 4.3633e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.5910e-05 - val_loss: 4.0252e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.4303e-05 - val_loss: 5.1291e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.9187e-05 - val_loss: 4.1158e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 4.5906e-05 - val_loss: 4.8884e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2248e-05 - val_loss: 4.3815e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6196e-05 - val_loss: 1.0791e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1143e-05 - val_loss: 4.3680e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5711e-05 - val_loss: 8.2438e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8055e-05 - val_loss: 7.7171e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9149e-05 - val_loss: 8.3923e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3875e-05 - val_loss: 7.4237e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.7818e-05 - val_loss: 4.3106e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.5594e-05 - val_loss: 5.7425e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.4562e-05 - val_loss: 5.2849e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9672e-05 - val_loss: 6.2377e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5168e-05 - val_loss: 4.8743e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2631e-05 - val_loss: 4.5980e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5412e-05 - val_loss: 4.8380e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8409e-05 - val_loss: 6.6181e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1814e-05 - val_loss: 1.4244e-04\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5092e-05 - val_loss: 1.1242e-04\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6899e-05 - val_loss: 4.2239e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7575e-05 - val_loss: 5.7786e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1542e-05 - val_loss: 4.6665e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4836e-05 - val_loss: 4.6496e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_39\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_39\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0084 - val_loss: 0.0023\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 1.2635e-04 - val_loss: 5.6096e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 8.1955e-05 - val_loss: 1.7592e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 743us/step - loss: 6.3844e-05 - val_loss: 5.8846e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 724us/step - loss: 5.6428e-05 - val_loss: 4.2572e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 727us/step - loss: 5.1211e-05 - val_loss: 4.6545e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 722us/step - loss: 5.0447e-05 - val_loss: 4.1607e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.1769e-05 - val_loss: 4.6245e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.9773e-05 - val_loss: 4.9179e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5508e-05 - val_loss: 4.0046e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1333e-05 - val_loss: 1.5838e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.4480e-05 - val_loss: 5.7218e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.8193e-05 - val_loss: 9.0953e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5771e-05 - val_loss: 4.4532e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7014e-05 - val_loss: 3.8778e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.5261e-05 - val_loss: 4.5067e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 1.0300e-04 - val_loss: 4.4766e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8880e-05 - val_loss: 1.6953e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 7.1158e-05 - val_loss: 4.4727e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.7650e-05 - val_loss: 1.3881e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6148e-05 - val_loss: 4.0516e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9954e-05 - val_loss: 1.0403e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.7148e-05 - val_loss: 4.5248e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.6917e-05 - val_loss: 4.4574e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4923e-05 - val_loss: 1.1098e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 8.0390e-05 - val_loss: 6.2460e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1317e-05 - val_loss: 4.2640e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8792e-05 - val_loss: 1.5065e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8613e-05 - val_loss: 9.1274e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2706e-05 - val_loss: 8.8670e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3137e-05 - val_loss: 4.8598e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1751e-05 - val_loss: 7.6800e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0227e-05 - val_loss: 1.5889e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0317e-05 - val_loss: 4.9057e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.0895e-05 - val_loss: 6.6233e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.5143e-05 - val_loss: 5.6811e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.5021e-05 - val_loss: 4.8030e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1305e-05 - val_loss: 4.7716e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.7216e-05 - val_loss: 4.0733e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_40\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_40\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0073 - val_loss: 0.0028\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 9.7902e-05 - val_loss: 4.3334e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2816e-05 - val_loss: 1.0824e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3278e-05 - val_loss: 7.2260e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6853e-05 - val_loss: 7.2406e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6957e-05 - val_loss: 1.2416e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.0795e-05 - val_loss: 5.8238e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9694e-05 - val_loss: 5.9376e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.9343e-05 - val_loss: 4.7452e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.2143e-05 - val_loss: 4.3477e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.6460e-05 - val_loss: 4.7389e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.3824e-05 - val_loss: 4.7782e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.8083e-05 - val_loss: 1.4224e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5507e-05 - val_loss: 4.1889e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.7235e-05 - val_loss: 5.9886e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5086e-05 - val_loss: 9.1220e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.7879e-05 - val_loss: 1.1636e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1281e-05 - val_loss: 1.3498e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 5.8454e-05 - val_loss: 4.8101e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.6703e-05 - val_loss: 8.9072e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.4642e-05 - val_loss: 1.6931e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6288e-05 - val_loss: 7.1954e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4519e-05 - val_loss: 6.2261e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 6.1193e-05 - val_loss: 4.3780e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 6.6787e-05 - val_loss: 5.4240e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.4591e-05 - val_loss: 3.0142e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7280e-05 - val_loss: 1.0685e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6626e-05 - val_loss: 1.9665e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9922e-05 - val_loss: 4.4832e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1620e-05 - val_loss: 4.4723e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.7482e-05 - val_loss: 5.9548e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9075e-05 - val_loss: 4.9250e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.9441e-05 - val_loss: 9.7031e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7882e-05 - val_loss: 6.4486e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3671e-05 - val_loss: 4.6221e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6642e-05 - val_loss: 1.1668e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 776us/step - loss: 5.4084e-05 - val_loss: 1.1911e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4247e-05 - val_loss: 4.3924e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_41\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_41\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0036 - val_loss: 1.8391e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.2577e-05 - val_loss: 1.3031e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.1923e-05 - val_loss: 3.0032e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.9777e-05 - val_loss: 1.0558e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.5252e-05 - val_loss: 3.1149e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 1.2818e-04 - val_loss: 5.7002e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 1.1891e-04 - val_loss: 1.4778e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 7.3100e-05 - val_loss: 5.5005e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 8.9073e-05 - val_loss: 4.9671e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.1167e-05 - val_loss: 1.0515e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 1.6166e-04 - val_loss: 1.2200e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.3724e-05 - val_loss: 4.6743e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.2838e-05 - val_loss: 8.6640e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 1.0602e-04 - val_loss: 4.3160e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 1.0211e-04 - val_loss: 2.2455e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.4362e-05 - val_loss: 5.3203e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.2013e-05 - val_loss: 3.2884e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.4568e-05 - val_loss: 6.0596e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9266e-05 - val_loss: 1.4750e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.1307e-05 - val_loss: 6.5669e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7247e-05 - val_loss: 9.4526e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8535e-05 - val_loss: 8.5469e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 6.7538e-05 - val_loss: 3.1585e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.5628e-05 - val_loss: 4.1898e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.6410e-05 - val_loss: 4.9121e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.7174e-05 - val_loss: 5.0919e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.1021e-05 - val_loss: 4.5549e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.3764e-05 - val_loss: 4.9325e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2707e-05 - val_loss: 1.8920e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4886e-05 - val_loss: 9.5159e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.1256e-05 - val_loss: 4.1424e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3820e-05 - val_loss: 4.7288e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8659e-05 - val_loss: 1.1934e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1006e-05 - val_loss: 5.3082e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1390e-05 - val_loss: 4.1117e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.8858e-05 - val_loss: 5.3722e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.0553e-05 - val_loss: 5.7977e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.6603e-05 - val_loss: 5.5894e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1134e-05 - val_loss: 5.8504e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0125e-05 - val_loss: 4.2501e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5185e-05 - val_loss: 6.0948e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4117e-05 - val_loss: 1.3856e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 5.3399e-05 - val_loss: 4.1266e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.4469e-05 - val_loss: 5.0401e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 5.6502e-05 - val_loss: 6.6913e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.4577e-05 - val_loss: 7.7930e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.4321e-05 - val_loss: 1.2243e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 6.3883e-05 - val_loss: 4.0627e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2050e-05 - val_loss: 5.2084e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 756us/step - loss: 6.1569e-05 - val_loss: 5.0945e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7712e-05 - val_loss: 8.4151e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4084e-05 - val_loss: 6.0489e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8144e-05 - val_loss: 1.0765e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.4075e-05 - val_loss: 7.9570e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2939e-05 - val_loss: 5.0393e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9281e-05 - val_loss: 1.0042e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 743us/step - loss: 4.9312e-05 - val_loss: 1.2126e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6820e-05 - val_loss: 4.2448e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 751us/step - loss: 6.8468e-05 - val_loss: 1.6222e-04\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1246e-05 - val_loss: 4.0032e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.6325e-05 - val_loss: 4.4274e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 5.8781e-05 - val_loss: 4.5788e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.6296e-05 - val_loss: 4.4400e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.8758e-05 - val_loss: 1.2659e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8144e-05 - val_loss: 6.1427e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6633e-05 - val_loss: 4.4046e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.2993e-05 - val_loss: 4.5709e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7239e-05 - val_loss: 8.9943e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4956e-05 - val_loss: 5.2881e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6872e-05 - val_loss: 1.0630e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0427e-05 - val_loss: 4.4075e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8167e-05 - val_loss: 7.2234e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.7062e-05 - val_loss: 8.2400e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.3882e-05 - val_loss: 5.1102e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.8259e-05 - val_loss: 1.0436e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.3002e-05 - val_loss: 4.2648e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 6.2840e-05 - val_loss: 1.0668e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8941e-05 - val_loss: 6.4727e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.4134e-05 - val_loss: 4.2697e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5932e-05 - val_loss: 4.6111e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4126e-05 - val_loss: 3.9430e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9326e-05 - val_loss: 7.7941e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8661e-05 - val_loss: 4.3204e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7368e-05 - val_loss: 8.7568e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.1593e-05 - val_loss: 6.8076e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7610e-05 - val_loss: 5.4500e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8580e-05 - val_loss: 4.5067e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9777e-05 - val_loss: 6.5428e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1817e-05 - val_loss: 5.8549e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2538e-05 - val_loss: 4.4267e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7915e-05 - val_loss: 7.4483e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8074e-05 - val_loss: 4.5585e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7563e-05 - val_loss: 4.7082e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6053e-05 - val_loss: 4.2939e-05\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9296e-05 - val_loss: 7.7420e-05\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2284e-05 - val_loss: 4.5601e-05\n",
      "Epoch 97/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6906e-05 - val_loss: 5.3273e-05\n",
      "Epoch 98/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8982e-05 - val_loss: 4.2092e-05\n",
      "Epoch 99/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.8151e-05 - val_loss: 4.2048e-05\n",
      "Epoch 100/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7412e-05 - val_loss: 4.5550e-05\n",
      "Epoch 101/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.4281e-05 - val_loss: 5.0532e-05\n",
      "Epoch 102/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6454e-05 - val_loss: 8.0632e-05\n",
      "Epoch 103/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7872e-05 - val_loss: 4.3538e-05\n",
      "Epoch 104/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1824e-05 - val_loss: 4.0285e-05\n",
      "Epoch 105/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.3399e-05 - val_loss: 4.0024e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_42\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_42\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0105 - val_loss: 8.1057e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 8.4591e-05 - val_loss: 3.2418e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2567e-05 - val_loss: 1.8719e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.1455e-05 - val_loss: 1.6605e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0705e-05 - val_loss: 5.3437e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.7287e-05 - val_loss: 4.5383e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 5.2898e-05 - val_loss: 5.1179e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 5.3346e-05 - val_loss: 8.3893e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.8545e-05 - val_loss: 1.4415e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 6.3259e-05 - val_loss: 6.4722e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 8.3164e-05 - val_loss: 5.0228e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 8.0736e-05 - val_loss: 5.5516e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 7.6077e-05 - val_loss: 6.1004e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.0471e-05 - val_loss: 1.3191e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.7106e-05 - val_loss: 1.8622e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5483e-05 - val_loss: 1.8331e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.1129e-05 - val_loss: 8.4216e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 8.3498e-05 - val_loss: 4.5476e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.6169e-05 - val_loss: 1.6689e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.4786e-05 - val_loss: 5.0700e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5704e-05 - val_loss: 7.1073e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.7166e-05 - val_loss: 4.6656e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.4320e-05 - val_loss: 4.9259e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.3379e-05 - val_loss: 2.3914e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 9.1614e-05 - val_loss: 4.3364e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1881e-05 - val_loss: 9.8238e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.5818e-05 - val_loss: 4.6525e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.6122e-05 - val_loss: 9.7583e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0278e-05 - val_loss: 8.8297e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.9634e-05 - val_loss: 1.2444e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.7664e-05 - val_loss: 6.1796e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.3801e-05 - val_loss: 7.1573e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.1480e-05 - val_loss: 7.5117e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9640e-05 - val_loss: 5.5029e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 8.0936e-05 - val_loss: 8.6882e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8472e-05 - val_loss: 4.6012e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.1069e-05 - val_loss: 4.2259e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.4104e-05 - val_loss: 4.5617e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7622e-05 - val_loss: 7.6123e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5122e-05 - val_loss: 4.8596e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3291e-05 - val_loss: 4.6940e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.9484e-05 - val_loss: 9.4480e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.4085e-05 - val_loss: 5.2736e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.3707e-05 - val_loss: 4.0929e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4243e-05 - val_loss: 5.2668e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.0487e-05 - val_loss: 8.2872e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.5271e-05 - val_loss: 6.6780e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.1654e-05 - val_loss: 4.4109e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5999e-05 - val_loss: 5.2597e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.3818e-05 - val_loss: 7.6743e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.3397e-05 - val_loss: 4.9733e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.8630e-05 - val_loss: 7.8238e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.4632e-05 - val_loss: 4.6447e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9488e-05 - val_loss: 4.2101e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9535e-05 - val_loss: 4.2655e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.6688e-05 - val_loss: 1.7595e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0162e-05 - val_loss: 4.7057e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 5.2709e-05 - val_loss: 4.3956e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8384e-05 - val_loss: 5.0347e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8638e-05 - val_loss: 4.5485e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5028e-05 - val_loss: 1.1051e-04\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.7514e-05 - val_loss: 1.1357e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9258e-05 - val_loss: 4.5759e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8760e-05 - val_loss: 4.7023e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2783e-05 - val_loss: 4.3464e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9882e-05 - val_loss: 4.8095e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4190e-05 - val_loss: 5.6363e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5987e-05 - val_loss: 6.9404e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_43\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_43\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0082 - val_loss: 6.9467e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 1.0125e-04 - val_loss: 2.8203e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 8.3198e-05 - val_loss: 1.2791e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 7.1939e-05 - val_loss: 1.0135e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.5928e-05 - val_loss: 1.7693e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2833e-05 - val_loss: 6.8089e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.7449e-05 - val_loss: 6.7587e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.8823e-05 - val_loss: 8.7361e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6041e-05 - val_loss: 5.1047e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 6.1238e-05 - val_loss: 5.6088e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.8885e-05 - val_loss: 5.0238e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.7012e-05 - val_loss: 4.9295e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4113e-05 - val_loss: 6.3787e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.2705e-05 - val_loss: 6.2524e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.7611e-05 - val_loss: 5.4983e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4830e-05 - val_loss: 1.8038e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3979e-05 - val_loss: 1.0255e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.2732e-05 - val_loss: 1.0158e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.0284e-05 - val_loss: 5.2395e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2637e-05 - val_loss: 7.3454e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.7900e-05 - val_loss: 6.5335e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.8348e-05 - val_loss: 6.0464e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.0979e-05 - val_loss: 4.5199e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6716e-05 - val_loss: 4.2894e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.1468e-05 - val_loss: 6.7767e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.4776e-05 - val_loss: 1.3564e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6310e-05 - val_loss: 4.5351e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8621e-05 - val_loss: 4.5152e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.9194e-05 - val_loss: 4.2608e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1162e-05 - val_loss: 1.3064e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8265e-05 - val_loss: 7.9426e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 5.4840e-05 - val_loss: 7.9806e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3974e-05 - val_loss: 2.2552e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8964e-05 - val_loss: 5.2661e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7904e-05 - val_loss: 6.9244e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4631e-05 - val_loss: 4.5404e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7439e-05 - val_loss: 5.0849e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9010e-05 - val_loss: 4.5459e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1603e-05 - val_loss: 4.1555e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6758e-05 - val_loss: 7.3349e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5576e-05 - val_loss: 8.2522e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1457e-05 - val_loss: 4.1460e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8146e-05 - val_loss: 4.0183e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0302e-05 - val_loss: 6.5881e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7446e-05 - val_loss: 4.8735e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6268e-05 - val_loss: 5.2178e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.8436e-05 - val_loss: 1.0536e-04\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5132e-05 - val_loss: 4.1369e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 5.5718e-05 - val_loss: 4.2718e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7116e-05 - val_loss: 7.9046e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1967e-05 - val_loss: 8.4692e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4305e-05 - val_loss: 1.0023e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.0636e-05 - val_loss: 6.5651e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2408e-05 - val_loss: 5.0117e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9334e-05 - val_loss: 5.2185e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9136e-05 - val_loss: 4.3583e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3223e-05 - val_loss: 1.3982e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6010e-05 - val_loss: 1.2408e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7051e-05 - val_loss: 3.9822e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.6533e-05 - val_loss: 7.5422e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.8469e-05 - val_loss: 4.7296e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6885e-05 - val_loss: 5.7904e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8555e-05 - val_loss: 4.7322e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5139e-05 - val_loss: 7.8388e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.0026e-05 - val_loss: 7.6652e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 756us/step - loss: 5.4019e-05 - val_loss: 6.5568e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4442e-05 - val_loss: 4.6484e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 4.2706e-05 - val_loss: 5.1408e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4393e-05 - val_loss: 4.1041e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5523e-05 - val_loss: 8.4461e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 4.0411e-05 - val_loss: 1.1789e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8731e-05 - val_loss: 7.0424e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6926e-05 - val_loss: 3.7672e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7860e-05 - val_loss: 6.1474e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.4736e-05 - val_loss: 5.7409e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7291e-05 - val_loss: 6.8002e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6681e-05 - val_loss: 8.1846e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7134e-05 - val_loss: 4.2541e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6732e-05 - val_loss: 4.3804e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2362e-05 - val_loss: 5.5852e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.0026e-05 - val_loss: 5.1828e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2218e-05 - val_loss: 4.3869e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.4433e-05 - val_loss: 6.1564e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.8240e-05 - val_loss: 4.9320e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 4.2484e-05 - val_loss: 3.9808e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 4.2308e-05 - val_loss: 3.9153e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 4.9669e-05 - val_loss: 3.7245e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3873e-05 - val_loss: 3.9303e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.5659e-05 - val_loss: 5.1283e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4163e-05 - val_loss: 3.7734e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.1607e-05 - val_loss: 3.9510e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5973e-05 - val_loss: 4.9519e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.4612e-05 - val_loss: 4.8509e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.3346e-05 - val_loss: 4.1524e-05\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1915e-05 - val_loss: 5.3074e-05\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.2482e-05 - val_loss: 4.8114e-05\n",
      "Epoch 97/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6951e-05 - val_loss: 9.3165e-05\n",
      "Epoch 98/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6398e-05 - val_loss: 4.1879e-05\n",
      "Epoch 99/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6805e-05 - val_loss: 9.4846e-05\n",
      "Epoch 100/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1410e-05 - val_loss: 4.6698e-05\n",
      "Epoch 101/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 5.4469e-05 - val_loss: 6.2993e-05\n",
      "Epoch 102/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.1324e-05 - val_loss: 4.5956e-05\n",
      "Epoch 103/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2671e-05 - val_loss: 7.9724e-05\n",
      "Epoch 104/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.2093e-05 - val_loss: 4.2840e-05\n",
      "Epoch 105/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.1849e-05 - val_loss: 3.9574e-05\n",
      "Epoch 106/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.2657e-05 - val_loss: 3.7096e-05\n",
      "Epoch 107/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.9657e-05 - val_loss: 4.8544e-05\n",
      "Epoch 108/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.1635e-05 - val_loss: 5.1806e-05\n",
      "Epoch 109/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1721e-05 - val_loss: 4.8783e-05\n",
      "Epoch 110/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1363e-05 - val_loss: 4.9065e-05\n",
      "Epoch 111/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5376e-05 - val_loss: 5.9320e-05\n",
      "Epoch 112/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.9545e-05 - val_loss: 5.2758e-05\n",
      "Epoch 113/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1293e-05 - val_loss: 4.3949e-05\n",
      "Epoch 114/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3756e-05 - val_loss: 3.8603e-05\n",
      "Epoch 115/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.9112e-05 - val_loss: 8.0069e-05\n",
      "Epoch 116/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.9766e-05 - val_loss: 4.6879e-05\n",
      "Epoch 117/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3207e-05 - val_loss: 3.8606e-05\n",
      "Epoch 118/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 3.8986e-05 - val_loss: 4.2110e-05\n",
      "Epoch 119/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8150e-05 - val_loss: 5.3250e-05\n",
      "Epoch 120/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1647e-05 - val_loss: 5.1952e-05\n",
      "Epoch 121/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2723e-05 - val_loss: 4.3142e-05\n",
      "Epoch 122/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.0333e-05 - val_loss: 3.8436e-05\n",
      "Epoch 123/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4874e-05 - val_loss: 4.1937e-05\n",
      "Epoch 124/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1656e-05 - val_loss: 3.8123e-05\n",
      "Epoch 125/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3496e-05 - val_loss: 6.3469e-05\n",
      "Epoch 126/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2131e-05 - val_loss: 4.0594e-05\n",
      "Epoch 127/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2153e-05 - val_loss: 3.7943e-05\n",
      "Epoch 128/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1926e-05 - val_loss: 4.6022e-05\n",
      "Epoch 129/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1336e-05 - val_loss: 3.8926e-05\n",
      "Epoch 130/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.3104e-05 - val_loss: 3.8077e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_44\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_44\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 1.4818e-04 - val_loss: 4.7974e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 9.5207e-05 - val_loss: 1.1973e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.3921e-05 - val_loss: 9.7808e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.5788e-05 - val_loss: 6.9379e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.7805e-05 - val_loss: 6.5105e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 8.1915e-05 - val_loss: 1.0924e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.1747e-05 - val_loss: 6.0035e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.4474e-05 - val_loss: 6.6695e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 9.1644e-05 - val_loss: 1.5987e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.0333e-05 - val_loss: 1.2451e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 9.1934e-05 - val_loss: 6.7186e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.7149e-05 - val_loss: 5.8389e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 9.7059e-05 - val_loss: 5.0171e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 841us/step - loss: 8.2661e-05 - val_loss: 8.4093e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 7.3461e-05 - val_loss: 1.6700e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.5791e-05 - val_loss: 6.7417e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.6788e-05 - val_loss: 1.2441e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9504e-05 - val_loss: 5.6614e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.3554e-05 - val_loss: 6.4861e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.3065e-05 - val_loss: 6.1033e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.2527e-05 - val_loss: 4.6808e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8048e-05 - val_loss: 4.6073e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.5351e-05 - val_loss: 1.7221e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2030e-05 - val_loss: 6.0495e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7888e-05 - val_loss: 6.5869e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.2212e-05 - val_loss: 5.0512e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8149e-05 - val_loss: 4.4547e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.5386e-05 - val_loss: 1.4296e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.7222e-05 - val_loss: 1.4803e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.4691e-05 - val_loss: 6.9699e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 735us/step - loss: 6.0311e-05 - val_loss: 4.3733e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.3198e-05 - val_loss: 6.3387e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 736us/step - loss: 5.1964e-05 - val_loss: 5.6306e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2728e-05 - val_loss: 4.6866e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 5.7579e-05 - val_loss: 4.5526e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.5217e-05 - val_loss: 5.2271e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5918e-05 - val_loss: 5.0087e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 5.2612e-05 - val_loss: 4.4033e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 747us/step - loss: 5.4341e-05 - val_loss: 7.9510e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 4.7101e-05 - val_loss: 4.0622e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7456e-05 - val_loss: 5.7486e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 5.6014e-05 - val_loss: 6.0570e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8716e-05 - val_loss: 4.7430e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4483e-05 - val_loss: 6.2121e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9913e-05 - val_loss: 5.5129e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6333e-05 - val_loss: 4.2414e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.7128e-05 - val_loss: 7.8914e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 7.5063e-05 - val_loss: 4.4733e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7048e-05 - val_loss: 4.2642e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4755e-05 - val_loss: 4.6294e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0582e-05 - val_loss: 4.4453e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.0186e-05 - val_loss: 4.7686e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8607e-05 - val_loss: 3.9751e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7830e-05 - val_loss: 1.2788e-04\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1334e-05 - val_loss: 5.0865e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7145e-05 - val_loss: 4.0475e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 5.4531e-05 - val_loss: 6.2075e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5906e-05 - val_loss: 6.6319e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9496e-05 - val_loss: 1.0351e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5900e-05 - val_loss: 9.1293e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3594e-05 - val_loss: 6.8101e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3050e-05 - val_loss: 4.7408e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8466e-05 - val_loss: 4.9637e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4516e-05 - val_loss: 7.1672e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8312e-05 - val_loss: 4.1635e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8402e-05 - val_loss: 6.0879e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0847e-05 - val_loss: 5.8598e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0101e-05 - val_loss: 6.8773e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5625e-05 - val_loss: 4.4585e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.9656e-05 - val_loss: 4.6978e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.2798e-05 - val_loss: 7.5632e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4865e-05 - val_loss: 3.9782e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8120e-05 - val_loss: 4.1981e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2715e-05 - val_loss: 6.0011e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3298e-05 - val_loss: 4.3475e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.0487e-05 - val_loss: 4.7807e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.8931e-05 - val_loss: 7.5081e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_45\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_45\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0143 - val_loss: 0.0021\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 1.0572e-04 - val_loss: 2.0914e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 8.2806e-05 - val_loss: 8.7814e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 8.0497e-05 - val_loss: 1.0704e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 7.4847e-05 - val_loss: 1.7692e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 6.8358e-05 - val_loss: 1.1313e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 852us/step - loss: 6.3753e-05 - val_loss: 6.5126e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 6.1546e-05 - val_loss: 5.5564e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 6.2997e-05 - val_loss: 7.1825e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 7.2066e-05 - val_loss: 5.1170e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 800us/step - loss: 5.8335e-05 - val_loss: 5.1862e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 5.6448e-05 - val_loss: 1.0560e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 806us/step - loss: 6.2149e-05 - val_loss: 1.5707e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 8.4482e-05 - val_loss: 5.7022e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 5.9773e-05 - val_loss: 9.9323e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 7.0880e-05 - val_loss: 1.2692e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 6.1846e-05 - val_loss: 1.2447e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 9.2516e-05 - val_loss: 8.4031e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9920e-05 - val_loss: 6.3445e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 9.9420e-05 - val_loss: 5.7915e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 7.8425e-05 - val_loss: 2.0217e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 7.0534e-05 - val_loss: 8.6736e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 821us/step - loss: 6.2219e-05 - val_loss: 4.5744e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 9.6340e-05 - val_loss: 5.4057e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 7.8018e-05 - val_loss: 1.9353e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 812us/step - loss: 7.4575e-05 - val_loss: 1.3071e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 6.0852e-05 - val_loss: 6.7457e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 9.5527e-05 - val_loss: 1.1403e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 6.8242e-05 - val_loss: 6.2173e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 814us/step - loss: 7.1209e-05 - val_loss: 1.7754e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 6.4735e-05 - val_loss: 1.2382e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 819us/step - loss: 6.7172e-05 - val_loss: 4.8850e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 902us/step - loss: 7.3567e-05 - val_loss: 1.9517e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 830us/step - loss: 6.1518e-05 - val_loss: 6.6136e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 5.7762e-05 - val_loss: 1.5221e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 5.5923e-05 - val_loss: 8.4766e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 7.6381e-05 - val_loss: 4.7898e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 7.1591e-05 - val_loss: 4.4647e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 6.6392e-05 - val_loss: 5.5798e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 6.6906e-05 - val_loss: 1.0954e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 797us/step - loss: 6.2226e-05 - val_loss: 5.1619e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1383e-05 - val_loss: 7.0108e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8063e-05 - val_loss: 6.6637e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7723e-05 - val_loss: 8.5332e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.4906e-05 - val_loss: 7.5371e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.6880e-05 - val_loss: 1.2237e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.7202e-05 - val_loss: 8.5165e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.8994e-05 - val_loss: 4.3185e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.7660e-05 - val_loss: 1.1267e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.1524e-05 - val_loss: 8.3649e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4738e-05 - val_loss: 5.1207e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.5503e-05 - val_loss: 7.6363e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1492e-05 - val_loss: 9.0981e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6818e-05 - val_loss: 4.8428e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.7311e-05 - val_loss: 9.4959e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.5767e-05 - val_loss: 1.6871e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2187e-05 - val_loss: 4.9786e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.3094e-05 - val_loss: 4.0466e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3753e-05 - val_loss: 5.6007e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.9467e-05 - val_loss: 6.2856e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6413e-05 - val_loss: 4.1971e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.4439e-05 - val_loss: 4.3627e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8752e-05 - val_loss: 2.4778e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8115e-05 - val_loss: 7.6379e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9100e-05 - val_loss: 4.5264e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1139e-05 - val_loss: 6.3590e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3480e-05 - val_loss: 4.7287e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.8421e-05 - val_loss: 1.1940e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3653e-05 - val_loss: 1.1778e-04\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7836e-05 - val_loss: 2.1994e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2794e-05 - val_loss: 1.1315e-04\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.0691e-05 - val_loss: 4.6591e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.6775e-05 - val_loss: 1.8903e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3920e-05 - val_loss: 4.4003e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4541e-05 - val_loss: 1.7586e-04\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5278e-05 - val_loss: 1.2111e-04\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7324e-05 - val_loss: 4.7281e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4197e-05 - val_loss: 1.0270e-04\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.8645e-05 - val_loss: 4.2463e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 740us/step - loss: 5.0670e-05 - val_loss: 5.1319e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0946e-05 - val_loss: 8.6914e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.1129e-05 - val_loss: 5.4373e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_46\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_46\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0118 - val_loss: 0.0022\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 1.3553e-04 - val_loss: 0.0011\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 9.7136e-05 - val_loss: 4.5449e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.6433e-05 - val_loss: 2.8250e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.6746e-05 - val_loss: 8.3717e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.9766e-05 - val_loss: 6.6316e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.2521e-05 - val_loss: 7.1105e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2226e-05 - val_loss: 5.7118e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 6.7857e-05 - val_loss: 6.1769e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 749us/step - loss: 6.3685e-05 - val_loss: 6.8236e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.6250e-05 - val_loss: 5.5575e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5275e-05 - val_loss: 6.0270e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4904e-05 - val_loss: 5.0055e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.9263e-05 - val_loss: 5.1402e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.3426e-05 - val_loss: 1.8189e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.3178e-05 - val_loss: 5.0756e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2818e-05 - val_loss: 6.1795e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.3500e-05 - val_loss: 5.6842e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.4819e-05 - val_loss: 5.2446e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 1.1147e-04 - val_loss: 2.3590e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.1726e-05 - val_loss: 4.8139e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.4384e-05 - val_loss: 5.6703e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.9719e-05 - val_loss: 7.5328e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 9.0754e-05 - val_loss: 4.3617e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4759e-05 - val_loss: 9.0448e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.9283e-05 - val_loss: 4.4654e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.6344e-05 - val_loss: 1.2854e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 7.1473e-05 - val_loss: 8.0031e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 7.3457e-05 - val_loss: 1.7805e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8399e-05 - val_loss: 7.7073e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.8350e-05 - val_loss: 2.2383e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.8928e-05 - val_loss: 7.6718e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.7344e-05 - val_loss: 6.9354e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7646e-05 - val_loss: 4.3168e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.3606e-05 - val_loss: 5.5421e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.0943e-05 - val_loss: 1.4637e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3357e-05 - val_loss: 6.6592e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.3926e-05 - val_loss: 1.4460e-04\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.8752e-05 - val_loss: 1.6448e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.7168e-05 - val_loss: 1.6305e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.0085e-05 - val_loss: 6.5392e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.1291e-05 - val_loss: 4.7669e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.9789e-05 - val_loss: 5.3002e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.6889e-05 - val_loss: 6.9113e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5983e-05 - val_loss: 5.9798e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3663e-05 - val_loss: 4.4561e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.2113e-05 - val_loss: 5.2044e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7748e-05 - val_loss: 8.2733e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5978e-05 - val_loss: 4.1161e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2815e-05 - val_loss: 8.7096e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4916e-05 - val_loss: 1.5978e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.3283e-05 - val_loss: 4.7906e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.3768e-05 - val_loss: 6.1488e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 5.4663e-05 - val_loss: 8.1941e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6375e-05 - val_loss: 7.4317e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.8822e-05 - val_loss: 4.4233e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.2607e-05 - val_loss: 5.0905e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.2081e-05 - val_loss: 4.3567e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7800e-05 - val_loss: 6.2971e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7774e-05 - val_loss: 4.0762e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6606e-05 - val_loss: 6.7377e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.8417e-05 - val_loss: 8.0492e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6977e-05 - val_loss: 5.2295e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 6.1544e-05 - val_loss: 1.6019e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2922e-05 - val_loss: 4.5532e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.7282e-05 - val_loss: 4.4761e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3389e-05 - val_loss: 6.8849e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.5105e-05 - val_loss: 5.0188e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 4.8867e-05 - val_loss: 4.2117e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6071e-05 - val_loss: 4.6239e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9276e-05 - val_loss: 5.3593e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2491e-05 - val_loss: 1.9576e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8181e-05 - val_loss: 4.0152e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6630e-05 - val_loss: 4.6561e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9981e-05 - val_loss: 5.2541e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 758us/step - loss: 4.6482e-05 - val_loss: 5.8725e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.1004e-05 - val_loss: 5.7147e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.4400e-05 - val_loss: 1.1020e-04\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.5137e-05 - val_loss: 5.6949e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5131e-05 - val_loss: 5.2625e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 4.9583e-05 - val_loss: 6.4608e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 4.7835e-05 - val_loss: 7.7376e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8901e-05 - val_loss: 7.3287e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.9438e-05 - val_loss: 1.6381e-04\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 4.2167e-05 - val_loss: 3.9192e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7063e-05 - val_loss: 4.3054e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.4970e-05 - val_loss: 3.9860e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7785e-05 - val_loss: 3.9710e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 746us/step - loss: 5.5604e-05 - val_loss: 5.3263e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4077e-05 - val_loss: 4.8904e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7842e-05 - val_loss: 5.3503e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4537e-05 - val_loss: 4.0881e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8681e-05 - val_loss: 4.8899e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 774us/step - loss: 4.8184e-05 - val_loss: 4.4450e-05\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5395e-05 - val_loss: 9.0894e-05\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.3823e-05 - val_loss: 5.1715e-05\n",
      "Epoch 97/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3289e-05 - val_loss: 6.7476e-05\n",
      "Epoch 98/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.7243e-05 - val_loss: 7.3676e-05\n",
      "Epoch 99/2000\n",
      "183/183 [==============================] - 0s 741us/step - loss: 4.6627e-05 - val_loss: 5.0359e-05\n",
      "Epoch 100/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.6583e-05 - val_loss: 7.7913e-05\n",
      "Epoch 101/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.6638e-05 - val_loss: 3.9062e-05\n",
      "Epoch 102/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.2895e-05 - val_loss: 3.9358e-05\n",
      "Epoch 103/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3044e-05 - val_loss: 4.0443e-05\n",
      "Epoch 104/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.0838e-05 - val_loss: 4.0929e-05\n",
      "Epoch 105/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3087e-05 - val_loss: 3.9553e-05\n",
      "Epoch 106/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.5146e-05 - val_loss: 4.3124e-05\n",
      "Epoch 107/2000\n",
      "183/183 [==============================] - 0s 863us/step - loss: 4.4390e-05 - val_loss: 6.7549e-05\n",
      "Epoch 108/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5701e-05 - val_loss: 5.8802e-05\n",
      "Epoch 109/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3481e-05 - val_loss: 5.8685e-05\n",
      "Epoch 110/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.5675e-05 - val_loss: 8.1494e-05\n",
      "Epoch 111/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.6497e-05 - val_loss: 5.9314e-05\n",
      "Epoch 112/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4508e-05 - val_loss: 5.0361e-05\n",
      "Epoch 113/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.7098e-05 - val_loss: 7.6869e-05\n",
      "Epoch 114/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4744e-05 - val_loss: 4.1871e-05\n",
      "Epoch 115/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.3300e-05 - val_loss: 4.0232e-05\n",
      "Epoch 116/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.3044e-05 - val_loss: 1.0785e-04\n",
      "Epoch 117/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.8596e-05 - val_loss: 4.4356e-05\n",
      "Epoch 118/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 4.0544e-05 - val_loss: 6.1479e-05\n",
      "Epoch 119/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.3768e-05 - val_loss: 4.1135e-05\n",
      "Epoch 120/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1135e-05 - val_loss: 3.9913e-05\n",
      "Epoch 121/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.0826e-05 - val_loss: 4.1469e-05\n",
      "Epoch 122/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.0036e-05 - val_loss: 6.4035e-05\n",
      "Epoch 123/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.9836e-05 - val_loss: 3.8522e-05\n",
      "Epoch 124/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.1582e-05 - val_loss: 1.0040e-04\n",
      "Epoch 125/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2036e-05 - val_loss: 5.2678e-05\n",
      "Epoch 126/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.1500e-05 - val_loss: 3.7469e-05\n",
      "Epoch 127/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.0251e-05 - val_loss: 4.0448e-05\n",
      "Epoch 128/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5099e-05 - val_loss: 4.4430e-05\n",
      "Epoch 129/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7819e-05 - val_loss: 3.7311e-05\n",
      "Epoch 130/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 3.9455e-05 - val_loss: 4.3379e-05\n",
      "Epoch 131/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.2556e-05 - val_loss: 9.6001e-05\n",
      "Epoch 132/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.2245e-05 - val_loss: 5.5392e-05\n",
      "Epoch 133/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.2959e-05 - val_loss: 1.5142e-04\n",
      "Epoch 134/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3362e-05 - val_loss: 7.4661e-05\n",
      "Epoch 135/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.0552e-05 - val_loss: 3.8739e-05\n",
      "Epoch 136/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.7217e-05 - val_loss: 8.8876e-05\n",
      "Epoch 137/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.3263e-05 - val_loss: 6.2863e-05\n",
      "Epoch 138/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.4963e-05 - val_loss: 4.2702e-05\n",
      "Epoch 139/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 3.8535e-05 - val_loss: 4.3682e-05\n",
      "Epoch 140/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.0221e-05 - val_loss: 6.2713e-05\n",
      "Epoch 141/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.0547e-05 - val_loss: 3.7675e-05\n",
      "Epoch 142/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.3602e-05 - val_loss: 4.4199e-05\n",
      "Epoch 143/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 3.9186e-05 - val_loss: 4.8988e-05\n",
      "Epoch 144/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 3.9530e-05 - val_loss: 3.7859e-05\n",
      "Epoch 145/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.3465e-05 - val_loss: 3.9149e-05\n",
      "Epoch 146/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.1568e-05 - val_loss: 4.1233e-05\n",
      "Epoch 147/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.4348e-05 - val_loss: 4.9257e-05\n",
      "Epoch 148/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.2765e-05 - val_loss: 5.1238e-05\n",
      "Epoch 149/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 3.8198e-05 - val_loss: 1.0799e-04\n",
      "Epoch 150/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.1112e-05 - val_loss: 4.6695e-05\n",
      "Epoch 151/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.1446e-05 - val_loss: 3.7920e-05\n",
      "Epoch 152/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.1203e-05 - val_loss: 4.0054e-05\n",
      "Epoch 153/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 3.7654e-05 - val_loss: 4.3800e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_47\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_47\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 4.4751e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 8.9022e-05 - val_loss: 2.7895e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 8.5452e-05 - val_loss: 8.4944e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 8.5088e-05 - val_loss: 6.8853e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 711us/step - loss: 7.6637e-05 - val_loss: 2.1294e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 9.0153e-05 - val_loss: 7.8626e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 8.4645e-05 - val_loss: 1.0088e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 713us/step - loss: 7.0437e-05 - val_loss: 6.0064e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 8.0272e-05 - val_loss: 2.6382e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 7.8122e-05 - val_loss: 1.4671e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.5927e-05 - val_loss: 1.2148e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 776us/step - loss: 8.7799e-05 - val_loss: 7.5949e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 7.2366e-05 - val_loss: 4.6772e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 8.4380e-05 - val_loss: 5.9007e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 775us/step - loss: 7.9160e-05 - val_loss: 7.0664e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 8.3695e-05 - val_loss: 1.3137e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.1266e-05 - val_loss: 4.7072e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 6.7409e-05 - val_loss: 7.9414e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 1.0249e-04 - val_loss: 4.4699e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.9642e-05 - val_loss: 1.0041e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 7.2586e-05 - val_loss: 5.8948e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.5620e-05 - val_loss: 5.3567e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.9548e-05 - val_loss: 2.9268e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 891us/step - loss: 6.5277e-05 - val_loss: 4.4123e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 6.0095e-05 - val_loss: 4.3263e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.9444e-05 - val_loss: 5.6347e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4108e-05 - val_loss: 1.8760e-04\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.2414e-05 - val_loss: 3.3164e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.9632e-05 - val_loss: 9.0517e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.9738e-05 - val_loss: 5.6345e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.1588e-05 - val_loss: 4.7824e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.4458e-05 - val_loss: 5.4647e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.2883e-05 - val_loss: 4.1984e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3483e-05 - val_loss: 1.0512e-04\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.8108e-05 - val_loss: 4.5846e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.6239e-05 - val_loss: 1.8306e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.5303e-05 - val_loss: 7.8942e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7008e-05 - val_loss: 5.3739e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9897e-05 - val_loss: 3.8666e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 8.5432e-05 - val_loss: 5.0336e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.1577e-05 - val_loss: 7.0905e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.4382e-05 - val_loss: 7.9914e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8047e-05 - val_loss: 8.6259e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.6788e-05 - val_loss: 8.7300e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.0852e-05 - val_loss: 4.2813e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.0377e-05 - val_loss: 8.3507e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9854e-05 - val_loss: 4.6095e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0518e-05 - val_loss: 8.8997e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.7285e-05 - val_loss: 5.8863e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.2694e-05 - val_loss: 5.2078e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8647e-05 - val_loss: 7.7162e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0112e-05 - val_loss: 5.3237e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.1593e-05 - val_loss: 1.6764e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.2757e-05 - val_loss: 6.5505e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7687e-05 - val_loss: 4.2012e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.4830e-05 - val_loss: 5.2377e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7226e-05 - val_loss: 1.5991e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4679e-05 - val_loss: 4.9177e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.1827e-05 - val_loss: 4.4211e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.1519e-05 - val_loss: 8.1577e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.9429e-05 - val_loss: 5.1746e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.7352e-05 - val_loss: 4.0561e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.1491e-05 - val_loss: 1.1833e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_48\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 1.2075e-04 - val_loss: 9.9855e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 9.3559e-05 - val_loss: 2.5559e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 8.3400e-05 - val_loss: 1.3399e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 7.8384e-05 - val_loss: 8.8953e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 7.4858e-05 - val_loss: 1.1188e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 8.1030e-05 - val_loss: 6.9382e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.4138e-05 - val_loss: 6.6794e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 7.3037e-05 - val_loss: 6.8577e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.9725e-05 - val_loss: 8.8151e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 6.4956e-05 - val_loss: 5.7182e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.6664e-05 - val_loss: 8.1143e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 8.4258e-05 - val_loss: 8.5474e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.1493e-05 - val_loss: 6.5063e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 7.3767e-05 - val_loss: 1.1684e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 9.9443e-05 - val_loss: 1.0017e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.9390e-05 - val_loss: 7.3984e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 703us/step - loss: 6.9740e-05 - val_loss: 1.0148e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 703us/step - loss: 6.5975e-05 - val_loss: 4.8981e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.4694e-05 - val_loss: 4.9334e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 7.4123e-05 - val_loss: 8.4843e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 7.5015e-05 - val_loss: 6.5065e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.7050e-05 - val_loss: 5.0783e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.4174e-05 - val_loss: 5.2893e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.5595e-05 - val_loss: 1.3930e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.6863e-05 - val_loss: 5.7864e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.2536e-05 - val_loss: 5.8870e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.2429e-05 - val_loss: 1.2948e-04\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.7836e-05 - val_loss: 1.0896e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 6.2945e-05 - val_loss: 4.4829e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.9602e-05 - val_loss: 6.5881e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.4342e-05 - val_loss: 1.2232e-04\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.8475e-05 - val_loss: 1.3329e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.6313e-05 - val_loss: 5.0663e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 6.0795e-05 - val_loss: 7.0161e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.9078e-05 - val_loss: 8.3991e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.1062e-05 - val_loss: 9.2719e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1230e-05 - val_loss: 6.3505e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.9984e-05 - val_loss: 1.6622e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7111e-05 - val_loss: 6.6745e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3371e-05 - val_loss: 1.1285e-04\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.7759e-05 - val_loss: 5.7440e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 6.0953e-05 - val_loss: 9.3974e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.8706e-05 - val_loss: 9.9127e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 6.2754e-05 - val_loss: 5.1813e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.2617e-05 - val_loss: 7.2435e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.0233e-05 - val_loss: 5.8965e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0024e-05 - val_loss: 8.4046e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.2397e-05 - val_loss: 4.2558e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4387e-05 - val_loss: 5.3924e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 6.2107e-05 - val_loss: 6.3244e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.6369e-05 - val_loss: 8.1553e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.4088e-05 - val_loss: 4.9220e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3003e-05 - val_loss: 7.1384e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8861e-05 - val_loss: 4.1540e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8572e-05 - val_loss: 8.5126e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3471e-05 - val_loss: 8.3668e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.2205e-05 - val_loss: 1.6617e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.6487e-05 - val_loss: 6.8268e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.2964e-05 - val_loss: 2.0297e-04\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.4832e-05 - val_loss: 6.2943e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.7621e-05 - val_loss: 4.3278e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.9452e-05 - val_loss: 4.3672e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.6757e-05 - val_loss: 1.0027e-04\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.2693e-05 - val_loss: 1.4908e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7773e-05 - val_loss: 6.5980e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.0374e-05 - val_loss: 4.4787e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7472e-05 - val_loss: 4.6700e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.0839e-05 - val_loss: 7.7206e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4472e-05 - val_loss: 1.2031e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.4950e-05 - val_loss: 5.4124e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1977e-05 - val_loss: 1.1316e-04\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.8595e-05 - val_loss: 4.6744e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.8888e-05 - val_loss: 4.3968e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6079e-05 - val_loss: 5.0901e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5352e-05 - val_loss: 4.0624e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.6141e-05 - val_loss: 1.1863e-04\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.0257e-05 - val_loss: 7.9208e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.8993e-05 - val_loss: 4.6591e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.4417e-05 - val_loss: 4.6305e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.9537e-05 - val_loss: 5.3079e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.6264e-05 - val_loss: 4.4793e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 5.1386e-05 - val_loss: 8.1901e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5004e-05 - val_loss: 3.9716e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9790e-05 - val_loss: 5.1968e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.9613e-05 - val_loss: 4.4017e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.2771e-05 - val_loss: 4.8331e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.9069e-05 - val_loss: 1.0588e-04\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 5.0735e-05 - val_loss: 8.5712e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.7686e-05 - val_loss: 4.6395e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.8549e-05 - val_loss: 8.0111e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.4252e-05 - val_loss: 4.1578e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.1541e-05 - val_loss: 4.5444e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.1409e-05 - val_loss: 4.5653e-05\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.3605e-05 - val_loss: 4.2270e-05\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.0641e-05 - val_loss: 5.3019e-05\n",
      "Epoch 97/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.5476e-05 - val_loss: 1.5365e-04\n",
      "Epoch 98/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.7216e-05 - val_loss: 1.0426e-04\n",
      "Epoch 99/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.6608e-05 - val_loss: 1.0647e-04\n",
      "Epoch 100/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.6055e-05 - val_loss: 7.2234e-05\n",
      "Epoch 101/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.6501e-05 - val_loss: 4.3263e-05\n",
      "Epoch 102/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.4213e-05 - val_loss: 7.9839e-05\n",
      "Epoch 103/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.3197e-05 - val_loss: 7.3910e-05\n",
      "Epoch 104/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.4966e-05 - val_loss: 4.5005e-05\n",
      "Epoch 105/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.5914e-05 - val_loss: 9.7509e-05\n",
      "Epoch 106/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.5056e-05 - val_loss: 5.1972e-05\n",
      "Epoch 107/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.8352e-05 - val_loss: 3.9432e-05\n",
      "Epoch 108/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.3090e-05 - val_loss: 8.1154e-05\n",
      "Epoch 109/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.5932e-05 - val_loss: 7.0146e-05\n",
      "Epoch 110/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.5081e-05 - val_loss: 5.0469e-05\n",
      "Epoch 111/2000\n",
      "183/183 [==============================] - 0s 698us/step - loss: 4.7922e-05 - val_loss: 5.0563e-05\n",
      "Epoch 112/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.1955e-05 - val_loss: 4.8075e-05\n",
      "Epoch 113/2000\n",
      "183/183 [==============================] - 0s 890us/step - loss: 4.3301e-05 - val_loss: 4.4752e-05\n",
      "Epoch 114/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.2053e-05 - val_loss: 4.0451e-05\n",
      "Epoch 115/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.2445e-05 - val_loss: 8.7906e-05\n",
      "Epoch 116/2000\n",
      "183/183 [==============================] - 0s 929us/step - loss: 5.2291e-05 - val_loss: 6.1262e-05\n",
      "Epoch 117/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.7548e-05 - val_loss: 4.7440e-05\n",
      "Epoch 118/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.1029e-05 - val_loss: 6.3543e-05\n",
      "Epoch 119/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5683e-05 - val_loss: 7.2729e-05\n",
      "Epoch 120/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8371e-05 - val_loss: 4.1754e-05\n",
      "Epoch 121/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.3436e-05 - val_loss: 6.8239e-05\n",
      "Epoch 122/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.3327e-05 - val_loss: 4.6216e-05\n",
      "Epoch 123/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.1564e-05 - val_loss: 3.9286e-05\n",
      "Epoch 124/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 4.0607e-05 - val_loss: 7.4084e-05\n",
      "Epoch 125/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.7472e-05 - val_loss: 4.6054e-05\n",
      "Epoch 126/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.7382e-05 - val_loss: 5.4196e-05\n",
      "Epoch 127/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9891e-05 - val_loss: 6.0353e-05\n",
      "Epoch 128/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.3520e-05 - val_loss: 8.8120e-05\n",
      "Epoch 129/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.3636e-05 - val_loss: 4.3955e-05\n",
      "Epoch 130/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.1365e-05 - val_loss: 4.2845e-05\n",
      "Epoch 131/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.2684e-05 - val_loss: 4.1495e-05\n",
      "Epoch 132/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.2740e-05 - val_loss: 6.4207e-05\n",
      "Epoch 133/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.5362e-05 - val_loss: 5.3767e-05\n",
      "Epoch 134/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.1904e-05 - val_loss: 3.8475e-05\n",
      "Epoch 135/2000\n",
      "183/183 [==============================] - 0s 803us/step - loss: 4.8181e-05 - val_loss: 6.5287e-05\n",
      "Epoch 136/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.6580e-05 - val_loss: 3.8528e-05\n",
      "Epoch 137/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.0264e-05 - val_loss: 4.1165e-05\n",
      "Epoch 138/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.8363e-05 - val_loss: 6.1359e-05\n",
      "Epoch 139/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4493e-05 - val_loss: 4.0914e-05\n",
      "Epoch 140/2000\n",
      "183/183 [==============================] - 0s 913us/step - loss: 4.7078e-05 - val_loss: 5.5446e-05\n",
      "Epoch 141/2000\n",
      "183/183 [==============================] - 0s 744us/step - loss: 4.8314e-05 - val_loss: 6.9851e-05\n",
      "Epoch 142/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.4357e-05 - val_loss: 3.8455e-05\n",
      "Epoch 143/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.0692e-05 - val_loss: 4.7425e-05\n",
      "Epoch 144/2000\n",
      "183/183 [==============================] - 0s 807us/step - loss: 4.6878e-05 - val_loss: 5.9178e-05\n",
      "Epoch 145/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 3.8102e-05 - val_loss: 8.5275e-05\n",
      "Epoch 146/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.7412e-05 - val_loss: 6.3947e-05\n",
      "Epoch 147/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.8832e-05 - val_loss: 6.3500e-05\n",
      "Epoch 148/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3469e-05 - val_loss: 4.5042e-05\n",
      "Epoch 149/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.9509e-05 - val_loss: 5.9506e-05\n",
      "Epoch 150/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6603e-05 - val_loss: 7.5638e-05\n",
      "Epoch 151/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.9328e-05 - val_loss: 3.9944e-05\n",
      "Epoch 152/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.3003e-05 - val_loss: 5.5174e-05\n",
      "Epoch 153/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.2277e-05 - val_loss: 4.6618e-05\n",
      "Epoch 154/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7192e-05 - val_loss: 6.2749e-05\n",
      "Epoch 155/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.2356e-05 - val_loss: 4.8039e-05\n",
      "Epoch 156/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.3461e-05 - val_loss: 4.2341e-05\n",
      "Epoch 157/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.9658e-05 - val_loss: 1.5422e-04\n",
      "Epoch 158/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 3.9713e-05 - val_loss: 5.6725e-05\n",
      "Epoch 159/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.9612e-05 - val_loss: 3.7336e-05\n",
      "Epoch 160/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.0574e-05 - val_loss: 4.1121e-05\n",
      "Epoch 161/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 4.8952e-05 - val_loss: 3.8233e-05\n",
      "Epoch 162/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.2896e-05 - val_loss: 3.9788e-05\n",
      "Epoch 163/2000\n",
      "183/183 [==============================] - 0s 825us/step - loss: 4.2974e-05 - val_loss: 4.1082e-05\n",
      "Epoch 164/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.1511e-05 - val_loss: 5.7009e-05\n",
      "Epoch 165/2000\n",
      "183/183 [==============================] - 0s 764us/step - loss: 4.2686e-05 - val_loss: 4.4855e-05\n",
      "Epoch 166/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.2556e-05 - val_loss: 4.9752e-05\n",
      "Epoch 167/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 3.9034e-05 - val_loss: 4.2001e-05\n",
      "Epoch 168/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.0937e-05 - val_loss: 6.5068e-05\n",
      "Epoch 169/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.5536e-05 - val_loss: 3.7966e-05\n",
      "Epoch 170/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.4420e-05 - val_loss: 9.9978e-05\n",
      "Epoch 171/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.9613e-05 - val_loss: 3.8374e-05\n",
      "Epoch 172/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.3544e-05 - val_loss: 4.0573e-05\n",
      "Epoch 173/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8054e-05 - val_loss: 4.9756e-05\n",
      "Epoch 174/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.2690e-05 - val_loss: 5.2331e-05\n",
      "Epoch 175/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 3.8619e-05 - val_loss: 4.4545e-05\n",
      "Epoch 176/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 3.9142e-05 - val_loss: 5.5261e-05\n",
      "Epoch 177/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.1639e-05 - val_loss: 5.1465e-05\n",
      "Epoch 178/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.3199e-05 - val_loss: 5.3046e-05\n",
      "Epoch 179/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 3.8539e-05 - val_loss: 3.9246e-05\n",
      "Epoch 180/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.0686e-05 - val_loss: 4.4848e-05\n",
      "Epoch 181/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.2871e-05 - val_loss: 4.0303e-05\n",
      "Epoch 182/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.3664e-05 - val_loss: 5.4691e-05\n",
      "Epoch 183/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 3.7337e-05 - val_loss: 4.2018e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_49\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_49\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 1.1599e-04 - val_loss: 7.8127e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.7524e-05 - val_loss: 1.5611e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 6.2132e-05 - val_loss: 1.8271e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.9714e-05 - val_loss: 4.7127e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.5981e-05 - val_loss: 4.3764e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.0898e-05 - val_loss: 6.5208e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.2414e-05 - val_loss: 6.3150e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.9757e-05 - val_loss: 1.9727e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.6859e-05 - val_loss: 7.7412e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 7.3108e-05 - val_loss: 2.4315e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.3607e-05 - val_loss: 5.6459e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.8895e-05 - val_loss: 5.7778e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 8.0203e-05 - val_loss: 1.2483e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 8.1315e-05 - val_loss: 1.2173e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 710us/step - loss: 5.9514e-05 - val_loss: 1.4273e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 6.6340e-05 - val_loss: 5.5482e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.1715e-05 - val_loss: 5.3732e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 6.3561e-05 - val_loss: 6.8144e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.5679e-05 - val_loss: 2.0252e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 710us/step - loss: 7.5544e-05 - val_loss: 2.9244e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.6088e-05 - val_loss: 5.1937e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 721us/step - loss: 5.9912e-05 - val_loss: 8.4715e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 5.7601e-05 - val_loss: 4.5996e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.4991e-05 - val_loss: 4.5807e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.3279e-05 - val_loss: 4.9117e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 6.3295e-05 - val_loss: 4.9714e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 6.2315e-05 - val_loss: 4.2286e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 5.3050e-05 - val_loss: 4.0442e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 5.4946e-05 - val_loss: 1.5031e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.4815e-05 - val_loss: 4.7235e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 5.9977e-05 - val_loss: 4.1031e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 5.3310e-05 - val_loss: 8.6125e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 6.1714e-05 - val_loss: 5.5584e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 7.2924e-05 - val_loss: 4.7085e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 6.2173e-05 - val_loss: 5.4231e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.5319e-05 - val_loss: 1.2934e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 703us/step - loss: 5.4636e-05 - val_loss: 8.8111e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 6.0155e-05 - val_loss: 4.9949e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8105e-05 - val_loss: 9.5716e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.9295e-05 - val_loss: 8.3564e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.3959e-05 - val_loss: 4.2340e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 721us/step - loss: 5.0636e-05 - val_loss: 4.5154e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8881e-05 - val_loss: 4.4563e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.2842e-05 - val_loss: 1.3072e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.6093e-05 - val_loss: 6.4473e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.3632e-05 - val_loss: 5.7877e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4877e-05 - val_loss: 4.8846e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.4031e-05 - val_loss: 1.7044e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.3582e-05 - val_loss: 1.0707e-04\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.4225e-05 - val_loss: 4.5795e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.7042e-05 - val_loss: 1.4215e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.1750e-05 - val_loss: 5.5378e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 1.3751e-04 - val_loss: 0.0021\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 1.0588e-04 - val_loss: 0.0010\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 1.0826e-04 - val_loss: 9.4922e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 1.0348e-04 - val_loss: 4.1371e-04\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 836us/step - loss: 6.9137e-05 - val_loss: 3.9002e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.6351e-05 - val_loss: 3.7574e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 8.0423e-05 - val_loss: 1.0063e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 8.1210e-05 - val_loss: 8.2137e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.6892e-05 - val_loss: 8.8992e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.7330e-05 - val_loss: 6.0918e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.8221e-05 - val_loss: 1.1336e-04\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 8.6638e-05 - val_loss: 7.1497e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 1.0386e-04 - val_loss: 2.8645e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 9.7649e-05 - val_loss: 1.3480e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 9.0051e-05 - val_loss: 8.9617e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.8167e-05 - val_loss: 4.1801e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.1060e-05 - val_loss: 8.3530e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.2352e-05 - val_loss: 5.3204e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.9033e-05 - val_loss: 6.2573e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.3222e-05 - val_loss: 4.3782e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 8.1011e-05 - val_loss: 1.1330e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7776e-05 - val_loss: 8.8455e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.2706e-05 - val_loss: 1.0251e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.1877e-05 - val_loss: 1.2969e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.0406e-05 - val_loss: 4.2428e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.5853e-05 - val_loss: 5.8366e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.1271e-05 - val_loss: 6.0512e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.7350e-05 - val_loss: 1.7467e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7093e-05 - val_loss: 6.7223e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.6630e-05 - val_loss: 5.7895e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0515e-05 - val_loss: 4.4491e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.6119e-05 - val_loss: 1.4560e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.0995e-05 - val_loss: 4.0412e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.6268e-05 - val_loss: 4.4814e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.0948e-05 - val_loss: 4.1075e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.6653e-05 - val_loss: 1.0642e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5010e-05 - val_loss: 5.3083e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.0620e-05 - val_loss: 1.8015e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.6470e-05 - val_loss: 5.2583e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 716us/step - loss: 5.1508e-05 - val_loss: 4.6099e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.6714e-05 - val_loss: 4.5728e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.3236e-05 - val_loss: 4.1592e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5242e-05 - val_loss: 4.5739e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9059e-05 - val_loss: 6.5331e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 721us/step - loss: 6.1712e-05 - val_loss: 7.6470e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 4.7372e-05 - val_loss: 7.1669e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 4.5653e-05 - val_loss: 4.7388e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 718us/step - loss: 5.8931e-05 - val_loss: 7.0295e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5872e-05 - val_loss: 8.8367e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5304e-05 - val_loss: 1.3242e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8243e-05 - val_loss: 1.3965e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.3916e-05 - val_loss: 5.8358e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0925e-05 - val_loss: 4.0415e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2482e-05 - val_loss: 4.4530e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 5.1785e-05 - val_loss: 9.7985e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5672e-05 - val_loss: 1.2073e-04\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.0571e-05 - val_loss: 1.2722e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_51\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_51\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 1.0608e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7311e-05 - val_loss: 9.1125e-05\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.4856e-05 - val_loss: 5.7793e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0503e-05 - val_loss: 5.8803e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1651e-05 - val_loss: 6.1287e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8473e-05 - val_loss: 8.1683e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.4263e-05 - val_loss: 8.7770e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.7707e-05 - val_loss: 6.5853e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1816e-05 - val_loss: 4.1725e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.6949e-05 - val_loss: 4.2143e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.9457e-05 - val_loss: 1.2072e-04\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.5088e-05 - val_loss: 6.1091e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1527e-05 - val_loss: 4.1797e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2999e-05 - val_loss: 7.1509e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.1126e-05 - val_loss: 4.8678e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8925e-05 - val_loss: 4.0509e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6441e-05 - val_loss: 8.7863e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.7249e-05 - val_loss: 4.2950e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0519e-05 - val_loss: 5.6608e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5301e-05 - val_loss: 5.1485e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0064e-05 - val_loss: 4.4482e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.8971e-05 - val_loss: 4.0989e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.7059e-05 - val_loss: 4.0169e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3657e-05 - val_loss: 4.0341e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.2885e-05 - val_loss: 4.3014e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5448e-05 - val_loss: 5.3692e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5858e-05 - val_loss: 6.3922e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5209e-05 - val_loss: 8.0298e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.6104e-05 - val_loss: 4.1909e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.8899e-05 - val_loss: 8.0257e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.9088e-05 - val_loss: 4.4648e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5888e-05 - val_loss: 5.5613e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8603e-05 - val_loss: 4.1678e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8964e-05 - val_loss: 3.9581e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.8419e-05 - val_loss: 1.0616e-04\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.7777e-05 - val_loss: 3.8168e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7319e-05 - val_loss: 5.9903e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8927e-05 - val_loss: 4.4573e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.6440e-05 - val_loss: 2.8961e-04\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9880e-05 - val_loss: 4.5374e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8588e-05 - val_loss: 3.8679e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.4661e-05 - val_loss: 5.0843e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.1980e-05 - val_loss: 7.8491e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8185e-05 - val_loss: 4.6105e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.6783e-05 - val_loss: 4.0830e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.1872e-05 - val_loss: 4.0452e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.8861e-05 - val_loss: 4.8587e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.1727e-05 - val_loss: 6.7937e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8696e-05 - val_loss: 1.9023e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.3403e-05 - val_loss: 6.9579e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9515e-05 - val_loss: 7.3903e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9971e-05 - val_loss: 4.4645e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7933e-05 - val_loss: 6.8116e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.3379e-05 - val_loss: 3.9781e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0293e-05 - val_loss: 7.0709e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 4.5393e-05 - val_loss: 5.9325e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 792us/step - loss: 5.2127e-05 - val_loss: 4.0054e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9284e-05 - val_loss: 6.5080e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.4113e-05 - val_loss: 4.0054e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9772e-05 - val_loss: 7.6588e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_52\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.6313e-05 - val_loss: 4.4938e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.9797e-05 - val_loss: 9.8628e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.5007e-05 - val_loss: 6.0723e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.2169e-05 - val_loss: 5.6735e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.0944e-05 - val_loss: 8.9212e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.1289e-05 - val_loss: 6.6707e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.0684e-05 - val_loss: 8.0090e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.4773e-05 - val_loss: 2.0188e-04\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.4472e-05 - val_loss: 6.6670e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.1752e-05 - val_loss: 6.1010e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7851e-05 - val_loss: 4.2709e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3638e-05 - val_loss: 1.1372e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9216e-05 - val_loss: 1.0340e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2583e-05 - val_loss: 2.1051e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.7014e-05 - val_loss: 1.2047e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5742e-05 - val_loss: 4.5154e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9726e-05 - val_loss: 7.0330e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3129e-05 - val_loss: 4.0275e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4678e-05 - val_loss: 7.0932e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.9891e-05 - val_loss: 2.3593e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.8071e-05 - val_loss: 4.0695e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.2849e-05 - val_loss: 4.1338e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.9221e-05 - val_loss: 4.5383e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3141e-05 - val_loss: 1.5698e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8074e-05 - val_loss: 2.7151e-04\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.6168e-05 - val_loss: 6.4151e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.5257e-05 - val_loss: 4.4512e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.3508e-05 - val_loss: 9.6481e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.2235e-05 - val_loss: 6.5760e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7574e-05 - val_loss: 3.9147e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.4931e-05 - val_loss: 5.3851e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.1528e-05 - val_loss: 3.9077e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.6096e-05 - val_loss: 4.3060e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7273e-05 - val_loss: 4.0718e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0662e-05 - val_loss: 1.0483e-04\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.5140e-05 - val_loss: 4.0850e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.6813e-05 - val_loss: 4.3277e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9298e-05 - val_loss: 5.1171e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4479e-05 - val_loss: 5.5919e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.1897e-05 - val_loss: 7.5785e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.5950e-05 - val_loss: 7.0084e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8031e-05 - val_loss: 7.3501e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7549e-05 - val_loss: 5.6741e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9343e-05 - val_loss: 4.8437e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.1801e-05 - val_loss: 2.1259e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.1677e-05 - val_loss: 4.7945e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.7017e-05 - val_loss: 7.6034e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.4118e-05 - val_loss: 1.2702e-04\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6065e-05 - val_loss: 4.6709e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.5459e-05 - val_loss: 6.8763e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.2064e-05 - val_loss: 5.3064e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.4773e-05 - val_loss: 4.7124e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.5475e-05 - val_loss: 7.8697e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.2455e-05 - val_loss: 9.2542e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.6564e-05 - val_loss: 4.7063e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.3216e-05 - val_loss: 1.2513e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_53\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_53\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0076 - val_loss: 8.3779e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 8.3104e-05 - val_loss: 2.8587e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.3628e-05 - val_loss: 3.3458e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.3670e-05 - val_loss: 7.9277e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 6.3480e-05 - val_loss: 6.1137e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.3065e-05 - val_loss: 8.3236e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.6994e-05 - val_loss: 4.9268e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.2410e-05 - val_loss: 5.7431e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 5.6455e-05 - val_loss: 8.0047e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 7.0408e-05 - val_loss: 4.6137e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.8959e-05 - val_loss: 4.7931e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 5.9883e-05 - val_loss: 4.8680e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 6.5134e-05 - val_loss: 6.1298e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 6.8639e-05 - val_loss: 5.1037e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 6.4599e-05 - val_loss: 1.2330e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.3989e-05 - val_loss: 4.4274e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.3480e-05 - val_loss: 6.8995e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.4001e-05 - val_loss: 8.1902e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.8213e-05 - val_loss: 5.2424e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.6480e-05 - val_loss: 1.0627e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 713us/step - loss: 7.3138e-05 - val_loss: 1.4446e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.2481e-05 - val_loss: 1.4773e-04\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 6.0257e-05 - val_loss: 6.6581e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 718us/step - loss: 7.5404e-05 - val_loss: 5.0070e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.6118e-05 - val_loss: 5.8885e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.7209e-05 - val_loss: 4.3811e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 6.5142e-05 - val_loss: 5.2346e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 7.0705e-05 - val_loss: 5.3793e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.3991e-05 - val_loss: 7.4413e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.0817e-05 - val_loss: 4.6267e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 8.3571e-05 - val_loss: 8.6835e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 5.5528e-05 - val_loss: 4.4751e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3314e-05 - val_loss: 4.9424e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.1216e-05 - val_loss: 5.0594e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.1601e-05 - val_loss: 6.7155e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.3042e-05 - val_loss: 4.9625e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.5250e-05 - val_loss: 9.6358e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.0689e-05 - val_loss: 4.9507e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 711us/step - loss: 5.7878e-05 - val_loss: 7.5256e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7964e-05 - val_loss: 5.1965e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.8119e-05 - val_loss: 4.9715e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7651e-05 - val_loss: 4.4334e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.5171e-05 - val_loss: 4.6147e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.2837e-05 - val_loss: 7.7057e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.7513e-05 - val_loss: 5.3824e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.2180e-05 - val_loss: 7.2860e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8934e-05 - val_loss: 5.3897e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.9712e-05 - val_loss: 2.4832e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7867e-05 - val_loss: 5.2065e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.3483e-05 - val_loss: 4.1993e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.4775e-05 - val_loss: 6.5384e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9666e-05 - val_loss: 5.0630e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.9139e-05 - val_loss: 5.6189e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2511e-05 - val_loss: 8.3976e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.1063e-05 - val_loss: 4.2787e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.3428e-05 - val_loss: 1.1150e-04\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7673e-05 - val_loss: 4.3898e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0010e-05 - val_loss: 1.1304e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.2398e-05 - val_loss: 5.7154e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7406e-05 - val_loss: 4.4084e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.8495e-05 - val_loss: 3.9558e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.4574e-05 - val_loss: 4.0623e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8855e-05 - val_loss: 5.7818e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.5828e-05 - val_loss: 4.1364e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.9855e-05 - val_loss: 8.5795e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.2798e-05 - val_loss: 1.4729e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.6295e-05 - val_loss: 4.9585e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.9751e-05 - val_loss: 4.2996e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.6161e-05 - val_loss: 8.0654e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9414e-05 - val_loss: 1.2501e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.1807e-05 - val_loss: 5.7734e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3478e-05 - val_loss: 3.9894e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.8578e-05 - val_loss: 4.4548e-05\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.7452e-05 - val_loss: 3.9481e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4048e-05 - val_loss: 4.2035e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.7442e-05 - val_loss: 5.5011e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.8826e-05 - val_loss: 4.3947e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.6195e-05 - val_loss: 7.1908e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.4609e-05 - val_loss: 1.1336e-04\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.0115e-05 - val_loss: 4.3006e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.6362e-05 - val_loss: 1.9328e-04\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.7824e-05 - val_loss: 4.6944e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.1173e-05 - val_loss: 6.8026e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.9849e-05 - val_loss: 5.1113e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.9227e-05 - val_loss: 5.0749e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3763e-05 - val_loss: 3.7766e-05\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.8502e-05 - val_loss: 4.5626e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9944e-05 - val_loss: 7.4671e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.1309e-05 - val_loss: 7.3902e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.3565e-05 - val_loss: 4.3316e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.5483e-05 - val_loss: 8.0727e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.4237e-05 - val_loss: 4.1996e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.1071e-05 - val_loss: 3.7794e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.5388e-05 - val_loss: 4.1584e-05\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.2207e-05 - val_loss: 3.8100e-05\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.2919e-05 - val_loss: 4.2615e-05\n",
      "Epoch 97/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.2975e-05 - val_loss: 4.5597e-05\n",
      "Epoch 98/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.4184e-05 - val_loss: 7.3164e-05\n",
      "Epoch 99/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8006e-05 - val_loss: 4.2363e-05\n",
      "Epoch 100/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.4081e-05 - val_loss: 3.9563e-05\n",
      "Epoch 101/2000\n",
      "183/183 [==============================] - 0s 713us/step - loss: 4.7208e-05 - val_loss: 9.9282e-05\n",
      "Epoch 102/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.0928e-05 - val_loss: 4.2703e-05\n",
      "Epoch 103/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.4647e-05 - val_loss: 9.4684e-05\n",
      "Epoch 104/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 4.3894e-05 - val_loss: 6.2859e-05\n",
      "Epoch 105/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.6339e-05 - val_loss: 5.5186e-05\n",
      "Epoch 106/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.2384e-05 - val_loss: 8.6271e-05\n",
      "Epoch 107/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.1892e-05 - val_loss: 4.3176e-05\n",
      "Epoch 108/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.2663e-05 - val_loss: 9.4583e-05\n",
      "Epoch 109/2000\n",
      "183/183 [==============================] - 0s 708us/step - loss: 4.2583e-05 - val_loss: 1.5710e-04\n",
      "Epoch 110/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.2397e-05 - val_loss: 8.6406e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_54\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_54\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0044 - val_loss: 3.2704e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 1.0041e-04 - val_loss: 2.7097e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 8.7736e-05 - val_loss: 8.0957e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.8392e-05 - val_loss: 8.2626e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.3250e-05 - val_loss: 7.6567e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.5189e-05 - val_loss: 3.7545e-04\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.3298e-05 - val_loss: 1.6893e-04\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.7907e-05 - val_loss: 6.4422e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.7374e-05 - val_loss: 8.4659e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.1729e-05 - val_loss: 1.1650e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.4792e-05 - val_loss: 6.2813e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 8.5918e-05 - val_loss: 6.7041e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.0454e-05 - val_loss: 6.6437e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.8613e-05 - val_loss: 5.4019e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.0436e-05 - val_loss: 2.3928e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 8.1182e-05 - val_loss: 6.3738e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.9256e-05 - val_loss: 5.8542e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.8718e-05 - val_loss: 1.6271e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.9555e-05 - val_loss: 1.2873e-04\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8246e-05 - val_loss: 2.4816e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.0438e-05 - val_loss: 4.7195e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5882e-05 - val_loss: 9.3403e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.5431e-05 - val_loss: 1.6695e-04\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.4782e-05 - val_loss: 1.1846e-04\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.7047e-05 - val_loss: 6.0036e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0045e-05 - val_loss: 6.7237e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.1693e-05 - val_loss: 5.8782e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.0078e-05 - val_loss: 7.3437e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6192e-05 - val_loss: 5.0277e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.2521e-05 - val_loss: 4.2430e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.5203e-05 - val_loss: 9.6676e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 6.4870e-05 - val_loss: 4.4168e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9306e-05 - val_loss: 6.5615e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.7107e-05 - val_loss: 5.8802e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.1657e-05 - val_loss: 4.6561e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.6580e-05 - val_loss: 6.1087e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8156e-05 - val_loss: 2.7854e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.6663e-05 - val_loss: 7.7401e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.3454e-05 - val_loss: 4.6568e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.7254e-05 - val_loss: 8.6716e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9157e-05 - val_loss: 7.4528e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.8780e-05 - val_loss: 7.5030e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2117e-05 - val_loss: 4.9352e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.2427e-05 - val_loss: 5.5763e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.5793e-05 - val_loss: 5.9007e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 733us/step - loss: 5.0517e-05 - val_loss: 6.5477e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 727us/step - loss: 4.8326e-05 - val_loss: 8.6645e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 724us/step - loss: 5.8109e-05 - val_loss: 9.7361e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9653e-05 - val_loss: 4.8726e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.3258e-05 - val_loss: 7.8670e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.4892e-05 - val_loss: 6.5517e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.2525e-05 - val_loss: 6.9613e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7551e-05 - val_loss: 6.9543e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9453e-05 - val_loss: 4.0191e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0523e-05 - val_loss: 6.0609e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 4.7100e-05 - val_loss: 4.9800e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.9395e-05 - val_loss: 6.5337e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.2956e-05 - val_loss: 8.5682e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.3034e-05 - val_loss: 6.0834e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9770e-05 - val_loss: 6.0069e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 4.6305e-05 - val_loss: 4.6863e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.0446e-05 - val_loss: 1.0073e-04\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.1025e-05 - val_loss: 7.7034e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.2164e-05 - val_loss: 4.2201e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1856e-05 - val_loss: 6.4654e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.5720e-05 - val_loss: 6.1309e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9577e-05 - val_loss: 9.7451e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.5285e-05 - val_loss: 5.5501e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 4.6053e-05 - val_loss: 4.5231e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.4554e-05 - val_loss: 4.8365e-05\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.4994e-05 - val_loss: 5.0599e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 4.7252e-05 - val_loss: 4.3036e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9344e-05 - val_loss: 2.8430e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.3587e-05 - val_loss: 4.4487e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.5929e-05 - val_loss: 4.4223e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.4936e-05 - val_loss: 4.4408e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.6540e-05 - val_loss: 4.8350e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.0791e-05 - val_loss: 7.9975e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_55\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_55\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 7.4759e-05 - val_loss: 3.5567e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.8738e-05 - val_loss: 2.3537e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.1636e-05 - val_loss: 1.9311e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.3618e-05 - val_loss: 6.1196e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3621e-05 - val_loss: 6.3270e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.5080e-05 - val_loss: 4.2490e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.7678e-05 - val_loss: 5.7621e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9091e-05 - val_loss: 7.5632e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.9413e-05 - val_loss: 1.2834e-04\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.5515e-05 - val_loss: 4.0729e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9183e-05 - val_loss: 3.9724e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.2573e-05 - val_loss: 1.3689e-04\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.3803e-05 - val_loss: 1.4262e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9404e-05 - val_loss: 4.1962e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.0099e-05 - val_loss: 4.1682e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.7109e-05 - val_loss: 6.2873e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 8.8905e-05 - val_loss: 1.2624e-04\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.7475e-05 - val_loss: 4.1189e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.8636e-05 - val_loss: 7.6420e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.6623e-05 - val_loss: 1.0429e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.1850e-05 - val_loss: 3.8779e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.6926e-05 - val_loss: 4.5622e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.1515e-05 - val_loss: 6.7425e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.2161e-05 - val_loss: 3.8100e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.1430e-05 - val_loss: 5.5400e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.4285e-05 - val_loss: 4.9050e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.2593e-05 - val_loss: 4.8617e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.9470e-05 - val_loss: 9.3477e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3359e-05 - val_loss: 1.0017e-04\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.1932e-05 - val_loss: 4.3005e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.9302e-05 - val_loss: 5.1335e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4686e-05 - val_loss: 4.0889e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 5.7738e-05 - val_loss: 6.4900e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.7498e-05 - val_loss: 8.1750e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.1970e-05 - val_loss: 3.9832e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.5946e-05 - val_loss: 6.5695e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.7012e-05 - val_loss: 4.8754e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.5323e-05 - val_loss: 4.4042e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9050e-05 - val_loss: 5.4673e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.5055e-05 - val_loss: 9.8049e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.2751e-05 - val_loss: 4.8654e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.1992e-05 - val_loss: 3.6910e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.6134e-05 - val_loss: 4.1538e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 4.2258e-05 - val_loss: 6.3360e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 790us/step - loss: 4.6175e-05 - val_loss: 4.4337e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 786us/step - loss: 4.6660e-05 - val_loss: 4.2005e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 770us/step - loss: 5.1331e-05 - val_loss: 1.0300e-04\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 749us/step - loss: 5.0733e-05 - val_loss: 4.0122e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 762us/step - loss: 5.4942e-05 - val_loss: 7.6761e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 5.3404e-05 - val_loss: 5.1566e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.7723e-05 - val_loss: 6.1329e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 6.2625e-05 - val_loss: 4.3443e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 5.2908e-05 - val_loss: 3.8785e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 752us/step - loss: 4.9813e-05 - val_loss: 4.0738e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.8862e-05 - val_loss: 4.3914e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.0402e-05 - val_loss: 3.8212e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.4121e-05 - val_loss: 6.0327e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 3.9425e-05 - val_loss: 3.9790e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.5131e-05 - val_loss: 4.0132e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 769us/step - loss: 4.6575e-05 - val_loss: 6.9918e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 749us/step - loss: 4.4622e-05 - val_loss: 9.6641e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 753us/step - loss: 4.6052e-05 - val_loss: 4.0286e-05\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 4.7813e-05 - val_loss: 6.3544e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 5.4077e-05 - val_loss: 6.4035e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.4401e-05 - val_loss: 4.7635e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 759us/step - loss: 4.9131e-05 - val_loss: 4.4178e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_56\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_56\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0068 - val_loss: 0.0037\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 1.9176e-04 - val_loss: 0.0013\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 1.0301e-04 - val_loss: 2.8871e-04\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 8.0287e-05 - val_loss: 1.0136e-04\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 748us/step - loss: 6.9784e-05 - val_loss: 6.8581e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.1612e-05 - val_loss: 8.0087e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.1500e-05 - val_loss: 9.0261e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.2020e-05 - val_loss: 2.0575e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.8113e-05 - val_loss: 5.3737e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.8180e-05 - val_loss: 5.1108e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.8310e-05 - val_loss: 6.3317e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.3445e-05 - val_loss: 5.4415e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.8297e-05 - val_loss: 9.4897e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.2488e-05 - val_loss: 1.1028e-04\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.4472e-05 - val_loss: 4.9543e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 7.5854e-05 - val_loss: 5.4983e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.4268e-05 - val_loss: 6.2020e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.3096e-05 - val_loss: 7.7714e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 8.7271e-05 - val_loss: 5.2411e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.3238e-05 - val_loss: 6.0314e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.0270e-05 - val_loss: 1.9004e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.6507e-05 - val_loss: 4.4074e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.0223e-05 - val_loss: 4.8088e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.9212e-05 - val_loss: 6.7687e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.1882e-05 - val_loss: 1.0956e-04\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.9440e-05 - val_loss: 4.4366e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.9984e-05 - val_loss: 4.1146e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.3783e-05 - val_loss: 4.6175e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 7.6590e-05 - val_loss: 1.5657e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.7372e-05 - val_loss: 4.2363e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.3840e-05 - val_loss: 1.0486e-04\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5085e-05 - val_loss: 7.9849e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.1011e-05 - val_loss: 5.2751e-05\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.4387e-05 - val_loss: 9.5376e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 734us/step - loss: 5.7570e-05 - val_loss: 5.0277e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 5.5349e-05 - val_loss: 4.1524e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.5559e-05 - val_loss: 1.7093e-04\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.9932e-05 - val_loss: 5.3842e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.1095e-05 - val_loss: 3.9120e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 718us/step - loss: 5.4147e-05 - val_loss: 1.3110e-04\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.4088e-05 - val_loss: 5.7861e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.2031e-05 - val_loss: 1.1060e-04\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.4108e-05 - val_loss: 4.0176e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.7560e-05 - val_loss: 9.1825e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0708e-05 - val_loss: 3.8368e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.5795e-05 - val_loss: 7.0511e-05\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.4167e-05 - val_loss: 3.9069e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.3796e-05 - val_loss: 5.2854e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.5570e-05 - val_loss: 4.7989e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 5.5613e-05 - val_loss: 6.0255e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 4.9813e-05 - val_loss: 1.5358e-04\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.4734e-05 - val_loss: 1.2960e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.2359e-05 - val_loss: 1.1582e-04\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 5.1037e-05 - val_loss: 1.7966e-04\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.8282e-05 - val_loss: 9.6153e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.4626e-05 - val_loss: 5.5769e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 717us/step - loss: 4.3752e-05 - val_loss: 4.6254e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 808us/step - loss: 5.2388e-05 - val_loss: 1.4738e-04\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.0150e-05 - val_loss: 8.3614e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3144e-05 - val_loss: 5.0517e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.0254e-05 - val_loss: 6.2999e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0275e-05 - val_loss: 3.9343e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.2881e-05 - val_loss: 1.5309e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4867e-05 - val_loss: 4.1491e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.4542e-05 - val_loss: 4.8223e-05\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.2948e-05 - val_loss: 1.8092e-04\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.1747e-05 - val_loss: 8.5888e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.4756e-05 - val_loss: 1.4340e-04\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.1967e-05 - val_loss: 5.5891e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_57\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_57\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 5.6438e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4726e-05 - val_loss: 1.2919e-04\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.2427e-05 - val_loss: 4.8533e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8247e-05 - val_loss: 4.4645e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.7885e-05 - val_loss: 6.8232e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3222e-05 - val_loss: 7.2637e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.5449e-05 - val_loss: 8.1082e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.5106e-05 - val_loss: 1.4608e-04\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.8691e-05 - val_loss: 4.1802e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.2822e-05 - val_loss: 6.6303e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7006e-05 - val_loss: 5.1713e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 5.8252e-05 - val_loss: 4.4243e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.6676e-05 - val_loss: 9.6510e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.6840e-05 - val_loss: 5.5330e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5524e-05 - val_loss: 4.4866e-05\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7012e-05 - val_loss: 1.3775e-04\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 7.1093e-05 - val_loss: 1.0397e-04\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9986e-05 - val_loss: 5.2195e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3028e-05 - val_loss: 9.2571e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 6.2214e-05 - val_loss: 1.3876e-04\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4433e-05 - val_loss: 1.0475e-04\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 5.8267e-05 - val_loss: 4.8232e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.7276e-05 - val_loss: 5.9543e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.3292e-05 - val_loss: 5.1396e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0836e-05 - val_loss: 5.8173e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.5576e-05 - val_loss: 4.1349e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 718us/step - loss: 5.1685e-05 - val_loss: 4.2686e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8508e-05 - val_loss: 4.6629e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.1516e-05 - val_loss: 1.1090e-04\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 713us/step - loss: 5.8968e-05 - val_loss: 3.9126e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7624e-05 - val_loss: 8.9202e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0717e-05 - val_loss: 5.8321e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.2078e-05 - val_loss: 1.1241e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.0259e-05 - val_loss: 5.1425e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4686e-05 - val_loss: 6.1890e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7380e-05 - val_loss: 6.5365e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.4476e-05 - val_loss: 4.0501e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 704us/step - loss: 4.5578e-05 - val_loss: 3.9369e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 713us/step - loss: 5.1280e-05 - val_loss: 5.0744e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.0527e-05 - val_loss: 9.4851e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 5.0372e-05 - val_loss: 5.3557e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 4.9096e-05 - val_loss: 9.0632e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.6343e-05 - val_loss: 5.0589e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 5.2419e-05 - val_loss: 4.3884e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 4.3180e-05 - val_loss: 5.2049e-05\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.6930e-05 - val_loss: 1.1165e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.9094e-05 - val_loss: 3.9191e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 5.4705e-05 - val_loss: 5.9426e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.3550e-05 - val_loss: 8.9827e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8144e-05 - val_loss: 6.1625e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 713us/step - loss: 5.1838e-05 - val_loss: 5.9835e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.5699e-05 - val_loss: 5.6751e-05\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7436e-05 - val_loss: 5.8704e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9797e-05 - val_loss: 3.9292e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_58\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_58\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "183/183 [==============================] - 1s 1ms/step - loss: 0.0047 - val_loss: 1.9869e-04\n",
      "Epoch 2/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 7.2052e-05 - val_loss: 8.4082e-05\n",
      "Epoch 3/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.1729e-05 - val_loss: 6.3352e-05\n",
      "Epoch 4/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.2486e-05 - val_loss: 6.2067e-05\n",
      "Epoch 5/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.8913e-05 - val_loss: 6.0648e-05\n",
      "Epoch 6/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.5128e-05 - val_loss: 6.4410e-05\n",
      "Epoch 7/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.6801e-05 - val_loss: 6.5814e-05\n",
      "Epoch 8/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.4490e-05 - val_loss: 5.9483e-05\n",
      "Epoch 9/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.6889e-05 - val_loss: 9.9104e-05\n",
      "Epoch 10/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.3823e-05 - val_loss: 5.5721e-05\n",
      "Epoch 11/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7504e-05 - val_loss: 7.0345e-05\n",
      "Epoch 12/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.4927e-05 - val_loss: 4.9346e-05\n",
      "Epoch 13/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.7940e-05 - val_loss: 4.8569e-05\n",
      "Epoch 14/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.3132e-05 - val_loss: 5.9197e-05\n",
      "Epoch 15/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.7315e-05 - val_loss: 1.0530e-04\n",
      "Epoch 16/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.6982e-05 - val_loss: 5.0613e-05\n",
      "Epoch 17/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.8589e-05 - val_loss: 5.1052e-05\n",
      "Epoch 18/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.5304e-05 - val_loss: 5.0383e-05\n",
      "Epoch 19/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.7937e-05 - val_loss: 7.3390e-05\n",
      "Epoch 20/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.6528e-05 - val_loss: 4.8971e-05\n",
      "Epoch 21/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.8927e-05 - val_loss: 8.9714e-05\n",
      "Epoch 22/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.6974e-05 - val_loss: 9.6160e-05\n",
      "Epoch 23/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 6.2594e-05 - val_loss: 6.6074e-05\n",
      "Epoch 24/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.8144e-05 - val_loss: 6.5421e-05\n",
      "Epoch 25/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.8888e-05 - val_loss: 5.0860e-05\n",
      "Epoch 26/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.7157e-05 - val_loss: 4.2169e-05\n",
      "Epoch 27/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.6528e-05 - val_loss: 8.5383e-05\n",
      "Epoch 28/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.6071e-05 - val_loss: 5.4192e-05\n",
      "Epoch 29/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.4036e-05 - val_loss: 5.4229e-05\n",
      "Epoch 30/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 7.9672e-05 - val_loss: 9.6590e-05\n",
      "Epoch 31/2000\n",
      "183/183 [==============================] - 0s 737us/step - loss: 6.4431e-05 - val_loss: 5.0581e-05\n",
      "Epoch 32/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.6840e-05 - val_loss: 8.7288e-05\n",
      "Epoch 33/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.4908e-05 - val_loss: 2.2142e-04\n",
      "Epoch 34/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.3564e-05 - val_loss: 5.6115e-05\n",
      "Epoch 35/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.9595e-05 - val_loss: 4.6105e-05\n",
      "Epoch 36/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.1072e-05 - val_loss: 4.6253e-05\n",
      "Epoch 37/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.0646e-05 - val_loss: 6.7026e-05\n",
      "Epoch 38/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 5.5610e-05 - val_loss: 9.4545e-05\n",
      "Epoch 39/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.9215e-05 - val_loss: 9.4270e-05\n",
      "Epoch 40/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.7961e-05 - val_loss: 8.4667e-05\n",
      "Epoch 41/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.9950e-05 - val_loss: 5.7962e-05\n",
      "Epoch 42/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.4686e-05 - val_loss: 4.9908e-05\n",
      "Epoch 43/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.1591e-05 - val_loss: 4.2975e-05\n",
      "Epoch 44/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.3449e-05 - val_loss: 5.7132e-05\n",
      "Epoch 45/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.6863e-05 - val_loss: 1.6026e-04\n",
      "Epoch 46/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 6.0858e-05 - val_loss: 2.7495e-04\n",
      "Epoch 47/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.4197e-05 - val_loss: 6.4442e-05\n",
      "Epoch 48/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8797e-05 - val_loss: 5.2279e-05\n",
      "Epoch 49/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3865e-05 - val_loss: 3.9252e-05\n",
      "Epoch 50/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3632e-05 - val_loss: 4.4221e-05\n",
      "Epoch 51/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.2269e-05 - val_loss: 3.9953e-05\n",
      "Epoch 52/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.3827e-05 - val_loss: 1.3539e-04\n",
      "Epoch 53/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.8339e-05 - val_loss: 6.0254e-05\n",
      "Epoch 54/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.7980e-05 - val_loss: 5.1114e-05\n",
      "Epoch 55/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.6934e-05 - val_loss: 4.3063e-05\n",
      "Epoch 56/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.5611e-05 - val_loss: 5.1345e-05\n",
      "Epoch 57/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.5740e-05 - val_loss: 3.9942e-05\n",
      "Epoch 58/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 6.2905e-05 - val_loss: 4.7745e-05\n",
      "Epoch 59/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 6.0759e-05 - val_loss: 7.1339e-05\n",
      "Epoch 60/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.5853e-05 - val_loss: 3.8927e-05\n",
      "Epoch 61/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.3398e-05 - val_loss: 7.2319e-05\n",
      "Epoch 62/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 5.0476e-05 - val_loss: 5.3213e-05\n",
      "Epoch 63/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 5.0320e-05 - val_loss: 1.0150e-04\n",
      "Epoch 64/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.3322e-05 - val_loss: 5.9420e-05\n",
      "Epoch 65/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.4641e-05 - val_loss: 1.3513e-04\n",
      "Epoch 66/2000\n",
      "183/183 [==============================] - 0s 718us/step - loss: 4.8207e-05 - val_loss: 5.8370e-05\n",
      "Epoch 67/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.7211e-05 - val_loss: 4.0353e-05\n",
      "Epoch 68/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 5.2058e-05 - val_loss: 4.0883e-05\n",
      "Epoch 69/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.3862e-05 - val_loss: 5.6974e-05\n",
      "Epoch 70/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.6547e-05 - val_loss: 1.0230e-04\n",
      "Epoch 71/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 6.0422e-05 - val_loss: 7.1696e-05\n",
      "Epoch 72/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7125e-05 - val_loss: 6.6381e-05\n",
      "Epoch 73/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 4.5067e-05 - val_loss: 1.5680e-04\n",
      "Epoch 74/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.9054e-05 - val_loss: 5.9323e-05\n",
      "Epoch 75/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.4405e-05 - val_loss: 4.6175e-05\n",
      "Epoch 76/2000\n",
      "183/183 [==============================] - 0s 730us/step - loss: 4.7841e-05 - val_loss: 5.9776e-05\n",
      "Epoch 77/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 4.7486e-05 - val_loss: 3.9812e-05\n",
      "Epoch 78/2000\n",
      "183/183 [==============================] - 0s 742us/step - loss: 4.4715e-05 - val_loss: 4.6657e-05\n",
      "Epoch 79/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 4.6406e-05 - val_loss: 6.6244e-05\n",
      "Epoch 80/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.6486e-05 - val_loss: 5.5509e-05\n",
      "Epoch 81/2000\n",
      "183/183 [==============================] - 0s 709us/step - loss: 5.2917e-05 - val_loss: 7.8158e-05\n",
      "Epoch 82/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.5000e-05 - val_loss: 4.7144e-05\n",
      "Epoch 83/2000\n",
      "183/183 [==============================] - 0s 719us/step - loss: 5.2288e-05 - val_loss: 3.8322e-05\n",
      "Epoch 84/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.0959e-05 - val_loss: 4.2350e-05\n",
      "Epoch 85/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6782e-05 - val_loss: 4.1666e-05\n",
      "Epoch 86/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 5.5651e-05 - val_loss: 1.4748e-04\n",
      "Epoch 87/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.4414e-05 - val_loss: 8.2166e-05\n",
      "Epoch 88/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.2082e-05 - val_loss: 7.0727e-05\n",
      "Epoch 89/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.5261e-05 - val_loss: 4.1433e-05\n",
      "Epoch 90/2000\n",
      "183/183 [==============================] - 0s 714us/step - loss: 4.4768e-05 - val_loss: 4.2241e-05\n",
      "Epoch 91/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 5.2918e-05 - val_loss: 8.7533e-05\n",
      "Epoch 92/2000\n",
      "183/183 [==============================] - 0s 763us/step - loss: 5.0552e-05 - val_loss: 8.2711e-05\n",
      "Epoch 93/2000\n",
      "183/183 [==============================] - 0s 725us/step - loss: 3.8480e-05 - val_loss: 3.8139e-05\n",
      "Epoch 94/2000\n",
      "183/183 [==============================] - 0s 723us/step - loss: 4.8468e-05 - val_loss: 5.2618e-05\n",
      "Epoch 95/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3669e-05 - val_loss: 4.2943e-05\n",
      "Epoch 96/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3342e-05 - val_loss: 5.7412e-05\n",
      "Epoch 97/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.2441e-05 - val_loss: 6.9758e-05\n",
      "Epoch 98/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.7603e-05 - val_loss: 1.1868e-04\n",
      "Epoch 99/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 5.1108e-05 - val_loss: 4.0916e-05\n",
      "Epoch 100/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 3.9308e-05 - val_loss: 6.0981e-05\n",
      "Epoch 101/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.2719e-05 - val_loss: 6.5065e-05\n",
      "Epoch 102/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.8599e-05 - val_loss: 4.0068e-05\n",
      "Epoch 103/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.9903e-05 - val_loss: 9.9056e-05\n",
      "Epoch 104/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.5926e-05 - val_loss: 5.4263e-05\n",
      "Epoch 105/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.3156e-05 - val_loss: 1.5200e-04\n",
      "Epoch 106/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.7409e-05 - val_loss: 5.8460e-05\n",
      "Epoch 107/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.5208e-05 - val_loss: 1.0017e-04\n",
      "Epoch 108/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.3130e-05 - val_loss: 4.5902e-05\n",
      "Epoch 109/2000\n",
      "183/183 [==============================] - 0s 781us/step - loss: 4.1760e-05 - val_loss: 9.5236e-05\n",
      "Epoch 110/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.6292e-05 - val_loss: 6.4506e-05\n",
      "Epoch 111/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.0395e-05 - val_loss: 4.4948e-05\n",
      "Epoch 112/2000\n",
      "183/183 [==============================] - 0s 731us/step - loss: 4.2032e-05 - val_loss: 9.4061e-05\n",
      "Epoch 113/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.4549e-05 - val_loss: 6.0561e-05\n",
      "Epoch 114/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.0584e-05 - val_loss: 4.6922e-05\n",
      "Epoch 115/2000\n",
      "183/183 [==============================] - 0s 726us/step - loss: 4.3839e-05 - val_loss: 8.6055e-05\n",
      "Epoch 116/2000\n",
      "183/183 [==============================] - 0s 720us/step - loss: 4.5848e-05 - val_loss: 5.3730e-05\n",
      "Epoch 117/2000\n",
      "183/183 [==============================] - 0s 715us/step - loss: 4.5403e-05 - val_loss: 3.8599e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_59\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_59\\assets\n"
     ]
    }
   ],
   "source": [
    "trainInputX = trainX\n",
    "trainInputY = trainY\n",
    "testInputX = testX\n",
    "testInputY = testY\n",
    "print(trainInputX.shape)\n",
    "print(trainInputY.shape)\n",
    "print(testInputX.shape)\n",
    "print(testInputY.shape)\n",
    "\n",
    "#validacao tamanho apos tratamentos\n",
    "print(len(trainX))\n",
    "print(len(trainInputX))\n",
    "\n",
    "print(len(trainY))\n",
    "print(len(trainInputY))\n",
    "\n",
    "trainInputX = trainInputX [:,0:14]\n",
    "testInputX = testInputX [:,0:14]\n",
    "print(trainInputX.shape)\n",
    "\n",
    "trained_models_MLP = []\n",
    "trained_models_MLP_history = []\n",
    "\n",
    "for i in range(0,60):\n",
    "\n",
    "    #giving it reproducibility\n",
    "    seed = (i+1000)\n",
    "\n",
    "    os.environ['PYTHONHASHseed']=str(seed)\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    batch_size = 64\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=24)\n",
    "    \n",
    "    trained_models_MLP.append(kr.Sequential())\n",
    "    # rnn_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(14))\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(32))\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(32))\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(32))\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(8))\n",
    "    # rnn_model.add(kr.layers.SimpleRNN(5,input_shape=(trainInputX.shape[1],trainInputX.shape[2])))\n",
    "    # rnn_model.add(kr.layers.BatchNormalization())\n",
    "    trained_models_MLP[i].add(kr.layers.Dense(1))\n",
    "    trained_models_MLP[i].compile(loss='mean_squared_error',optimizer='adam')\n",
    "    \n",
    "    trained_models_MLP_history.append(trained_models_MLP[i].fit(trainInputX, trainInputY, epochs=2000, batch_size=batch_size, verbose = 1, validation_data=(testInputX,testInputY), callbacks=[callback]))\n",
    "    \n",
    "    trained_models_MLP[i].save('C:/Users/guilh/PythonCodes/Models/MLP_predicting1ahead_param_14_32_32_32_8_batch_256_earlystop_valloss_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b413ac58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
